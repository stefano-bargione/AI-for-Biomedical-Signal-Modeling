{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "029e10be-3ece-48b6-b343-445339550478",
   "metadata": {},
   "source": [
    "# Deep Learning Analyses - Motor Intention Decoding from 2D EEG Data Formulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671113ad-5981-40e5-a706-68ab507fdb41",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b18f97-c284-46e6-80e1-8e7325c21bd9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Dataset Infos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1506e694-970e-4aaf-ad73-a20933c59f56",
   "metadata": {},
   "source": [
    "Esatto, quello che stai guardando – EEGMMIDB_Curated.mat – è il “contenitore” principale già pronto all’uso:\n",
    "\n",
    "all’interno del file .mat non troverai tante sottocartelle sul disco, ma una struttura MATLAB chiamata EEGMMIDB con questi campi:\n",
    "\n",
    "matlab\n",
    "\n",
    "EEGMMIDB\n",
    "├─ Frequency          % 160 Hz\n",
    "├─ Subjects           % mappa vecchi→nuovi ID (103 soggetti)\n",
    "├─ Signal             % 103 celle: Subject_1_Signal … Subject_103_Signal\n",
    "└─ Annotations        % 103 celle: Subject_1_Annotations … Subject_103_Annotations\n",
    "\n",
    "\n",
    "Ogni cella Subject_x_Signal contiene 12 matrici (una per run); lo stesso vale per Annotations. \n",
    "Quindi i dati di tutti i soggetti e di tutte le run sono già organizzati lì dentro, non in singole cartelle. \n",
    "\n",
    "\n",
    "Il paper spiega che, oltre al .mat, esiste anche la versione CSV compressa in un archivio WinRAR: eegmmidb.rar, con 2 472 file chiamati\n",
    "SUB_[sss]_SIG_[rr].csv e SUB_[sss]_ANN_[rr].csv (uno per segnale, uno per annotazioni, 12×103 soggetti). \n",
    "PMC\n",
    "\n",
    "Nel tuo zip hai effettivamente:\n",
    "\n",
    "vbnet\n",
    "\n",
    "Physionet EEGMMIDB in MATLAB structure and CSV files to leverage accessibility and exploitation/\n",
    "├─ MATLAB structure/EEGMMIDB_Curated.mat\n",
    "└─ CSV files/eegmmidb.rar          ← qui dentro ci sono tutti i CSV\n",
    "\n",
    "\n",
    "\n",
    "Cosa fare adesso\n",
    "Se ti basta lavorare in Python o MATLAB direttamente sul .mat:\n",
    "In Jupyter puoi caricarlo così:\n",
    "\n",
    "python\n",
    "Copia\n",
    "Modifica\n",
    "import scipy.io as sio\n",
    "data = sio.loadmat('EEGMMIDB/Physionet ... /MATLAB structure/EEGMMIDB_Curated.mat',\n",
    "                   simplify_cells=True)   # opzionale, per avere dict “puliti”\n",
    "\n",
    "print(data.keys())        # ['EEGMMIDB']\n",
    "sig   = data['EEGMMIDB']['Signal']        # lista di 103 soggetti\n",
    "ann   = data['EEGMMIDB']['Annotations']   # idem\n",
    "Da lì estrai run, epoche, ecc. senza bisogno di altri file.\n",
    "\n",
    "Se vuoi anche i CSV (utile per pipeline Pandas, MNE, ecc.):\n",
    "\n",
    "bash\n",
    "\n",
    "#Crea una cartella d’uscita\n",
    "mkdir -p EEGMMIDB/csv\n",
    "\n",
    "#Estrai con 7‑Zip (più robusto degli spazi): metti il percorso tra virgolette\n",
    "7z x \"EEGMMIDB/Physionet EEGMMIDB in MATLAB structure and CSV files to leverage accessibility and exploitation/CSV files/eegmmidb.rar\" \\\n",
    "   -oEEGMMIDB/csv\n",
    "   \n",
    "In alternativa, dopo aver installato unrar:\n",
    "\n",
    "bash\n",
    "Copia\n",
    "Modifica\n",
    "unrar x \"…/eegmmidb.rar\"  EEGMMIDB/csv/\n",
    "Finirai con tutti i file SUB_001_SIG_01.csv, SUB_001_ANN_01.csv, … fino a SUB_103_ANN_12.csv.\n",
    "\n",
    "Riassumendo\n",
    ".mat → unica struttura già indicizzata per soggetto/run: subito pronta per la decodifica.\n",
    "\n",
    ".rar → stessa informazione ma in tanti CSV; estraila solo se ti serve un formato tabellare.\n",
    "\n",
    "Scegli la via più comoda per la tua pipeline (Python + scipy/io per il .mat, oppure Pandas/MNE sui CSV)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ee8e7a-177a-4f18-a9e8-c235800b2e4b",
   "metadata": {},
   "source": [
    "### EEGMMIDB Dataset EEG (link for papers e dataset)\n",
    "\n",
    "Link Paper Dataset: https://pmc.ncbi.nlm.nih.gov/articles/PMC10998040/pdf/main.pdf\n",
    "\n",
    "Link Curated Dataset: https://data.mendeley.com/datasets/dpmtgrn8d8\n",
    "\n",
    "Link Original Dataset: https://physionet.org/content/eegmmidb/1.0.0/\n",
    "\n",
    "Link EEG Cap Distribution: https://physionet.org/content/eegmmidb/1.0.0/64_channel_sharbrough.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e72a61-0f3c-4c5d-8b69-4e18fd9eb0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5c885e-f031-48ca-9fee-afbfcefdfa42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "raw = mne.io.read_raw_edf('/home/stefano/EEGMMIDB_Analyses/S001R01.edf', preload=False)\n",
    "print(raw.ch_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eac4a59-b0ce-4ea4-8330-48a30ce4c5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "EEG_channels_names = raw.ch_names"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e8cc0c06-b68a-4479-95bc-7a0596fd4355",
   "metadata": {},
   "source": [
    "type(channels_names)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "83b29d17-98ad-401b-8666-9b8f7a148d5d",
   "metadata": {},
   "source": [
    "# supponendo che EEG_channels_names sia la tua lista originale\n",
    "clean_names = [ch.rstrip('.') for ch in EEG_channels_names]\n",
    "\n",
    "print(clean_names)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8f66b30c-0fd6-4c75-8c41-b119cd60825e",
   "metadata": {},
   "source": [
    "import pickle\n",
    "\n",
    "# Salvare l'intero dizionario annidato con pickle\n",
    "path = '/home/stefano/EEGMMIDB_Analyses/'\n",
    "\n",
    "with open(f'{path}EEG_channels_names.pkl', 'wb') as f:\n",
    "    pickle.dump(EEG_channels_names, f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6179b7c-d50b-4bef-bed1-ff3d18eee299",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Library Importing \n",
    "    \n",
    "import os\n",
    "import math\n",
    "import copy as cp \n",
    "\n",
    "import tqdm\n",
    "\n",
    "import mne \n",
    "import scipy\n",
    "\n",
    "import numpy as np  # NumPy per operazioni numeriche\n",
    "import matplotlib.pyplot as plt  # Matplotlib per la isualizzazione dei dati\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#import torch\n",
    "#import torch.nn as nn\n",
    "\n",
    "#import torch.optim as optim\n",
    "#from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc36d9e-4e55-4433-b92c-5c0518c852e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "EEG_path = '/home/stefano/EEGMMIDB/Physionet EEGMMIDB in MATLAB structure and CSV files to leverage accessibility and exploitation'\n",
    "matlab_files = 'MATLAB structure/EEGMMIDB_Curated.mat'\n",
    "\n",
    "mat_path = os.path.join(EEG_path, matlab_files)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "158df0f9-f238-4741-b808-2960adf8ba84",
   "metadata": {},
   "source": [
    "import scipy.io as sio\n",
    "data = sio.loadmat(mat_path,\n",
    "                   simplify_cells = True)   # opzionale, per avere dict “puliti”\n",
    "\n",
    "print(data.keys())        # ['EEGMMIDB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1892a758-fecf-4a93-a54a-e1c79452391a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Il risultato (sig, ann, ecc.) è esattamente quello che avresti avuto con simplify_cells=True:\n",
    "liste native Python / array NumPy, niente mat_struct o object arrays.\n",
    "'''\n",
    "\n",
    "import mat73\n",
    "\n",
    "data = mat73.loadmat(mat_path)   # ← già “semplificato\" dict principale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a342dcff-ca0e-442c-b4a7-af94349e76af",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463fa3e0-8f75-487d-af0a-05de0004ac2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.keys())\n",
    "print(data['EEGMMIDB'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4cbfac2-6054-4515-9e2c-2d2ae232d196",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['EEGMMIDB'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57dc5c5-e326-41ae-90ba-6555aed7a72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(data['EEGMMIDB']['Annotations']))\n",
    "print(type(data['EEGMMIDB']['Annotations']))\n",
    "print(type(data['EEGMMIDB']['Signal']))\n",
    "print(type(data['EEGMMIDB']['Subjects']))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f9cedaac-e2e5-40d7-a350-c4ffd6bc2456",
   "metadata": {},
   "source": [
    "import pickle\n",
    "\n",
    "# Salvare l'intero dizionario annidato con pickle\n",
    "path = '/home/stefano/EEGMMIDB_Analyses/'\n",
    "\n",
    "with open(f'{path}EEG_data.pkl', 'wb') as f:\n",
    "    pickle.dump(data, f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b121ed4-004c-4d7c-8b02-c7366e71b02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Caricare l'intero dizionario annidato con pickle\n",
    "path = '/home/stefano/EEGMMIDB_Analyses/'\n",
    "\n",
    "# Caricare l'intero dizionario annidato con pickle\n",
    "with open(f'{path}EEG_data.pkl', 'rb') as f:\n",
    "    EEG_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9cbcca-8952-40ca-81db-ff258d6f7691",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(EEG_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085926de-c39c-4f81-bd27-18b57c98715e",
   "metadata": {},
   "outputs": [],
   "source": [
    "EEG_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c6e048-1df5-4a5c-8805-52eccb89e2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "EEG_data['EEGMMIDB'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7596b3d1-2267-4933-acc4-d68259ed7ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "signal  = EEG_data['EEGMMIDB']['Signal']                 # lista (len=103) di soggetti\n",
    "labels  = EEG_data['EEGMMIDB']['Annotations']            # idem\n",
    "fs      = EEG_data['EEGMMIDB']['Frequency']              # 160\n",
    "subject_ids = EEG_data['EEGMMIDB']['Subjects']           # mapping vecchi→nuovi ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7c18b6-b734-486f-a7a5-bfd3d170b97c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Exploratory Data Analysis: Inspection EEG Dataset Organization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcbbc1f-4cde-4608-b12d-5c94c5a31510",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb6698c-c732-4ca5-8971-1a9bb8fe9eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0352bde-7a37-483d-96fe-af6ce3782546",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(signal[0]))\n",
    "print(len(signal[1]))\n",
    "print()\n",
    "print('... e così via per 12 indici')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00df85d-f5f9-47f5-b2aa-61fba0bcdce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(signal[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f31fe1-d929-412d-ae07-8f4ab7482d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(signal[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73545752-2534-4200-b36c-cfbd1d590300",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "signal[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca50059-7ba5-4f1a-a59b-6fb31b344e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(signal[0]['Subject_100_Signal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a85a04-0511-4572-b2e2-08beed3a76f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(signal[0]['Subject_100_Signal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89eeb0e2-fcbc-4ab2-953c-f0a7eb549e92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "signal[0]['Subject_100_Signal'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8175ce-48e9-44b7-ac29-62ded37931c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Le strutture di Signal è una struttura così composta\n",
    "\n",
    "Signal -> lista di 12 elementi, ciascuna riferita ai dati di una certa run.\n",
    "        \n",
    "        -> Ogni elemento (ogni run) contiene i dati di una certa run di tutti e 103 i soggetti\n",
    "        \n",
    "            -> Per accedere ai dati di una specifica run di uno specifico soggetto (contenuti dentro una lista -> len(signal[0]) = 103)\n",
    "                bisogna indicare una specifica chiave relativa ad un dizionario dello specifico soggetto (i.e., type(signal[0]) --> dict)\n",
    "            \n",
    "                --> ESEMPIO: signal[0]['Subject_100_Signal']\n",
    "                \n",
    "                    --> Dentro al dizionario di una run di uno specifico soggetto, c'è una lista \n",
    "                        (i.e., type(signal[0]['Subject_100_Signal']) = list), \n",
    "                        \n",
    "                        Composta di un elemento solo \n",
    "                        (i.e., len(signal[0]['Subject_100_Signal']) = 1)\n",
    "                        \n",
    "                        --> Per accedere proprio all'array dei dati, devi indicizzare ulteriormente \n",
    "                            \n",
    "                            signal[0]['Subject_100_Signal'][0].shape = (19680, 64)\n",
    "                        \n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "print(type(signal))\n",
    "print()\n",
    "print(type(signal[0]))\n",
    "print()\n",
    "print(signal[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8164845-b7b5-4c38-b93e-cbc3063842e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Questo contiene la lista dei valori credo della run del relativo soggetto...\n",
    "print(type(signal[0]['Subject_100_Signal']))\n",
    "print()\n",
    "print(type(labels[0]['Subject_100_Annotations']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622a0493-12b8-440a-8896-f30dfea16e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Questo valore dovrebbe corrispondere al numero di campioni dell'intera run di 2 minuti descritta dal paper...\n",
    "\n",
    "#https://pmc.ncbi.nlm.nih.gov/articles/PMC10998040/pdf/main.pdf\n",
    "\n",
    "\n",
    "print(len(signal[0]['Subject_100_Signal'][0]))\n",
    "print()\n",
    "print(len(labels[0]['Subject_100_Annotations'][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751d2a7c-f345-4e01-afa8-8e8d6119aafa",
   "metadata": {},
   "source": [
    "Hai quasi centrato il punto, ma non è esattamente un “errore” – è solo che il file che stai caricando contiene qualche secondo in più \n",
    "oltre ai 120 s previsti dal protocollo.\n",
    "\n",
    "<br>\n",
    "\n",
    "**Cosa dice il paper (e la documentazione originale)**\n",
    "\n",
    "\n",
    "| Fonte | Campionamento | Durata (nominale/effettiva) | # campioni |\n",
    "|-------|---------------|-----------------------------|------------|\n",
    "| Paper di curation, Tab. 1 (PMC) | 160 Hz | 2 min (= 120 s) | 160 × 120 = 19 200 |\n",
    "| Scheda del dataset su PhysioNet (physionet.org) | 160 Hz | “two‑minute runs” | 19 200 |\n",
    "| Quello che vedi tu | 160 Hz | 123 s (≈ 2 min + 3 s) | 19 680 |\n",
    "\n",
    "<br>\n",
    "\n",
    "**Da dove arrivano quei 3 secondi?**\n",
    "\n",
    "Nei file EDF originali il sistema BCI2000 lascia un piccolo buffer prima che appaia il primo target e dopo la scomparsa dell’ultimo \n",
    "(tipicamente 1–2 s all’inizio + 1 s alla fine).\n",
    "\n",
    "Gli autori della curation non li hanno tagliati: in Fig. 5 del paper si vede infatti che la “Total length of each run” spesso \n",
    "supera la durata indicata nelle annotazioni .\n",
    "\n",
    "<br>\n",
    "\n",
    "**Quindi la risposta alla tua domanda**\n",
    "«…dovrebbe corrispondere al numero di campioni dell’intera run di 2 minuti descritta dal paper.. giusto?»\n",
    "\n",
    "In teoria la run “utile” è di 19 200 campioni.\n",
    "\n",
    "In pratica il file che hai in RAM contiene anche il buffer, perciò trovi 19 680 campioni.\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "**Come gestirlo**\n",
    "\n",
    "fs = 160          # Hz\n",
    "run_nominale = 120\n",
    "n_teorico = fs * run_nominale            # 19200\n",
    "n_osservato = 19680\n",
    "extra = n_osservato - n_teorico          # 480 campioni ≈ 3 s\n",
    "\n",
    "#Se vuoi esattamente 2 minuti:\n",
    "trim = extra // 2                        # 240 campioni da tagliare all’inizio e alla fine\n",
    "clean_run = raw_signal[trim:-trim]       # shape: (19200, 64)\n",
    "Usa le annotazioni (T0/T1/T2) se vuoi essere sicuro di includere solo le prove effettive; taglia pure di conseguenza invece di assumere sempre 240 campioni.\n",
    "\n",
    "Così il tuo array avrà davvero **19 200 campioni**, coerenti con quanto scritto nel paper."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406d1272-d721-43e3-95de-b6d1f7cb6d39",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Info delle Runs del Dataset EEG"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7d418ad3-898b-444c-840e-8104982c3f01",
   "metadata": {
    "tags": []
   },
   "source": [
    "Se vuoi vedere lo screenshot anche copia ed incolla questo codice\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "**Fonte: Tabella 2 “Dataset run specifications” del paper, colonna “Curated dataset … Run file number”**\n",
    "\n",
    "<br>\n",
    "\n",
    "markdown ![Run mapping](run_map.png)\n",
    "\n",
    "<br>\n",
    "\n",
    "markdown ![Run mapping](run_specifications.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5313d6e9-107f-483c-b2ce-9824240e99b8",
   "metadata": {},
   "source": [
    "Di seguito trovi la mappa “ufficiale” che il paper (Tabella 2) assegna ai 12 run curati.\n",
    "\n",
    "Nel tuo array signal[subj][run_idx] (e in labels), l’indice Python run_idx va da 0 a 11 e corrisponde esattamente\n",
    "ai numeri di run 1 – 12 indicati nella colonna più a destra della tabella.\n",
    "\n",
    "\n",
    "| run_idx (Python) | # run curato | TASK                                                                       | Modalità | Tipo mov.   | Classi presenti nel run (T0, T1, T2)                   |\n",
    "|------------------|--------------|----------------------------------------------------------------------------|----------|-------------|--------------------------------------------------------|\n",
    "| 0                | 1            | Motor **Execution** – “open/close *unilateral* fist”                        | ME       | Unilaterale | Relax · **Left fist** · **Right fist**                 |\n",
    "| 1                | 2            | idem (2ᵃ ripetizione)                                                      | ME       | Unil.       | Relax · Left fist · Right fist                         |\n",
    "| 2                | 3            | idem (3ᵃ ripetizione)                                                      | ME       | Unil.       | Relax · Left fist · Right fist                         |\n",
    "| 3                | 4            | Motor **Imagery** – “imagine open/close *unilateral* fist”                  | MI       | Unil.       | Relax · Left fist · Right fist                         |\n",
    "| 4                | 5            | idem (2ᵃ)                                                                  | MI       | Unil.       | Relax · Left fist · Right fist                         |\n",
    "| 5                | 6            | idem (3ᵃ)                                                                  | MI       | Unil.       | Relax · Left fist · Right fist                         |\n",
    "| 6                | 7            | Motor **Execution** – “open/close *bilateral* fists & feet”                 | ME       | Bilat.      | Relax · **Both fists** · **Both feet**                |\n",
    "| 7                | 8            | idem (2ᵃ)                                                                  | ME       | Bilat.      | Relax · Both fists · Both feet                         |\n",
    "| 8                | 9            | idem (3ᵃ)                                                                  | ME       | Bilat.      | Relax · Both fists · Both feet                         |\n",
    "| 9                | 10           | Motor **Imagery** – “imagine open/close *bilateral* fists & feet”           | MI       | Bilat.      | Relax · Both fists · Both feet                         |\n",
    "| 10               | 11           | idem (2ᵃ)                                                                  | MI       | Bilat.      | Relax · Both fists · Both feet                         |\n",
    "| 11               | 12           | idem (3ᵃ)                                                                  | MI       | Bilat.      | Relax · Both fists · Both feet                         |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821559de-edc6-444e-82c8-c4303677af76",
   "metadata": {},
   "source": [
    "## EEG Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9335f0fa-211b-4a81-afd2-b17365e97345",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Creazione dei Vari Datasets: Notch 60 Hz, Filtro Passa-Banda 1-45 Hz + PyPrep + Custom ICA + Epoching + Autoreject\n",
    "\n",
    "- Task 1: Motor Execution (Open and close right or left fist) - Unilateral - Runs 3, 7, 11 \n",
    "- Task 2: Motor Imagery (Imagine opening and closing right and left fists) - Unilateral - Runs 4, 8, 12 \n",
    "- Task 3: Motor Execution (Open and close both fists and feet) - Bilateral - Runs 5, 9, 13 \n",
    "- Task 4: Motor Imagery (Imagine opening and closing both fists and feet) - Bilateral - Runs 6, 10, 14 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba073d46-bb07-4dbd-8b3c-81c50e7adc29",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### **Canali Physionet Dataset == Canali dataset EEGMMIDB !** \n",
    "\n",
    "#### **(N.B. Canali dataset EEGMMIDB = gli stessi ma sistemati con capitalizzazione giusta)**"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cd424f3a-adee-4b99-b22f-55215c5f57de",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "'''\n",
    "                                                            FUNZIONI PROPOSTE\n",
    "Ho scomposto la pipeline in 5 moduli:\n",
    "\n",
    "get_raw_for_run: crea l’oggetto Raw MNE già filtrato e referenziato.\n",
    "\n",
    "build_raw_collection: itera su tutti i task/run/soggetto e costruisce una mappa raw_collection[task][subj][run] con (raw, ann_arr).\n",
    "\n",
    "explore_ica_for_run: interfaccia interattiva per visualizzare i componenti, selezionare manualmente quelli da escludere e \n",
    "restituire l’oggetto ica con ica.exclude già impostato.\n",
    "\n",
    "apply_ica_and_epoch: applica l’ICA pulita e suddivide in epoche di 4 s restituendo una lista di (segment, label).\n",
    "\n",
    "Blocco __main__: orchestra tutto, salva checkpoint parziali (sia task_data che ica_models) soggetto/run per soggetto/run e infine effettua lo stacking numpy e il salvataggio finale.\n",
    "\n",
    "Ora puoi:\n",
    "\n",
    "Eseguire interattivamente ogni run di ogni soggetto attraverso explore_ica_for_run.\n",
    "\n",
    "Controllare, in ogni iterazione, via GUI MNE i componenti e decidere cosa escludere.\n",
    "\n",
    "A pipeline terminata, ritrovi tutti i dati puliti in task_data[task][subj][T0/T1/T2]['data'] e ['labels'], già impilati in array.\n",
    "\n",
    "Fammi sapere se vuoi aggiungere logica di avanzamento automatico (es. salvare esclusioni in un file, saltare runs già processate, ecc.).\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple\n",
    "import mne\n",
    "\n",
    "# --- Configurazioni globali ---\n",
    "CHECKPOINT_PATH = Path(\"/home/stefano/EEGMMIDB_Analyses/task_data_ICA.pkl\")\n",
    "ICA_MODELS_PATH  = Path(\"/home/stefano/EEGMMIDB_Analyses/ica_models.pkl\")\n",
    "CHECKPOINT_PATH.parent.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "TASK_RUNS = {\n",
    "    \"task_1\": [0, 4, 8],\n",
    "    \"task_2\": [1, 5, 9],\n",
    "    \"task_3\": [2, 6, 10],\n",
    "    \"task_4\": [3, 7, 11],\n",
    "}\n",
    "\n",
    "def label_to_Tx(label_num: int) -> str:\n",
    "    return [\"T0\", \"T1\", \"T2\"][(label_num - 1) % 3]\n",
    "\n",
    "def to_plain_dict(d):\n",
    "    if isinstance(d, dict) or isinstance(d, defaultdict):\n",
    "        return {k: to_plain_dict(v) for k, v in d.items()}\n",
    "    return d\n",
    "\n",
    "\n",
    "# 1) Estrae RawArray per run e soggetto\n",
    "def get_raw_for_run(\n",
    "    sig_arr: np.ndarray,\n",
    "    fs: int,\n",
    "    channel_names: List[str]\n",
    ") -> mne.io.Raw:\n",
    "    info = mne.create_info(ch_names=channel_names, sfreq=fs, ch_types='eeg')\n",
    "    raw = mne.io.RawArray(sig_arr.T, info)\n",
    "    raw.set_montage(\"standard_1020\")\n",
    "    raw.set_eeg_reference(\"average\", projection=False)\n",
    "    raw.filter(1.5, 45.0, fir_design='firwin')\n",
    "    raw.notch_filter([50, 100])\n",
    "    return raw\n",
    "\n",
    "\n",
    "# 2) Costruisce struttura RAW (non epocata) per tutti i task/run/soggetto\n",
    "def build_raw_collection(\n",
    "    signal: List[Dict[str, list]],\n",
    "    labels: List[Dict[str, list]],\n",
    "    fs: int,\n",
    "    channel_names: List[str]\n",
    ") -> Dict[str, Dict[str, Dict[int, Tuple[mne.io.Raw, np.ndarray]]]]:\n",
    "    \"\"\"\n",
    "    Restituisce raw_collection[task][subject][run] = (raw, annotation_array)\n",
    "    \"\"\"\n",
    "    raw_collection = defaultdict(lambda: defaultdict(dict))\n",
    "    for task, runs in TASK_RUNS.items():\n",
    "        for r in runs:\n",
    "            run_sig   = signal[r]\n",
    "            run_label = labels[r]\n",
    "            for subj_key, sig_list in run_sig.items():\n",
    "                subj_id = subj_key.split('_')[1]\n",
    "                sig_arr = sig_list[0]  # (n_samples, 64)\n",
    "                ann_arr = np.asarray(run_label[subj_key.replace('Signal', 'Annotations')][0])\n",
    "                raw = get_raw_for_run(sig_arr, fs, channel_names)\n",
    "                raw_collection[task][subj_id][r] = (raw, ann_arr)\n",
    "    return raw_collection\n",
    "\n",
    "\n",
    "# 3) Esplora ICA manuale per un singolo raw\n",
    "def explore_ica_for_run(\n",
    "    raw: mne.io.Raw,\n",
    "    subj_id: str,\n",
    "    run_idx: int,\n",
    "    eog_chs: List[str]\n",
    ") -> mne.preprocessing.ICA:\n",
    "    ica = mne.preprocessing.ICA(n_components=0.999, method='fastica', random_state=97, max_iter='auto')\n",
    "    ica.fit(raw, decim=3)\n",
    "    ica.plot_components()\n",
    "    ica.plot_sources(raw)\n",
    "    eeg_overlay = ica.plot_overlay(raw, exclude=[], picks='eeg')\n",
    "    print(f\"Run {run_idx} - Subject {subj_id}: seleziona componenti da escludere (es: 0,1,2)\")\n",
    "    to_exclude = input(\"Componenti → \")\n",
    "    ica.exclude = [int(x) for x in to_exclude.split(',') if x.strip().isdigit()]\n",
    "    return ica\n",
    "\n",
    "\n",
    "# 4) Applica ICA ed esegue epoching\n",
    "def apply_ica_and_epoch(\n",
    "    raw: mne.io.Raw,\n",
    "    ica: mne.preprocessing.ICA,\n",
    "    ann_arr: np.ndarray,\n",
    "    fs: int,\n",
    "    epoch_len_s: float,\n",
    "    drop_shorter: bool\n",
    ") -> List[Tuple[np.ndarray, int]]:\n",
    "    raw_clean = ica.apply(raw.copy())\n",
    "    epoch_len = int(epoch_len_s * fs)\n",
    "    onsets = ann_arr[:, 3].astype(int) - 1\n",
    "    durs   = ann_arr[:, 2].astype(int)\n",
    "    labels = ann_arr[:, 0].astype(int)\n",
    "    segments = []\n",
    "    for onset, dur, lab in zip(onsets, durs, labels):\n",
    "        if dur < epoch_len and drop_shorter: continue\n",
    "        if onset + epoch_len > raw_clean.n_times: continue\n",
    "        seg = raw_clean.get_data()[:, onset:onset+epoch_len]  # (64, epoch_len)\n",
    "        segments.append((seg.astype(np.float32), lab))\n",
    "    return segments\n",
    "\n",
    "\n",
    "# 5) Pipeline generale interattiva\n",
    "if __name__ == '__main__':\n",
    "    # supponendo che `signal`, `labels`, `EEG_channels_names` siano caricati\n",
    "    raw_col = build_raw_collection(signal, labels, fs=160, channel_names=EEG_channels_names)\n",
    "    task_data = defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: {'data':[], 'labels':[]})))\n",
    "    ica_models = {}\n",
    "    for task, subjects in raw_col.items():\n",
    "        for subj_id, runs in subjects.items():\n",
    "            for run_idx, (raw, ann_arr) in runs.items():\n",
    "                ica = explore_ica_for_run(raw, subj_id, run_idx, eog_chs=EEG_channels_names)\n",
    "                ica_models[(task, subj_id, run_idx)] = ica\n",
    "                segments = apply_ica_and_epoch(raw, ica, ann_arr, fs=160,\n",
    "                                                epoch_len_s=4.0, drop_shorter=True)\n",
    "                for seg, lab in segments:\n",
    "                    Tx = label_to_Tx(lab)\n",
    "                    td = task_data[task][subj_id][Tx]\n",
    "                    td['data'].append(seg)\n",
    "                    td['labels'].append(lab)\n",
    "                # checkpoint\n",
    "                plain = to_plain_dict(task_data)\n",
    "                with open(CHECKPOINT_PATH, 'wb') as f:\n",
    "                    pickle.dump(plain, f)\n",
    "                with open(ICA_MODELS_PATH, 'wb') as f:\n",
    "                    pickle.dump(ica_models, f)\n",
    "    # stacking finale\n",
    "    for task in task_data:\n",
    "        for subj in task_data[task]:\n",
    "            for Tx in task_data[task][subj]:\n",
    "                td = task_data[task][subj][Tx]\n",
    "                if td['data']:\n",
    "                    td['data']   = np.stack(td['data'], axis=0)\n",
    "                    td['labels'] = np.asarray(td['labels'], dtype=int)\n",
    "                else:\n",
    "                    td['data']   = np.empty((0,64,int(4.0*160)), np.float32)\n",
    "                    td['labels'] = np.empty((0,), int)\n",
    "    # salvataggio finale\n",
    "    plain = to_plain_dict(task_data)\n",
    "    with open(CHECKPOINT_PATH, 'wb') as f:\n",
    "        pickle.dump(plain, f)\n",
    "    with open(ICA_MODELS_PATH, 'wb') as f:\n",
    "        pickle.dump(ica_models, f)\n",
    "    print(\"[Done] task_data e ICA models salvati.\")\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68e3e40-33c5-436c-a95f-cf68691b5276",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "\n",
    "# Percorso del file EDF scaricato dal dataset originale (modifica se necessario)\n",
    "raw = mne.io.read_raw_edf('/home/stefano/EEGMMIDB_Analyses/S001R01.edf', preload=False, verbose=False)\n",
    "\n",
    "# Estrae i nomi dei canali (elettrodi EEG)\n",
    "channel_names = raw.info['ch_names']\n",
    "\n",
    "# Stampa ordinata\n",
    "print(\"Lista dei canali trovati ORIGINALI nel file:\")\n",
    "for ch in channel_names:\n",
    "    print(ch, end = \" \")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cda4adb-0eb3-408e-bd9d-b60cf1216a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "\n",
    "✅ Soluzione: normalizza il nome dei canali EEG prima di metterli dentro la configurazione standard 10_20\n",
    "secondo la configurazione voluta da MNE\n",
    "\n",
    "Serve una funzione di normalizzazione intelligente, che:\n",
    "\n",
    "rimuove i punti (.),\n",
    "\n",
    "converte tutto in maiuscolo eccetto la lettera z finale,\n",
    "che deve rimanere minuscola se il canale è uno di quelli \"centrali\" con z (Fz, Cz, Pz, Oz, Fpz, Poz, Afz, ecc.).\n",
    "\n",
    "\n",
    "In particolare,la tua funzione normalize_ch_names(...) deve preservare correttamente la capitalizzazione ufficiale MISTA, ovvero:\n",
    "\n",
    "MNE usa nomi capitalizzati solo parzialmente, ad esempio:\n",
    "\n",
    "Tuo input\tNome giusto in standard_1020\n",
    "'Fcz'\t❌ non esiste ('FCz' sì!)\n",
    "'Cpz'\t❌ non esiste ('CPz' sì!)\n",
    "'Afz'\t❌ non esiste ('AFz' sì!)\n",
    "'FP1'\t✅ OK\n",
    "'FP2'\t✅ OK\n",
    "'Poz'\t✅ OK\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "def normalize_ch_names(ch_list):\n",
    "    \n",
    "    # Lista dei nomi dei canali standard (inclusi nel 10-20 ufficiale di MNE)\n",
    "    montage_ch_names = set(mne.channels.make_standard_montage('standard_1020').ch_names)\n",
    "\n",
    "    corrected = []\n",
    "    for ch in ch_list:\n",
    "        ch_clean = ch.replace('.', '')  # rimuovi i punti\n",
    "        ch_upper = ch_clean.upper()\n",
    "\n",
    "        # Trova il match nel montage standard (case-insensitive)\n",
    "        match = next((std_ch for std_ch in montage_ch_names if std_ch.upper() == ch_upper), None)\n",
    "\n",
    "        if match:\n",
    "            corrected.append(match)\n",
    "        else:\n",
    "            print(f\"[WARN] Canale non trovato nel montage: {ch_clean}\")\n",
    "            corrected.append(ch_clean)  # fallback\n",
    "    return corrected\n",
    "\n",
    "\n",
    "EEG_channels = normalize_ch_names(channel_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ea27dd-b242-4c5a-8fef-b7116092b4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(EEG_channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c82a763-d0d8-499a-bf88-3344bbd289f5",
   "metadata": {},
   "source": [
    "#### **Sintesi - Struttura dei Dati EEG & Labels Summary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd26f29b-13f6-434e-a41f-b407136e3cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "La stuttura dati di partenza per dati e labels è \n",
    "\n",
    "#signal  = EEG_data['EEGMMIDB']['Signal']                 # lista (len=103) di soggetti\n",
    "#labels  = EEG_data['EEGMMIDB']['Annotations']            # idem\n",
    "\n",
    "\n",
    "Signal -> lista di 12 elementi, ciascuna riferita ai dati di una certa run.\n",
    "        \n",
    "        -> Ogni elemento (ogni run) contiene i dati di una certa run di tutti e 103 i soggetti\n",
    "        \n",
    "            -> Per accedere ai dati di una specifica run di uno specifico soggetto (contenuti dentro una lista -> len(signal[0]) = 103)\n",
    "                bisogna indicare una specifica chiave relativa ad un dizionario dello specifico soggetto (i.e., type(signal[0]) --> dict)\n",
    "            \n",
    "                --> ESEMPIO: signal[0]['Subject_100_Signal']\n",
    "                \n",
    "                    --> Dentro al dizionario di una run di uno specifico soggetto, c'è una lista \n",
    "                        (i.e., type(signal[0]['Subject_100_Signal']) = list), \n",
    "                        \n",
    "                        Composta di un elemento solo \n",
    "                        (i.e., len(signal[0]['Subject_100_Signal']) = 1)\n",
    "                        \n",
    "                        --> Per accedere proprio all'array dei dati, devi indicizzare ulteriormente \n",
    "                            \n",
    "                            signal[0]['Subject_100_Signal'][0].shape = (19680, 64)\n",
    "                            \n",
    "#dict_keys(['Subject_100_Signal', 'Subject_101_Signal', 'Subject_102_Signal', 'Subject_103_Signal', 'Subject_10_Signal', 'Subject_11_Signal', \n",
    "            #'Subject_12_Signal', 'Subject_13_Signal', 'Subject_14_Signal', 'Subject_15_Signal', 'Subject_16_Signal', 'Subject_17_Signal', \n",
    "            #'Subject_18_Signal', 'Subject_19_Signal', 'Subject_1_Signal', 'Subject_20_Signal', 'Subject_21_Signal', 'Subject_22_Signal', \n",
    "            #'Subject_23_Signal', 'Subject_24_Signal', 'Subject_25_Signal', 'Subject_26_Signal', 'Subject_27_Signal', 'Subject_28_Signal',\n",
    "            #'Subject_29_Signal', 'Subject_2_Signal', 'Subject_30_Signal', 'Subject_31_Signal', 'Subject_32_Signal', 'Subject_33_Signal', \n",
    "            #'Subject_34_Signal', 'Subject_35_Signal', 'Subject_36_Signal', 'Subject_37_Signal', 'Subject_38_Signal', 'Subject_39_Signal', \n",
    "            #'Subject_3_Signal', 'Subject_40_Signal', 'Subject_41_Signal', 'Subject_42_Signal', 'Subject_43_Signal', 'Subject_44_Signal', \n",
    "            #'Subject_45_Signal', 'Subject_46_Signal', 'Subject_47_Signal', 'Subject_48_Signal', 'Subject_49_Signal', 'Subject_4_Signal', \n",
    "            #'Subject_50_Signal', 'Subject_51_Signal', 'Subject_52_Signal', 'Subject_53_Signal', 'Subject_54_Signal', 'Subject_55_Signal', \n",
    "            #'Subject_56_Signal', 'Subject_57_Signal', 'Subject_58_Signal', 'Subject_59_Signal', 'Subject_5_Signal', 'Subject_60_Signal', \n",
    "            #'Subject_61_Signal', 'Subject_62_Signal', 'Subject_63_Signal', 'Subject_64_Signal', 'Subject_65_Signal', 'Subject_66_Signal',\n",
    "            #'Subject_67_Signal', 'Subject_68_Signal', 'Subject_69_Signal', 'Subject_6_Signal', 'Subject_70_Signal', 'Subject_71_Signal', \n",
    "            #'Subject_72_Signal', 'Subject_73_Signal', 'Subject_74_Signal', 'Subject_75_Signal', 'Subject_76_Signal', 'Subject_77_Signal',\n",
    "            #'Subject_78_Signal', 'Subject_79_Signal', 'Subject_7_Signal', 'Subject_80_Signal', 'Subject_81_Signal', 'Subject_82_Signal', \n",
    "            #'Subject_83_Signal', 'Subject_84_Signal', 'Subject_85_Signal', 'Subject_86_Signal', 'Subject_87_Signal', 'Subject_88_Signal', \n",
    "            #'Subject_89_Signal', 'Subject_8_Signal', 'Subject_90_Signal', 'Subject_91_Signal', 'Subject_92_Signal', 'Subject_93_Signal', \n",
    "            #'Subject_94_Signal', 'Subject_95_Signal', 'Subject_96_Signal', 'Subject_97_Signal', 'Subject_98_Signal', 'Subject_99_Signal',\n",
    "            #'Subject_9_Signal'])\n",
    "            \n",
    "            \n",
    "Labels -> lista di 12 elementi, ciascuna riferita ai dati di una certa run.\n",
    "        \n",
    "        -> Ogni elemento (ogni run) contiene le labels di una certa run di tutti e 103 i soggetti\n",
    "        \n",
    "            -> Per accedere alle labels di una specifica run di uno specifico soggetto (contenuti dentro una lista -> len(labels[0]) = 103)\n",
    "                bisogna indicare una specifica chiave relativa ad un dizionario dello specifico soggetto (i.e., type(labels[0]) --> dict)\n",
    "            \n",
    "                --> ESEMPIO: labels[0]['Subject_100_Annotations']\n",
    "                \n",
    "                    --> Dentro al dizionario di una run di uno specifico soggetto, c'è una lista \n",
    "                        (i.e., type(labels[0]['Subject_100_Annotations']) = list), \n",
    "                        \n",
    "                        Composta di un elemento solo \n",
    "                        (i.e., len(labels[0]['Subject_100_Annotations']) = 1)\n",
    "                        \n",
    "                        --> Per accedere proprio all'array della labels della SPECIFICA RUN dello SPECIFICO SOGGETTO,\n",
    "                            devi indicizzare ulteriormente!\n",
    "                            \n",
    "                            In questo modo, dovresti avere tutti e 30 i trial della specifica run, ciascuno composto da 5 campi\n",
    "                            \n",
    "                            \n",
    "                            \n",
    "                            type(labels[0]['Subject_100_Annotations'][0]) -> list\n",
    "                            \n",
    "                            Output:\n",
    "                            \n",
    "                            [[array(1.), array(4.1), array(656.), array(1.), array(656.)],\n",
    "                             [array(3.), array(4.1), array(656.), array(657.), array(1312.)],\n",
    "                             [array(1.), array(4.1), array(656.), array(1313.), array(1968.)],\n",
    "                             [array(2.), array(4.1), array(656.), array(1969.), array(2624.)],\n",
    "                             [array(1.), array(4.1), array(656.), array(2625.), array(3280.)],\n",
    "                             [array(3.), array(4.1), array(656.), array(3281.), array(3936.)],\n",
    "                             [array(1.), array(4.1), array(656.), array(3937.), array(4592.)],\n",
    "                             [array(2.), array(4.1), array(656.), array(4593.), array(5248.)],\n",
    "                             [array(1.), array(4.1), array(656.), array(5249.), array(5904.)],\n",
    "                             [array(2.), array(4.1), array(656.), array(5905.), array(6560.)],\n",
    "                             [array(1.), array(4.1), array(656.), array(6561.), array(7216.)],\n",
    "                             [array(3.), array(4.1), array(656.), array(7217.), array(7872.)],\n",
    "                             [array(1.), array(4.1), array(656.), array(7873.), array(8528.)],\n",
    "                             [array(2.), array(4.1), array(656.), array(8529.), array(9184.)],\n",
    "                             [array(1.), array(4.1), array(656.), array(9185.), array(9840.)],\n",
    "                             [array(3.), array(4.1), array(656.), array(9841.), array(10496.)],\n",
    "                             [array(1.), array(4.1), array(656.), array(10497.), array(11152.)],\n",
    "                             [array(2.), array(4.1), array(656.), array(11153.), array(11808.)],\n",
    "                             [array(1.), array(4.1), array(656.), array(11809.), array(12464.)],\n",
    "                             [array(3.), array(4.1), array(656.), array(12465.), array(13120.)],\n",
    "                             [array(1.), array(4.1), array(656.), array(13121.), array(13776.)],\n",
    "                             [array(2.), array(4.1), array(656.), array(13777.), array(14432.)],\n",
    "                             [array(1.), array(4.1), array(656.), array(14433.), array(15088.)],\n",
    "                             [array(3.), array(4.1), array(656.), array(15089.), array(15744.)],\n",
    "                             [array(1.), array(4.1), array(656.), array(15745.), array(16400.)],\n",
    "                             [array(3.), array(4.1), array(656.), array(16401.), array(17056.)],\n",
    "                             [array(1.), array(4.1), array(656.), array(17057.), array(17712.)],\n",
    "                             [array(2.), array(4.1), array(656.), array(17713.), array(18368.)],\n",
    "                             [array(1.), array(4.1), array(656.), array(18369.), array(19024.)],\n",
    "                             [array(3.), array(4.1), array(656.), array(19025.), array(19680.)]]\n",
    "                            \n",
    "                        \n",
    "                        --> Per accedere proprio all'array della labels di uno SPECIFICO TRIAL di quella SPECIFICA RUN, devi indicizzare ulteriormente \n",
    "                            (se ne vuoi prendere proprio uno specifico!) \n",
    "                            \n",
    "                            type(labels[0]['Subject_100_Annotations'][0][0]) -> list\n",
    "                            \n",
    "                            Output:\n",
    "                            \n",
    "                            labels[0]['Subject_100_Annotations'][0][0] ->  [array(1.), array(4.1), array(656.), array(1.), array(656.)]\n",
    "                            \n",
    "                            \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a74ff1-23b4-49ee-8582-6525c2bdd213",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(signal[0]['Subject_100_Signal'])\n",
    "\n",
    "\n",
    "# Questo contiene la lista dei valori della run del relativo soggetto...\n",
    "\n",
    "#Questa per i dati\n",
    "\n",
    "#A questo livello prendo la run del soggetto 100 ed è una lista\n",
    "\n",
    "print(type(signal[0]['Subject_100_Signal']))\n",
    "\n",
    "#Una lista di un elemento solo (ossia, tutto il reading di una run intera)\n",
    "\n",
    "#Questo valore dovrebbe corrispondere al numero di campioni dell'intera run di 2 minuti descritta dal paper...\n",
    "\n",
    "#--> https://pmc.ncbi.nlm.nih.gov/articles/PMC10998040/pdf/main.pdf\n",
    "\n",
    "print(len(signal[0]['Subject_100_Signal']))\n",
    "\n",
    "\n",
    "#Vedendo il singolo elemento della lista, ossia tutto il reading di una run intera\n",
    "#So che questo sia un'array!\n",
    "print(type(signal[0]['Subject_100_Signal'][0]))\n",
    "\n",
    "#Se voglio prendere solo la prima dimensione dell'array, e sapere la sua lunghezza so che è pari al numero tot campioni EEG dell'intera run!\n",
    "print(len(signal[0]['Subject_100_Signal'][0]))\n",
    "\n",
    "#Se voglio prendere l'intera shape dell'array, vedo che l'intero EEG reading ha come dimensioni: \n",
    "print(signal[0]['Subject_100_Signal'][0].shape)\n",
    "    #dim 1: length totale della run\n",
    "    #dim 2: 64 (elettrodi usati durante la rec) \n",
    "\n",
    "print()\n",
    "\n",
    "\n",
    "#Questa per le labels\n",
    "\n",
    "print(type(labels[0]['Subject_100_Annotations']))\n",
    "\n",
    "#Se voglio sapere la lunghezza delle annotazioni so che la sua lunghezza è pari al numero di trials componibili in base alla lunghezza dell'intera run\n",
    "print(len(labels[0]['Subject_100_Annotations'][0]))\n",
    "\n",
    "#Per ogni trial invece della run del relativo soggetto, so che ogni elemento è composto da 5 campi, che si riferiscono a:\n",
    "\n",
    "#label usata\n",
    "#durata in secondi\n",
    "#duranta in termini di sample\n",
    "#indice di inizio del sample\n",
    "#indice di fine del sample\n",
    "\n",
    "print(len(labels[0]['Subject_100_Annotations'][0][0]))\n",
    "\n",
    "#Per accedere al valore di ognuno dei 5 campi, vedo prima il suo tipo\n",
    "print(type(labels[0]['Subject_100_Annotations'][0][0][0]))\n",
    "      \n",
    "#Poi, accedo al suo valore\n",
    "print(labels[0]['Subject_100_Annotations'][0][0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fc8b45-d675-4d15-b069-3379fe65bce7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### **EEG Proprocessing - Filtering Notch 60 Hz and IIR 1-45 Hz**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b3c951-4369-4d5a-aa23-2e8403f9ef16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a369565-5fa5-48e5-88bc-57dc2d5c160a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "raw = mne.io.read_raw_edf('/home/stefano/EEGMMIDB_Analyses/S001R01.edf', preload=False)\n",
    "print(raw.ch_names)\n",
    "\n",
    "channel_names = raw.ch_names\n",
    "print()\n",
    "print(type(channel_names))\n",
    "print()\n",
    "print(channel_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccdd8068-39a0-417a-80a1-c8610e44da4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "\n",
    "✅ Soluzione: normalizza il nome dei canali EEG prima di metterli dentro la configurazione standard 10_20\n",
    "secondo la configurazione voluta da MNE\n",
    "\n",
    "Serve una funzione di normalizzazione intelligente, che:\n",
    "\n",
    "rimuove i punti (.),\n",
    "\n",
    "converte tutto in maiuscolo eccetto la lettera z finale,\n",
    "che deve rimanere minuscola se il canale è uno di quelli \"centrali\" con z (Fz, Cz, Pz, Oz, Fpz, Poz, Afz, ecc.).\n",
    "\n",
    "\n",
    "In particolare,la tua funzione normalize_ch_names(...) deve preservare correttamente la capitalizzazione ufficiale MISTA, ovvero:\n",
    "\n",
    "MNE usa nomi capitalizzati solo parzialmente, ad esempio:\n",
    "\n",
    "Tuo input\tNome giusto in standard_1020\n",
    "'Fcz'\t❌ non esiste ('FCz' sì!)\n",
    "'Cpz'\t❌ non esiste ('CPz' sì!)\n",
    "'Afz'\t❌ non esiste ('AFz' sì!)\n",
    "'FP1'\t✅ OK\n",
    "'FP2'\t✅ OK\n",
    "'Poz'\t✅ OK\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "def normalize_ch_names(ch_list):\n",
    "    \n",
    "    # Lista dei nomi dei canali standard (inclusi nel 10-20 ufficiale di MNE)\n",
    "    montage_ch_names = set(mne.channels.make_standard_montage('standard_1020').ch_names)\n",
    "\n",
    "    corrected = []\n",
    "    for ch in ch_list:\n",
    "        ch_clean = ch.replace('.', '')  # rimuovi i punti\n",
    "        ch_upper = ch_clean.upper()\n",
    "\n",
    "        # Trova il match nel montage standard (case-insensitive)\n",
    "        match = next((std_ch for std_ch in montage_ch_names if std_ch.upper() == ch_upper), None)\n",
    "\n",
    "        if match:\n",
    "            corrected.append(match)\n",
    "        else:\n",
    "            print(f\"[WARN] Canale non trovato nel montage: {ch_clean}\")\n",
    "            corrected.append(ch_clean)  # fallback\n",
    "    return corrected\n",
    "\n",
    "\n",
    "EEG_channels = normalize_ch_names(channel_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09ea207-6ac5-4c5b-8468-d9b83794be5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple\n",
    "import mne\n",
    "import time \n",
    "\n",
    "\n",
    "from tqdm import tqdm  # Assicurati di avere tqdm installato\n",
    "\n",
    "\n",
    "# --- Configurazioni globali ---\n",
    "\n",
    "#ICA_MODELS_PATH  = Path(\"/home/stefano/EEGMMIDB_Analyses/ica_models.pkl\")\n",
    "\n",
    "CHECKPOINT_PATH = Path(\"/home/stefano/EEGMMIDB_Analyses/task_data_ICA.pkl\")\n",
    "\n",
    "CHECKPOINT_PATH.parent.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# === Lista dei 64 canali compatibili con il dataset Mendeley ===\n",
    "\n",
    "'''NORMALIZZO I CANALI EEG (GIA' FATTO SOPRA)\n",
    "EEG_channels = normalize_ch_names(channel_names)\n",
    "'''\n",
    "\n",
    "# Mappatura Task → indice run (0-based)\n",
    "TASK_RUNS = {\n",
    "    \"task_1\": [0, 4, 8],\n",
    "    \"task_2\": [1, 5, 9],\n",
    "    \"task_3\": [2, 6, 10],\n",
    "    \"task_4\": [3, 7, 11],\n",
    "}\n",
    "\n",
    "def label_to_Tx(label_num: int) -> str:\n",
    "    return [\"T0\", \"T1\", \"T2\"][(label_num - 1) % 3]\n",
    "\n",
    "def to_plain_dict(d):\n",
    "    if isinstance(d, dict) or isinstance(d, defaultdict):\n",
    "        return {k: to_plain_dict(v) for k, v in d.items()}\n",
    "    return d\n",
    "\n",
    "'''\n",
    "Dove cercare ESATTAMENTE questa cosa che il dato vada convertito in Volt?\n",
    "\n",
    "\n",
    "vai qui --> https://mne.tools/stable/generated/mne.io.RawArray.html?utm_source=chatgpt.com \n",
    "\n",
    "al metodo 'get_data', vai nella sua sezione del parametro \"units\", dove dice \n",
    "\n",
    "unitsstr | dict | None\n",
    "Specify the unit(s) that the data should be returned in. \n",
    "If None (default), the data is returned in the channel-type-specific default units, \n",
    "which are SI units (see Internal representation (units) and data channels).\n",
    "\n",
    "A quel punto clicca sul link di \"internal units\"\n",
    "(https://mne.tools/stable/documentation/implementation.html#units) \n",
    "\n",
    "E poi andando nella sezione che si apre cercando la tabella \"Supported channel types\" e vedendo che, su riga \"eeg\" compare 'Volts\"\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "# 1) Estrae RawArray filtrato e con solo i 64 canali Mendeley\n",
    "def get_raw_for_run(\n",
    "    sig_arr: np.ndarray,\n",
    "    fs: int,\n",
    "    channel_names: List[str]\n",
    ") -> mne.io.Raw:\n",
    "    \n",
    "    # Filtra solo i canali ufficiali\n",
    "    keep_idx = [i for i, ch in enumerate(channel_names) if ch in channel_names]\n",
    "    \n",
    "    sig_arr = sig_arr * 1e-6  # Converti da µV a Volt\n",
    "    \n",
    "    \n",
    "    sig_arr = sig_arr[:, keep_idx]\n",
    "    chs = [channel_names[i] for i in keep_idx]\n",
    "\n",
    "    # Crea RawArray\n",
    "    info = mne.create_info(ch_names=chs, sfreq=fs, ch_types='eeg')\n",
    "    raw = mne.io.RawArray(sig_arr.T, info)\n",
    "    \n",
    "    # Costruisci montage ridotto\n",
    "    \n",
    "    '''\n",
    "    Carichi il montaggio standard (standard_1020) che contiene le posizioni 3D per tutti i canali noti.\n",
    "    Filtri queste posizioni con --> if ch in EEG_channels\n",
    "    \n",
    "    quindi mantieni solo le posizioni dei canali effettivamente presenti nei tuoi dati .mat, confrontando i nomi.\n",
    "    \n",
    "    Crei un nuovo montaggio personalizzato con solo quei canali tramite make_dig_montage.\n",
    "    Lo assegni al tuo oggetto raw.\n",
    "\n",
    "    Quindi sì, questo approccio:\n",
    "    Si assicura che i nomi dei tuoi canali matchino esattamente con quelli nel montaggio standard.\n",
    "    Evita errori nel caso tu abbia un sottoinsieme (come i 64 canali della Mendeley EEG dataset).\n",
    "    È robusto per dati che non vengono direttamente da MNE (come i tuoi .mat) perché ti consente un controllo esplicito sulla selezione dei canali.\n",
    "\n",
    "    '''\n",
    "    \n",
    "    montage = mne.channels.make_standard_montage('standard_1020')\n",
    "    pos = {ch: pos for ch, pos in montage.get_positions()['ch_pos'].items() if ch in EEG_channels}\n",
    "    montage_eegmidb = mne.channels.make_dig_montage(ch_pos=pos, coord_frame='head')\n",
    "    raw.set_montage(montage_eegmidb)\n",
    "    \n",
    "    iir_params = dict(order = 2, ftype='butter', output = 'sos')\n",
    "    \n",
    "    raw.notch_filter([60], method='iir', iir_params = iir_params)\n",
    "    \n",
    "    raw.filter(1.0, 45.0, method ='iir', iir_params = iir_params)\n",
    "\n",
    "    return raw\n",
    "\n",
    "\n",
    "'''\n",
    "VERSIONE GIA' IN FORMATO DICT DIRETTO\n",
    "\n",
    "✅ Cosa fa:\n",
    "Estrae i dati da signal e labels (entrambi strutturati come liste di dizionari).\n",
    "\n",
    "Converte ogni array di segnali (sig_arr) in un oggetto mne.io.RawArray usando get_raw_for_run(...).\n",
    "\n",
    "Salva:\n",
    "\n",
    "raw: il segnale EEG PREPROCESATO già in formato MNE.\n",
    "ann_arr: le annotazioni in formato np.ndarray (30 x 5).\n",
    "\n",
    "Organizza tutto in una struttura gerarchica raw_collection[task][subject][run] = (raw, ann_arr).\n",
    "\n",
    "\n",
    "N.B. il metodo get_data() restituisce i dati EEG in formato NumPy array direttamente dal tuo oggetto mne.io.RawArray\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "# 2) Costruisce struttura RAW (non epocata) per tutti i task/run/soggetto\n",
    "def build_raw_collection(\n",
    "    signal: List[Dict[str, list]],\n",
    "    labels: List[Dict[str, list]],\n",
    "    fs: int,\n",
    "    channel_names: List[str]\n",
    ") -> Dict[str, Dict[str, Dict[int, Tuple[mne.io.Raw, np.ndarray]]]]:\n",
    "    \n",
    "    \"\"\"\n",
    "    Restituisce raw_collection[task][subject][run] = (raw, annotation_array)\n",
    "    \"\"\"\n",
    "    #raw_collection = defaultdict(lambda: defaultdict(dict))\n",
    "    \n",
    "    raw_collection = dict()\n",
    "    \n",
    "    # Avvia il timer\n",
    "    start_time = time.time()\n",
    "    \n",
    "    #Il numero totale di soggetto×run è semplicemente la somma del numero di soggetti per ogni run\n",
    "    \n",
    "    # Stima del numero totale di soggetti × run → per la progress bar\n",
    "    total_jobs = sum(len(signal[r]) for runs in TASK_RUNS.values() for r in runs)\n",
    "    pbar = tqdm(total=total_jobs, desc=\"Costruzione RAW filtrati\", unit=\"run\")\n",
    "    \n",
    "\n",
    "    for task, runs in TASK_RUNS.items():\n",
    "        for r in runs:\n",
    "            run_sig   = signal[r]\n",
    "            run_label = labels[r]\n",
    "            for subj_key, sig_list in run_sig.items():\n",
    "                subj_id = subj_key.split('_')[1]\n",
    "                sig_arr = sig_list[0]  # (n_samples, n_channels)\n",
    "                ann_arr = np.asarray(run_label[subj_key.replace('Signal', 'Annotations')][0])\n",
    "\n",
    "                raw = get_raw_for_run(sig_arr, fs, channel_names)\n",
    "                \n",
    "                if task not in raw_collection:\n",
    "                    raw_collection[task] = dict()\n",
    "                    \n",
    "                if subj_id not in raw_collection[task]:\n",
    "                    raw_collection[task][subj_id] = dict()\n",
    "                \n",
    "                raw_collection[task][subj_id][r] = (raw, ann_arr)\n",
    "                \n",
    "                pbar.update(1)\n",
    "    \n",
    "    pbar.close()\n",
    "    \n",
    "    # Calcola il tempo totale\n",
    "    end_time = time.time()\n",
    "    \n",
    "    # Calcola il tempo totale\n",
    "    total_time = end_time - start_time\n",
    "    hours = int(total_time // 3600)\n",
    "    minutes = int((total_time % 3600) // 60)\n",
    "    seconds = int(total_time % 60)\n",
    "\n",
    "    # Stampa il tempo totale in formato leggibile\n",
    "    print(f\"\\nTempo totale impiegato: \\033[1m{hours} ore, {minutes} minuti e {seconds} secondi\\033[0m.\\n\")\n",
    "\n",
    "    return raw_collection\n",
    "\n",
    "\n",
    "\n",
    "# Versione \"non filtrata\" di get_raw_for_run\n",
    "\n",
    "def get_raw_for_run_unfiltered(\n",
    "    sig_arr: np.ndarray,\n",
    "    fs: int,\n",
    "    channel_names: List[str]\n",
    ") -> mne.io.Raw:\n",
    "    \n",
    "    # Filtra solo i canali ufficiali\n",
    "    keep_idx = [i for i, ch in enumerate(channel_names) if ch in channel_names]\n",
    "    \n",
    "    sig_arr = sig_arr * 1e-6  # Converti da µV a Volt\n",
    "    \n",
    "    \n",
    "    sig_arr = sig_arr[:, keep_idx]\n",
    "    chs = [channel_names[i] for i in keep_idx]\n",
    "\n",
    "    # Crea RawArray\n",
    "    info = mne.create_info(ch_names=chs, sfreq=fs, ch_types='eeg')\n",
    "    raw = mne.io.RawArray(sig_arr.T, info)\n",
    "    \n",
    "    montage = mne.channels.make_standard_montage('standard_1020')\n",
    "    pos = {ch: pos for ch, pos in montage.get_positions()['ch_pos'].items() if ch in EEG_channels}\n",
    "    montage_eegmidb = mne.channels.make_dig_montage(ch_pos=pos, coord_frame='head')\n",
    "    raw.set_montage(montage_eegmidb)\n",
    "\n",
    "    return raw\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''VERSIONE GIA' IN FORMATO DICT DIRETTO\n",
    "\n",
    "✅ Cosa fa:\n",
    "Estrae i dati da signal e labels (entrambi strutturati come liste di dizionari).\n",
    "\n",
    "Converte ogni array di segnali (sig_arr) in un oggetto mne.io.RawArray usando get_raw_for_run(...).\n",
    "\n",
    "Salva:\n",
    "\n",
    "raw: il segnale EEG NON PROCESSATO già in formato MNE.\n",
    "ann_arr: le annotazioni in formato np.ndarray (30 x 5).\n",
    "\n",
    "Organizza tutto in una struttura gerarchica raw_collection[task][subject][run] = (raw, ann_arr).\n",
    "\n",
    "\n",
    "N.B. il metodo .get_data() restituisce i dati EEG in formato NumPy array direttamente dal tuo oggetto mne.io.RawArray\n",
    "\n",
    "Ossia raw.get_data() restituisce i dati EEG in formato NumPy array direttamente dal tuo oggetto mne.io.RawArray.\n",
    "\n",
    "🔍 Cosa ottieni:\n",
    "\n",
    "data = raw.get_data()\n",
    "print(data.shape)\n",
    "\n",
    "→ Restituisce una matrice di shape: (n_channels, n_times)\n",
    "\n",
    "Ad esempio: (64, 19680)  # 64 canali EEG, 19680 campioni (≈ 123 secondi a 160 Hz)\n",
    "\n",
    "\n",
    "🧠 Se vuoi l'array trasposto (per n_times × n_channels):\n",
    "\n",
    "Puoi fare:\n",
    "\n",
    "data = raw.get_data().T\n",
    "print(data.shape)  # (n_times, n_channels)\n",
    "\n",
    "💡 Ricorda:\n",
    "Il metodo raw.get_data() non restituisce segmenti o epoche — è l'intero segnale continuo.\n",
    "\n",
    "Se vuoi i singoli trial, devi usare le colonne 3 e 4 di ann_arr per tagliare i segmenti desiderati.\n",
    "\n",
    "Se vuoi ti aiuto a costruire quella parte 👇 (cioè extract_trials_from_raw(...)).\n",
    "\n",
    "\n",
    "'''\n",
    "# 3bis) Costruisce struttura RAW (non epocata) NON filtrata\n",
    "def build_raw_collection_unfiltered(\n",
    "    signal: List[Dict[str, list]],\n",
    "    labels: List[Dict[str, list]],\n",
    "    fs: int,\n",
    "    channel_names: List[str]\n",
    ") -> Dict[str, Dict[str, Dict[int, Tuple[mne.io.Raw, np.ndarray]]]]:\n",
    "    \n",
    "    \"\"\"\n",
    "    Restituisce raw_collection_unfiltered[task][subject][run] = (raw, annotation_array)\n",
    "    \"\"\"\n",
    "    #raw_collection_unfiltered = defaultdict(lambda: defaultdict(dict))\n",
    "    \n",
    "    raw_collection_unfiltered = dict()\n",
    "    \n",
    "    # Avvia il timer\n",
    "    start_time = time.time()\n",
    "    \n",
    "    #Il numero totale di soggetto×run è semplicemente la somma del numero di soggetti per ogni run\n",
    "    \n",
    "    # Stima del numero totale di soggetti × run → per la progress bar\n",
    "    total_jobs = sum(len(signal[r]) for runs in TASK_RUNS.values() for r in runs)\n",
    "    pbar = tqdm(total=total_jobs, desc=\"Costruzione RAW non filtrati\", unit=\"run\")\n",
    "    \n",
    "    \n",
    "    for task, runs in TASK_RUNS.items():\n",
    "        for r in runs:\n",
    "            run_sig   = signal[r]\n",
    "            run_label = labels[r]\n",
    "            \n",
    "            for subj_key, sig_list in run_sig.items():\n",
    "                subj_id = subj_key.split('_')[1]\n",
    "                sig_arr = sig_list[0]  # (n_samples, n_channels)\n",
    "                ann_arr = np.asarray(run_label[subj_key.replace('Signal', 'Annotations')][0])\n",
    "\n",
    "                raw = get_raw_for_run_unfiltered(sig_arr, fs, channel_names)\n",
    "                \n",
    "                if task not in raw_collection_unfiltered:\n",
    "                    raw_collection_unfiltered[task] = dict()\n",
    "                    \n",
    "                if subj_id not in raw_collection_unfiltered[task]:\n",
    "                    raw_collection_unfiltered[task][subj_id] = dict()\n",
    "                    \n",
    "                raw_collection_unfiltered[task][subj_id][r] = (raw, ann_arr)\n",
    "                \n",
    "                pbar.update(1)\n",
    "    \n",
    "    pbar.close()\n",
    "    \n",
    "    # Calcola il tempo totale\n",
    "    end_time = time.time()\n",
    "    \n",
    "    # Calcola il tempo totale\n",
    "    total_time = end_time - start_time\n",
    "    hours = int(total_time // 3600)\n",
    "    minutes = int((total_time % 3600) // 60)\n",
    "    seconds = int(total_time % 60)\n",
    "\n",
    "    # Stampa il tempo totale in formato leggibile\n",
    "    print(f\"\\nTempo totale impiegato: \\033[1m{hours} ore, {minutes} minuti e {seconds} secondi\\033[0m.\\n\")\n",
    "    \n",
    "    return raw_collection_unfiltered\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aba4c36-ae2e-4ec8-a446-53378028f08f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "RUN PULITE\n",
    "'''\n",
    "raw_collection = build_raw_collection(\n",
    "    signal=signal,\n",
    "    labels=labels,\n",
    "    fs=160,\n",
    "    channel_names=EEG_channels  # <-- la lista normalizzata\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e2ea47-5f37-41ec-a778-5c94679c3300",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "RUN NON PULITE\n",
    "'''\n",
    "raw_unfiltered_collection = build_raw_collection_unfiltered(\n",
    "    signal=signal,\n",
    "    labels=labels,\n",
    "    fs=160,\n",
    "    channel_names = EEG_channels  # <-- la lista normalizzata\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d34de1-1ce9-422b-9e64-67d07aa81499",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('finito')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848c7634-605d-4e5a-96b6-05e2ce7354cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Salvo strutture dati per \n",
    "\n",
    "1) Dati Filtrati\n",
    "2) Dati Non Filtrati (puri raw)\n",
    "\n",
    "'''\n",
    "\n",
    "import pickle\n",
    "\n",
    "# Salvare l'intero dizionario annidato con pickle\n",
    "path = '/home/stefano/EEGMMIDB_Analyses/'\n",
    "\n",
    "with open(f'{path}EEG_only_filtered_data.pkl', 'wb') as f:\n",
    "    pickle.dump(raw_collection, f) \n",
    "    \n",
    "with open(f'{path}EEG_unfiltered_data.pkl', 'wb') as f:\n",
    "    pickle.dump(raw_unfiltered_collection, f) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917e80e1-d918-482c-8b41-620b2e2c1d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Caricare l'intero dizionario annidato con pickle\n",
    "path = '/home/stefano/EEGMMIDB_Analyses/'\n",
    "\n",
    "# Caricare l'intero dizionario annidato con pickle\n",
    "with open(f'{path}EEG_only_filtered_data.pkl', 'rb') as f:\n",
    "    EEG_data_filtered = pickle.load(f)\n",
    "    \n",
    "    \n",
    "# Caricare l'intero dizionario annidato con pickle\n",
    "with open(f'{path}EEG_unfiltered_data.pkl', 'rb') as f:\n",
    "    EEG_data_unfiltered = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102917cd-f856-4b2f-8a12-471d631e511f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mne\n",
    "from IPython.display import clear_output\n",
    "import numpy as np\n",
    "\n",
    "def plot_comparison(raw_filt: mne.io.Raw, raw_unfilt: mne.io.Raw,\n",
    "                    start_sec: float = 0.0, duration_sec: float = 5.0,\n",
    "                    ch_start: int = 0, ch_end: int = 0):\n",
    "    \"\"\"\n",
    "    Estrae un segmento di durata duration_sec a partire da start_sec,\n",
    "    per i canali dal ch_start a ch_end (inclusi), e ne plotta il confronto filtrato vs non filtrato\n",
    "    usando due subplot (non filtrato sopra, filtrato sotto) e legenda centrale sotto.\n",
    "    \"\"\"\n",
    "    sfreq = raw_filt.info['sfreq']\n",
    "    start_samp = int(start_sec * sfreq)\n",
    "    stop_samp  = int((start_sec + duration_sec) * sfreq)\n",
    "    times = np.arange(start_samp, stop_samp) / sfreq\n",
    "    \n",
    "    microvolt_scale = 1e6\n",
    "    \n",
    "    # Configura figura con 2 righe, asse x condiviso\n",
    "    fig, (ax_unfilt, ax_filt) = plt.subplots(2, 1, sharex=True, figsize=(12, 8))\n",
    "    \n",
    "    # Plot dati non filtrati\n",
    "    for ch_idx in range(ch_start, ch_end + 1):\n",
    "        data_u = raw_unfilt.get_data(picks=[ch_idx]).squeeze()[start_samp:stop_samp] * microvolt_scale\n",
    "        ch_name = raw_filt.ch_names[ch_idx]\n",
    "        ax_unfilt.plot(times, data_u, label=ch_name, alpha=0.7)\n",
    "    ax_unfilt.set_title(f\"Non filtrato (Task={task}, Sbj={sbj}, Run={run})\")\n",
    "    ax_unfilt.set_ylabel(\"Ampiezza (µV)\")\n",
    "\n",
    "    # Plot dati filtrati\n",
    "    for ch_idx in range(ch_start, ch_end + 1):\n",
    "        data_f = raw_filt.get_data(picks=[ch_idx]).squeeze()[start_samp:stop_samp] * microvolt_scale\n",
    "        ch_name = raw_filt.ch_names[ch_idx]\n",
    "        ax_filt.plot(times, data_f, label=ch_name, alpha=0.7)\n",
    "    ax_filt.set_title(\"Filtrato (1-45Hz + notch 50Hz)\")\n",
    "    ax_filt.set_xlabel(\"Tempo (s)\")\n",
    "    ax_filt.set_ylabel(\"Ampiezza (µV)\")\n",
    "\n",
    "    # Legenda unica sotto i subplot\n",
    "    handles, labels = ax_unfilt.get_legend_handles_labels()\n",
    "    fig.legend(handles, labels, loc='lower center', ncol=min(len(labels), 6), bbox_to_anchor=(0.5, -0.05))\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(bottom=0.15)  # spazio per legenda\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# ------ MENU INTERATTIVO ------\n",
    "while True:\n",
    "    clear_output(wait=True)\n",
    "    cmd = input(\"Digita 'ok' per plottare o andare al soggetto successivo, 'stop' per uscire: \").strip().lower()\n",
    "    if cmd == 'stop':\n",
    "        confirm = input(\"Sei sicuro di voler uscire? ('ok' per confermare, continua per proseguire): \").strip().lower()\n",
    "        if confirm == 'ok':\n",
    "            print(\"Uscita confermata. Bye!\")\n",
    "            clear_output(wait=True)\n",
    "            break\n",
    "        else:\n",
    "            clear_output(wait=True)\n",
    "            continue\n",
    "    elif cmd != 'ok':\n",
    "        print(\"Comando non riconosciuto, digita 'ok' o 'stop'.\")\n",
    "        continue\n",
    "\n",
    "    # Ora procedi con scelta task, soggetto e run e plotting\n",
    "    task = input(f\"\\nScegli task tra {list(EEG_data_filtered.keys())}: \").strip()\n",
    "    if task not in EEG_data_filtered:\n",
    "        print(\"Task non valido.\")\n",
    "        continue\n",
    "\n",
    "    sbj = input(f\"\\nScegli soggetto tra {list(EEG_data_filtered[task].keys())}: \").strip()\n",
    "    if sbj not in EEG_data_filtered[task]:\n",
    "        print(\"Soggetto non valido.\")\n",
    "        continue\n",
    "\n",
    "    available_runs = list(EEG_data_filtered[task][sbj].keys())\n",
    "    run = int(input(f\"\\nScegli run tra {available_runs}: \").strip())\n",
    "    if run not in available_runs:\n",
    "        print(\"Run non valido.\")\n",
    "        continue\n",
    "\n",
    "    start_sec    = float(input(\"\\nStart time (s) [default 0]: \") or 0.0)\n",
    "    duration_sec = float(input(\"Duration (s) [default 5]: \") or 5.0)\n",
    "\n",
    "    raw_filt    = EEG_data_filtered[task][sbj][run][0]\n",
    "    raw_unfilt  = EEG_data_unfiltered[task][sbj][run][0]\n",
    "\n",
    "    # Stampa canali orizzontalmente\n",
    "    ch_names = raw_filt.ch_names\n",
    "    print(\"\\nElenco canali:\", \"  \".join(f\"\\033[1m{i}\\033[0m: \\033[1m{ch}\\033[0m\" for i,ch in enumerate(ch_names)))\n",
    "    max_idx = len(ch_names) - 1\n",
    "    ch_start = int(input(f\"Inizio canale [0–{max_idx}] [default 0]: \") or 0)\n",
    "    ch_end   = int(input(f\"Fine canale [0–{max_idx}] [default {ch_start}]: \") or ch_start)\n",
    "\n",
    "    plot_comparison(raw_filt, raw_unfilt,\n",
    "                    start_sec, duration_sec,\n",
    "                    ch_start, ch_end)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d49a03-7638-481a-863c-88ed9227300f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### **EEG Preprocessing - Data Quality Check Canali Post Filtering Stage Notch 60 and IIR 1-45Hz**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102d6a0a-526e-4867-9163-d7e61d4d6ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Caricare l'intero dizionario annidato con pickle\n",
    "path = '/home/stefano/EEGMMIDB_Analyses/'\n",
    "\n",
    "# Caricare l'intero dizionario annidato con pickle\n",
    "with open(f'{path}EEG_only_filtered_data.pkl', 'rb') as f:\n",
    "    EEG_data_filtered = pickle.load(f)\n",
    "    \n",
    "    \n",
    "# Caricare l'intero dizionario annidato con pickle\n",
    "with open(f'{path}EEG_unfiltered_data.pkl', 'rb') as f:\n",
    "    EEG_data_unfiltered = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f09a1d-803c-4265-ba73-8b42d637a07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Dopo che io ho filtrato i dati, vado a fare una esplorazione del valore di ogni canale per ogni task, soggetto e run. \n",
    "\n",
    "Ossia, vado a vedere per ogni canale quante volte, ossia quanti campioni superano la sogia di meno o più 100 microvolt, in valore assoluto.\n",
    "\n",
    "Questa cosa la faccio per ogni canale, soggetto, task e run. \n",
    "\n",
    "Vorrei vedere se c'è una certa consistenza o pattern nel modo in cui determinati canali, anche dopo il filtraggio, sono con dei valori sopra la soia consentita.\n",
    "Vorrei poi definire per ogni soggetto quali sono i canali che effettivamente creano problemi. \n",
    "\n",
    "Questo perché vorrei capire se c'è un problema comune per gli stessi canali tra i soggetti a parità di task e run, punto. \n",
    "\n",
    "A quel punto, se effettivamente c'è una certa consistenza, potremmo pensare di togliere questi canali. Può avere senso?\n",
    "\n",
    "'''\n",
    "print(EEG_data_filtered.keys())\n",
    "print(EEG_data_filtered['task_1'].keys())\n",
    "print(EEG_data_filtered['task_1']['100'].keys())\n",
    "print(type(EEG_data_filtered['task_1']['100'][0][0]))\n",
    "print(type(EEG_data_filtered['task_1']['100'][0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca548c84-5d33-4c0d-94ad-43b9d0a95784",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mne\n",
    "from IPython.display import clear_output\n",
    "import numpy as np\n",
    "\n",
    "def plot_comparison(raw_filt: mne.io.Raw, raw_unfilt: mne.io.Raw,\n",
    "                    start_sec: float = 0.0, duration_sec: float = 5.0,\n",
    "                    ch_start: int = 0, ch_end: int = 0):\n",
    "    \"\"\"\n",
    "    Estrae un segmento di durata duration_sec a partire da start_sec,\n",
    "    per i canali dal ch_start a ch_end (inclusi), e ne plotta il confronto filtrato vs non filtrato\n",
    "    usando due subplot (non filtrato sopra, filtrato sotto) e legenda centrale sotto.\n",
    "    \"\"\"\n",
    "    sfreq = raw_filt.info['sfreq']\n",
    "    start_samp = int(start_sec * sfreq)\n",
    "    stop_samp  = int((start_sec + duration_sec) * sfreq)\n",
    "    times = np.arange(start_samp, stop_samp) / sfreq\n",
    "    \n",
    "    microvolt_scale = 1e6\n",
    "    \n",
    "    # Configura figura con 2 righe, asse x condiviso\n",
    "    fig, (ax_unfilt, ax_filt) = plt.subplots(2, 1, sharex=True, figsize=(12, 8))\n",
    "    \n",
    "    # Plot dati non filtrati\n",
    "    for ch_idx in range(ch_start, ch_end + 1):\n",
    "        data_u = raw_unfilt.get_data(picks=[ch_idx]).squeeze()[start_samp:stop_samp] * microvolt_scale\n",
    "        ch_name = raw_filt.ch_names[ch_idx]\n",
    "        ax_unfilt.plot(times, data_u, label=ch_name, alpha=0.7)\n",
    "    ax_unfilt.set_title(f\"Non filtrato (Task={task}, Sbj={sbj}, Run={run})\")\n",
    "    ax_unfilt.set_ylabel(\"Ampiezza (µV)\")\n",
    "\n",
    "    # Plot dati filtrati\n",
    "    for ch_idx in range(ch_start, ch_end + 1):\n",
    "        data_f = raw_filt.get_data(picks=[ch_idx]).squeeze()[start_samp:stop_samp] * microvolt_scale\n",
    "        ch_name = raw_filt.ch_names[ch_idx]\n",
    "        ax_filt.plot(times, data_f, label=ch_name, alpha=0.7)\n",
    "    ax_filt.set_title(\"Filtrato (1-45Hz + notch 60Hz)\")\n",
    "    ax_filt.set_xlabel(\"Tempo (s)\")\n",
    "    ax_filt.set_ylabel(\"Ampiezza (µV)\")\n",
    "\n",
    "    # Legenda unica sotto i subplot\n",
    "    handles, labels = ax_unfilt.get_legend_handles_labels()\n",
    "    fig.legend(handles, labels, loc='lower center', ncol=min(len(labels), 6), bbox_to_anchor=(0.5, -0.05))\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(bottom=0.15)  # spazio per legenda\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# ------ MENU INTERATTIVO ------\n",
    "while True:\n",
    "    clear_output(wait=True)\n",
    "    cmd = input(\"Digita 'ok' per plottare o andare al soggetto successivo, 'stop' per uscire: \").strip().lower()\n",
    "    if cmd == 'stop':\n",
    "        confirm = input(\"Sei sicuro di voler uscire? ('ok' per confermare, continua per proseguire): \").strip().lower()\n",
    "        if confirm == 'ok':\n",
    "            print(\"Uscita confermata. Bye!\")\n",
    "            clear_output(wait=True)\n",
    "            break\n",
    "        else:\n",
    "            clear_output(wait=True)\n",
    "            continue\n",
    "    elif cmd != 'ok':\n",
    "        print(\"Comando non riconosciuto, digita 'ok' o 'stop'.\")\n",
    "        continue\n",
    "\n",
    "    # Ora procedi con scelta task, soggetto e run e plotting\n",
    "    task = input(f\"\\nScegli task tra {list(EEG_data_filtered.keys())}: \").strip()\n",
    "    if task not in EEG_data_filtered:\n",
    "        print(\"Task non valido.\")\n",
    "        continue\n",
    "\n",
    "    sbj = input(f\"\\nScegli soggetto tra {list(EEG_data_filtered[task].keys())}: \").strip()\n",
    "    if sbj not in EEG_data_filtered[task]:\n",
    "        print(\"Soggetto non valido.\")\n",
    "        continue\n",
    "\n",
    "    available_runs = list(EEG_data_filtered[task][sbj].keys())\n",
    "    run = int(input(f\"\\nScegli run tra {available_runs}: \").strip())\n",
    "    if run not in available_runs:\n",
    "        print(\"Run non valido.\")\n",
    "        continue\n",
    "\n",
    "    start_sec    = float(input(\"\\nStart time (s) [default 0]: \") or 0.0)\n",
    "    duration_sec = float(input(\"Duration (s) [default 5]: \") or 5.0)\n",
    "\n",
    "    raw_filt    = EEG_data_filtered[task][sbj][run][0]\n",
    "    raw_unfilt  = EEG_data_unfiltered[task][sbj][run][0]\n",
    "\n",
    "    # Stampa canali orizzontalmente\n",
    "    ch_names = raw_filt.ch_names\n",
    "    print(\"\\nElenco canali:\", \"  \".join(f\"\\033[1m{i}\\033[0m: \\033[1m{ch}\\033[0m\" for i,ch in enumerate(ch_names)))\n",
    "    max_idx = len(ch_names) - 1\n",
    "    ch_start = int(input(f\"Inizio canale [0–{max_idx}] [default 0]: \") or 0)\n",
    "    ch_end   = int(input(f\"Fine canale [0–{max_idx}] [default {ch_start}]: \") or ch_start)\n",
    "\n",
    "    plot_comparison(raw_filt, raw_unfilt,\n",
    "                    start_sec, duration_sec,\n",
    "                    ch_start, ch_end)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c8bbc2-a4da-4def-97ce-5dec122d3336",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### **EEG Preprocessing - Cleaning via PyPREP Pipeline**\n",
    "\n",
    "#### **PyPrep con oggetto PrepPipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98435ea-0664-4b1d-9758-d69cfada2882",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Ottimo — prendo esattamente la tua funzione e ci innesto (senza stravolgerla):\n",
    "\n",
    "un checkpoint opzionale per-run (salvo il Raw pulito in .fif, salvo le labels in file a parte, e salvo il mini log della run in CSV);\n",
    "\n",
    "la ripartenza che salta le run già fatte e le ricarica dal disco ricostruendo la stessa struttura (Raw pulito, labels);\n",
    "\n",
    "i metadati ref_max_iterations e converged (True se n_iter < ref_max_iterations, False se uguale, None se l’informazione non è disponibile);\n",
    "\n",
    "nessuna modifica alla forma dell’output in RAM: sempre dict nidificato; ogni run: Raw oppure (Raw, labels).\n",
    "\n",
    "Di seguito trovi:\n",
    "\n",
    "due piccoli helper per checkpoint;\n",
    "\n",
    "la tua funzione aggiornata (solo aggiunte, il resto resta come l’hai scritto);\n",
    "\n",
    "un esempio d’uso.\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "#1) Helper per checkpoint (salvataggio/ricarica per-run)\n",
    "\n",
    "import os, json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mne\n",
    "import pickle\n",
    "from typing import Any, Tuple\n",
    "\n",
    "'''\n",
    "1) _paths(base): crea (se non ci sono) le cartelle:\n",
    "\n",
    "raw_prep_fif/ (per i .fif)\n",
    "labels/ (per le labels in vari formati)\n",
    "logs_per_run/ (csv per-run)\n",
    "completed_runs.json (indice delle run già fatte)\n",
    "\n",
    "\n",
    "2) _key(task, subj, run): genera una chiave hashable per indicizzare la run. (Vedi nota sopra: meglio tornare una tupla).\n",
    "\n",
    "3) _load_done / _save_done: caricano/salvano l’insieme di chiavi “già fatte”.\n",
    "\n",
    "4) _save_labels / _load_labels: serializzano labels in vari formati (npz, csv, json, annotations come CSV, pickle fallback) e le ricaricano.\n",
    "\n",
    "    Nota: se vuoi ricostruire davvero un mne.Annotations (e non un DataFrame), in _load_labels quando trovi annotations_csv puoi fare:\n",
    "    \n",
    "    df = pd.read_csv(p)\n",
    "    return mne.Annotations(onset=df['onset'], duration=df['duration'], description=df['description'])\n",
    "    \n",
    "    … adegua i nomi colonnari a quelli che hai salvato.\n",
    "\n",
    "5) _save_run_checkpoint: salva il raw .fif, le labels (via _save_labels) e il mini-log per-run (csv) nelle loro cartelle dedicate, e restituisce i path/meta utili.\n",
    "\n",
    "6) _load_run_checkpoint: ricarica il raw .fif, cerca labels nei formati supportati e ritorna anche il mini-log csv se esiste.\n",
    "\n",
    "\n",
    "'''\n",
    "def _paths(base: str) -> Tuple[Path, Path, Path, Path]:\n",
    "    base = Path(base)\n",
    "    raw_dir = base / \"raw_prep_fif\"\n",
    "    lbl_dir = base / \"labels\"\n",
    "    log_dir = base / \"logs_per_run\"\n",
    "    idx_json = base / \"completed_runs.json\"\n",
    "    raw_dir.mkdir(parents=True, exist_ok=True)\n",
    "    lbl_dir.mkdir(parents=True, exist_ok=True)\n",
    "    log_dir.mkdir(parents=True, exist_ok=True)\n",
    "    return raw_dir, lbl_dir, log_dir, idx_json\n",
    "\n",
    "def _key(task, subj, run):\n",
    "    #return [str(task), str(subj), int(run)]\n",
    "    \n",
    "    return (str(task), str(subj), int(run))\n",
    "\n",
    "def _load_done(idx_json: Path):\n",
    "    if idx_json.exists():\n",
    "        return {tuple(x) for x in json.loads(idx_json.read_text())}\n",
    "    return set()\n",
    "\n",
    "def _save_done(idx_json: Path, done_set):\n",
    "    idx_json.write_text(json.dumps([list(x) for x in done_set]))\n",
    "\n",
    "def _save_labels(lbl_dir: Path, task, subj, run, labels: Any) -> dict:\n",
    "    \"\"\"Salva labels in vari formati comuni; ritorna un dict meta {kind, path}.\"\"\"\n",
    "    if labels is None:\n",
    "        return {\"kind\": \"none\", \"path\": None}\n",
    "    out_dir = lbl_dir / str(task) / str(subj)\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    base = out_dir / f\"run-{run}\"\n",
    "    if isinstance(labels, np.ndarray):\n",
    "        path = base.with_suffix(\".npz\")\n",
    "        np.savez_compressed(path, labels=labels)\n",
    "        return {\"kind\": \"npz\", \"path\": str(path)}\n",
    "    if isinstance(labels, pd.DataFrame):\n",
    "        path = base.with_suffix(\".csv\")\n",
    "        labels.to_csv(path, index=False)\n",
    "        return {\"kind\": \"csv\", \"path\": str(path)}\n",
    "    if isinstance(labels, dict):\n",
    "        path = base.with_suffix(\".json\")\n",
    "        path.write_text(json.dumps(labels))\n",
    "        return {\"kind\": \"json\", \"path\": str(path)}\n",
    "    if isinstance(labels, mne.Annotations):\n",
    "        # serializza come tabella semplice\n",
    "        df = labels.to_data_frame()\n",
    "        path = base.with_suffix(\".annotations.csv\")\n",
    "        df.to_csv(path, index=False)\n",
    "        return {\"kind\": \"annotations_csv\", \"path\": str(path)}\n",
    "    # fallback: pickle\n",
    "    path = base.with_suffix(\".pkl\")\n",
    "    with open(path, \"wb\") as f:\n",
    "        pickle.dump(labels, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    return {\"kind\": \"pickle\", \"path\": str(path)}\n",
    "\n",
    "def _load_labels(meta: dict):\n",
    "    kind = meta.get(\"kind\"); path = meta.get(\"path\")\n",
    "    if kind in (None, \"none\") or not path:\n",
    "        return None\n",
    "    p = Path(path)\n",
    "    if kind == \"npz\":\n",
    "        return np.load(p)[\"labels\"]\n",
    "    if kind == \"csv\":\n",
    "        return pd.read_csv(p)\n",
    "    if kind == \"json\":\n",
    "        return json.loads(p.read_text())\n",
    "    if kind == \"annotations_csv\":\n",
    "        return pd.read_csv(p)  # ricostruisci mne.Annotations qui se ti serve\n",
    "    if kind == \"pickle\":\n",
    "        with open(p, \"rb\") as f:\n",
    "            return pickle.load(f)\n",
    "    return None\n",
    "\n",
    "def _save_run_checkpoint(base_dir: str, task, subj, run, raw, labels, run_log_df: pd.DataFrame):\n",
    "    raw_dir, lbl_dir, log_dir, idx_json = _paths(base_dir)\n",
    "    # Raw -> FIF\n",
    "    out_dir = raw_dir / str(task) / str(subj)\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    fif_path = out_dir / f\"run-{run}_prep-raw.fif\"\n",
    "    raw.save(fif_path.as_posix(), overwrite=True)\n",
    "    # labels\n",
    "    lbl_meta = _save_labels(lbl_dir, task, subj, run, labels)\n",
    "    # mini-log per-run\n",
    "    log_out_dir = log_dir / str(task) / str(subj)\n",
    "    log_out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    #1) Scrittura del mini-log per-run in _save_run_checkpoint\n",
    "    \n",
    "    #Perché: nel tuo codice fai (...).write_text(run_log_df.to_csv(index=False)).\n",
    "    #to_csv restituisce già una stringa, quindi write_text(...) va ma è superfluo. \n",
    "    #Meglio lasciare che sia pandas a scrivere il file direttamente: è più pulito e gestisce anche l’encoding.\n",
    "\n",
    "    #(log_out_dir / f\"run-{run}.csv\").write_text(run_log_df.to_csv(index=False))\n",
    "    \n",
    "    #Niente cambia nel comportamento, solo più solido/idiomatico.\n",
    "    run_log_path = log_out_dir / f\"run-{run}.csv\"\n",
    "    run_log_df.to_csv(run_log_path, index=False)\n",
    "\n",
    "    return str(fif_path), lbl_meta\n",
    "\n",
    "def _load_run_checkpoint(base_dir: str, task, subj, run):\n",
    "    raw_dir, lbl_dir, log_dir, idx_json = _paths(base_dir)\n",
    "    fif_path = raw_dir / str(task) / str(subj) / f\"run-{run}_prep-raw.fif\"\n",
    "    raw = mne.io.read_raw_fif(fif_path.as_posix(), preload=True)\n",
    "    # labels: cerca nei formati salvati\n",
    "    base = lbl_dir / str(task) / str(subj) / f\"run-{run}\"\n",
    "    labels = None\n",
    "    for cand in [base.with_suffix(s) for s in (\".npz\",\".csv\",\".json\",\".annotations.csv\",\".pkl\")]:\n",
    "        if cand.exists():\n",
    "            # ricava kind\n",
    "            if cand.suffix == \".npz\":\n",
    "                meta = {\"kind\":\"npz\",\"path\":str(cand)}\n",
    "            elif cand.name.endswith(\".annotations.csv\"):\n",
    "                meta = {\"kind\":\"annotations_csv\",\"path\":str(cand)}\n",
    "            elif cand.suffix == \".csv\":\n",
    "                meta = {\"kind\":\"csv\",\"path\":str(cand)}\n",
    "            elif cand.suffix == \".json\":\n",
    "                meta = {\"kind\":\"json\",\"path\":str(cand)}\n",
    "            else:\n",
    "                meta = {\"kind\":\"pickle\",\"path\":str(cand)}\n",
    "            labels = _load_labels(meta)\n",
    "            break\n",
    "    # mini-log\n",
    "    run_log = None\n",
    "    run_log_path = log_dir / str(task) / str(subj) / f\"run-{run}.csv\"\n",
    "    if run_log_path.exists():\n",
    "        run_log = pd.read_csv(run_log_path)\n",
    "    return raw, labels, run_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe962f2e-d561-40cb-a3c1-943a081850a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Codice: pipeline end-to-end (riusa i tuoi helper di checkpoint)\n",
    "'''\n",
    "\n",
    "from typing import Dict, Tuple, List, Any, Optional\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mne\n",
    "\n",
    "# NEW: importa la pipeline\n",
    "from pyprep.prep_pipeline import PrepPipeline\n",
    "\n",
    "# --- riusa i TUOI helper già definiti ---\n",
    "# _paths, _key, _load_done, _save_done, _save_labels, _load_labels,\n",
    "# _save_run_checkpoint, _load_run_checkpoint\n",
    "# (li lascio invariati: incollarli così come li hai già)\n",
    "\n",
    "def _safe_list(x):\n",
    "    \"\"\"Rende lista in modo robusto (anche se None o np.ndarray scalare).\"\"\"\n",
    "    if x is None:\n",
    "        return []\n",
    "    if isinstance(x, (list, tuple, set)):\n",
    "        return list(x)\n",
    "    try:\n",
    "        return list(x)\n",
    "    except Exception:\n",
    "        return [x]\n",
    "\n",
    "def _get_attr_any(obj, *names):\n",
    "    \"\"\"Ritorna il primo attributo esistente tra quelli elencati (altrimenti None).\"\"\"\n",
    "    for n in names:\n",
    "        if hasattr(obj, n):\n",
    "            return getattr(obj, n)\n",
    "    return None\n",
    "\n",
    "def _extract_pipeline_lists(prep: Any) -> Tuple[List[str], List[str], List[str], Optional[int]]:\n",
    "    \"\"\"\n",
    "    Estrae in modo cross-version:\n",
    "      - pre_ref_bad_channels         (bad_before_interpolation)\n",
    "      - interpolated_channels\n",
    "      - post_interp_residual_channels (still_noisy_channels)\n",
    "      - n_iter (se esposto)\n",
    "    \"\"\"\n",
    "    pre_ref_bad = _safe_list(_get_attr_any(\n",
    "        prep,\n",
    "        \"bad_before_interpolation\",      # nome comune\n",
    "        \"excluded_before_interpolation\", # in alcune versioni\n",
    "    ))\n",
    "    interpolated = _safe_list(_get_attr_any(\n",
    "        prep, \"interpolated_channels\", \"interpolated\"\n",
    "    ))\n",
    "    still_noisy = _safe_list(_get_attr_any(\n",
    "        prep, \"still_noisy_channels\", \"final_noisy_channels\", \"ref_still_noisy_channels\"\n",
    "    ))\n",
    "    # iterazioni effettive (se disponibile)\n",
    "    n_iter = _get_attr_any(prep, \"n_iterations_\", \"n_iterations\", \"iterations\")\n",
    "    try:\n",
    "        n_iter = int(n_iter) if n_iter is not None else None\n",
    "    except Exception:\n",
    "        n_iter = None\n",
    "\n",
    "    # ordina e de-duplica\n",
    "    pre_ref_bad = sorted(set(pre_ref_bad))\n",
    "    interpolated = sorted(set(interpolated))\n",
    "    still_noisy = sorted(set(still_noisy))\n",
    "    return pre_ref_bad, interpolated, still_noisy, n_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a885f13-8491-4633-b0eb-e8f289cbd430",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Cosa fa la run_preppipeline_on_nested step-by-step\n",
    "\n",
    "Riassumo il flusso della versione “end-to-end” che ti ho passato:\n",
    "\n",
    "Checkpoint setup\n",
    "Crea/simula raw_prep_fif/, labels/, logs_per_run/, legge completed_runs.json.\n",
    "\n",
    "Loop su task → subject → run\n",
    "Mantiene la stessa struttura in output.\n",
    "\n",
    "Skip run già completate\n",
    "Se la run è in done, carica da disco (_load_run_checkpoint) e aggiunge il mini-log.\n",
    "\n",
    "Normalizza input\n",
    "Supporta Raw o (Raw, labels). Copia il Raw e fa .load_data().\n",
    "\n",
    "Controllo montage\n",
    "Se non c’è un montage/dig, solleva un errore chiaro (l’interpolazione ne ha bisogno).\n",
    "\n",
    "\n",
    "\n",
    "Costruisce i parametri della pipeline\n",
    "\n",
    "\n",
    "prep_params = {\n",
    "    \"ref_chs\": \"eeg\",       # usa tutti gli EEG per stimare la ref\n",
    "    \"reref_chs\": \"eeg\",     # re-referenzia tutti gli EEG\n",
    "    \"max_iterations\": 4,\n",
    "    # \"line_freqs\": None  # (nel tuo caso)\n",
    "}\n",
    "\n",
    "\n",
    "Esegue la pipeline\n",
    "\n",
    "prep = PrepPipeline(raw_in, prep_params, montage=montage)\n",
    "prep.fit()\n",
    "raw_out = prep.raw  # Raw pulito\n",
    "\n",
    "Estrae le liste chiave (cross-version)\n",
    "Con un helper robusto prende:\n",
    "\n",
    "pre_ref_bad_channels ← bad_before_interpolation\n",
    "\n",
    "interpolated_channels\n",
    "\n",
    "post_interp_residual_channels ← still_noisy_channels\n",
    "\n",
    "n_iter (se disponibile)\n",
    "\n",
    "Deriva i bad after-ref (pre-interp)\n",
    "post_ref_bad_channels = interpolated − pre_ref (vedi punto 2).\n",
    "\n",
    "Convergenza\n",
    "converged = (n_iter is not None) and (n_iter < max_iterations).\n",
    "\n",
    "Log per-canale (mini-log)\n",
    "Per ogni canale salva: liste pre/post, flag was_interpolated, bad_any_post, e meta (iterazioni, convergenza).\n",
    "Scrive il CSV per-run in logs_per_run/task/subject/run-*.csv.\n",
    "\n",
    "Checkpoint salvataggio\n",
    "Salva il .fif pulito, le labels (se presenti) e aggiorna completed_runs.json.\n",
    "\n",
    "Output in RAM\n",
    "Rimonta la stessa struttura: Raw oppure (Raw, labels).\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf533305-92a6-4175-9f1a-310e855e2330",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_preppipeline_on_nested(\n",
    "    EEG_data_filtered: Dict[str, Dict[str, Dict[int, Any]]],\n",
    "    checkpoint_dir: Optional[str] = None,\n",
    "    skip_completed: bool = True,\n",
    "    \n",
    "    # parametri PREP/REF\n",
    "    max_iterations: int = 4,\n",
    "    line_freqs: Optional[List[float]] = None,   # es. [50] o [60]; se None, lascia alla pipeline\n",
    ") -> Tuple[Dict[str, Dict[str, Dict[int, Any]]], pd.DataFrame]:\n",
    "    \n",
    "    \"\"\"\n",
    "    Versione 'end-to-end' con PrepPipeline:\n",
    "    - in:  dict nidificato task -> subject -> run -> Raw oppure (Raw, labels)\n",
    "    - out: stessa forma (Raw pulito o (Raw pulito, labels)) + prep_log per-canale\n",
    "    - checkpoint: identico al tuo\n",
    "    \"\"\"\n",
    "    \n",
    "    if checkpoint_dir:\n",
    "        raw_dir, lbl_dir, log_dir, idx_json = _paths(checkpoint_dir)\n",
    "        done = _load_done(idx_json)\n",
    "    else:\n",
    "        done = set()\n",
    "\n",
    "    EEG_data_prep: Dict[str, Dict[str, Dict[int, Any]]] = {}\n",
    "    all_log_rows: List[Dict[str, Any]] = []\n",
    "\n",
    "    for task, subjs in EEG_data_filtered.items():\n",
    "        EEG_data_prep.setdefault(task, {})\n",
    "        for subj, runs in subjs.items():\n",
    "            EEG_data_prep[task].setdefault(subj, {})\n",
    "\n",
    "            for run, value in runs.items():\n",
    "                key = _key(task, subj, run)\n",
    "\n",
    "                # checkpoint: salta se già fatto\n",
    "                if checkpoint_dir and skip_completed and key in done:\n",
    "                    raw_loaded, labels_loaded, run_log_df = _load_run_checkpoint(checkpoint_dir, task, subj, run)\n",
    "                    EEG_data_prep[task][subj][run] = (raw_loaded, labels_loaded) if labels_loaded is not None else raw_loaded\n",
    "                    if run_log_df is not None:\n",
    "                        all_log_rows.extend(run_log_df.to_dict(\"records\"))\n",
    "                    continue\n",
    "\n",
    "                # normalizza input (Raw oppure (Raw, labels))\n",
    "                if isinstance(value, tuple) and len(value) >= 1:\n",
    "                    raw_in = value[0]\n",
    "                    labels = value[1] if len(value) > 1 else None\n",
    "                else:\n",
    "                    raw_in = value\n",
    "                    labels = None\n",
    "\n",
    "                if not isinstance(raw_in, mne.io.BaseRaw):\n",
    "                    raise TypeError(\n",
    "                        f\"Atteso mne.io.Raw o (Raw, labels), trovato {type(raw_in)} in {task}/{subj}/{run}\"\n",
    "                    )\n",
    "\n",
    "                raw_in = raw_in.copy().load_data()  # dati già filtrati (come prima)\n",
    "\n",
    "                # --- MONTAGE: PrepPipeline richiede posizioni sensori coerenti per interpolare ---\n",
    "                # Se non hai già un montage su raw_in, impostalo PRIMA (altrimenti l’interpolazione fallisce)\n",
    "                montage = raw_in.get_montage()\n",
    "                if montage is None and (raw_in.info.get(\"dig\") is None):\n",
    "                    \n",
    "                    # Se NON hai un montage definito, è meglio fermarsi esplicitamente:\n",
    "                    raise RuntimeError(\n",
    "                        f\"Nessun montage trovato in {task}/{subj}/{run}. \"\n",
    "                        \"Imposta un montage (es. standard_1020) prima di chiamare la pipeline.\"\n",
    "                    )\n",
    "\n",
    "                # --- Parametri PrepPipeline ---\n",
    "                # ref_chs / reref_chs: usa tutti gli EEG; la pipeline escluderà i bad nelle iterazioni.\n",
    "                \n",
    "                #Note:\n",
    "\n",
    "                #Non serve convertirla in np.array; una lista va benissimo (la pipeline fa solo len(...)).\n",
    "                #Se hai già fatto il notch a 60 Hz, tieni line_freqs = [].\n",
    "                #Se vuoi far rimuovere a PREP il line-noise, passa ad es. [60] o [50] a seconda della rete.\n",
    "\n",
    "                # 1) Normalizza line_freqs\n",
    "                if line_freqs is None:\n",
    "                    line_freqs = []                 # già notchato: niente rimozione linea\n",
    "                else:\n",
    "                    line_freqs = [float(f) for f in line_freqs]  # es. [50], [60], [50, 100]\n",
    "    \n",
    "                # 2) Costruisci i params includendo SEMPRE la chiave\n",
    "                prep_params = {\n",
    "                    \"ref_chs\": \"eeg\",\n",
    "                    \"reref_chs\": \"eeg\",\n",
    "                    \"max_iterations\": int(max_iterations),\n",
    "                    \"line_freqs\": line_freqs,\n",
    "                }\n",
    "\n",
    "\n",
    "                # --- Esegui PrepPipeline ---\n",
    "                \n",
    "                #https://pyprep.readthedocs.io/en/latest/generated/pyprep.PrepPipeline.html\n",
    "                \n",
    "                prep = PrepPipeline(raw_in, prep_params, montage=montage)\n",
    "                prep.fit()\n",
    "\n",
    "                # Raw pulito prodotto dalla pipeline\n",
    "                raw_out = _get_attr_any(prep, \"raw\", \"raw_out\")\n",
    "                if raw_out is None:\n",
    "                    # fallback conservativo: se per qualche ragione non esposto, usa raw_in\n",
    "                    raw_out = raw_in.copy()\n",
    "\n",
    "                # Estrai liste chiave (cross-version)\n",
    "                pre_ref_bad_channels, interpolated_channels, post_interp_residual_channels, n_iter = \\\n",
    "                    _extract_pipeline_lists(prep)\n",
    "\n",
    "                # Proxy dei bad AFTER-REF (pre-interp): nuovi bad emersi durante la robust ref\n",
    "                post_ref_bad_channels = sorted(\n",
    "                    set(interpolated_channels) - set(pre_ref_bad_channels)\n",
    "                )\n",
    "\n",
    "                # convergenza (se disponibile)\n",
    "                ref_max_iterations = max_iterations\n",
    "                converged = (n_iter is not None) and (n_iter < ref_max_iterations)\n",
    "\n",
    "                # --- LOG per-canale (più snello: niente A1/A2/B, niente amp-gate) ---\n",
    "                run_rows = []\n",
    "                for ch in raw_out.ch_names:\n",
    "                    run_rows.append({\n",
    "                        \"task\": task,\n",
    "                        \"subject\": subj,\n",
    "                        \"run\": run,\n",
    "                        \"channel\": ch,\n",
    "\n",
    "                        # fasi chiare\n",
    "                        \"pre_ref_bad_channels\": pre_ref_bad_channels,\n",
    "                        \"post_ref_bad_channels\": post_ref_bad_channels,\n",
    "                        \"interpolated_channels\": interpolated_channels,\n",
    "                        \"post_interp_residual_channels\": post_interp_residual_channels,\n",
    "\n",
    "                        # indicatori per-canale\n",
    "                        \"was_interpolated\": int(ch in interpolated_channels),\n",
    "                        \"bad_any_post\": int(ch in post_interp_residual_channels),\n",
    "\n",
    "                        # meta ref\n",
    "                        \"ref_n_iterations\": n_iter,\n",
    "                        \"ref_max_iterations\": ref_max_iterations,\n",
    "                        \"ref_converged\": converged,\n",
    "                    })\n",
    "                all_log_rows.extend(run_rows)\n",
    "\n",
    "                # --- checkpoint per-run (identico al tuo)\n",
    "                if checkpoint_dir:\n",
    "                    run_log_df = pd.DataFrame(run_rows)\n",
    "                    _save_run_checkpoint(checkpoint_dir, task, subj, run, raw_out, labels, run_log_df)\n",
    "                    done.add(key)\n",
    "                    _save_done(idx_json, done)\n",
    "\n",
    "                # --- salva in RAM (stessa forma dell'input)\n",
    "                if labels is None:\n",
    "                    EEG_data_prep[task][subj][run] = raw_out\n",
    "                else:\n",
    "                    EEG_data_prep[task][subj][run] = (raw_out, labels)\n",
    "\n",
    "    prep_log = pd.DataFrame(all_log_rows).sort_values([\"task\", \"subject\", \"run\", \"channel\"])\n",
    "    return EEG_data_prep, prep_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66917db-5d59-4c6e-80e5-bfd94d2bd346",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "EEG_data_prep, prep_log = run_preppipeline_on_nested(\n",
    "    EEG_data_filtered,\n",
    "    checkpoint_dir=\"/home/stefano/EEGMMIDB_Analyses/pyprep_outputs\",  # oppure None\n",
    "    skip_completed=True,\n",
    "    max_iterations=4,\n",
    "    line_freqs=None  # già fatto il notch a 60 Hz\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68b9062-58f1-4904-a286-74ea3d126166",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dd22ad96-ea42-466f-9c3a-45b05a222c18",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### **Salvataggio strutture dati DOPO pipeline PyPrep**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190b3837-a230-4adb-a39c-ad8098def854",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(EEG_data_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a622f02-8293-47a9-9e7d-cf8c87715ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "IO:\n",
    "\n",
    "Ma scusa tanto comunque la mia struttura EEG_data_prep sta iterativamente salvando al suo interno i dati di tutti i soggetti, task e runs.. giusto?\n",
    "\n",
    "per cui alla fine il salvataggio lo sta già facendo gradualmente.. e per cui se faccio \n",
    "\n",
    "# 1) salva i Dati Ricostruiti\n",
    "\n",
    "import pickle\n",
    "\n",
    "base = '/home/stefano/EEGMMIDB_Analyses/'  # cartella di destinazione\n",
    "\n",
    "with open(f\"{base}EEG_post_pyprep_data.pkl\", \"wb\") as f:\n",
    "    pickle.dump(EEG_data_prep, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "dovrebbe essere abbastanza ok come cosa no?\n",
    "\n",
    "e la stessa cosa per \n",
    "\n",
    "# 2) salva i log/tabelloni\n",
    "\n",
    "prep_log.to_csv(f\"{path}prep_log.csv\", index=False)\n",
    "\n",
    "se volessi salvarmi il file completo di tutti i log dei dati di tutti i soggetti, task e runs?\n",
    "\n",
    "\n",
    "\n",
    "CHATGPT:\n",
    "Esatto, hai centrato il punto 👍\n",
    "\n",
    "Durante l’esecuzione, la pipeline sta già popolando EEG_data_prep con tutti i (Raw_pulito, labels) per ogni task → subject → run\n",
    "\n",
    "Alla fine, fare il tuo pickle.dump(...) è sufficiente per salvare tutta la struttura completa in un colpo solo\n",
    "\n",
    "Stessa cosa per prep_log: alla fine della pipeline, se prep_log contiene tutte le righe accumulate di tutti i soggetti/task/run, un semplice\n",
    "\n",
    "python\n",
    "Copia\n",
    "Modifica\n",
    "prep_log.to_csv(f\"{base}prep_log.csv\", index=False)\n",
    "ti salva il file unico e completo\n",
    "\n",
    "📌 In pratica:\n",
    "\n",
    "EEG_data_prep → salvi l’oggetto Python (dati Raw + labels)\n",
    "\n",
    "prep_log → salvi il tabellone completo in CSV\n",
    "\n",
    "💡 Ti segnalo solo che, se i tuoi dati sono grandi, il .pkl potrebbe essere pesante e lento da ricaricare; \n",
    "se in futuro ti servisse, potresti anche salvare i .fif separati nei checkpoint e poi ricostruire la struttura a runtime.\n",
    "\n",
    "Vuoi che ti scriva anche il loader “ufficiale” per ricaricare EEG_data_prep e prep_log insieme e ripristinare tutto in un colpo?\n",
    "\n",
    "\n",
    "Salvo strutture dati per \n",
    "\n",
    "1) Dati Ripulti dopo PyPREP \n",
    "2) Log dei Dati Ripulti dopo PyPREP \n",
    "\n",
    "\n",
    "Se salvi prep_log con pickle (o joblib), il DataFrame manterrà esattamente:\n",
    "\n",
    "Tutti i tipi originali di ogni colonna (liste, dict, array ecc.)\n",
    "L’indice originale (index)\n",
    "\n",
    "Eventuali tipi complessi che nel CSV diventerebbero stringhe\n",
    "\n",
    "'''\n",
    "\n",
    "import pickle\n",
    "\n",
    "# Salvare l'intero dizionario annidato con pickle\n",
    "path = '/home/stefano/EEGMMIDB_Analyses/pyprep_outputs/'\n",
    "\n",
    "# 1) salva i dati preppati (Raw o (Raw, labels))\n",
    "with open(f\"{path}EEG_post_pyprep_data.pkl\", \"wb\") as f:\n",
    "    pickle.dump(EEG_data_prep, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "# 2) salva i log/tabelloni\n",
    "#prep_log.to_csv(f\"{path}prep_log.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a614e13-a6dd-4b86-b9c9-bd34af7bbc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Salvare l'intero dizionario annidato con pickle\n",
    "path = '/home/stefano/EEGMMIDB_Analyses/pyprep_outputs/'\n",
    "\n",
    "# 1) salva i dati preppati (Raw o (Raw, labels))\n",
    "with open(f\"{path}prep_log.pkl\", \"wb\") as f:\n",
    "    pickle.dump(prep_log, f, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1af37c3-46ac-4d23-9d67-a1d0292a9fea",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### **EEG Preprocessing - Data Quality Check Canali Post PyPrep Stage**\n",
    "##### **Visual Inspection - Data Comparison between files 1) EEG_prep_data and 2) EEG_data_filtered**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edddd941-27da-4cba-8458-5e9c088ca27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Caricare l'intero dizionario annidato con pickle\n",
    "path = '/home/stefano/EEGMMIDB_Analyses/'\n",
    "\n",
    "# Caricare l'intero dizionario annidato con pickle\n",
    "with open(f'{path}EEG_only_filtered_data.pkl', 'rb') as f:\n",
    "    EEG_data_filtered = pickle.load(f)\n",
    "    \n",
    "\n",
    "path_post_prep = '/home/stefano/EEGMMIDB_Analyses/pyprep_outputs/'\n",
    "\n",
    "# Caricare l'intero dizionario annidato con pickle\n",
    "with open(f'{path_post_prep}EEG_post_pyprep_data.pkl', 'rb') as f:\n",
    "    EEG_data_prep = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7b7d74-bc80-42be-932e-5b8eb4779b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Ora, posso ri-usare questo codice per vedere se i dati son stati ripuliti correttamente, prima di passarli alla mia ICA custom,\n",
    "confrontano \n",
    "\n",
    "1) i dati solo pre-filtrati con \n",
    "2) i dati post pipeline prep, ossia quelli dopo esser passati e ripuliti con la pipeline pyprep?\n",
    "\n",
    "'''\n",
    "\n",
    "# import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mne\n",
    "from IPython.display import clear_output\n",
    "    \n",
    "    \n",
    "def plot_comparison(raw_filt: mne.io.Raw, raw_prep: mne.io.Raw,\n",
    "                    start_sec: float = 0.0, duration_sec: float = 5.0,\n",
    "                    ch_start: int = 0, ch_end: int = 0):\n",
    "    \"\"\"\n",
    "    Estrae un segmento di durata duration_sec a partire da start_sec,\n",
    "    per i canali dal ch_start a ch_end (inclusi), e ne plotta il confronto filtrato vs non filtrato\n",
    "    usando due subplot (non filtrato sopra, filtrato sotto) e legenda centrale sotto.\n",
    "    \"\"\"\n",
    "    sfreq = raw_filt.info['sfreq']\n",
    "    start_samp = int(start_sec * sfreq)\n",
    "    stop_samp  = int((start_sec + duration_sec) * sfreq)\n",
    "    times = np.arange(start_samp, stop_samp) / sfreq\n",
    "    \n",
    "    microvolt_scale = 1e6\n",
    "    \n",
    "    # Configura figura con 2 righe, asse x condiviso\n",
    "    fig, (ax_filt, ax_prep) = plt.subplots(2, 1, sharex=True, figsize=(12, 8))\n",
    "\n",
    "    # PRE (filtrato prima di PyPREP)\n",
    "    for ch_idx in range(ch_start, ch_end + 1):\n",
    "        data_filtered = raw_filt.get_data(picks=[ch_idx]).squeeze()[start_samp:stop_samp] * microvolt_scale\n",
    "        ch_name = raw_filt.ch_names[ch_idx]\n",
    "        ax_filt.plot(times, data_filtered, label=ch_name, alpha=0.7)\n",
    "    ax_filt.set_title(\"PRE PyPREP\")\n",
    "    ax_filt.set_xlabel(\"Tempo (s)\")\n",
    "    ax_filt.set_ylabel(\"Ampiezza (µV)\")\n",
    "    \n",
    "    # POST (dopo PyPREP)\n",
    "    \n",
    "    for ch_idx in range(ch_start, ch_end + 1):\n",
    "        data_prep = raw_prep.get_data(picks=[ch_idx]).squeeze()[start_samp:stop_samp] * microvolt_scale\n",
    "        ch_name = raw_prep.ch_names[ch_idx]\n",
    "        ax_prep.plot(times, data_prep, label=ch_name, alpha=0.7)\n",
    "    ax_prep.set_title(f\"POST PyPREP\")\n",
    "    ax_prep.set_ylabel(\"Ampiezza (µV)\")\n",
    "    \n",
    "    \n",
    "    # Legenda unica sotto i subplot\n",
    "    handles, labels = ax_prep.get_legend_handles_labels()\n",
    "    fig.legend(handles, labels, loc='lower center', ncol=min(len(labels), 6), bbox_to_anchor=(0.5, -0.05))\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(bottom=0.15)  # spazio per legenda\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# ------ MENU INTERATTIVO ------\n",
    "while True:\n",
    "    clear_output(wait=True)\n",
    "    cmd = input(\"Digita 'ok' per plottare o andare al soggetto successivo, 'stop' per uscire: \").strip().lower()\n",
    "    if cmd == 'stop':\n",
    "        confirm = input(\"Sei sicuro di voler uscire? ('ok' per confermare, continua per proseguire): \").strip().lower()\n",
    "        if confirm == 'ok':\n",
    "            print(\"Uscita confermata. Bye!\")\n",
    "            clear_output(wait=True)\n",
    "            break\n",
    "        else:\n",
    "            clear_output(wait=True)\n",
    "            continue\n",
    "    elif cmd != 'ok':\n",
    "        print(\"Comando non riconosciuto, digita 'ok' o 'stop'.\")\n",
    "        continue\n",
    "\n",
    "    # Ora procedi con scelta task, soggetto e run e plotting\n",
    "    task = input(f\"\\nScegli task tra {list(EEG_data_filtered.keys())}: \").strip()\n",
    "    if task not in EEG_data_filtered:\n",
    "        print(\"Task non valido.\")\n",
    "        continue\n",
    "\n",
    "    sbj = input(f\"\\nScegli soggetto tra {list(EEG_data_prep[task].keys())}: \").strip()\n",
    "    if sbj not in EEG_data_prep[task]:\n",
    "        print(\"Soggetto non valido.\")\n",
    "        continue\n",
    "\n",
    "    available_runs = list(EEG_data_filtered[task][sbj].keys())\n",
    "    run = int(input(f\"\\nScegli run tra {available_runs}: \").strip())\n",
    "    if run not in available_runs:\n",
    "        print(\"Run non valido.\")\n",
    "        continue\n",
    "\n",
    "    start_sec    = float(input(\"\\nStart time (s) [default 0]: \") or 0.0)\n",
    "    duration_sec = float(input(\"End Time (s) [default 5]: \") or 5.0)\n",
    "\n",
    "    raw_filt = EEG_data_filtered[task][sbj][run][0]\n",
    "    raw_prep = EEG_data_prep[task][sbj][run][0]\n",
    "\n",
    "    # Stampa canali orizzontalmente\n",
    "    ch_names = raw_filt.ch_names\n",
    "    print(\"\\nElenco canali:\", \"  \".join(f\"\\033[1m{i}\\033[0m: {ch}\" for i,ch in enumerate(ch_names)))\n",
    "    max_idx = len(ch_names) - 1\n",
    "    ch_start = int(input(f\"Inizio canale [0–{max_idx}] [default 0]: \") or 0)\n",
    "    ch_end   = int(input(f\"Fine canale [0–{max_idx}] [default {ch_start}]: \") or ch_start)\n",
    "\n",
    "    plot_comparison(raw_filt, raw_prep,\n",
    "                    start_sec, duration_sec,\n",
    "                    ch_start, ch_end)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a39fe8f-8992-47c2-8357-b05473dfc18f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### **Re-Loading dei files 1) EEG_prep_data e 2) Prep_Log direttamente come file .pkl**\n",
    "\n",
    "#### **Per PyPrep con oggetto Prep Pipeline**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa86a5e-b9c4-49d0-a4fb-593be5cce120",
   "metadata": {},
   "source": [
    "**Pipeline eseguita da qui in avanti**\n",
    "\n",
    "1) Import/filtri iniziali (per ogni run)\n",
    "\n",
    "- Conversione da µV a V.\n",
    "\n",
    "- Montage: posizioni 10–20 ridotte ai canali del dataset.\n",
    "\n",
    "- Notch 60 Hz (IIR Butterworth, SOS, fase zero).\n",
    "\n",
    "- Band-pass 1–45 Hz (IIR Butterworth, SOS, fase zero).\n",
    "\n",
    "    - Nota: con order=2 il band-pass ha ~8° ordine effettivo.\n",
    "\n",
    "        Nota su ordine effettivo dei filtri IIR\n",
    "\n",
    "        Con butter(N, ...) un band-pass ha ordine 2·N nel passaggio forward.\n",
    "\n",
    "        MNE usa filtro a fase zero (forward + backward), che raddoppia l’ordine in ampiezza.\n",
    "\n",
    "        Nel tuo caso order = 2 → 4° ordine forward (perché 2·N) → ~8° ordine effettivo con fase zero.\n",
    "\n",
    "        Idem per il notch a 60 Hz: order=2 → ~8° effettivo.\n",
    "        ➡️ Il settaggio attuale è equilibrato per EEG; impostare order=8 porterebbe a ~32° effettivo (troppo ripido).\n",
    "\n",
    "\n",
    "\n",
    "2) Costruzione del contenitore\n",
    "\n",
    "- Funzione build_raw_collection(...) → struttura:\n",
    "\n",
    "        raw_collection[task][subject][run] = (Raw, annotations_array)\n",
    "\n",
    "\n",
    "    I Raw sono già filtrati; le annotazioni ( = labels) - sono caricate.\n",
    "\n",
    "\n",
    "3) Pulizia automatica con PyPREP (end-to-end)\n",
    "\n",
    "- Funzione: run_preppipeline_on_nested(...) (checkpoint per-run attivo).\n",
    "\n",
    "- Parametri principali:\n",
    "\n",
    "    - ref_chs='eeg', reref_chs='eeg', max_iterations=4\n",
    "    - line_freqs=[] (nessuna rimozione linea: notch già applicato)\n",
    "\n",
    "- Per ogni run, PrepPipeline.fit() esegue:\n",
    "\n",
    "    - Robust average reference iterativa\n",
    "    - Identificazione canali “bad”\n",
    "    - Interpolazione canali interi (spherical splines)\n",
    "    - Re-reference finale\n",
    "\n",
    "- Log per-canale salvato a ogni run, con:\n",
    "\n",
    "    - pre_ref_bad_channels\n",
    "    - post_ref_bad_channels (nuovi bad emersi durante la robust-ref)\n",
    "    - interpolated_channels (canali interpolati integralmente)\n",
    "    - post_interp_residual_channels (= still_noisy_channels post-PREP)\n",
    "    - meta: ref_n_iterations, ref_converged, ecc.\n",
    "    \n",
    "- Output:\n",
    "\n",
    "    - EEG_data_prep (stessa struttura dell’input, Raw puliti)\n",
    "    - prep_log (tabella per-canale)\n",
    "\n",
    "\n",
    "4) QC finale “solo residui”\n",
    "\n",
    "- Funzione: summarize_run_quality_residuals(prep_log, max_resid_warning_n=3, max_resid_warning_frac=0.125).\n",
    "\n",
    "- Per ogni run calcola:\n",
    "\n",
    "    - post_interp_residual_channels_n\n",
    "    - residual_frac = post_interp_residual_channels_n / n_chan\n",
    "\n",
    "- Regola decisionale (solo residui):\n",
    "\n",
    "    - OK se n_residui == 0\n",
    "    - WARNING se 1–3 e residual_frac ≤ 0.125\n",
    "    - DISCARD se n_residui > 3 oppure residual_frac > 0.125\n",
    "\n",
    "- Tabelle prodotte:\n",
    "\n",
    "    - df_runs (una riga per run, con liste/contatori e decision_final)\n",
    "    - df_subjects (conteggio OK/WARNING/DISCARD per soggetto e task)\n",
    "\n",
    "\n",
    "\n",
    "Risultati ottenuti\n",
    "\n",
    "- OK: 682 run \n",
    "- WARNING: 480 run \n",
    "- DISCARD: 74 run\n",
    "\n",
    "\n",
    "Approfondimento WARNING\n",
    "\n",
    "- con ≤ 8 canali interpolati: 307 run (warn_keep)\n",
    "- con > 8 canali interpolati: 173 run (warn_drop)\n",
    "\n",
    "Interpretazione\n",
    "\n",
    "Stai usando i residui post-PREP come metrica principale di qualità. \n",
    "In aggiunta, un criterio prudente sul numero di canali interpolati separa le WARNING “accettabili” (da includere per ICA/analisi estese) da quelle da scartare.\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "Infine:\n",
    "\n",
    "Contiamo le runs OK/WARNING/DISCARD senza errori (len(...) o mask .sum());\n",
    "\n",
    "una funzione riutilizzabile che:\n",
    "\n",
    "seleziona OK + WARNING con ≤ 8 canali interpolati\n",
    "ricostruisce il nuovo contenitore EEG_for_ICA a partire da EEG_data_prep\n",
    "per le sole WARNING sovrascrive raw.info['bads'] con i soli residui finali (post_interp_residual_channels)\n",
    "restituisce anche keep_df (la tabella delle run tenute) e un bads_log (audit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bffe49a-d600-4c90-8e44-cda37c37f1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import pickle\n",
    "\n",
    "# Caricare l'intero dizionario annidato con pickle\n",
    "path = '/home/stefano/EEGMMIDB_Analyses/pyprep_outputs/'\n",
    "\n",
    "# Caricare l'intero dizionario annidato con pickle\n",
    "with open(f'{path}EEG_post_pyprep_data.pkl', 'rb') as f:\n",
    "    EEG_data_prep = pickle.load(f)\n",
    "    \n",
    "\n",
    "# Caricare l'intero dizionario annidato con pickle\n",
    "with open(f'{path}prep_log.pkl', 'rb') as f:\n",
    "    prep_log = pickle.load(f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17279bd-ba98-408b-b3e5-bbb3505d7d2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "1) Che cosa fa summarize_run_quality_residuals\n",
    "\n",
    "Input: il prep_log prodotto da run_preppipeline_on_nested, ovvero un DataFrame per-canale in cui ogni riga ha, tra le altre cose, le liste per-run replicate:\n",
    "interpolated_channels\n",
    "post_interp_residual_channels ⟵ questa è la lista chiave\n",
    "pre_ref_bad_channels\n",
    "post_ref_bad_channels\n",
    "\n",
    "Idea: sintetizza il log per ottenere una riga per run e decide lo stato qualità solo in base ai residui post-PREP con le regole:\n",
    "\n",
    "OK se n_residui == 0\n",
    "WARNING se 1–3 e residual_frac ≤ 0.125\n",
    "DISCARD se n_residui > 3 oppure residual_frac > 0.125\n",
    "\n",
    "\n",
    "Output:\n",
    "\n",
    "df_runs (una riga per run) con:\n",
    "numero canali (n_chan)\n",
    "liste una sola volta per run (interpolated / residual / pre_ref / post_ref)\n",
    "contatori (es. post_interp_residual_channels_n)\n",
    "residual_frac (= residui / n_chan)\n",
    "decision_final (OK / WARNING / DISCARD)\n",
    "flag pratici: keep_for_analysis, keep_for_ica\n",
    "df_subjects: pivot per soggetto (quante run OK/WARNING/DISCARD e totale)\n",
    "\n",
    "'''\n",
    "\n",
    "# ============================================\n",
    "# 2) QC basato SOLO sui residui post-PREP\n",
    "#    (regole: OK / WARNING / DISCARD come richiesto)\n",
    "# ============================================\n",
    "\n",
    "'''\n",
    "Accetta il log per-canale; fissa le soglie per classificare i residui (1–3 e ≤12.5% → WARNING)\n",
    "'''\n",
    "\n",
    "import pandas as pd\n",
    "from typing import Tuple\n",
    "\n",
    "def summarize_run_quality_residuals(\n",
    "    prep_log: pd.DataFrame,\n",
    "    max_resid_warning_n: int = 3,          # 1–3 → WARNING (se frazione ≤ soglia)\n",
    "    max_resid_warning_frac: float = 0.125, # 12.5% → WARNING se entro questa frazione\n",
    ") -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    Crea un riepilogo per-run con decisione basata SOLO sui residui post-PREP:\n",
    "\n",
    "      OK       se n_residui == 0\n",
    "      WARNING  se 1–3 e residual_frac ≤ 0.125\n",
    "      DISCARD  se n_residui > 3 oppure residual_frac > 0.125\n",
    "    \"\"\"\n",
    "    \n",
    "    '''\n",
    "    Setup base\n",
    "\n",
    "    import ast : servirà a trasformare stringhe come \"['F3','F4']\" in vere liste.\n",
    "    \n",
    "    keys = [\"task\",\"subject\",\"run\"] : le tre colonne usate per raggruppare per run.\n",
    "    '''\n",
    "\n",
    "    import ast\n",
    "    keys = [\"task\",\"subject\",\"run\"]\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    Helper di normalizzazione\n",
    "\n",
    "    def _ensure_list(x): ...\n",
    "    se x è lista → la restituisce;\n",
    "    se x è stringa → ast.literal_eval per convertirla in lista (se possibile);\n",
    "    altrimenti → [].\n",
    "\n",
    "    Obiettivo: qualunque valore “diventa lista”, evitando crash quando contiamo o facciamo set(...).\n",
    "    '''\n",
    "\n",
    "    def _ensure_list(x):\n",
    "        if isinstance(x, list): return x\n",
    "        if isinstance(x, str):\n",
    "            try:\n",
    "                v = ast.literal_eval(x)\n",
    "                return v if isinstance(v, list) else []\n",
    "            except Exception:\n",
    "                return []\n",
    "        return []\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    Numero di canali per run\n",
    "\n",
    "    base = (prep_log.groupby(keys, as_index=False).agg(n_chan=('channel','count'))): conta quante righe (canali) ha ogni run → produce n_chan per run.\n",
    "    '''\n",
    "        \n",
    "\n",
    "    # n_chan per run\n",
    "    base = (prep_log.groupby(keys, as_index=False)\n",
    "            .agg(n_chan=('channel','count')))\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    Utility per estrarre una lista “una volta per run”\n",
    "\n",
    "    def _pull_first(col): ...\n",
    "    prende, per la colonna col (che contiene una lista replicata su ogni riga della run), il primo valore per ciascuna run.\n",
    "    se la colonna non esiste in prep_log, ritorna un DataFrame vuoto con quella colonna.\n",
    "    '''\n",
    "    \n",
    "    # estrai (una sola volta per run) le liste prodotte da PREP\n",
    "    def _pull_first(col):\n",
    "        if col not in prep_log.columns:\n",
    "            return pd.DataFrame({**{k:[] for k in keys}, col: []})\n",
    "        return (prep_log.groupby(keys, as_index=False)\n",
    "                .agg(**{col: (col, 'first')}))\n",
    "    \n",
    "    '''\n",
    "    Recupero delle 4 liste principali\n",
    "\n",
    "    inter_meta = _pull_first(\"interpolated_channels\")\n",
    "    resid_meta = _pull_first(\"post_interp_residual_channels\")\n",
    "    pre_meta = _pull_first(\"pre_ref_bad_channels\")\n",
    "    after_meta = _pull_first(\"post_ref_bad_channels\")\n",
    "    per ciascuna lista, ottieni “una lista per run”.\n",
    "    '''\n",
    "    \n",
    "    inter_meta = _pull_first(\"interpolated_channels\")\n",
    "    resid_meta = _pull_first(\"post_interp_residual_channels\")\n",
    "    pre_meta   = _pull_first(\"pre_ref_bad_channels\")\n",
    "    after_meta = _pull_first(\"post_ref_bad_channels\")\n",
    "    \n",
    "    '''\n",
    "    Merge in un unico DataFrame per-run\n",
    "\n",
    "    df_runs = base.merge(inter_meta, ...).merge(resid_meta, ...).merge(pre_meta, ...).merge(after_meta, ...)\n",
    "\n",
    "    unisce n_chan e tutte le liste in un’unica riga per run.\n",
    "    '''\n",
    "    \n",
    "    df_runs = base.merge(inter_meta, on=keys, how='left') \\\n",
    "                  .merge(resid_meta, on=keys, how='left') \\\n",
    "                  .merge(pre_meta,   on=keys, how='left') \\\n",
    "                  .merge(after_meta, on=keys, how='left')\n",
    "    \n",
    "    '''\n",
    "    Sanificazione delle liste\n",
    "\n",
    "    for col in [...]: df_runs[col] = df_runs[col].apply(_ensure_list)\n",
    "    garantisce che ognuna di quelle colonne sia davvero una lista (mai NaN/stringhe).\n",
    "    '''\n",
    "    for col in [\"interpolated_channels\",\"post_interp_residual_channels\",\n",
    "                \"pre_ref_bad_channels\",\"post_ref_bad_channels\"]:\n",
    "        df_runs[col] = df_runs[col].apply(_ensure_list)\n",
    "        \n",
    "    '''\n",
    "    Contatori e frazioni\n",
    "\n",
    "    df_runs[\"interpolated_channels_n\"] = df_runs[\"interpolated_channels\"].apply(len)\n",
    "    quanti canali sono stati interpolati in quella run.\n",
    "    df_runs[\"post_interp_residual_channels_n\"] = df_runs[\"post_interp_residual_channels\"].apply(len)\n",
    "    quanti residui post-PREP (metrica chiave).\n",
    "    df_runs[\"residual_frac\"] = df_runs[\"post_interp_residual_channels_n\"] / df_runs[\"n_chan\"]\n",
    "\n",
    "    frazione di residui rispetto ai canali totali.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # contatori e frazioni\n",
    "    df_runs[\"interpolated_channels_n\"]        = df_runs[\"interpolated_channels\"].apply(len)\n",
    "    df_runs[\"post_interp_residual_channels_n\"] = df_runs[\"post_interp_residual_channels\"].apply(len)\n",
    "    df_runs[\"residual_frac\"] = df_runs[\"post_interp_residual_channels_n\"] / df_runs[\"n_chan\"]\n",
    "    \n",
    "    '''\n",
    "    Regola decisionale (solo residui)\n",
    "\n",
    "    def decide_resid(n_resid, frac, n_warn=..., frac_warn=...): ...\n",
    "        implementa le tre condizioni:\n",
    "        n_resid == 0 → \"OK\"\n",
    "        1 ≤ n_resid ≤ n_warn e frac ≤ frac_warn → \"WARNING\"\n",
    "        altrimenti → \"DISCARD\".\n",
    "        \n",
    "    df_runs[\"decision_final\"] = df_runs.apply(lambda r: decide_resid(...), axis=1)\n",
    "        calcola la classe per ogni run.\n",
    "    '''\n",
    "    \n",
    "\n",
    "    # decisione (solo residui) – come richiesto\n",
    "    def decide_resid(n_resid, frac, n_warn=max_resid_warning_n, frac_warn=max_resid_warning_frac):\n",
    "        if n_resid == 0:\n",
    "            return \"OK\"\n",
    "        if (1 <= n_resid <= n_warn) and (frac <= frac_warn):\n",
    "            return \"WARNING\"\n",
    "        return \"DISCARD\"\n",
    "\n",
    "    df_runs[\"decision_final\"] = df_runs.apply(\n",
    "        lambda r: decide_resid(r[\"post_interp_residual_channels_n\"], r[\"residual_frac\"]),\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    '''\n",
    "    Flag pratici\n",
    "\n",
    "    df_runs[\"keep_for_analysis\"] = (df_runs[\"post_interp_residual_channels_n\"] == 0)\n",
    "    vero solo se OK (nessun residuo) → perfetta per analisi “pulite”.\n",
    "    df_runs[\"keep_for_ica\"] = ( (resid==0) | (1–3 & frac≤0.125) )\n",
    "    consenti OK e WARNING (pochi residui e quota bassa) per includere più dati nell’ICA.\n",
    "    \n",
    "    '''\n",
    "    # flag utili\n",
    "    df_runs[\"keep_for_analysis\"] = (df_runs[\"post_interp_residual_channels_n\"] == 0)\n",
    "    df_runs[\"keep_for_ica\"] = (\n",
    "        (df_runs[\"post_interp_residual_channels_n\"] == 0) |\n",
    "        (\n",
    "            (df_runs[\"post_interp_residual_channels_n\"] >= 1) &\n",
    "            (df_runs[\"post_interp_residual_channels_n\"] <= max_resid_warning_n) &\n",
    "            (df_runs[\"residual_frac\"] <= max_resid_warning_frac)\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    '''\n",
    "    Riepilogo per soggetto\n",
    "\n",
    "    df_subjects = (df_runs.pivot_table(..., columns='decision_final', ...))\n",
    "    conteggi OK/WARNING/DISCARD per (task, subject).\n",
    "    for loop che assicura le tre colonne sempre presenti (anche se zero).\n",
    "    df_subjects['runs_total'] = ...sum(axis=1)\n",
    "    totale run per soggetto.\n",
    "    '''\n",
    "    \n",
    "    # riepilogo per soggetto\n",
    "    df_subjects = (df_runs\n",
    "                   .pivot_table(index=['task','subject'],\n",
    "                                columns='decision_final',\n",
    "                                values='run',\n",
    "                                aggfunc='count',\n",
    "                                fill_value=0)\n",
    "                   .reset_index())\n",
    "    for col in ['OK','WARNING','DISCARD']:\n",
    "        if col not in df_subjects.columns:\n",
    "            df_subjects[col] = 0\n",
    "    df_subjects['runs_total'] = df_subjects[['OK','WARNING','DISCARD']].sum(axis=1)\n",
    "    \n",
    "    '''\n",
    "    Ordina e restituisci\n",
    "\n",
    "    return df_runs.sort_values(keys), df_subjects.sort_values(['task','subject'])\n",
    "\n",
    "    tabelle finali ordinate.\n",
    "    '''\n",
    "    return df_runs.sort_values(keys), df_subjects.sort_values(['task','subject'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418ad41b-5f18-45e6-bc46-9ef6eb44e027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) QC solo-residui con le regole richieste\n",
    "df_runs, df_subjects = summarize_run_quality_residuals(\n",
    "    prep_log,\n",
    "    max_resid_warning_n=3,\n",
    "    max_resid_warning_frac=0.125\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1dda580-8fe0-4adf-98d4-ddb53b48d039",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esempi filtri:\n",
    "runs_ok        = df_runs[df_runs.decision_final == \"OK\"]\n",
    "runs_warning   = df_runs[df_runs.decision_final == \"WARNING\"]\n",
    "runs_discard   = df_runs[df_runs.decision_final == \"DISCARD\"]\n",
    "\n",
    "runs_for_ica       = df_runs[df_runs.keep_for_ica]\n",
    "runs_for_analysis  = df_runs[df_runs.keep_for_analysis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b706ac5a-d7c2-4ec1-8418-9328982296bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "runs_ok "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120aa3ea-c5a7-45af-a9ab-1f7c65aae2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "runs_warning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da247f7-37fc-40e8-bc34-df2b144a2166",
   "metadata": {},
   "outputs": [],
   "source": [
    "runs_discard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a88653-91ca-46ef-9cf9-afef3a654f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Sì, ha senso 👍\n",
    "Con 64 canali, 8/64 = 12.5%: è coerente con la soglia che stai già usando per i residui. Quindi:\n",
    "\n",
    "ICA: tieni le run WARNING solo se interpolated_channels_n ≤ 8 (oppure, meglio: interpolated_frac ≤ 0.125).\n",
    "\n",
    "Escludi (DISCARD) le WARNING con più di 8 canali interpolati.\n",
    "\n",
    "Ecco due modi pratici.\n",
    "\n",
    "A) Filtro “al volo” sulle WARNING già calcolate\n",
    "\n",
    "Se hai df_runs da summarize_run_quality_residuals:\n",
    "\n",
    "# quante WARNING tenere (≤ 8 canali interpolati)?\n",
    "warn_keep = df_runs[(df_runs.decision_final == 'WARNING') &\n",
    "                    (df_runs.interpolated_channels_n <= 8)]\n",
    "n_warn_keep = len(warn_keep)\n",
    "\n",
    "# quante WARNING escludere (> 8 canali interpolati)?\n",
    "warn_drop = df_runs[(df_runs.decision_final == 'WARNING') &\n",
    "                    (df_runs.interpolated_channels_n > 8)]\n",
    "n_warn_drop = len(warn_drop)\n",
    "\n",
    "\n",
    "Perché è una buona idea\n",
    "\n",
    "Eviti run con troppe ricostruzioni (interpolazioni) che possono biasare ICA e analisi successive.\n",
    "\n",
    "La soglia “8 su 64” è la stessa del 12.5%: se un domani cambi numero di canali, la versione con frazione resta valida.\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c4e4f6-8efc-42e7-9552-fa42910c0df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "warn_keep = df_runs[(df_runs.decision_final == 'WARNING') &\n",
    "                    (df_runs.interpolated_channels_n <= 8)]\n",
    "n_warn_keep = len(warn_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59146a14-7321-4244-a082-610c4e5bb8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_warn_keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43726eb-c0d5-40c9-afb6-72320a36e9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quante WARNING escludere (> 8 canali interpolati)?\n",
    "warn_drop = df_runs[(df_runs.decision_final == 'WARNING') &\n",
    "                    (df_runs.interpolated_channels_n > 8)]\n",
    "n_warn_drop = len(warn_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c90fe01-771c-4b91-8092-76c6ae605673",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_warn_drop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3af242-4618-46b0-84b7-3b5fda2721ef",
   "metadata": {},
   "source": [
    "##### **Creazione del nuovo dataset filtrato a partire da EEG_prep_data**\n",
    "\n",
    "##### A partire da df_runs (ossia il totale delle runs) vado a \n",
    "\n",
    "##### 1) **escludere** le runs che son con **'DISCARD'** (i.e., mask_discard = (df_runs['decision_post_interp'] == 'DISCARD'))\n",
    "\n",
    "\n",
    "##### Dopodiché, da df_runs (SENZA le runs che son con 'DISCARD') vado a \n",
    "\n",
    "##### 2) **tenermi** le runs che son con **'OK'** \n",
    "\n",
    "##### 3) **tenermi** le runs che son con **'WARNING'**\n",
    "    \n",
    "   ##### 3.a) Per le runs con 'WARNING' -> ossia, per ogni runs, task e soggetto, ossia nel file raw corrispondente, andarmi a segnare i canali EEG come 'bad' (ossia di quelli che si trovano nella colonna 'post_interp_residual_channels'), in modo da poi eventualmente escluderli dalla ICA custom che ho creato (che comunque esegue anche una ulteriore interpolazione dei canali sporchi anche post-ICA, per cui anche quei canali sporchi che son dentro a 'post_interp_residual_channels' per le runs che son 'WARNING' dovrebbero essere poi ripuliti comunque anche loro, perché verrebbero esclusi dall'ICA ma al tempo stesso riceverebbero una ulteriore pulizia)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2c29f4-edab-4122-8e95-63f5265f5fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 0) Maschere coerenti con summarize_run_quality_residuals(decision_final) ---\n",
    "\n",
    "#1) Conteggi senza errori\n",
    "\n",
    "# Conteggi corretti\n",
    "n_ok       = int((df_runs['decision_final'] == 'OK').sum())\n",
    "n_warning  = int((df_runs['decision_final'] == 'WARNING').sum())\n",
    "n_discard  = int((df_runs['decision_final'] == 'DISCARD').sum())\n",
    "\n",
    "print(f\"OK: {n_ok} | WARNING: {n_warning} | DISCARD: {n_discard}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad09548-7501-4064-bd87-d50101c1fb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_warn_keep = int(((df_runs['decision_final'] == 'WARNING') &\n",
    "                   (df_runs['interpolated_channels_n'] <= 8)).sum())\n",
    "n_warn_drop = int(((df_runs['decision_final'] == 'WARNING') &\n",
    "                   (df_runs['interpolated_channels_n'] > 8)).sum())\n",
    "\n",
    "print(f\"WARNING ≤8 interpolati: {n_warn_keep} | WARNING >8 interpolati: {n_warn_drop}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b03280-8fff-4a25-9a88-eca7f30025c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2) Selezione + ricostruzione dataset (OK ∪ WARNING≤8) con bads settati ai residui\n",
    "\n",
    "'''\n",
    "\n",
    "Questa funzione:\n",
    "\n",
    "seleziona OK + WARNING con ≤ 8 canali interpolati,\n",
    "ricostruisce il nuovo contenitore EEG_for_ICA a partire da EEG_data_prep,\n",
    "per le sole WARNING sovrascrive raw.info['bads'] con i soli residui finali (post_interp_residual_channels),\n",
    "restituisce anche keep_df (la tabella delle run tenute) e un bads_log (audit).\n",
    "\n",
    "Perché overwrite dei bads solo coi residui?\n",
    "\n",
    "Dopo PyPREP hai già interpolato i canali pre/after-ref e, con reset_bads=True, raw.info['bads'] viene svuotato.\n",
    "Per le run WARNING vuoi che l’ICA ignori solo i canali ancora residui: quindi è corretto sovrascrivere raw.info['bads'] con post_interp_residual_channels (filtrati ai nomi validi).\n",
    "Le run OK non hanno residui → raw.info['bads'] resta vuoto.\n",
    "\n",
    "'''\n",
    "\n",
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "def _ensure_list(x):\n",
    "    if isinstance(x, list):\n",
    "        return x\n",
    "    if isinstance(x, str):\n",
    "        try:\n",
    "            v = ast.literal_eval(x)\n",
    "            return v if isinstance(v, list) else []\n",
    "        except Exception:\n",
    "            return []\n",
    "    return []\n",
    "\n",
    "def select_and_build_dataset(df_runs: pd.DataFrame,\n",
    "                             EEG_data_prep: dict,\n",
    "                             max_interp_warn: int = 8):\n",
    "    \"\"\"\n",
    "    Tieni:\n",
    "      - tutte le run OK\n",
    "      - le WARNING con interpolated_channels_n ≤ max_interp_warn\n",
    "\n",
    "    Ricostruisce EEG_for_ICA con la stessa struttura annidata di EEG_data_prep.\n",
    "    Per le sole WARNING, sovrascrive raw.info['bads'] con i canali in\n",
    "    post_interp_residual_channels (filtrati ai nomi validi presenti in raw).\n",
    "\n",
    "    Ritorna:\n",
    "      - EEG_for_ICA  : dict annidato task->subject->run -> Raw oppure (Raw, labels)\n",
    "      - keep_df      : dataframe delle run tenute (task, subject, run, decision_final, residui)\n",
    "      - bads_log     : lista di dict (audit: per WARNING, cosa è stato marcato bad)\n",
    "    \"\"\"\n",
    "    # --- maschere di selezione ---\n",
    "    ok_mask = (df_runs['decision_final'] == 'OK')\n",
    "    warn_keep_mask = ((df_runs['decision_final'] == 'WARNING') &\n",
    "                      (df_runs['interpolated_channels_n'] <= max_interp_warn))\n",
    "\n",
    "    # --- subset delle run da tenere ---\n",
    "    cols_needed = ['task', 'subject', 'run', 'decision_final', 'post_interp_residual_channels']\n",
    "    keep_df = df_runs.loc[ok_mask | warn_keep_mask, cols_needed].copy()\n",
    "\n",
    "    # normalizza tipi e liste\n",
    "    keep_df['subject'] = keep_df['subject'].astype(str)\n",
    "    keep_df['run'] = keep_df['run'].astype(int)\n",
    "    keep_df['post_interp_residual_channels'] = keep_df['post_interp_residual_channels'].apply(_ensure_list)\n",
    "\n",
    "    EEG_for_ICA = {}\n",
    "    bads_log = []\n",
    "\n",
    "    # utility per inserimento nel contenitore\n",
    "    def _put(container, t, s, r, val):\n",
    "        container.setdefault(t, {}).setdefault(s, {})[r] = val\n",
    "\n",
    "    # costruzione nuovo dataset\n",
    "    for row in keep_df.itertuples(index=False):\n",
    "        t, s, r = row.task, row.subject, row.run\n",
    "        status = row.decision_final\n",
    "        resid_list = row.post_interp_residual_channels or []\n",
    "\n",
    "        # recupera dall'originale\n",
    "        val = EEG_data_prep[t][s][r]\n",
    "        if isinstance(val, tuple):\n",
    "            raw_in, labels = val\n",
    "        else:\n",
    "            raw_in, labels = val, None\n",
    "\n",
    "        raw = raw_in.copy()\n",
    "\n",
    "        # WARNING: sovrascrivi i bads con i soli RESIDUI FINALI (validi)\n",
    "        if status == 'WARNING':\n",
    "            resid_valid = [ch for ch in resid_list if ch in raw.ch_names]\n",
    "            raw.info['bads'] = sorted(set(resid_valid))\n",
    "            # audit\n",
    "            bads_log.append({\n",
    "                'task': t, 'subject': s, 'run': r,\n",
    "                'n_residual': len(resid_valid),\n",
    "                'bads_set': raw.info['bads']\n",
    "            })\n",
    "        # OK: non tocchiamo raw.info['bads'] (dovrebbe essere vuoto dopo PREP)\n",
    "\n",
    "        # inserisci nel nuovo contenitore\n",
    "        _put(EEG_for_ICA, t, s, r, (raw, labels) if labels is not None else raw)\n",
    "\n",
    "    # report rapido\n",
    "    n_kept = sum(len(runs) for subj in EEG_for_ICA.values() for runs in subj.values())\n",
    "    print(f\"Run mantenute nel nuovo dataset: {n_kept}\")\n",
    "\n",
    "    return EEG_for_ICA, keep_df, bads_log\n",
    "\n",
    "# ---- ESECUZIONE ----\n",
    "EEG_for_ICA, keep_df, bads_log = select_and_build_dataset(\n",
    "    df_runs=df_runs,\n",
    "    EEG_data_prep=EEG_data_prep,\n",
    "    max_interp_warn=8\n",
    ")\n",
    "\n",
    "# conteggi finali\n",
    "print(\"OK tenute:\", int((keep_df['decision_final'] == 'OK').sum()))\n",
    "print(\"WARNING≤8 tenute:\", int((keep_df['decision_final'] == 'WARNING').sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6af41d6-5bd0-4db5-ac8d-dedb4d6853f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bads_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b13082a-d7d6-43e3-887a-cfa956ce64f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "4) Salvataggi su disco (opzionale)\n",
    "'''\n",
    "\n",
    "# --- 4) (Opzionale) salvataggi su disco ---\n",
    "\n",
    "'''\n",
    "Imposta la cartella di output e la crea se non esiste.\n",
    "'''\n",
    "import pickle, os\n",
    "outdir = '/home/stefano/EEGMMIDB_Analyses/pyprep_outputs'\n",
    "os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "'''\n",
    "Salva la nuova struttura annidata (solo OK+WARNING, con i WARNING già marcati) in un .pkl per riuso.\n",
    "'''\n",
    "\n",
    "with open(os.path.join(outdir, 'EEG_for_ICA.pkl'), 'wb') as f:\n",
    "    pickle.dump(EEG_for_ICA, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "    \n",
    "with open(os.path.join(outdir, 'keep_df.pkl'), 'wb') as f:\n",
    "    pickle.dump(keep_df, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open(os.path.join(outdir, 'bads_log.pkl'), 'wb') as f:\n",
    "    pickle.dump(bads_log, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f65116e-efc8-428c-b727-ed1202fb7a88",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### **EEG Post PyPREP: Ispezione delle Strutture Dati**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4187d3-dbfc-4d87-999b-e1c907001494",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Caricare l'intero dizionario annidato con pickle\n",
    "path = '/home/stefano/EEGMMIDB_Analyses/pyprep_outputs/'\n",
    "\n",
    "# Caricare l'intero dizionario annidato con pickle\n",
    "with open(f'{path}EEG_for_ICA.pkl', 'rb') as f:\n",
    "    EEG_for_ICA = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d54df7-ff74-4f69-8699-10d2fe668bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(EEG_for_ICA.keys())\n",
    "print(EEG_for_ICA['task_1'].keys())\n",
    "print(EEG_for_ICA['task_1']['100'].keys())\n",
    "print(type(EEG_for_ICA['task_1']['100'][0][0]))\n",
    "print(type(EEG_for_ICA['task_1']['100'][0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a13dd6-5ebe-4abb-add8-bb23b7bc9d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Per verificare che la struttura del dizionario sia corretta e uguale per entrambe le collezioni (raw_collection e raw_collection_unfiltered), \n",
    "possiamo ispezionarla con uno script che:\n",
    "\n",
    "Controlla i livelli del dizionario.\n",
    "Stampa il numero di soggetti per ogni task.\n",
    "Conta il numero di run per ciascun soggetto.\n",
    "Mostra la shape dei dati EEG e delle annotazioni.\n",
    "Verifica che i tipi siano coerenti: mne.io.Raw e np.ndarray.\n",
    "Ecco un codice che puoi lanciare dopo aver caricato i due dizionari da file o averli creati:\n",
    "\n",
    "\n",
    "Possiamo estendere la funzione inspect_raw_collection per:\n",
    "\n",
    "raccogliere tutti i soggetti (subj) e tutte le run (run) disponibili nel collection,\n",
    "mostrarli alla fine con np.unique per avere una lista completa e verificare quali soggetti e run siano presenti \n",
    "in ciascuna struttura (filtrata e non filtrata),\n",
    "eventualmente restituire le liste uniche per confrontarle.\n",
    "\n",
    "\n",
    "Nel tuo caso, gli annotations non sono un oggetto mne.Annotations, ma un array numpy.ndarray con forma (N, 5), dove:\n",
    "\n",
    "N = 30 è il numero di eventi o segmenti annotati (tipicamente i 30 trial della run),\n",
    "e le 5 colonne rappresentano probabilmente attributi di un array fatto così, ad esempio:\n",
    "[  1.    4.1 656.    1.  656. ]\n",
    "\n",
    "\n",
    "Vediamolo passo per passo e confrontiamolo con le informazioni dal paper PMC10998040, \n",
    "in particolare Tabella 2 e le descrizioni relative all’organizzazione temporale dei trial.\n",
    "\n",
    "| Colonna | Significato                        | Esempio                            |\n",
    "| ------- | ---------------------------------- | ---------------------------------- |\n",
    "| `[0]`   | **Etichetta originale** del trial  | `1` (T0), `2` (T1), `3` (T2)       |\n",
    "| `[1]`   | **Durata del trial (secondi)**     | `4.1`                              |\n",
    "| `[2]`   | **Durata in campioni** (`samples`) | `656`                              |\n",
    "| `[3]`   | **Indice di inizio trial**         | `657`                              |\n",
    "| `[4]`   | **Indice di fine trial**           | `1312`                             |\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def inspect_raw_collection(collection, name=\"\"):\n",
    "    print(f\"\\nInspecting structure: \\033[1m{name}\\033[0m\\n\" + \"-\"*50)\n",
    "    \n",
    "    all_subjects = []\n",
    "    all_runs = []\n",
    "\n",
    "    for task, subjects in collection.items():\n",
    "        print(f\"📁 Task: \\033[94m{task}\\033[0m → {len(subjects)} subjects\")\n",
    "        \n",
    "        # Mappa etichette in base al task\n",
    "        if task in [\"task_1\", \"task_2\"]:\n",
    "            label_map = {1: \"T0 (Rest)\", 2: \"T1 (Left Fist)\", 3: \"T2 (Right Fist)\"}\n",
    "        else:\n",
    "            label_map = {1: \"T0 (Rest)\", 2: \"T1 (Both Feet)\", 3: \"T2 (Both Fists)\"}\n",
    "\n",
    "        for subj, runs in subjects.items():\n",
    "            all_subjects.append(subj)\n",
    "            print(f\"  └─ 👤 Subject {subj} → {len(runs)} runs\")\n",
    "            for run, (raw, annotations) in runs.items():\n",
    "                all_runs.append(run)\n",
    "                print(f\"      └─ 🏃‍♂️ Run {run}:\")\n",
    "                print(f\"         ├─ Raw type:      {type(raw)}\")\n",
    "                print(f\"         ├─ Data shape:    {raw.get_data().shape}  (channels x time)\")\n",
    "                print(f\"         ├─ Annotations:   {type(annotations)}, shape={annotations.shape}\")\n",
    "                if isinstance(annotations, np.ndarray):\n",
    "                    print(f\"           ├─ First annotation row: {annotations[0]}\")\n",
    "                    print()\n",
    "                    print(f\"             ├─ Unique stimolo_id [0]: {np.unique(annotations[:, 0])}\")\n",
    "                    print(f\"             ├─ Durata trial secondi [1]: {np.unique(annotations[:, 1])}\")\n",
    "                    print(f\"             ├─ Durata trial in samples [2]: {np.unique(annotations[:, 2])}\\n\")\n",
    "                    print(f\"             ├─ Start sample  [3]: {np.unique(annotations[:, 3])}\\n\")\n",
    "                    print(f\"             └─ End sample [4]: {np.unique(annotations[:, 4])}\\n\")\n",
    "                print(f\"         └─ Duration (s):  {raw.times[-1]:.2f}s\")\n",
    "                \n",
    "            break  # Solo il primo soggetto per ogni task\n",
    "        print()\n",
    "\n",
    "    # Mostra soggetti e run unici\n",
    "    unique_subjects = np.unique(all_subjects)\n",
    "    unique_runs = np.unique(all_runs)\n",
    "\n",
    "    print(f\"\\n📊 \\033[1mRiepilogo {name}\\033[0m\")\n",
    "    print(f\"→ Soggetti unici: {len(unique_subjects)} → {unique_subjects}\")\n",
    "    print(f\"→ Run uniche:     {len(unique_runs)} → {unique_runs}\")\n",
    "    print(\"✓ Done.\\n\")\n",
    "\n",
    "    return unique_subjects, unique_runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aeac84f-2ebb-42b4-8f14-fab94b699f23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#inspect_raw_collection(EEG_data_filtered, \"Filtered\")\n",
    "#inspect_raw_collection(EEG_data_unfiltered, \"Unfiltered (raw original)\")\n",
    "inspect_raw_collection(EEG_for_ICA, \"Post PyPREP (ICA-ready)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c970c2-1cac-473a-bce7-04ad6055868f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(EEG_for_ICA['task_1'].keys())\n",
    "print()\n",
    "print(EEG_for_ICA['task_1']['100'].keys())\n",
    "print()\n",
    "print(type(EEG_for_ICA['task_1']['100'][0]))\n",
    "print()\n",
    "print(len(EEG_for_ICA['task_1']['100'][0]))\n",
    "print()\n",
    "print(type(EEG_for_ICA['task_1']['100'][0][0]))\n",
    "print(type(EEG_for_ICA['task_1']['100'][0][1]))\n",
    "print(EEG_for_ICA['task_1']['100'][0][1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff23664-522e-41d9-aacd-87f051bd6d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "EEG_for_ICA['task_1'].keys()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7d6e4baa-1fb9-4c85-8a62-f64e4db55458",
   "metadata": {},
   "source": [
    "'''\n",
    "🔍 E poi confronti:\n",
    "python\n",
    "Copia\n",
    "Modifica\n",
    "# Scegli ad esempio il task_1, soggetto 100, run 0\n",
    "raw_filt = raw_collection_filtered[\"task_1\"][\"100\"][0][0]\n",
    "raw_unfilt = raw_collection_unfiltered[\"task_1\"][\"100\"][0][0]\n",
    "\n",
    "# Confronta PSD\n",
    "raw_unfilt.plot_psd(fmax=60, average=True, show=True)\n",
    "raw_filt.plot_psd(fmax=60, average=True, show=True)\n",
    "\n",
    "# Oppure tracce temporali\n",
    "raw_unfilt.plot(n_channels=10, duration=5)\n",
    "raw_filt.plot(n_channels=10, duration=5)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8a53eb7c-ed7a-470d-bae1-d5af2ee9429f",
   "metadata": {},
   "source": [
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "raw",
   "id": "13d76153-bd79-4d47-9299-49f15cf99739",
   "metadata": {},
   "source": [
    "# Parametri\n",
    "task = 'task_1'\n",
    "subject = '100'\n",
    "run = 0\n",
    "trial_idx = 0\n",
    "\n",
    "# Estrai il raw e le annotations\n",
    "raw_filt, ann_filt = EEG_data_filtered[task][subject][run]\n",
    "raw_unfilt, ann_unfilt = EEG_data_unfiltered[task][subject][run]\n",
    "\n",
    "# Estrai inizio e fine del trial (colonne 3 e 4)\n",
    "start_sample = int(ann_filt[trial_idx, 3])\n",
    "end_sample = int(ann_filt[trial_idx, 4])\n",
    "\n",
    "# Crea una copia del raw filtrato per isolare solo quel trial\n",
    "raw_trial_filt = raw_filt.copy().crop(tmin=raw_filt.times[start_sample],\n",
    "                                      tmax=raw_filt.times[end_sample - 1])\n",
    "\n",
    "# Crea anche per il non filtrato\n",
    "raw_trial_unfilt = raw_unfilt.copy().crop(tmin=raw_unfilt.times[start_sample],\n",
    "                                          tmax=raw_unfilt.times[end_sample - 1])\n",
    "\n",
    "# Plot filtrato\n",
    "print(\"✅ Mostro trial filtrato\")\n",
    "raw_trial_filt.plot(title=f\"Filtrato - Soggetto {subject}, Run {run}, Trial {trial_idx}\")\n",
    "\n",
    "# Plot non filtrato\n",
    "print(\"✅ Mostro trial non filtrato\")\n",
    "raw_trial_unfilt.plot(title=f\"Non Filtrato - Soggetto {subject}, Run {run}, Trial {trial_idx}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e0a81fa7-cf8b-43a9-8aff-c8a47c22ec86",
   "metadata": {},
   "source": [
    "import os\n",
    "\n",
    "filtered = \"/home/stefano/EEGMMIDB_Analyses/EEG_only_filtered_data.pkl\"\n",
    "\n",
    "unfiltered = \"/home/stefano/EEGMMIDB_Analyses/EEG_unfiltered_data.pkl\"\n",
    "\n",
    "size_bytes_filtered = os.path.getsize(f\"{filtered}\")\n",
    "print(f\"Dimensione: {size_bytes_filtered} bytes\")\n",
    "\n",
    "\n",
    "size_bytes_unfiltered = os.path.getsize(f\"{unfiltered}\")\n",
    "print(f\"Dimensione: {size_bytes_unfiltered} bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e555d3ed-be74-453c-bdd8-eaf327f4cec3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### **EEG Preprocessing - Data Quality Check tra i files tra 1) EEG_post_pyprep_data e 2) EEG_for_ICA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ab391b-789a-4aaf-a0e5-dc8006af45fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Caricare l'intero dizionario annidato con pickle\n",
    "path = '/home/stefano/EEGMMIDB_Analyses/pyprep_outputs/'\n",
    "\n",
    "# Caricare l'intero dizionario annidato con pickle\n",
    "with open(f'{path}EEG_post_pyprep_data.pkl', 'rb') as f:\n",
    "    EEG_data_prep = pickle.load(f)\n",
    "    \n",
    "    \n",
    "# Caricare l'intero dizionario annidato con pickle\n",
    "with open(f'{path}EEG_for_ICA.pkl', 'rb') as f:\n",
    "    EEG_for_ICA = pickle.load(f)\n",
    "\n",
    "    \n",
    "# Caricare l'intero dizionario annidato con pickle\n",
    "with open(f'{path}keep_df.pkl', 'rb') as f:\n",
    "    keep_df = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ca3a0e-7d9a-4c90-8b65-a04ec230eea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(EEG_data_prep.keys())\n",
    "print(EEG_data_prep['task_1'].keys())\n",
    "print(EEG_data_prep['task_1']['100'].keys())\n",
    "print(type(EEG_data_prep['task_1']['100'][0][0]))\n",
    "print(type(EEG_data_prep['task_1']['100'][0][1]))\n",
    "print()\n",
    "print()\n",
    "print(EEG_for_ICA.keys())\n",
    "print(EEG_for_ICA['task_1'].keys())\n",
    "print(EEG_for_ICA['task_1']['100'].keys())\n",
    "print(type(EEG_for_ICA['task_1']['100'][0][0]))\n",
    "print(type(EEG_for_ICA['task_1']['100'][0][1]))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "eb01083f-701c-4aa9-8172-283101c1b99b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "'''\n",
    "\n",
    "Ma ci sono due cose che vorrei chiederti: \n",
    "\n",
    "1) c'è un modo per automatizzare il tutto affinché io riusi l'approccio di prima ma integrandolo con questo nuovo che automaticamente mi plotta,\n",
    "per la relativa runs, del relativo soggetto e task, i solo canali che son considerati bad con l'aggiunta di questi helper?\n",
    "\n",
    "\n",
    "2) se plotto i canali, in realtà non mi sembrano fuori soglia ... per cui mi sto chiedendo come mai son stati etichettati come bad.. \n",
    "dipende dalla pipeline di pyprep che internamente ha imposto che quei canali fossero sporchi per qualche motivo?\n",
    "\n",
    "\n",
    "\n",
    "Grandissimo — il confronto che hai plottato è perfetto 💪. Rispondo ai due punti e ti lascio del codice pronto-uso.\n",
    "\n",
    "1) Automatizzare il browser per plottare solo i canali residui\n",
    "\n",
    "Qui sotto c’è una versione “drop-in” che riusa il tuo menù ma:\n",
    "\n",
    "prende raw_for_ica e raw_full come prima,\n",
    "\n",
    "recupera i residui direttamente da raw_for_ica.info['bads'] (fallback su df_runs),\n",
    "\n",
    "se ci sono residui li plotta, altrimenti ti fa scegliere l’intervallo di canali.\n",
    "\n",
    "Incolla tutto e lancia: sostituisce solo la parte del loop e la plot_comparison supporta picks_by_name.\n",
    "\n",
    "\n",
    "\n",
    "2) “Ma visivamente non sembrano sporchi… perché sono WARNING?”\n",
    "\n",
    "È normale che a occhio (su 5 s) i residui non “saltino” sempre. PyPREP marca canali in base a metriche globali su tutta la registrazione, non su una finestra breve. \n",
    "\n",
    "In particolare:\n",
    "\n",
    "bad_by_deviation: deviazione standard anomala rispetto al gruppo (anche più bassa del normale).\n",
    "\n",
    "bad_by_correlation: bassa correlazione con i vicini (pattern incoerente anche se l’ampiezza è simile).\n",
    "\n",
    "bad_by_hf_noise: rumore ad alta frequenza (lo vedi più in PSD che nel tempo).\n",
    "\n",
    "bad_by_ransac (solo pre-ref nel tuo post-check la metti False): ricostruzione da subset fallita.\n",
    "\n",
    "bad_by_flat / bad_by_nan: canali piatti o con NaN anche sporadici.\n",
    "\n",
    "Con la tua pipeline:\n",
    "\n",
    "fai NoisyChannels(..., ransac=False) dopo l’interpolazione + final reref → i residui (colonna post_interp_residual_channels) sono quelli che ancora non passano,\n",
    "tipicamente per correlazione o HF noise.\n",
    "\n",
    "la finestra da 5 s può non includere il tratto “peggiore”.\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "VEDI ESEMPIO CON: TASK_2 SUBJ_1 RUN_5 da 0 a 40 secondi con CANALI PRIMI 10\n",
    "\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mne\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# --- helper: prendi Raw dalla struttura annidata (gestisce Raw o (Raw, labels))\n",
    "def get_raw(d, task, subj, run):\n",
    "    v = d[task][str(subj)][int(run)]\n",
    "    return v[0] if isinstance(v, tuple) else v\n",
    "\n",
    "# --- helper: residui per-run (1) dal Raw, (2) fallback df_runs\n",
    "def get_residual_channels(df_runs, task, subject, run, raw):\n",
    "    \n",
    "    # fonte primaria: bads dentro il Raw usato per l'ICA\n",
    "    \n",
    "    bads = raw.info.get('bads') or []\n",
    "    if isinstance(bads, list) and len(bads) > 0:\n",
    "        return sorted([ch for ch in bads if ch in raw.ch_names])\n",
    "\n",
    "    # fallback: df_runs (se per qualche motivo i bads non sono nel Raw)\n",
    "    row = df_runs[(df_runs['task'] == task) &\n",
    "                  (df_runs['subject'] == int(subject)) &\n",
    "                  (df_runs['run'] == int(run))]\n",
    "    if len(row) == 0:\n",
    "        return []\n",
    "    resid = row.iloc[0]['post_interp_residual_channels']\n",
    "    if not isinstance(resid, list):\n",
    "        resid = []\n",
    "    return sorted([ch for ch in resid if ch in raw.ch_names])\n",
    "\n",
    "# --- plotting: supporta 'picks_by_name' (lista nomi) oppure range di indici\n",
    "def plot_comparison(raw_for_ica: mne.io.Raw,\n",
    "                    raw_full: mne.io.Raw,\n",
    "                    start_sec: float = 0.0,\n",
    "                    duration_sec: float = 5.0,\n",
    "                    picks_by_name=None,\n",
    "                    ch_start: int = 0,\n",
    "                    ch_end: int = 0):\n",
    "    sfreq = raw_for_ica.info['sfreq']\n",
    "    start_samp = int(start_sec * sfreq)\n",
    "    stop_samp  = int((start_sec + duration_sec) * sfreq)\n",
    "    stop_samp = min(stop_samp, raw_for_ica.n_times, raw_full.n_times)  # guardrail\n",
    "    times = np.arange(start_samp, stop_samp) / sfreq\n",
    "    microvolt_scale = 1e6\n",
    "\n",
    "    if picks_by_name and len(picks_by_name) > 0:\n",
    "        picks_names = [ch for ch in picks_by_name if ch in raw_for_ica.ch_names]\n",
    "        picks_idx   = [raw_for_ica.ch_names.index(ch) for ch in picks_names]\n",
    "    else:\n",
    "        ch_end = max(ch_end, ch_start)\n",
    "        picks_idx   = list(range(ch_start, ch_end + 1))\n",
    "        picks_names = [raw_for_ica.ch_names[i] for i in picks_idx]\n",
    "\n",
    "    fig, (ax_top, ax_bot) = plt.subplots(2, 1, sharex=True, figsize=(12, 8))\n",
    "\n",
    "    # TOP: EEG_for_ICA (i residui sono marcati in bads → linewidth più spesso)\n",
    "    for i, ch_idx in enumerate(picks_idx):\n",
    "        ch_name = picks_names[i]\n",
    "        data = raw_for_ica.get_data(picks=[ch_idx]).squeeze()[start_samp:stop_samp] * microvolt_scale\n",
    "        lw = 2.5 if ch_name in (raw_for_ica.info.get('bads') or []) else 1.0\n",
    "        ax_top.plot(times, data, label=ch_name, linewidth=lw, alpha=0.85)\n",
    "    ax_top.set_title(\"EEG_for_ICA (post-PyPREP, OK/WARNING — residui marcati)\")\n",
    "    ax_top.set_ylabel(\"µV\")\n",
    "\n",
    "    # BOTTOM: EEG_data_prep (dataset completo post-PyPREP)\n",
    "    for ch_idx, ch_name in zip(picks_idx, picks_names):\n",
    "        data = raw_full.get_data(picks=[ch_idx]).squeeze()[start_samp:stop_samp] * microvolt_scale\n",
    "        ax_bot.plot(times, data, label=ch_name, alpha=0.85)\n",
    "    ax_bot.set_title(\"EEG_data_prep (post-PyPREP, dataset completo)\")\n",
    "    ax_bot.set_xlabel(\"Tempo (s)\")\n",
    "    ax_bot.set_ylabel(\"µV\")\n",
    "\n",
    "    handles, labels = ax_bot.get_legend_handles_labels()\n",
    "    fig.legend(handles, labels, loc='lower center',\n",
    "               ncol=min(len(labels), 6), bbox_to_anchor=(0.5, -0.05))\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(bottom=0.15)\n",
    "    plt.show()\n",
    "\n",
    "# ------ MENU INTERATTIVO ------\n",
    "while True:\n",
    "    clear_output(wait=True)\n",
    "    cmd = input(\"Digita 'ok' per plottare, 'stop' per uscire: \").strip().lower()\n",
    "    if cmd == 'stop':\n",
    "        print(\"Bye!\")\n",
    "        break\n",
    "    if cmd != 'ok':\n",
    "        print(\"Comando non riconosciuto.\")\n",
    "        continue\n",
    "\n",
    "    task = input(f\"\\nScegli task tra {list(EEG_for_ICA.keys())}: \").strip()\n",
    "    if task not in EEG_for_ICA: print(\"Task non valido.\"); continue\n",
    "\n",
    "    sbj = input(f\"\\nScegli soggetto tra {list(EEG_for_ICA[task].keys())}: \").strip()\n",
    "    if sbj not in EEG_for_ICA[task]: print(\"Soggetto non valido.\"); continue\n",
    "\n",
    "    available_runs = list(EEG_for_ICA[task][sbj].keys())\n",
    "    run = int(input(f\"\\nScegli run tra {available_runs}: \").strip())\n",
    "    if run not in available_runs: print(\"Run non valida.\"); continue\n",
    "\n",
    "    start_sec    = float(input(\"\\nStart time (s) [default 0]: \") or 0.0)\n",
    "    duration_sec = float(input(\"Durata (s) [default 5]: \") or 5.0)\n",
    "\n",
    "    raw_for_ica = get_raw(EEG_for_ICA,   task, sbj, run)\n",
    "    raw_full    = get_raw(EEG_data_prep, task, sbj, run)\n",
    "\n",
    "    resid = get_residual_channels(keep_df, task, sbj, run, raw_for_ica)\n",
    "    print(\"Residui post-interp:\", resid if resid else \"nessuno\")\n",
    "\n",
    "    if resid:\n",
    "        plot_comparison(raw_for_ica, raw_full, start_sec, duration_sec, picks_by_name=resid)\n",
    "    else:\n",
    "        ch_names = raw_for_ica.ch_names\n",
    "        print(\"\\nElenco canali:\", \"  \".join(f\"\\033[1m{i}\\033[0m:{ch}\" for i,ch in enumerate(ch_names)))\n",
    "        max_idx = len(ch_names) - 1\n",
    "        ch_start = int(input(f\"Inizio canale [0–{max_idx}] [default 0]: \") or 0)\n",
    "        ch_end   = int(input(f\"Fine canale [0–{max_idx}] [default {ch_start}]: \") or ch_start)\n",
    "        plot_comparison(raw_for_ica, raw_full, start_sec, duration_sec, ch_start=ch_start, ch_end=ch_end)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "152c9890-67ab-45ef-9bf6-445c36ee981f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "'''\n",
    "\n",
    "Perfetto — ecco la versione “while True” che plottà automaticamente SOLO i canali residui post-PREP (quelli marcati in raw.info['bads'] \n",
    "o, in fallback, presi da keep_df['post_interp_residual_channels']).\n",
    "Se una run non ha residui, ti mostra l’elenco canali e ti lascia scegliere un intervallo di indici da plottare.\n",
    "\n",
    "Assumo che tu abbia già in RAM: EEG_for_ICA, EEG_data_prep, keep_df.\n",
    "\n",
    "\n",
    "\n",
    "'task': 'task_1',\n",
    "  'subject': '10',\n",
    "  'run': 4,\n",
    "  'n_residual': 1,\n",
    "  'bads_set': [np.str_('P6')]},\n",
    " {'task': 'task_1',\n",
    "  'subject': '100',\n",
    "  'run': 8,\n",
    "  'n_residual': 1,\n",
    "  'bads_set': ['Fp2']},\n",
    " {'task': 'task_1',\n",
    "  'subject': '101',\n",
    "  'run': 4,\n",
    "  'n_residual': 1,\n",
    "  'bads_set': [np.str_('T10')]},\n",
    " {'task': 'task_1',\n",
    "  'subject': '102',\n",
    "  'run': 0,\n",
    "  'n_residual': 1,\n",
    "  'bads_set': [np.str_('F6')]},\n",
    " {'task': 'task_1',\n",
    "  'subject': '102',\n",
    "  'run': 4,\n",
    "  'n_residual': 1,\n",
    "  'bads_set': [np.str_('T10')]},\n",
    " {'task': 'task_1',\n",
    "  'subject': '11',\n",
    "  'run': 8,\n",
    "  'n_residual': 1,\n",
    "  'bads_set': ['FT8']},\n",
    " {'task': 'task_1',\n",
    "  'subject': '12',\n",
    "  'run': 4,\n",
    "  'n_residual': 1,\n",
    "  'bads_set': ['FT7']},\n",
    " {'task': 'task_1',\n",
    "  'subject': '13',\n",
    "  'run': 0,\n",
    "  'n_residual': 3,\n",
    "  'bads_set': ['AF8', 'Fp1', 'Fp2']},\n",
    " {'task': 'task_1',\n",
    "  'subject': '18',\n",
    "  \n",
    "  \n",
    "  \n",
    "ok e potresti includere anche una parte che \n",
    "\n",
    "\n",
    "1) se non trova i canali sopra soglia, di quelli residui post-PREP, mi scrive invece\n",
    "i canali sopra soglia che trova, \n",
    "\n",
    "e plotta SOLO sia il canale residuo post post-PREP (in quel caso non sopra soglia)\n",
    "ed i canali trovati sopra soglia? \n",
    "\n",
    "\n",
    "2) se trova che i canali residui post-PREP son sopra soglia, \n",
    "e poi mi trova anche altri canali sopra soglia (che non fanno parte di quelli residui post-PREP),\n",
    "mi scrive sia i canali sopra soglia che trova in post-PREP che quelli sopra soglia che non fanno parte di quelli residui post-PREP,\n",
    "e plotta SOLO sia i canale residui post post-PREP (in questo caso sopra soglia) sia i canali trovati sopra soglia\n",
    "(che che non fanno parte di quelli residui post-PREP)?\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mne\n",
    "from IPython.display import clear_output\n",
    "import ast\n",
    "\n",
    "# =============== Helpers ===============\n",
    "\n",
    "def _ensure_list(x):\n",
    "    \"\"\"Rende 'x' sempre una lista (gestisce anche stringhe tipo \"['F3','F4']\").\"\"\"\n",
    "    if isinstance(x, list): \n",
    "        return x\n",
    "    if isinstance(x, str):\n",
    "        try:\n",
    "            v = ast.literal_eval(x)\n",
    "            return v if isinstance(v, list) else []\n",
    "        except Exception:\n",
    "            return []\n",
    "    return []\n",
    "\n",
    "def get_raw(d, task, subj, run):\n",
    "    \"\"\"Recupera Raw o (Raw, labels) dalla struttura annidata e ritorna il Raw.\"\"\"\n",
    "    v = d[task][str(subj)][int(run)]\n",
    "    return v[0] if isinstance(v, tuple) else v\n",
    "\n",
    "def get_residual_channels_from_keep(keep_df, task, subject, run, raw=None):\n",
    "    \"\"\"\n",
    "    Ritorna i canali residui post-PREP per (task, subject, run).\n",
    "      1) Se 'raw' ha bads -> usa quelli\n",
    "      2) Altrimenti fallback da keep_df['post_interp_residual_channels']\n",
    "    \"\"\"\n",
    "    if raw is not None:\n",
    "        bads = raw.info.get('bads') or []\n",
    "        if isinstance(bads, list) and len(bads) > 0:\n",
    "            return sorted([ch for ch in bads if ch in raw.ch_names])\n",
    "\n",
    "    row = keep_df[(keep_df['task'] == task) &\n",
    "                  (keep_df['subject'].astype(str) == str(subject)) &\n",
    "                  (keep_df['run'].astype(int) == int(run))]\n",
    "    if len(row) == 0:\n",
    "        return []\n",
    "    resid = _ensure_list(row.iloc[0]['post_interp_residual_channels'])\n",
    "    if raw is not None:\n",
    "        resid = [ch for ch in resid if ch in raw.ch_names]\n",
    "    return sorted(resid)\n",
    "\n",
    "def plot_comparison(raw_for_ica: mne.io.Raw,\n",
    "                    raw_full: mne.io.Raw,\n",
    "                    start_sec: float = 0.0,\n",
    "                    duration_sec: float = 5.0,\n",
    "                    picks_by_name=None,\n",
    "                    ch_start: int = 0,\n",
    "                    ch_end: int = 0):\n",
    "    \"\"\"Confronto 2 pannelli: sopra EEG_for_ICA (residui spessore maggiore), sotto EEG_data_prep.\"\"\"\n",
    "    sfreq = raw_for_ica.info['sfreq']\n",
    "    start_samp = int(start_sec * sfreq)\n",
    "    stop_samp  = int((start_sec + duration_sec) * sfreq)\n",
    "    stop_samp  = min(stop_samp, raw_for_ica.n_times, raw_full.n_times)  # guardrail\n",
    "    times = np.arange(start_samp, stop_samp) / sfreq\n",
    "    microvolt_scale = 1e6\n",
    "\n",
    "    # Scelta canali\n",
    "    if picks_by_name and len(picks_by_name) > 0:\n",
    "        picks_names = [ch for ch in picks_by_name if ch in raw_for_ica.ch_names]\n",
    "        picks_idx   = [raw_for_ica.ch_names.index(ch) for ch in picks_names]\n",
    "    else:\n",
    "        ch_end = max(ch_end, ch_start)\n",
    "        picks_idx   = list(range(ch_start, ch_end + 1))\n",
    "        picks_names = [raw_for_ica.ch_names[i] for i in picks_idx]\n",
    "\n",
    "    fig, (ax_top, ax_bot) = plt.subplots(2, 1, sharex=True, figsize=(12, 8))\n",
    "\n",
    "    # TOP: EEG_for_ICA — linewidth maggiore se canale è nei bads\n",
    "    bads = set(raw_for_ica.info.get('bads') or [])\n",
    "    for i, ch_idx in enumerate(picks_idx):\n",
    "        ch_name = picks_names[i]\n",
    "        data = raw_for_ica.get_data(picks=[ch_idx]).squeeze()[start_samp:stop_samp] * microvolt_scale\n",
    "        lw = 2.5 if ch_name in bads else 1.0\n",
    "        ax_top.plot(times, data, label=ch_name, linewidth=lw, alpha=0.9)\n",
    "    ax_top.set_title(\"EEG_for_ICA (post-PyPREP, residui marcati)\")\n",
    "    ax_top.set_ylabel(\"µV\")\n",
    "\n",
    "    # BOTTOM: EEG_data_prep\n",
    "    for ch_idx, ch_name in zip(picks_idx, picks_names):\n",
    "        data = raw_full.get_data(picks=[ch_idx]).squeeze()[start_samp:stop_samp] * microvolt_scale\n",
    "        ax_bot.plot(times, data, label=ch_name, alpha=0.9)\n",
    "    ax_bot.set_title(\"EEG_data_prep (post-PyPREP)\")\n",
    "    ax_bot.set_xlabel(\"Tempo (s)\")\n",
    "    ax_bot.set_ylabel(\"µV\")\n",
    "\n",
    "    # legenda unica\n",
    "    handles, labels = ax_bot.get_legend_handles_labels()\n",
    "    if labels:\n",
    "        fig.legend(handles, labels, loc='lower center',\n",
    "                   ncol=min(len(labels), 6), bbox_to_anchor=(0.5, -0.05))\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(bottom=0.15)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# =============== MENU INTERATTIVO ===============\n",
    "while True:\n",
    "    clear_output(wait=True)\n",
    "    cmd = input(\"Digita 'ok' per plottare, 'stop' per uscire: \").strip().lower()\n",
    "    if cmd == 'stop':\n",
    "        print(\"Bye!\")\n",
    "        break\n",
    "    if cmd != 'ok':\n",
    "        print(\"Comando non riconosciuto.\")\n",
    "        continue\n",
    "\n",
    "    # Selezione task\n",
    "    tasks = list(EEG_for_ICA.keys())\n",
    "    print(f\"\\nTask disponibili: {tasks}\")\n",
    "    task = input(\"Scegli task: \").strip()\n",
    "    if task not in EEG_for_ICA:\n",
    "        print(\"Task non valido.\")\n",
    "        continue\n",
    "\n",
    "    # Selezione soggetto\n",
    "    subjects = list(EEG_for_ICA[task].keys())\n",
    "    print(f\"\\nSoggetti disponibili: {subjects}\")\n",
    "    sbj = input(\"Scegli soggetto: \").strip()\n",
    "    if sbj not in EEG_for_ICA[task]:\n",
    "        print(\"Soggetto non valido.\")\n",
    "        continue\n",
    "\n",
    "    # Selezione run\n",
    "    available_runs = sorted(list(EEG_for_ICA[task][sbj].keys()))\n",
    "    print(f\"\\nRun disponibili: {available_runs}\")\n",
    "    try:\n",
    "        run = int(input(\"Scegli run: \").strip())\n",
    "    except Exception:\n",
    "        print(\"Run non valida.\")\n",
    "        continue\n",
    "    if run not in available_runs:\n",
    "        print(\"Run non valida.\")\n",
    "        continue\n",
    "\n",
    "    # Finestra temporale\n",
    "    try:\n",
    "        start_sec    = float(input(\"\\nStart time (s) [default 0]: \") or 0.0)\n",
    "        duration_sec = float(input(\"Durata (s) [default 5]: \") or 5.0)\n",
    "    except Exception:\n",
    "        print(\"Valori tempo non validi.\")\n",
    "        continue\n",
    "\n",
    "    # Raw e canali residui\n",
    "    raw_for_ica = get_raw(EEG_for_ICA,   task, sbj, run)\n",
    "    raw_full    = get_raw(EEG_data_prep, task, sbj, run)\n",
    "    resid = get_residual_channels_from_keep(keep_df, task, sbj, run, raw_for_ica)\n",
    "\n",
    "    # Log e plot\n",
    "    if resid:\n",
    "        print(\"Canali residui post-interp:\", resid)\n",
    "        plot_comparison(raw_for_ica, raw_full, start_sec, duration_sec, picks_by_name=resid)\n",
    "    else:\n",
    "        print(f\"\\n\\033[1m[{task} / subj {sbj} / run {run}] Nessun canale residuo post-PREP\\033[0m.\")\n",
    "        ch_names = raw_for_ica.ch_names\n",
    "        print(\"\\nElenco canali:\", \"  \".join(f\"\\033[1m{i}\\033[0m:{ch}\" for i, ch in enumerate(ch_names)))\n",
    "        max_idx = len(ch_names) - 1\n",
    "        try:\n",
    "            ch_start = int(input(f\"Inizio canale [0–{max_idx}] [default 0]: \") or 0)\n",
    "            ch_end   = int(input(f\"Fine canale [0–{max_idx}] [default {ch_start}]: \") or ch_start)\n",
    "        except Exception:\n",
    "            print(\"Intervallo canali non valido.\")\n",
    "            continue\n",
    "        plot_comparison(raw_for_ica, raw_full, start_sec, duration_sec,\n",
    "                        ch_start=ch_start, ch_end=ch_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbaf3eb5-5f0a-4bf8-bd30-e1d2b0e402c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Ok e potresti includere anche una parte che \n",
    "\n",
    "\n",
    "1) se non trova i canali sopra soglia, di quelli residui post-PREP, mi scrive invece\n",
    "i canali sopra soglia che trova, \n",
    "\n",
    "e plotta SOLO sia il canale residuo post post-PREP (in quel caso non sopra soglia)\n",
    "ed i canali trovati sopra soglia? \n",
    "\n",
    "\n",
    "2) se trova che i canali residui post-PREP son sopra soglia, \n",
    "e poi mi trova anche altri canali sopra soglia (che non fanno parte di quelli residui post-PREP),\n",
    "mi scrive sia i canali sopra soglia che trova in post-PREP che quelli sopra soglia che non fanno parte di quelli residui post-PREP,\n",
    "e plotta SOLO sia i canale residui post post-PREP (in questo caso sopra soglia) sia i canali trovati sopra soglia\n",
    "(che che non fanno parte di quelli residui post-PREP)?\n",
    "\n",
    "\n",
    "perfetto — ecco la versione con while True che:\n",
    "\n",
    "prende i residui post-PREP (da raw.info['bads'] o keep_df),\n",
    "trova i canali sopra soglia (es. 100 µV) nella finestra scelta,\n",
    "\n",
    "A) Stampa un riepilogo chiaro dei casi:\n",
    "\n",
    "residui sopra soglia,\n",
    "canali sopra soglia non residui,\n",
    "\n",
    "B) Plotta SOLO:\n",
    "\n",
    "se nessun residuo è sopra soglia: tutti i residui + i canali sopra soglia non residui;\n",
    "se ci sono residui sopra soglia: residui sopra soglia + canali sopra soglia non residui;\n",
    "se non c’è nulla sopra soglia e non ci sono residui: chiede un range di canali da plottare.\n",
    "\n",
    "\n",
    "La soglia è interattiva (default 100 µV).\n",
    "\n",
    "Nella traccia sopra:\n",
    "residui = linea più spessa,\n",
    "canali “> soglia” non-residui = spessore medio.\n",
    "\n",
    "Nessuna modifica viene fatta ai Raw: qui stiamo solo ispezionando.\n",
    "Se vuoi una modalità che aggiunge i canali > soglia a raw.info['bads'] (per un’ICA “augmented bads”), dillo e te la integro come toggle.\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mne\n",
    "from IPython.display import clear_output\n",
    "import ast\n",
    "\n",
    "# =============== Helpers ===============\n",
    "\n",
    "def _ensure_list(x):\n",
    "    \"\"\"Rende 'x' sempre una lista (gestisce anche stringhe tipo \"['F3','F4']\").\"\"\"\n",
    "    if isinstance(x, list): \n",
    "        return x\n",
    "    if isinstance(x, str):\n",
    "        try:\n",
    "            v = ast.literal_eval(x)\n",
    "            return v if isinstance(v, list) else []\n",
    "        except Exception:\n",
    "            return []\n",
    "    return []\n",
    "\n",
    "def get_raw(d, task, subj, run):\n",
    "    \"\"\"Recupera Raw o (Raw, labels) dalla struttura annidata e ritorna il Raw.\"\"\"\n",
    "    v = d[task][str(subj)][int(run)]\n",
    "    return v[0] if isinstance(v, tuple) else v\n",
    "\n",
    "def get_residual_channels_from_keep(keep_df, task, subject, run, raw=None):\n",
    "    \"\"\"\n",
    "    Ritorna i canali residui post-PREP per (task, subject, run).\n",
    "      1) Se 'raw' ha bads -> usa quelli\n",
    "      2) Altrimenti fallback da keep_df['post_interp_residual_channels']\n",
    "    \"\"\"\n",
    "    if raw is not None:\n",
    "        bads = raw.info.get('bads') or []\n",
    "        if isinstance(bads, list) and len(bads) > 0:\n",
    "            return sorted([ch for ch in bads if ch in raw.ch_names])\n",
    "\n",
    "    row = keep_df[(keep_df['task'] == task) &\n",
    "                  (keep_df['subject'].astype(str) == str(subject)) &\n",
    "                  (keep_df['run'].astype(int) == int(run))]\n",
    "    if len(row) == 0:\n",
    "        return []\n",
    "    resid = _ensure_list(row.iloc[0]['post_interp_residual_channels'])\n",
    "    if raw is not None:\n",
    "        resid = [ch for ch in resid if ch in raw.ch_names]\n",
    "    return sorted(resid)\n",
    "\n",
    "def channels_above_threshold(raw: mne.io.Raw,\n",
    "                             start_sec: float,\n",
    "                             duration_sec: float,\n",
    "                             threshold_uv: float) -> list:\n",
    "    \"\"\"\n",
    "    Lista di canali con |amp| > threshold_uv in [start_sec, start_sec+duration_sec] (µV).\n",
    "    \"\"\"\n",
    "    sfreq = raw.info['sfreq']\n",
    "    start_samp = int(start_sec * sfreq)\n",
    "    stop_samp  = int((start_sec + duration_sec) * sfreq)\n",
    "    stop_samp  = min(stop_samp, raw.n_times)\n",
    "    if stop_samp <= start_samp:\n",
    "        return []\n",
    "    data = raw.get_data()[:, start_samp:stop_samp] * 1e6  # µV\n",
    "    mask = np.max(np.abs(data), axis=1) > float(threshold_uv)\n",
    "    return [ch for ch, is_hi in zip(raw.ch_names, mask) if is_hi]\n",
    "\n",
    "def plot_comparison(raw_for_ica: mne.io.Raw,\n",
    "                    raw_full: mne.io.Raw,\n",
    "                    start_sec: float = 0.0,\n",
    "                    duration_sec: float = 5.0,\n",
    "                    picks_by_name=None,\n",
    "                    ch_start: int = 0,\n",
    "                    ch_end: int = 0,\n",
    "                    hi_set: set = None):\n",
    "    \"\"\"\n",
    "    Confronto 2 pannelli: sopra EEG_for_ICA (residui = linewidth maggiore; canali > soglia = medio),\n",
    "    sotto EEG_data_prep. 'hi_set' serve per evidenziare canali sopra soglia (non-residui).\n",
    "    \"\"\"\n",
    "    sfreq = raw_for_ica.info['sfreq']\n",
    "    start_samp = int(start_sec * sfreq)\n",
    "    stop_samp  = int((start_sec + duration_sec) * sfreq)\n",
    "    stop_samp  = min(stop_samp, raw_for_ica.n_times, raw_full.n_times)  # guardrail\n",
    "    times = np.arange(start_samp, stop_samp) / sfreq\n",
    "    microvolt_scale = 1e6\n",
    "\n",
    "    # Scelta canali\n",
    "    if picks_by_name and len(picks_by_name) > 0:\n",
    "        picks_names = [ch for ch in picks_by_name if ch in raw_for_ica.ch_names]\n",
    "        picks_idx   = [raw_for_ica.ch_names.index(ch) for ch in picks_names]\n",
    "    else:\n",
    "        ch_end = max(ch_end, ch_start)\n",
    "        picks_idx   = list(range(ch_start, ch_end + 1))\n",
    "        picks_names = [raw_for_ica.ch_names[i] for i in picks_idx]\n",
    "\n",
    "    fig, (ax_top, ax_bot) = plt.subplots(2, 1, sharex=True, figsize=(12, 8))\n",
    "\n",
    "    # TOP: EEG_for_ICA — linewidth:\n",
    "    #   residui (in bads)      -> 2.8\n",
    "    #   sopra soglia (hi_set)  -> 2.0\n",
    "    #   altri                   -> 1.0\n",
    "    bads = set(raw_for_ica.info.get('bads') or [])\n",
    "    hi_set = set(hi_set or [])\n",
    "    for i, ch_idx in enumerate(picks_idx):\n",
    "        ch_name = picks_names[i]\n",
    "        data = raw_for_ica.get_data(picks=[ch_idx]).squeeze()[start_samp:stop_samp] * microvolt_scale\n",
    "        if ch_name in bads:\n",
    "            lw = 2.8\n",
    "        elif ch_name in hi_set:\n",
    "            lw = 2.0\n",
    "        else:\n",
    "            lw = 1.0\n",
    "        ax_top.plot(times, data, label=ch_name, linewidth=lw, alpha=0.95)\n",
    "    ax_top.set_title(\"EEG_for_ICA (post-PyPREP) — residui (spesso) & > soglia (medio)\")\n",
    "    ax_top.set_ylabel(\"µV\")\n",
    "\n",
    "    # BOTTOM: EEG_data_prep\n",
    "    for ch_idx, ch_name in zip(picks_idx, picks_names):\n",
    "        data = raw_full.get_data(picks=[ch_idx]).squeeze()[start_samp:stop_samp] * microvolt_scale\n",
    "        ax_bot.plot(times, data, label=ch_name, alpha=0.9)\n",
    "    ax_bot.set_title(\"EEG_data_prep (post-PyPREP)\")\n",
    "    ax_bot.set_xlabel(\"Tempo (s)\")\n",
    "    ax_bot.set_ylabel(\"µV\")\n",
    "\n",
    "    # legenda unica\n",
    "    handles, labels = ax_bot.get_legend_handles_labels()\n",
    "    if labels:\n",
    "        fig.legend(handles, labels, loc='lower center',\n",
    "                   ncol=min(len(labels), 6), bbox_to_anchor=(0.5, -0.05))\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(bottom=0.15)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# =============== MENU INTERATTIVO ===============\n",
    "while True:\n",
    "    clear_output(wait=True)\n",
    "    cmd = input(\"Digita 'ok' per plottare, 'stop' per uscire: \").strip().lower()\n",
    "    if cmd == 'stop':\n",
    "        print(\"Bye!\")\n",
    "        break\n",
    "    if cmd != 'ok':\n",
    "        print(\"Comando non riconosciuto.\")\n",
    "        continue\n",
    "\n",
    "    # Selezione task\n",
    "    tasks = list(EEG_for_ICA.keys())\n",
    "    print(f\"\\nTask disponibili: {tasks}\")\n",
    "    task = input(\"Scegli task: \").strip()\n",
    "    if task not in EEG_for_ICA:\n",
    "        print(\"Task non valido.\")\n",
    "        continue\n",
    "\n",
    "    # Selezione soggetto\n",
    "    subjects = list(EEG_for_ICA[task].keys())\n",
    "    print(f\"\\nSoggetti disponibili: {subjects}\")\n",
    "    sbj = input(\"Scegli soggetto: \").strip()\n",
    "    if sbj not in EEG_for_ICA[task]:\n",
    "        print(\"Soggetto non valido.\")\n",
    "        continue\n",
    "\n",
    "    # Selezione run\n",
    "    available_runs = sorted(list(EEG_for_ICA[task][sbj].keys()))\n",
    "    print(f\"\\nRun disponibili: {available_runs}\")\n",
    "    try:\n",
    "        run = int(input(\"Scegli run: \").strip())\n",
    "    except Exception:\n",
    "        print(\"Run non valida.\")\n",
    "        continue\n",
    "    if run not in available_runs:\n",
    "        print(\"Run non valida.\")\n",
    "        continue\n",
    "\n",
    "    # Parametri analisi\n",
    "    try:\n",
    "        start_sec    = float(input(\"\\nStart time (s) [default 0]: \") or 0.0)\n",
    "        duration_sec = float(input(\"Durata (s) [default 5]: \") or 5.0)\n",
    "        thr_uv       = float(input(\"Soglia (µV) [default 100]: \") or 100.0)\n",
    "    except Exception:\n",
    "        print(\"Valori inseriti non validi.\")\n",
    "        continue\n",
    "\n",
    "    # Raw e insiemi di canali\n",
    "    raw_for_ica = get_raw(EEG_for_ICA,   task, sbj, run)\n",
    "    raw_full    = get_raw(EEG_data_prep, task, sbj, run)\n",
    "\n",
    "    R = set(get_residual_channels_from_keep(keep_df, task, sbj, run, raw_for_ica))  # residui post-PREP\n",
    "    T = set(channels_above_threshold(raw_for_ica, start_sec, duration_sec, thr_uv)) # > soglia nella finestra\n",
    "\n",
    "    T_R     = sorted(R & T)   # residui sopra soglia\n",
    "    T_notR  = sorted(T - R)   # sopra soglia non-residui\n",
    "    R_only  = sorted(R)       # tutti i residui (anche non sopra soglia)\n",
    "\n",
    "    # ---- Report testuale ----\n",
    "    print(\"\\n=== RIEPILOGO CANALI ===\")\n",
    "    print(f\"Residui post-PREP (R): {R_only if R_only else 'nessuno'}\")\n",
    "    if T:\n",
    "        print(f\"Canali > {thr_uv:.1f} µV (T): {sorted(T)}\")\n",
    "    else:\n",
    "        print(f\"Nessun canale > {thr_uv:.1f} µV nella finestra selezionata.\")\n",
    "\n",
    "    if T_R:\n",
    "        print(f\"Residui > {thr_uv:.1f} µV (R ∩ T): {T_R}\")\n",
    "    else:\n",
    "        print(f\"Nessun residuo > {thr_uv:.1f} µV.\")\n",
    "\n",
    "    if T_notR:\n",
    "        print(f\"> {thr_uv:.1f} µV NON-residui (T \\\\ R): {T_notR}\")\n",
    "    else:\n",
    "        print(f\"Nessun canale > {thr_uv:.1f} µV al di fuori dei residui.\")\n",
    "\n",
    "    # ---- Scelta cosa plottare (logica richiesta) ----\n",
    "    picks = []\n",
    "    hi_set = set()  # per evidenziare canali > soglia\n",
    "\n",
    "    if T:  # esistono canali sopra soglia\n",
    "        if T_R:  # residui sopra soglia presenti\n",
    "            # Plotta SOLO residui sopra soglia + non-residui sopra soglia\n",
    "            picks = sorted(set(T_R) | set(T_notR))\n",
    "            hi_set = set(picks)  # tutti i picks qui sono > soglia\n",
    "            print(\"\\nPlot: residui sopra soglia + non-residui sopra soglia.\")\n",
    "        else:\n",
    "            # Nessun residuo sopra soglia -> plotta T_notR + TUTTI i residui (anche non > soglia)\n",
    "            picks = sorted(set(T_notR) | set(R_only))\n",
    "            hi_set = set(T_notR)  # evidenzia solo i > soglia non-residui\n",
    "            print(\"\\nPlot: tutti i residui (non > soglia) + canali > soglia NON-residui.\")\n",
    "    else:\n",
    "        if R:\n",
    "            # Nessun canale > soglia, ma ci sono residui: plotta solo i residui\n",
    "            picks = R_only\n",
    "            hi_set = set()  # nessuno > soglia\n",
    "            print(\"\\nPlot: nessun canale > soglia, mostro solo i residui.\")\n",
    "        else:\n",
    "            # Nessun residuo e nessun > soglia: fallback manuale\n",
    "            ch_names = raw_for_ica.ch_names\n",
    "            print(\"\\nNessun residuo e nessun canale > soglia.\")\n",
    "            print(\"Elenco canali:\", \"  \".join(f\"\\033[1m{i}\\033[0m:{ch}\" for i, ch in enumerate(ch_names)))\n",
    "            max_idx = len(ch_names) - 1\n",
    "            try:\n",
    "                ch_start = int(input(f\"Inizio canale [0–{max_idx}] [default 0]: \") or 0)\n",
    "                ch_end   = int(input(f\"Fine canale [0–{max_idx}] [default {ch_start}]: \") or ch_start)\n",
    "            except Exception:\n",
    "                print(\"Intervallo canali non valido.\")\n",
    "                continue\n",
    "            plot_comparison(raw_for_ica, raw_full, start_sec, duration_sec,\n",
    "                            ch_start=ch_start, ch_end=ch_end, hi_set=set())\n",
    "            continue\n",
    "\n",
    "    # Esegui il plot sui canali selezionati\n",
    "    if len(picks) == 0:\n",
    "        print(\"\\nNulla da plottare con i criteri scelti.\")\n",
    "        continue\n",
    "\n",
    "    plot_comparison(raw_for_ica, raw_full, start_sec, duration_sec,\n",
    "                    picks_by_name=picks, hi_set=hi_set)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c317d2-0d75-4870-bdcf-4701a02daf25",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### **EEG Post PyPREP - Custom ICA Pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90ab9bd-551f-4e42-8b74-bcaf7dd60a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Caricare l'intero dizionario annidato con pickle\n",
    "path = '/home/stefano/EEGMMIDB_Analyses/pyprep_outputs/'\n",
    "\n",
    "# Caricare l'intero dizionario annidato con pickle\n",
    "with open(f'{path}EEG_for_ICA.pkl', 'rb') as f:\n",
    "    EEG_for_ICA = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ae113f-68ce-4c23-be74-270d4dc3bbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(EEG_for_ICA.keys())\n",
    "print(EEG_for_ICA['task_1'].keys())\n",
    "print(EEG_for_ICA['task_1']['100'].keys())\n",
    "print(type(EEG_for_ICA['task_1']['100'][0][0]))\n",
    "print(type(EEG_for_ICA['task_1']['100'][0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e172a7-0133-45b1-b329-87d59e450305",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(EEG_for_ICA.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982b1863-e52d-4d5d-820c-2571f6c2e192",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "                                                            ATTENZIONE: UFFICIALE SENZA TRASCRIZIONI\n",
    "                                                                        PER USO CON SPYDER\n",
    "\n",
    "                                                                        CON PLOT STATICI\n",
    "                                                                          \n",
    "                                                                        OLD 3 AGOSTO FINO A 14:20\n",
    "                                                                        DOPO CANCELLAZIONI \n",
    "                                                                          FUNZIONI VECCHIE\n",
    "\n",
    "                                                                        \n",
    "\n",
    "\n",
    "                                                                        \n",
    "📁 File locali\n",
    "Questi sono i file che salvi sul tuo computer locale, dentro base_path:\n",
    "\n",
    "base_path = \"/home/stefano/Downloads/\"s\n",
    "\n",
    "post_ica_path = f\"{base_path}post_ica_data.pkl\"\n",
    "ica_models_path = f\"{base_path}ica_models.pkl\"\n",
    "bad_components_path = f\"{base_path}ica_bad_components.pkl\"\n",
    "\n",
    "completed_runs_file = f\"{base_path}processed_runs_file.pkl\"\n",
    "\n",
    "\n",
    "Ti danno come output:\n",
    "\n",
    "/home/stefano/Downloads/post_ica_data.pkl\n",
    "\n",
    "/home/stefano/Downloads/ica_models.pkl\n",
    "\n",
    "/home/stefano/Downloads/ica_bad_components.pkl\n",
    "\n",
    "/home/stefano/Downloads/processed_runs_file.pkl\n",
    "\n",
    "\n",
    "🌐 File sul server remoto\n",
    "\n",
    "\n",
    "Quando chiami:\n",
    "\n",
    "\n",
    "send_to_server(\n",
    "    [post_ica_path, ica_models_path, bad_components_path],\n",
    "    remote_user, remote_host, remote_path\n",
    ")\n",
    "viene generato un comando scp simile a questo:\n",
    "\n",
    "\n",
    "scp /home/stefano/Downloads/post_ica_data.pkl  stefano@160.80.53.119:/home/stefano/EEGMMIDB_Analyses/\n",
    "Il comportamento è:\n",
    "\n",
    "il file viene copiato da /home/stefano/Downloads/...\n",
    "fino a /home/stefano/EEGMMIDB_Analyses/ sul server remoto\n",
    "\n",
    "Lo stesso succede anche per ica_models.pkl e ica_bad_components.pkl.\n",
    "\n",
    "Il file processed_runs_file.pkl non viene inviato al server, serve solo per salvare localmente le run completate.\n",
    "\n",
    "🧠 Riepilogo\n",
    "\n",
    "| File                      | Percorso locale                                                 | Percorso nel server (`scp`)                              |\n",
    "| ------------------------- | --------------------------------------------------------------- | -------------------------------------------------------- |\n",
    "| post\\_ica\\_data.pkl       | `/home/stefano/Downloads/post_ica_data.pkl`                     | `/home/stefano/EEGMMIDB_Analyses/post_ica_data.pkl`      |\n",
    "| ica\\_models.pkl           | `/home/stefano/Downloads/ica_models.pkl`                        | `/home/stefano/EEGMMIDB_Analyses/ica_models.pkl`         |\n",
    "| ica\\_bad\\_components.pkl  | `/home/stefano/Downloads/ica_bad_components.pkl`                | `/home/stefano/EEGMMIDB_Analyses/ica_bad_components.pkl` |\n",
    "| processed\\_runs\\_file.pkl | `/home/stefano/Downloads/processed_runs_file.pkl` (solo locale) | —                                                        |\n",
    "\n",
    "\n",
    "✅ In uso\n",
    "Il codice salva i file locali, li invia al server, e poi rimuove le run già processate dal file locale.\n",
    "\n",
    "Il server mantiene sempre una copia completa di tutti i file inviati, anche se li elimini dal locale.\n",
    "\n",
    "Il file processed_runs_file.pkl serve solo come tracking locale, e non viene copiato sulla macchina remota.\n",
    "\n",
    "\n",
    "Perfetto vorrei solo aggiungere delle chiarificazioni ai plots.. ossia...\n",
    "\n",
    "1) nella prima colonna, mi devo chiedo se l'asse x conviene metterlo come \"time (s) \" mentre l'asse y non so se tenere il range minimo e massimo\n",
    "\n",
    "2) nella seconda e terza colonna, mi devo chiedo se l'asse x conviene metterlo come \"time (s) \" mentre l'asse y direi che sia una indicazione \n",
    "dei microvolts ossia mv (con la m greca magari).. \n",
    "per verificare però con certezza il range di voltaggio del potenziale, allora conviene che esploro dai dati originali il range, giusto? \n",
    "così che, se son sicuro che sia in microvolt (magari identificabile dall'unità di misura quanticabile ossia a quanti microvolts corrisponde un volt e\n",
    "vedere se effettivamente nei miei dati c'è quel range là?) \n",
    "\n",
    "E poi, verificato questo, metterò sull'asse y di 2° e 3° colonna una indicazione in range microvolt su asse y... giusto?\n",
    "\n",
    "\n",
    "| colonna                             | cosa stai tracciando                                 | unità “fisica”                                                                               | che etichetta mettere?                                                                 |\n",
    "| ----------------------------------- | ---------------------------------------------------- | -------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------- |\n",
    "| **ICA Sources**                     | coefficienti delle sorgenti (mix lineare dei canali) | stesso ordine di grandezza dell’EEG (Volt → µV) ma non hanno *un significato fisico diretto* | `µV (ICA)` oppure semplicemente `a.u.` se vuoi ricordare che non è un segnale misurato |\n",
    "| **Segnale originale / ricostruito** | canali EEG reali                                     | Volt ⇒ tipicamente 10-100 µV                                                                 | `µV`                                                                                   |\n",
    "\n",
    "\n",
    "Regola spiccia: se stai già moltiplicando i tracciati per 1e6 (oppure MNE lo fa per te) puoi etichettare l’asse Y con µV.\n",
    "Gli assi X vanno invece sempre in secondi (Time (s)).\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "Di seguito trovi tutto il necessario per:\n",
    "\n",
    "Controllare che il segnale ricostruito non superi ±100 µV.\n",
    "\n",
    "Interpolare (facoltativamente o in automatico) i canali che sforano, prima di passare al prompt ICA_confirm.\n",
    "\n",
    "Gli snippet sono pensati per essere incollati nella tua stessa cella di definizioni;\n",
    "basta poi integrare poche righe nel loop principale subito dopo raw_clean = ica.apply(raw_copy).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Come funziona l’interpolazione in MNE\n",
    "Quando chiami:\n",
    "\n",
    "    raw_out.info[\"bads\"] = chan_names\n",
    "    raw_out = raw_out.interpolate_bads(reset_bads=reset_bads)\n",
    "    \n",
    "    \n",
    "MNE:\n",
    "\n",
    "Identifica le posizioni degli elettrodi (serve un montage valido in raw_out.info).\n",
    "\n",
    "Per i canali marcati come bads calcola i valori per ogni istante di tempo usando una interpolazione spaziale basata sulle potenzialità dei canali buoni circostanti.\n",
    "\n",
    "Per EEG usa tipicamente spherical spline interpolation (Perrin et al.), cioè una soluzione liscia sullo scalpo costruita dai vicini.\n",
    "\n",
    "Sostituisce nel dato i campioni dei canali “bad” con i valori interpolati.\n",
    "\n",
    "Se reset_bads=True, svuota info['bads'] alla fine (i canali non risultano più “bad”).\n",
    "\n",
    "In pratica: non stima un filtro nel tempo, ma ricostruisce spazialmente i canali “guasti” a partire dagli altri elettrodi a ogni time point.\n",
    "Le unità restano quelle di partenza (nel tuo caso µV). \n",
    "\n",
    "L’ICA non viene modificata: stai operando sul segnale ricostruito (raw_clean) dopo ica.apply().\n",
    "\n",
    "\n",
    "    def interpolate_selected_channels(raw_in, channels, by=\"index\", reset_bads=True, verbose=True):\n",
    "        raw_out = raw_in.copy()\n",
    "        # 1) Risolve i nomi canale (da indici o da nomi)\n",
    "        if by == \"index\":\n",
    "            chan_names = [raw_out.ch_names[i] for i in channels]\n",
    "        else:\n",
    "            chan_names = list(channels)\n",
    "\n",
    "        # 2) Valida che i nomi esistano\n",
    "        missing = [ch for ch in chan_names if ch not in raw_out.ch_names]\n",
    "        if missing:\n",
    "            raise ValueError(...)\n",
    "\n",
    "        # 3) Marca quei canali come \"bads\"\n",
    "        raw_out.info[\"bads\"] = chan_names\n",
    "        if verbose:\n",
    "            print(\"Interpolo i canali:\", raw_out.info[\"bads\"])\n",
    "\n",
    "        # 4) Interpola i \"bads\" usando gli altri canali e le posizioni elettrodiche\n",
    "        raw_out = raw_out.interpolate_bads(reset_bads=reset_bads)\n",
    "\n",
    "        # 5) Restituisce una *copia* con i canali rimpiazzati dalla versione interpolata\n",
    "        return raw_out\n",
    "        \n",
    "        \n",
    "\n",
    "Nel tuo flusso succede questo:\n",
    "\n",
    "Applichi l’ICA → raw_clean = ica.apply(raw_copy).\n",
    "\n",
    "Controlli le ampiezze ±100 µV → ottieni bad_idx / bad_names.\n",
    "\n",
    "Se decidi di interpolare, chiami:\n",
    "\n",
    "    raw_clean = interpolate_selected_channels(\n",
    "        raw_in=raw_clean, channels=bad_idx, by=\"index\", reset_bads=True\n",
    "    )\n",
    "e sovrascrivi raw_clean con la versione interpolata.\n",
    "\n",
    "\n",
    "\n",
    "Riplotti con plot_sources_vs_original_vs_reconstructed(...) per vedere l’effetto.\n",
    "\n",
    "Requisiti/attenzioni pratiche\n",
    "Montage obbligatorio: senza posizioni 3D degli elettrodi l’interpolazione non può funzionare correttamente. \n",
    "Assicurati di avere già raw.set_montage(...) (o che le posizioni siano nel file).\n",
    "\n",
    "Interpolare pochi canali: l’interpolazione è affidabile se i “bads” sono pochi e ben circondati da canali buoni. \n",
    "                            Interpolare molti canali contigui degrada la qualità.\n",
    "\n",
    "Tipi di canale: MNE interpola i canali EEG. Se nel tuo raw ci sono EOG/EMG/etc., non passarli alla funzione. (Se vuoi, si può limitare ai soli EEG).\n",
    "\n",
    "reset_bads:\n",
    "\n",
    "    True → dopo l’interpolazione info['bads'] viene svuotato (di solito ciò che si vuole).\n",
    "    False → tieni traccia di quali canali sono stati interpolati.\n",
    "\n",
    "\n",
    "\n",
    "(Opzionale) Versione più robusta della funzione\n",
    "Se vuoi: 1) preservare eventuali “bads” già presenti; 2) limitarti ai soli EEG; 3) restituire anche quali canali sono stati interpolati:\n",
    "\n",
    "\n",
    "    def interpolate_selected_channels(raw_in, channels, by=\"index\", reset_bads=True, verbose=True):\n",
    "        raw_out = raw_in.copy()\n",
    "\n",
    "        # Limita ai soli EEG\n",
    "        eeg_names = set([raw_out.ch_names[i] for i in mne.pick_types(raw_out.info, eeg=True, meg=False)])\n",
    "        if by == \"index\":\n",
    "            chan_names_req = [raw_out.ch_names[i] for i in channels]\n",
    "        else:\n",
    "            chan_names_req = list(channels)\n",
    "\n",
    "        # Tieni solo canali EEG e presenti\n",
    "        chan_names = [ch for ch in chan_names_req if ch in eeg_names]\n",
    "        missing = [ch for ch in chan_names_req if ch not in raw_out.ch_names]\n",
    "        if missing:\n",
    "            raise ValueError(f\"Canali inesistenti: {missing}\")\n",
    "\n",
    "        # Unione con bads già presenti\n",
    "        already_bads = set(raw_out.info.get(\"bads\", []))\n",
    "        raw_out.info[\"bads\"] = list(already_bads.union(chan_names))\n",
    "\n",
    "        if verbose:\n",
    "            print(\"🛠️ Interpolo i canali (EEG):\", raw_out.info[\"bads\"])\n",
    "\n",
    "        raw_out = raw_out.interpolate_bads(reset_bads=reset_bads)\n",
    "\n",
    "        return raw_out\n",
    "Messaggio chiave\n",
    "Dopo l’ICA, prima della conferma: marchi i canali oltre soglia come “bad”, MNE li ricostruisce spazialmente dai vicini, ottieni un raw_clean interpolato, riplotti e poi salvi.\n",
    "\n",
    "Non tocca l’ICA già calcolata; agisce solo sul segnale pulito nel dominio dei canali.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "IO: volevo solo capire se con 'auto' effettivamente interpola quelli che stampa già come quelli fuori range appunto \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "CHATGPT:\n",
    "\n",
    "1 – Le posizioni elettrodiche (“montage”)\n",
    "Topomap: la chiamata plot_topomap(...) funziona anche senza un vero montage, perché se i canali non hanno coordinate 3-D MNE li disegna comunque in cerchio.\n",
    "\n",
    "interpolate_bads: invece ha davvero bisogno delle coordinate.\n",
    "\n",
    "Se mancano, MNE solleva un’eccezione del tipo\n",
    "\n",
    "\n",
    "RuntimeError: Cannot interpolate bad channels. No location available.\n",
    "Quindi sì: se nel tuo raw non ci fosse già raw.info['chs'][i]['loc'] valorizzato, l’interpolazione fallirebbe.\n",
    "\n",
    "Il fatto che non dia errori indica che il montage c’è (o che lo hai impostato con raw.set_montage(...) in fase di import).\n",
    "\n",
    "Check rapido\n",
    "\n",
    "\n",
    "# se non sei sicuro:\n",
    "print(raw.get_montage())    # None se non c’è nulla\n",
    "Se stampa qualcosa (es. DigitizedMontage | 64 channels), sei a posto.\n",
    "\n",
    "2 – Cosa succede quando scegli “auto”\n",
    "check_recon_amplitude_uV ritorna bad_idx, cioè gli indici dei canali che superano ±100 µV.\n",
    "\n",
    "Col comando auto fai, letteralmente:\n",
    "\n",
    "\n",
    "raw_clean = interpolate_selected_channels(\n",
    "    raw_in=raw_clean,\n",
    "    channels=bad_idx,     # <-- proprio quelli segnalati\n",
    "    by=\"index\",\n",
    "    reset_bads=True\n",
    ")\n",
    "Dentro interpolate_selected_channels:\n",
    "\n",
    "Converte quegli indici in nomi (chan_names).\n",
    "\n",
    "Li mette in raw_out.info[\"bads\"].\n",
    "\n",
    "Chiama raw_out.interpolate_bads(...).\n",
    "\n",
    "Restituisce la copia con i canali ricostruiti.\n",
    "\n",
    "Quindi “auto” interpolerà esattamente i canali che il check ha stampato.\n",
    "\n",
    "\n",
    "\n",
    "IO:\n",
    "\n",
    "\n",
    "ok ma quindi se io metto false, i dati di quei canali bad mi vengono interpolati, il plot DOPO l'interpolazione avrà i dati correttamente interpolati \n",
    "MA comunque questa info io la posso 'rintracciare nei metadati di quella run specifica di quel task e soggetto successivamente, \n",
    "SE volessi ricordarmi quali canali erano stati interpolati?\n",
    "\n",
    "cioè nella mia pipeline in caso successivamente, dopo potrei ri-prelevare dai metadati di quella  di quella run specifica di quel task e soggetto\n",
    "che QUEI CANALI erano bads ed erano stati interpolati?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "CHATGPT:\n",
    "\n",
    "Esattamente — con reset_bads=False ottieni entrambe le cose:\n",
    "\n",
    "| Cosa rimane nel file `.raw` salvato                                                          | Dove lo trovi      |\n",
    "| -------------------------------------------------------------------------------------------- | ------------------ |\n",
    "| **Segnale** dei canali “guasti” ricostruito (quindi il plot dopo l’interpolazione è a posto) | `raw.get_data()`   |\n",
    "| **Etichetta** che quei canali erano “bad” al momento dell’interpolazione                     | `raw.info['bads']` |\n",
    "\n",
    "\n",
    "Come recuperarlo in un secondo momento\n",
    "\n",
    "# Carichi la run dal pickle\n",
    "raw_clean, ann = post_ica_master[task_id][subject_id][run_id]\n",
    "\n",
    "# I canali che hai interpolato all’epoca\n",
    "interpolated_channels = raw_clean.info['bads']\n",
    "print(\"Canali marcati come bad/interpolati:\", interpolated_channels)\n",
    "\n",
    "\n",
    "Se all’epoca avevi usato reset_bads=True, la lista sarebbe vuota; con\n",
    "False resta popolata e puoi sempre risalire a quali elettrodi sono stati\n",
    "ritoccati.\n",
    "\n",
    "\n",
    "Suggerimento per la tua pipeline\n",
    "\n",
    "Se vuoi essere sicuro di non perdere l’informazione anche nel caso in cui\n",
    "domani decida di fare reset_bads=True, puoi salvarla a parte, subito dopo\n",
    "l’interpolazione:\n",
    "\n",
    "# dopo interpolate_selected_channels(...)\n",
    "interpolated_now = list(raw_clean.info['bads'])\n",
    "append_pickle(\n",
    "    {task: {subject: {run: interpolated_now}}},\n",
    "    interpolated_chans_path,   # un nuovo pkl dedicato, se vuoi\n",
    "    return_master=False\n",
    ")\n",
    "Ma se per te va bene che resti dentro raw.info['bads'], basta portare avanti\n",
    "reset_bads=False: MNE conserverà quel promemoria insieme ai dati.\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "import mne\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from mne.viz import plot_topomap\n",
    "\n",
    "from IPython.display import clear_output  \n",
    "\n",
    "import io\n",
    "\n",
    "\n",
    "import collections  # serve per il merge ricorsivo\n",
    "\n",
    "\n",
    "#1 · Funzione di check ampiezza ±100 µV\n",
    "\n",
    "#1.1) Riconversione dinamica in MICROVOLT (i dati di partenza son in VOLT!)\n",
    "\n",
    "def get_data_uV(raw, picks=None):\n",
    "    return raw.get_data(picks=picks) * 1e6  # V → µV\n",
    "\n",
    "def check_recon_amplitude_uV(raw_obj, threshold_uV=100.0, picks=None, verbose=True):\n",
    "    \"\"\"\n",
    "    Ritorna:\n",
    "        bad_idx  – lista indici canali > soglia\n",
    "        bad_names – nomi canali corrispondenti\n",
    "        peak_abs_uV – array picco |µV| per ciascun canale controllato\n",
    "    \"\"\"\n",
    "    \n",
    "    data = get_data_uV(raw_obj, picks=picks)   # <-- ora in µV (lo confermi con il tuo test)\n",
    "    peak_abs_uV = np.max(np.abs(data), axis=1)\n",
    "\n",
    "    if picks is None:\n",
    "        idx = np.arange(len(raw_obj.ch_names))\n",
    "        names = raw_obj.ch_names\n",
    "    else:\n",
    "        idx = np.array(picks, dtype=int)\n",
    "        names = [raw_obj.ch_names[i] for i in idx]\n",
    "\n",
    "    bad_mask = peak_abs_uV > threshold_uV\n",
    "    bad_idx = idx[bad_mask].tolist()\n",
    "    bad_names = [names[i] for i, m in enumerate(bad_mask) if m]\n",
    "\n",
    "    if verbose:\n",
    "        if bad_names:\n",
    "            print(f\"⚠️  Canali oltre ±{threshold_uV} µV:\", bad_names)\n",
    "        else:\n",
    "            print(f\"✅ Tutti i canali entro ±{threshold_uV} µV\")\n",
    "\n",
    "    return bad_idx, bad_names, peak_abs_uV\n",
    "\n",
    "\n",
    "#2 · Funzione di interpolazione selettiva\n",
    "\n",
    "def interpolate_selected_channels(raw_in, channels, by=\"index\", reset_bads=False, verbose=True, final_reref=False):  # + final_reref\n",
    "    \"\"\"\n",
    "    Interpola i canali indicati (indici o nomi).\n",
    "    Ritorna una *copia* di raw con i canali interpolati.\n",
    "    \"\"\"\n",
    "    raw_out = raw_in.copy()\n",
    "    if by == \"index\":\n",
    "        chan_names = [raw_out.ch_names[i] for i in channels]\n",
    "    else:\n",
    "        chan_names = list(channels)\n",
    "\n",
    "    # Verifica che esistano\n",
    "    missing = [ch for ch in chan_names if ch not in raw_out.ch_names]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Canali inesistenti: {missing}\")\n",
    "\n",
    "    raw_out.info[\"bads\"] = chan_names\n",
    "    if verbose:\n",
    "        print(\"🛠️  Interpolo i canali:\", raw_out.info[\"bads\"])\n",
    "    raw_out = raw_out.interpolate_bads(reset_bads=reset_bads)\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    …e dove la chiami (auto o “idx”), puoi passare final_reref=True per farla lì dentro e togliere la chiamata separata.\n",
    "    '''\n",
    "    \n",
    "    if final_reref:                                  # + opzionale: reref finale qui\n",
    "        raw_out.set_eeg_reference('average', projection=False)\n",
    "    \n",
    "    return raw_out\n",
    "\n",
    "\n",
    "\n",
    "# Helper per accodare (deep-merge) i dati nel pickle\n",
    "\n",
    "def append_pickle(obj_to_add: dict, pkl_path: str, return_master = False):\n",
    "\n",
    "    \"\"\"Accoda obj_to_add al pickle (merge task→subject→run).\"\"\"\n",
    "    if os.path.exists(pkl_path):\n",
    "        with open(pkl_path, \"rb\") as f:\n",
    "            master = pickle.load(f)\n",
    "    else:\n",
    "        master = {}\n",
    "        # merge ricorsivo\n",
    "        \n",
    "    for task, subj_dict in obj_to_add.items():\n",
    "        master.setdefault(task, {})\n",
    "        for subj, run_dict in subj_dict.items():\n",
    "            master[task].setdefault(subj, {})\n",
    "            master[task][subj].update(run_dict)\n",
    "            \n",
    "    with open(pkl_path, \"wb\") as f:\n",
    "        pickle.dump(master, f)\n",
    "        f.flush(); os.fsync(f.fileno())\n",
    "        \n",
    "    if return_master:\n",
    "        return master\n",
    "\n",
    "# --- FUNZIONE locale per plottare tutte le ICA components in una sola figura ---\n",
    "def plot_all_components_single_figure(ica, n_cols=8, title=\"ICA Components\"):\n",
    "\n",
    "    '''\n",
    "    components --> restituisce la matrice (n_canali × n_componenti)\n",
    "    '''\n",
    "    components = ica.get_components()\n",
    "    n_components = components.shape[1]\n",
    "    n_rows = int(np.ceil(n_components / n_cols))\n",
    "\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(n_cols * 2, n_rows * 2))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for idx, ax in enumerate(axes):\n",
    "        if idx < n_components:\n",
    "            plot_topomap(components[:, idx], ica.info, axes=ax, show=False)\n",
    "            ax.set_title(f\"ICA {idx}\", fontsize=8)\n",
    "        else:\n",
    "            ax.axis(\"off\")\n",
    "\n",
    "    plt.suptitle(title, fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "#✅ 1. Plot statico delle sorgenti ICA su un range temporale limitato\n",
    "\n",
    "def plot_static_ica_sources(ica, raw, picks, start_time=0, end_time=15, task=None, subject=None, run=None):\n",
    "    sfreq = raw.info['sfreq']\n",
    "    start_sample = int(start_time * sfreq)\n",
    "    stop_sample = int((start_time + end_time) * sfreq)\n",
    "\n",
    "    # Estrai le sorgenti ICA (componenti selezionate)\n",
    "    sources = ica.get_sources(raw).get_data()[picks, start_sample:stop_sample]\n",
    "\n",
    "    # 🛡️ Verifica se ci sono sorgenti da plottare\n",
    "    if sources.shape[0] == 0:\n",
    "        print(\"⚠️ Nessuna sorgente ICA da plottare (picks vuoto o indici non validi)\")\n",
    "\n",
    "    ymin, ymax = np.min(sources), np.max(sources)  # Y-range comune\n",
    "    \n",
    "    # Plot\n",
    "    fig, axes = plt.subplots(len(picks), 1, figsize=(12, len(picks) * 1.5), sharex=True)\n",
    "    for idx, ax in enumerate(axes):\n",
    "        ax.plot(np.linspace(start_time, start_time + end_time, sources.shape[1]), sources[idx])\n",
    "        ax.set_ylabel(f\"ICA {picks[idx]}\")\n",
    "        ax.set_xlim(start_time, start_time + end_time)\n",
    "        ax.set_ylim(ymin, ymax)\n",
    "\n",
    "    plt.suptitle(f\"ICA Sources — Task {task}, Subject {subject}, Run {run}\", y=1.02)\n",
    "    fig.subplots_adjust(top=0.93)\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "#✅ 2. Plot statico del segnale ricostruito su canali EEG selezionati\n",
    "\n",
    "\n",
    "def plot_static_reconstructed_signal(raw_clean, channel_indices, start_time=0, end_time=15, task=None, subject=None, run=None):\n",
    "    sfreq = raw_clean.info['sfreq']\n",
    "    start_sample = int(start_time * sfreq)\n",
    "    stop_sample = int((start_time + end_time) * sfreq)\n",
    "\n",
    "    data = raw_clean.get_data(picks=channel_indices)[:, start_sample:stop_sample] * 1e6  # V → µV\n",
    "    ymin, ymax = np.min(data), np.max(data)\n",
    "\n",
    "    fig, axes = plt.subplots(len(channel_indices), 1, figsize=(12, len(channel_indices) * 1.5), sharex=True)\n",
    "    for idx, ax in enumerate(axes):\n",
    "        ax.plot(np.linspace(start_time, start_time + end_time, data.shape[1]), data[idx])\n",
    "        ax.set_ylabel(raw_clean.ch_names[channel_indices[idx]])\n",
    "        ax.set_xlim(start_time, start_time + end_time)\n",
    "        ax.set_ylim(ymin, ymax)\n",
    "        \n",
    "\n",
    "    plt.suptitle(f\"Segnale Ricostruito — Task {task}, Subject {subject}, Run {run}\", y=1.02)\n",
    "    fig.subplots_adjust(top=0.93)\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "#Ecco la versione “adattiva” della funzione, con\n",
    "#asse X «Time (s)» sempre mostrato sull’ultima riga effettivamente popolata di ciascuna colonna;\n",
    "#etichette Y già come le avevi definite (µV per EEG);\n",
    "#nessuna modifica alla logica del toggle same_scale_eeg\n",
    "\n",
    "#Come funziona\n",
    "\n",
    "#| Colonna | Riga dove si mette l’etichetta “Time (s)” |\n",
    "#| ------- | ----------------------------------------- |\n",
    "#| ICA     | `last_row_ic = len(picks_sources) - 1`    |\n",
    "#| Orig.   | `len(picks_channels) - 1`                 |\n",
    "#| Ricost. | idem Orig.                                |\n",
    "\n",
    "#Se n_rows > len(picks_channels) (succede se mostri più IC che canali),\n",
    "#l’etichetta rimane comunque sull’ultima riga che contiene dati EEG; \n",
    "#le righe vuote ereditano l’asse ma non visualizzano label duplicati.\n",
    "#Così i plot restano ordinati indipendentemente da quanti componenti o canali scegli di visualizzare\n",
    "\n",
    "\n",
    "def plot_sources_vs_original_vs_reconstructed(\n",
    "    ica,\n",
    "    raw_for_sources,          # raw usato nel fit ICA (es. raw_copy)\n",
    "    raw_original,             # raw originale PRIMA dell’ICA\n",
    "    raw_clean,                # raw dopo ica.apply(...)\n",
    "    picks_sources, picks_channels,\n",
    "    start_time, end_time,\n",
    "    task=None, subject=None, run=None,\n",
    "    same_scale_eeg=True,\n",
    "    return_bytes = True\n",
    "):\n",
    "    # -------------------------- estrazione --------------------------\n",
    "    sfreq = raw_for_sources.info['sfreq']\n",
    "    start_sample = int(start_time * sfreq)\n",
    "    stop_sample  = int((start_time + end_time) * sfreq)\n",
    "\n",
    "    sources  = ica.get_sources(raw_for_sources).get_data()[\n",
    "                 picks_sources, start_sample:stop_sample]\n",
    "    original = raw_original.get_data(picks=picks_channels)[:, start_sample:stop_sample]* 1e6  # V→µV\n",
    "    recon    = raw_clean.get_data(picks=picks_channels)[:, start_sample:stop_sample]* 1e6  # V→µV\n",
    "\n",
    "    # -------------------------- limiti Y --------------------------\n",
    "    y_min_src, y_max_src = sources.min(), sources.max()\n",
    "\n",
    "    if same_scale_eeg:\n",
    "        y_min_eeg = min(original.min(), recon.min())\n",
    "        y_max_eeg = max(original.max(), recon.max())\n",
    "        y_min_ori = y_min_rec = y_min_eeg\n",
    "        y_max_ori = y_max_rec = y_max_eeg\n",
    "    else:\n",
    "        y_min_ori, y_max_ori = original.min(), original.max()\n",
    "        y_min_rec, y_max_rec = recon.min(),    recon.max()\n",
    "\n",
    "    # -------------------------- plotting --------------------------\n",
    "    n_rows = max(len(picks_sources), len(picks_channels))\n",
    "    fig, axes = plt.subplots(n_rows, 3, figsize=(18, n_rows * 1.8), sharex=True)\n",
    "\n",
    "    # --- col. 0 – ICA sources\n",
    "    for i in range(len(picks_sources)):\n",
    "        ax = axes[i, 0] if n_rows > 1 else axes[0]\n",
    "        ax.plot(np.linspace(start_time, start_time + end_time, sources.shape[1]), sources[i])\n",
    "        ax.set_ylabel(f\"ICA {picks_sources[i]}\")\n",
    "        ax.set_ylim(y_min_src, y_max_src)\n",
    "        \n",
    "    # etichetta X per la colonna 0 (sempre ultima riga effettiva delle IC)\n",
    "    last_row_ic = len(picks_sources) - 1\n",
    "    axes[last_row_ic, 0].set_xlabel(\"Time (s)\")\n",
    "\n",
    "    # --- col. 1 – originale\n",
    "    for i in range(len(picks_channels)):\n",
    "        ax = axes[i, 1] if n_rows > 1 else axes[1]\n",
    "        ax.plot(np.linspace(start_time, start_time + end_time, original.shape[1]), original[i])\n",
    "        ax.set_ylabel(f\"{raw_original.ch_names[picks_channels[i]]} (µV)\")\n",
    "        ax.set_ylim(y_min_ori, y_max_ori)\n",
    "    # etichetta X ultima riga effettiva degli EEG\n",
    "    axes[len(picks_channels) - 1, 1].set_xlabel(\"Time (s)\")\n",
    "\n",
    "    # --- col. 2 – ricostruito\n",
    "    for i in range(len(picks_channels)):\n",
    "        ax = axes[i, 2] if n_rows > 1 else axes[2]\n",
    "        ax.plot(np.linspace(start_time, start_time + end_time, recon.shape[1]), recon[i])\n",
    "        ax.set_ylabel(f\"{raw_original.ch_names[picks_channels[i]]} (µV)\")\n",
    "        ax.set_ylim(y_min_rec, y_max_rec)\n",
    "    axes[len(picks_channels) - 1, 2].set_xlabel(\"Time (s)\")\n",
    "\n",
    "    # -------------------------- titoli & layout --------------------------\n",
    "    axes[0, 0].set_title(\"ICA Sources\")\n",
    "    axes[0, 1].set_title(\"Segnale Originale\")\n",
    "    axes[0, 2].set_title(\"Segnale Ricostruito\")\n",
    "\n",
    "    fig.suptitle(\n",
    "        f\"Confronto Completo — Task {task}, Subject {subject}, Run {run}\",\n",
    "        fontsize=14, y=1.02\n",
    "    )\n",
    "    fig.subplots_adjust(top=0.93)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # …  tutta la parte di plotting rimane invariata  …\n",
    "\n",
    "    plt.tight_layout()\n",
    "    if not return_bytes:                    # ❶  caso “vecchio”: mostra e basta\n",
    "        plt.show()\n",
    "        return None\n",
    "\n",
    "    # ❷  nuovo: salva in buffer e restituisci bytes\n",
    "    buf = io.BytesIO()\n",
    "    fig.savefig(buf, format=\"png\", dpi=150)\n",
    "    buf.seek(0)\n",
    "    img_bytes = buf.getvalue()\n",
    "    plt.close(fig)\n",
    "    buf.close()\n",
    "    return img_bytes                        # <-- eccoli\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "Ecco un modo per rendere il range Y completamente dinamico in base ai canali che, dopo interpolazione, restano sopra soglia, aggiungendo un margine delta:\n",
    "\n",
    "Come funziona\n",
    "Estrai il segnale ricostruito in µV e prendi solo i canali ancora “bad” (post_bad_idx).\n",
    "\n",
    "Calcoli max_bad = max(abs(recon[bad_channels])).\n",
    "\n",
    "Applichi un range Y uniforme per tutti i subplot ricostruiti:\n",
    "\n",
    "[ -(max_bad + delta_uV), +(max_bad + delta_uV) ]\n",
    "Tracci le righe tratteggiate a ± threshold_uV.\n",
    "\n",
    "In questo modo:\n",
    "\n",
    "Il plot si “adatta” automaticamente all’ampiezza residua degli artefatti.\n",
    "\n",
    "Vedi esattamente se e quanto i canali post-interpolazione superano ±100 µV.\n",
    "\n",
    "Il margine delta_uV evita che le tracce tocchino i bordi del grafico.\n",
    "\n",
    "Puoi naturalmente incorporare questa funzione al posto di quella precedente, passando post_bad_idx preso da check_recon_amplitude_uV dopo l’interpolazione.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "perfetto — ti lascio un diff puntuale (stile unified) + spiegazione chiara di cosa cambia e perché.\n",
    "L’obiettivo è: \n",
    "\n",
    "1) evitare l’IndexError quando passi indici “globali” dei canali a un plot che usa un sottoinsieme (picks_channels), \n",
    "2) forzare il plot di TUTTI i canali nel check post-ICA,\n",
    "3) darti una funzione di plot “robusta” che rimappa automaticamente gli indici globali in indici locali (e accetta anche i nomi dei canali).\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "def plot_sources_vs_original_vs_reconstructed_post_interp(\n",
    "    ica,\n",
    "    raw_for_sources,\n",
    "    raw_original,\n",
    "    raw_clean,\n",
    "    picks_sources,\n",
    "    picks_channels,\n",
    "    start_time,\n",
    "    end_time,\n",
    "    \n",
    "    #post_bad_idx,\n",
    "    \n",
    "    post_bad_idx = None,          # lista di indici canali ancora > threshold\n",
    "    post_bad_names = None,   # oppure, in alternativa, i NOMI dei canali\n",
    "    \n",
    "    threshold_uV=100.0,\n",
    "    delta_uV=10.0,         # margine extra da aggiungere al range dinamico\n",
    "    same_scale_eeg=True,\n",
    "    task=None,        # ← aggiungi\n",
    "    subject=None,     # ← aggiungi\n",
    "    run=None,         # ← aggiungi\n",
    "    return_bytes=True\n",
    "):\n",
    "    sfreq = raw_for_sources.info['sfreq']\n",
    "    start_sample = int(start_time * sfreq)\n",
    "    stop_sample  = int((start_time + end_time) * sfreq)\n",
    "\n",
    "    # Estrai dati in µV\n",
    "    sources  = ica.get_sources(raw_for_sources).get_data()[picks_sources, start_sample:stop_sample]\n",
    "    original = raw_original.get_data(picks=picks_channels)[:, start_sample:stop_sample] * 1e6\n",
    "    recon    = raw_clean.get_data(picks=picks_channels)[:, start_sample:stop_sample] * 1e6\n",
    "\n",
    "    \n",
    "    # Calcola il valore assoluto massimo tra i canali \"bad\" post-interpolazione\n",
    "    #if post_bad_idx:\n",
    "        #max_bad = np.max(np.abs(recon[post_bad_idx, :]))\n",
    "    #else:\n",
    "        #max_bad = np.max(np.abs(recon))\n",
    "    \n",
    "    \n",
    "    # --- Rimappo gli INDICI \"globali\" (o i Nomi) -> indici LOCALI rispetto a picks_channels ---\n",
    "    local_bad_idx = []\n",
    "    if post_bad_names is not None:\n",
    "        picks_names    = [raw_clean.ch_names[i] for i in picks_channels]\n",
    "        name_to_local  = {nm: i for i, nm in enumerate(picks_names)}\n",
    "        local_bad_idx  = [name_to_local[nm] for nm in post_bad_names if nm in name_to_local]\n",
    "    elif post_bad_idx is not None:\n",
    "        global_set     = set(post_bad_idx)\n",
    "        local_bad_idx  = [i for i, ch_idx in enumerate(picks_channels) if ch_idx in global_set]\n",
    "\n",
    "    # Calcola il valore assoluto massimo tra i canali \"bad\" (locali) post-interpolazione\n",
    "    if local_bad_idx:\n",
    "        max_bad = np.max(np.abs(recon[local_bad_idx, :]))\n",
    "    else:\n",
    "        max_bad = np.max(np.abs(recon))\n",
    "    \n",
    "    \n",
    "    # Imposta il range dinamico attorno a ±(max_bad + delta_uV)\n",
    "    y_lim_low  = - (max_bad + delta_uV)\n",
    "    y_lim_high =   (max_bad + delta_uV)\n",
    "\n",
    "    n_rows = max(len(picks_sources), len(picks_channels))\n",
    "    fig, axes = plt.subplots(n_rows, 3, figsize=(18, n_rows*1.8), sharex=True)\n",
    "    axes = np.atleast_2d(axes)\n",
    "    \n",
    "    \n",
    "\n",
    "    # colonna 0: ICA\n",
    "    t = np.linspace(start_time, start_time + end_time, sources.shape[1])\n",
    "    for i, comp in enumerate(picks_sources):\n",
    "        ax = axes[i,0]\n",
    "        ax.plot(t, sources[i])\n",
    "        ax.set_ylabel(f\"ICA {comp}\")\n",
    "    axes[picks_sources[-1],0].set_xlabel(\"Time (s)\")\n",
    "\n",
    "    # colonna 1: originale\n",
    "    for i, ch in enumerate(picks_channels):\n",
    "        ax = axes[i,1]\n",
    "        ax.plot(t, original[i])\n",
    "        ax.set_ylabel(f\"{raw_original.ch_names[ch]} (µV)\")\n",
    "    axes[picks_channels[-1],1].set_xlabel(\"Time (s)\")\n",
    "\n",
    "    # colonna 2: ricostruito + righe soglia\n",
    "    for i, ch in enumerate(picks_channels):\n",
    "        ax = axes[i,2]\n",
    "        ax.plot(t, recon[i])\n",
    "        \n",
    "        # righe di soglia ±threshold\n",
    "        \n",
    "        #ax.axhline( threshold_uV, linestyle='--', linewidth=1)\n",
    "        #ax.axhline(-threshold_uV, linestyle='--', linewidth=1)\n",
    "        \n",
    "        # range dinamico\n",
    "        \n",
    "        #ax.set_ylim(y_lim_low, y_lim_high)\n",
    "        #ax.set_ylabel(f\"{raw_original.ch_names[ch]} (µV)\")\n",
    "    #axes[picks_channels[-1],2].set_xlabel(\"Time (s)\")\n",
    "        \n",
    "        # righe di soglia ±threshold\n",
    "        ax.axhline( threshold_uV, linestyle='--', linewidth=1)\n",
    "        ax.axhline(-threshold_uV, linestyle='--', linewidth=1)\n",
    "        \n",
    "        # range dinamico\n",
    "        ax.set_ylim(y_lim_low, y_lim_high)\n",
    "        ax.set_ylabel(f\"{raw_original.ch_names[ch]} (µV)\")\n",
    "    axes[picks_channels[-1],2].set_xlabel(\"Time (s)\")\n",
    "    \n",
    "    \n",
    "    axes[0,2].set_title(f\"Ricostruito (+/–{threshold_uV} µV)\\n(dyn±{max_bad:.1f}+{delta_uV} µV)\")\n",
    "    fig.suptitle(f\"{task} | {subject} | {run}\", y=1.02)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if not return_bytes:\n",
    "        plt.show()\n",
    "        return\n",
    "\n",
    "    buf = io.BytesIO()\n",
    "    fig.savefig(buf, format='png', dpi=150)\n",
    "    buf.seek(0)\n",
    "    img = buf.getvalue()\n",
    "    plt.close(fig)\n",
    "    return img\n",
    "\n",
    "\n",
    "\n",
    "def save_completed_runs(completed_runs, completed_runs_file):\n",
    "    with open(completed_runs_file, \"wb\") as f:\n",
    "        pickle.dump(completed_runs, f)\n",
    "    print(f\"\\n📌 Set di run completate salvato in: {completed_runs_file}\")\n",
    "    return completed_runs          # ← AGGIUNGI QUESTO\n",
    "\n",
    "def load_completed_runs(completed_runs_file):\n",
    "    if os.path.exists(completed_runs_file):\n",
    "        with open(completed_runs_file, \"rb\") as f:\n",
    "            return pickle.load(f)\n",
    "    return set()  # Se il file non esiste, è la prima esecuzione\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "Strategia consigliata (robusta e “standard-friendly”)\n",
    "\n",
    "Selezione run\n",
    "Tieni le OK + le WARNING con ≤3 residui e ≤8 canali interpolati (come hai già fatto).\n",
    "Non mi preoccuperei se in alcune finestre compaiono molti canali “sopra 100 µV”: gran parte di quei picchi è transient \n",
    "e verrà gestita meglio dopo l’ICA e soprattutto a livello di epoca.\n",
    "\n",
    "ICA sui dati “quasi grezzi” post-PyPREP\n",
    "\n",
    "Escludi dal fit ICA i canali segnati in raw.info['bads'] (lo fai già con picks=..., exclude='bads')\n",
    "Non interpolare altri canali prima dell’ICA: più canali “veri” (anche un po’ sporchi) → mixing più realistico → componenti ICA migliori.\n",
    "Apply ICA → reintegro bad pre-ICA → reref unico\n",
    "raw_clean = ica.apply(raw_copy)\n",
    "Interpola solo i “pre-bads” (quelli marchiati prima del fit), come hai già inserito.\n",
    "Average reference una sola volta qui (niente re-ref successivi): raw_clean.set_eeg_reference('average', projection=False).\n",
    "Check ampiezza post-ICA (solo guardrail)\n",
    "Il tuo check ±100 µV va bene come safety: se trovi canali persistentemente sopra soglia (non picchi sporadici), puoi interpolarli ora.\n",
    "Bene anche non fare un secondo re-ref qui (evita “drift” della baseline).\n",
    "Epocaggio + Autoreject/local\n",
    "Epoca in base al tuo paradigma.\n",
    "Usa autoreject (local) per stimare per canale e per epoca le soglie di picco-picco e interpolare solo nelle epoche dove serve.\n",
    "Questo è il punto in cui elimini davvero i residui “fastidiosi” senza buttare via run intere.\n",
    "\n",
    "\n",
    "Perché questa sequenza ha senso\n",
    "ICA prima delle decisioni dure per-epoca: separa blink/EMG dalla sorgente “neurale” senza distruggere la struttura statistica con troppe interpolazioni.\n",
    "Interpolazioni mirate: prima solo i “pre-bads” (strutturali), poi autoreject si occupa del transient a granularità di epoca.\n",
    "Un solo re-ref stabile: evita di rimuovere e riaggiungere offset più volte.\n",
    "Riduci i falsi positivi dei picchi occasionali >100 µV: sono il classico caso che l’autoreject gestisce meglio dell’hard-threshold globale.\n",
    "Micro-check sulla tua implementazione\n",
    "Nel tuo codice già fai: picks con exclude='bads', ica.apply, interpolazione dei pre-bads, re-ref unico → ✅\n",
    "Il check ±100 µV lo usi dopo l’ICA → ✅ (mantienilo come guardrail; se vuoi, passa al criterio “persistente” vs “sporadico” che ti ho dato prima).\n",
    "Poi passa a epocare e autoreject: lì farai la pulizia fine.\n",
    "In breve: sì, proseguirei subito con la tua pipeline ICA (come l’hai scritta) e demanderei le scelte “severe” sulla qualità al livello di epoca con autoreject/local.\n",
    "\n",
    "\n",
    "quindi tu in questo step quando dicevi \n",
    "\n",
    "\"Check ampiezza post-ICA (solo guardrail) \n",
    "Il tuo check ±100 µV va bene come safety:\n",
    "se trovi canali persistentemente sopra soglia (non picchi sporadici), puoi interpolarli ora.\"\n",
    "\n",
    "quale di queste strategie adotteresti, se fossi un neuroscienziato? \n",
    "\n",
    "o 1) non ti preoccuperesti di interpolare eventualmente anche altri canali persistentemente sopra soglia, \n",
    "(ma definiti come persistentemente sopra soglia in caso?) \n",
    "\n",
    "o 2) ti preoccuperesti di interpolare eventualmente anche altri canali persistentemente sopra soglia,\n",
    "(ma definiti come persistentemente sopra soglia in caso?) \n",
    "\n",
    "o 3) lasciare la pipeline così com'è, senza interpolare null'altro, tranne solo i “pre-bads” \n",
    "(quelli marchiati prima del fit), come hai già inserito e occuparsi eventualmente del tutto in fase di epoca (con autoreject)?\n",
    "\n",
    "\n",
    "Breve e chiaro: io sceglierei la 3 di default — niente altre interpolazioni subito dopo l’ICA (oltre ai “pre-bads” che già reintegri),\n",
    "e delegare il resto a autoreject/local a livello di epoca.\n",
    "È la strategia più stabile e riproducibile: eviti di “levigare” troppo il segnale globale \n",
    "e lasci che l’algoritmo decida dove e quando intervenire, solo nelle epoche realmente contaminate.\n",
    "\n",
    "'''\n",
    "def interactive_ica_pipeline(\n",
    "    raw_collection: dict,\n",
    "    \n",
    "    post_ica_path: str,\n",
    "    ica_models_path: str,\n",
    "    bad_components_path: str,\n",
    "    \n",
    "    #recon_figs_path: str,  #<<<<< <<<<< <<<<<\n",
    "    \n",
    "    post_interp_bad_chan_path : str, #<<<<< <<<<< <<<<< #<<<<< <<<<< <<<<<\n",
    "    \n",
    "    \n",
    "    show_sources: bool, #= True,\n",
    "    n_components: int, #= 63,\n",
    "    \n",
    "    resume_from_last: bool, #= False,\n",
    "\n",
    "    #--> CI DEVI INSERIRE LA PATH DI SALVATAGGIO IN .PKL DEL SET RICHIAMO\n",
    "    completed_runs_file: str, \n",
    "\n",
    "    ICA_confirm: bool, #= True,\n",
    "):\n",
    "    \n",
    "    cleaned_data = dict()\n",
    "    ica_models = dict()\n",
    "    bad_components_data = dict()\n",
    "    #recon_figs_data = dict() #<<<<< <<<<< <<<<<\n",
    "    post_interp_bad_chan_data = dict() #<<<<< <<<<< <<<<< #<<<<< <<<<< <<<<<\n",
    "\n",
    "    \n",
    "    # all'inizio\n",
    "    completed_runs = set()\n",
    "\n",
    "    # Carica il set delle run completate\n",
    "    completed_runs = load_completed_runs(completed_runs_file)\n",
    "   \n",
    "    # Calcolare solo le run totali \n",
    "    #total_runs = sum(len(runs) for subjects in raw_collection.values() for runs in subjects.values())\n",
    "\n",
    "    # Calcolare total_runs \n",
    "    total_runs = 0\n",
    "\n",
    "    # Calcolare le run completate dentro al set di run già completate\n",
    "    processed_runs = 0\n",
    "\n",
    "    # All'inizio della funzione, inizializza bad_components_official fuori dai cicli\n",
    "    bad_components_official = set()  # Inizializza un set vuoto per tenere traccia dei componenti da escludere\n",
    "\n",
    "    bad_components = {}\n",
    "    \n",
    "    for task, subjects in raw_collection.items():\n",
    "        for subject, runs in subjects.items():\n",
    "            for run in runs:\n",
    "                total_runs += 1\n",
    "                if (task, subject, run) in completed_runs:\n",
    "                    processed_runs += 1  # Conta le run già completate\n",
    "\n",
    "\n",
    "    missing_runs = total_runs - processed_runs  # Calcola le run mancanti\n",
    "\n",
    "    print(f\"Trovate già in \\033[1mcompleted_runs\\033[0m n° \\033[1m{processed_runs} runs\\033[0m, ne \\033[1mmancano\\033[0m n° \\033[1m{missing_runs}\\033[0m!\")\n",
    "\n",
    "    run_counter = 0\n",
    "\n",
    "    for task, subjects in raw_collection.items():\n",
    "        cleaned_data[task] = {}\n",
    "        ica_models[task] = {}\n",
    "        bad_components_data[task] = {}\n",
    "        \n",
    "        #recon_figs_data[task] = {} #<<<<< <<<<< <<<<<\n",
    "        \n",
    "        \n",
    "        post_interp_bad_chan_data[task] = {} #<<<<< <<<<< <<<<< #<<<<< <<<<< <<<<<\n",
    "\n",
    "\n",
    "        for subject, runs in tqdm(subjects.items(), desc=f\"Processing Task {task}\", total=len(subjects)):\n",
    "\n",
    "            cleaned_data[task][subject] = {}\n",
    "            ica_models[task][subject] = {}\n",
    "            bad_components_data[task][subject] = {}\n",
    "            \n",
    "            #recon_figs_data[task][subject] = {} #<<<<< <<<<< <<<<<\n",
    "            \n",
    "            post_interp_bad_chan_data[task][subject] = {} #<<<<< <<<<< <<<<< #<<<<< <<<<< <<<<<\n",
    "\n",
    "            \n",
    "            for run in sorted(runs):\n",
    "                                \n",
    "                if resume_from_last and (task, subject, run) in completed_runs:\n",
    "                    print(f\"→ Task \\033[1m{task}\\033[0m, Subject \\033[1m{subject}\\033[0m, run \\033[1m{run}\\033[0m è già completata, ripartiamo dalla successiva...\")\n",
    "                    continue  # Salta la run già completata\n",
    "\n",
    "                run_counter += 1\n",
    "                print(f\"\\n🧪 Processinng ICA per Task: \\033[1m{task}\\033[0m | Subject: \\033[1m{subject}\\033[0m | Run: \\033[1m{run}\\033[0m\")\n",
    "\n",
    "                '''ADESSO QUI TI CARICHI I DATI (RUN) DEL TASK, SOGGETTO (E QUINDI RUN) CORRENTE (O CHE MANCA RISPETTO A COMPLETED_RUNS!)'''\n",
    "                raw, annotations = runs[run]  # 🧠 AGGIUNGI QUESTA RIGA\n",
    "                \n",
    "                '''\n",
    "                Mini check-list (riassunto operativo)\n",
    "\n",
    "                Fit ICA: usa picks = mne.pick_types(..., exclude='bads') e n_comp <= len(picks).\n",
    "                Dopo ica.apply: interpola sempre i pre_bads (quelli marcati in EEG_for_ICA) e fai set_eeg_reference('average', ...).\n",
    "                Poi il tuo check ±100 µV e (se serve) ulteriore interpolazione dei canali rimasti sopra soglia (con eventuale reref finale).\n",
    "                Così la tua pipeline è allineata alle buone pratiche: i canali “rotti” non inficiano il fit ICA, ma rientrano puliti nel segnale finale.\n",
    "                '''\n",
    "               \n",
    "                while True:\n",
    "                    try:\n",
    "                        # --- Fit ICA -----------------------------------------------------------\n",
    "\n",
    "                        #✔️ OK — Crei una copia di raw su cui eseguire il fitting ICA, così non tocchi i dati originali\n",
    "\n",
    "                        raw_copy = raw.copy().load_data()\n",
    "                        \n",
    "                        \n",
    "                        '''NEW LAST ADDITION 19 AGOSTO\n",
    "                        \n",
    "                        Sì 👍, quello che hai scritto va già molto bene:\n",
    "\n",
    "                        Calcoli i picks escludendo i bad → ✅ così i canali da interpolare non entrano nel fit ICA.\n",
    "                        Limiti n_components al numero di canali buoni (min(n_components, n_good)) → ✅ evita crash se ci sono pochi canali.\n",
    "                        Fit ICA con picks e reject_by_annotation=True → ✅ best practice, esclude anche eventuali segmenti annotati come “BAD”.\n",
    "                        Ricavi picks_sources da ica.n_components_ → ✅ hai il numero effettivo di componenti.\n",
    "                        \n",
    "                        '''\n",
    "                        \n",
    "                        # + calcola i picks escludendo i canali bad\n",
    "                        # + (usa solo EEG; niente MEG/EOG nel fit)\n",
    "                        picks = mne.pick_types(raw_copy.info, eeg=True, meg=False, eog=False, exclude='bads')\n",
    "                        \n",
    "                        # + per sicurezza imponi n_components ≤ #canali buoni\n",
    "                        n_good = len(picks)\n",
    "                        n_comp = min(n_components, n_good)  # (se vuoi: usa il rank reale)\n",
    "\n",
    "\n",
    "                        '''OLD APPROACH PRE 19 AGOSTO'''\n",
    "                        #ica = mne.preprocessing.ICA(n_components=n_components, random_state=97, max_iter='auto')\n",
    "                        #ica.fit(raw_copy)\n",
    "                        \n",
    "                        '''NEW LAST ADDITION 19 AGOSTO'''\n",
    "                        \n",
    "                        ica = mne.preprocessing.ICA(n_components=n_components, random_state=97, max_iter='auto')\n",
    "                        \n",
    "                        # + IMPORTANT: passa i picks e rispetta le annotazioni (reject_by_annotation)\n",
    "                        ica.fit(raw_copy, picks=picks, reject_by_annotation=True)\n",
    "\n",
    "\n",
    "                        #✔️ OK — Se hai fatto ICA con n_components=0.99 o simili, ica.n_components_ \n",
    "                        #ti dà il numero effettivo di componenti spieganti il 99% della varianza.\n",
    "\n",
    "                        picks_sources = list(range(ica.n_components_))  # tutte le comp. estratte\n",
    "\n",
    "                        #  (se vuoi un massimo di 20: picks_sources = picks_sources[:20])\n",
    "                        # ---------------------------------------------\n",
    "\n",
    "\n",
    "                        # --- 1. Topomap di tutte le IC in figura unica matplotlib (come in Jupyter) ---\n",
    "\n",
    "                        #✔️ OK — La funzione plottando ica.get_components() ti mostra le topografie (ossia “dove” ogni componente ha peso nel cervello).\n",
    "                        plot_all_components_single_figure(ica, title=f\"ICA Components — Task {task}, Subject {subject}, Run {run}\")\n",
    "\n",
    "                        # --- 2. PLOT SOURCES (GUI interattiva non bloccante) ---\n",
    "                        # ---------- LOOP interattivo sources → bads → ricostruzione ------\n",
    "\n",
    "                        if show_sources:\n",
    "\n",
    "                            # 1. Definisco intervallo temporale\n",
    "                            while True:\n",
    "                                # ↳ start-time scelto dall’utente\n",
    "                                try:\n",
    "                                    user_input_start = float(input(\"→ Inserisci Start-time in secondi: \"))\n",
    "                                    user_input_end = float(input(\"→ Inserisci End-time in secondi: \"))\n",
    "                                    if user_input_end <= user_input_start:\n",
    "                                        print(\"ATTENZIONE ⚠️! End-time deve essere maggiore di start-time.\")\n",
    "                                        continue\n",
    "                                    break\n",
    "\n",
    "                                except ValueError:\n",
    "                                    print(\"❌ Input non valido, inserisci solo numeri interi\")\n",
    "                                    #start_time = 0\n",
    "\n",
    "\n",
    "\n",
    "                            # --- 2. Plot statico delle SOURCES (prime 10 IC)\n",
    "                            plot_static_ica_sources(\n",
    "                                ica=ica,\n",
    "                                raw=raw_copy,\n",
    "\n",
    "                                picks=picks_sources,                 ### <-- QUI\n",
    "\n",
    "                                start_time=user_input_start,\n",
    "                                end_time=user_input_end,\n",
    "                                task=task, subject=subject, run=run\n",
    "                            )\n",
    "\n",
    "                            plt.pause(0.1)\n",
    "\n",
    "\n",
    "                            # --- 2.1 Se vuoi cambiare intervallo SOURCES\n",
    "                            #change_interval = input(\"→ Cambiare Intervallo delle Sources? (yes/no/stop): \").lower()\n",
    "\n",
    "                            # --- 2.1 Vuoi cambiare intervallo SOURCES?\n",
    "                            while True:\n",
    "                                change_interval = input(\n",
    "                                    \"→ Cambiare Intervallo delle Sources? (yes/no/stop): \"\n",
    "                                ).strip().lower()\n",
    "\n",
    "                                #Fa sparire le immagini già disegnate dall’area di output di Jupyter, così il notebook rimane “pulito”.\n",
    "                                #clear_output(wait=True)      # <— pulisci l’area di output\n",
    "\n",
    "\n",
    "                                # valori ammessi ----------------------------------------------------------\n",
    "                                if change_interval in {\"yes\", \"no\", \"stop\", \"no stop\"}:\n",
    "                                    break  # OK, esci dal loop e gestisci la scelta qui sotto\n",
    "\n",
    "                                # qualunque altra cosa = errore ------------------------------------------\n",
    "                                print(\"❌ Input non valido. Digita 'yes', 'no' oppure 'stop'.\")\n",
    "                                # e il while ricomincia\n",
    "                            # ---------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "                            if change_interval == 'yes':\n",
    "                                plt.close('all')  # Chiudi il plot\n",
    "                                continue  # Torna al loop per scegliere un nuovo intervallo\n",
    "\n",
    "                                #Dopo aver chiesto se vuoi cambiare intervallo (ramo change_interval == 'yes')\n",
    "                                #– lì chiudi già le figure per mostrarne di nuove.\n",
    "\n",
    "                                #Fa sparire le immagini già disegnate dall’area di output di Jupyter, così il notebook rimane “pulito”.\n",
    "                                clear_output(wait=True)      # <— pulisci l’area di output\n",
    "\n",
    "\n",
    "                            elif change_interval == 'no':\n",
    "                                plt.close('all')  # Chiudi il plot\n",
    "                                # Definisci raw_clean qui, **prima di applicare l'ICA**\n",
    "                                raw_clean = raw_copy.copy()\n",
    "                                # Esci dal loop per continuare con la selezione delle componenti\n",
    "\n",
    "                            elif change_interval in ['stop', 'no stop']:\n",
    "                                print(\"🛑 Interruzione manuale richiesta. Salvataggio parziale e uscita immediata.\")\n",
    "                                raise KeyboardInterrupt\n",
    "\n",
    "                                #plt.close('all')\n",
    "                                #gc.collect()\n",
    "\n",
    "                                #Fa sparire le immagini già disegnate dall’area di output di Jupyter, così il notebook rimane “pulito”.\n",
    "                                #clear_output(wait=True)      # <— pulisci l’area di output\n",
    "                                #return cleaned_data, ica_models, bad_components_data, recon_figs_data, post_interp_bad_chan_data # 🧠 STOP TOTALE\n",
    "\n",
    "\n",
    "                            bad_components = {}\n",
    "\n",
    "                            bad_components_official = set()  # Set vuoto per ogni run\n",
    "\n",
    "\n",
    "                            bads = input(\"→ Scegli le componenti da escludere (es. 0,1,5 o digita 'stop' per uscire): \")\n",
    "\n",
    "                            if bads.strip().lower() == 'stop':\n",
    "                                print(\"🛑 Interruzione richiesta manualmente. Chiudo tutto e salvo stato corrente.\")\n",
    "                                plt.close('all')\n",
    "                                gc.collect()\n",
    "\n",
    "                                #Fa sparire le immagini già disegnate dall’area di output di Jupyter, così il notebook rimane “pulito”.\n",
    "                                clear_output(wait=True)      # <— pulisci l’area di output\n",
    "                                #return cleaned_data, ica_models, bad_components_data, recon_figs_data, post_interp_bad_chan_data # 🧠 STOP TOTALE\n",
    "                                raise KeyboardInterrupt\n",
    "\n",
    "\n",
    "                            bad_components = {int(idx) for idx in bads.split(\",\") if idx.strip().isdigit()}  # Converte l'input in un set\n",
    "\n",
    "                            # Crea una copia indipendente di bad_components\n",
    "                            # Se sono state selezionate delle componenti da escludere, aggiorna `bad_components_official`\n",
    "\n",
    "                            bad_components_official.update(bad_components)  # Aggiunge i componenti esclusi al set\n",
    "\n",
    "\n",
    "                            ica.exclude = list(bad_components_official)  # Converte il set in lista per ICA\n",
    "\n",
    "                            # --- 3. APPLY ICA & PLOT RECONSTRUCTED SIGNAL (GUI interattiva non bloccante) ---\n",
    "                            \n",
    "\n",
    "                            raw_clean = ica.apply(raw_copy)\n",
    "                            \n",
    "                            '''\n",
    "                            NEW LAST ADDITION 19 AGOSTO\n",
    "                            \n",
    "                            Qui L’unica cosa che rimane da fare è il passo dopo ica.apply(...):\n",
    "                            👉 interpolare i pre-bads + fare una reref.\n",
    "\n",
    "                            Se non aggiungi quel passaggio, i canali segnati come bad nel fit restano vuoti/NaN nel raw_clean, quindi rischi:\n",
    "                            di avere meno canali del previsto per i plot/check successivi,\n",
    "                            e di non rimettere dentro i canali esclusi.\n",
    "\n",
    "                            \n",
    "                            Perché: i “bad” sono stati esclusi dal fit; ora li reintegri via interpolazione e stabilizzi la baseline con la average re-ref. \n",
    "                            Così i plot e il check ±100 µV guardano già il segnale con i pre-bads sistemati.\n",
    "                            \n",
    "                            👉 Se aggiungi queste 6 righe dopo ica.apply(...), ossia\n",
    "                            \n",
    "                            pre_bads = list(raw_copy.info.get(\"bads\", []))\n",
    "                            if pre_bads:\n",
    "                                raw_clean = interpolate_selected_channels(\n",
    "                                    raw_in=raw_clean,\n",
    "                                    channels=pre_bads,\n",
    "                                    by=\"name\",          # passiamo i NOMI dei canali\n",
    "                                    reset_bads=True,\n",
    "                                    final_reref=False,  # niente reref qui, lo facciamo subito sotto\n",
    "                                    verbose=True\n",
    "                                )\n",
    "\n",
    "                            # >>> REREF finale (una sola volta qui)\n",
    "                            raw_clean.set_eeg_reference('average', projection=False)\n",
    "                            \n",
    "                            Allora sei a posto:\n",
    "\n",
    "                            fit ICA pulito (solo canali buoni),\n",
    "                            reintegri i bad con l’interpolazione,\n",
    "                            reref finale fatto una sola volta.\n",
    "\n",
    "                            In sintesi\n",
    "\n",
    "                            ✔️ Fit ICA con picks che escludono i bad → OK.\n",
    "                            ✔️ n_comp ≤ #canali buoni → OK.\n",
    "                            ✅ Manca solo: interpolare i pre-bads + una reref subito dopo ica.apply(...).\n",
    "                            🔁 Poi prosegui con il tuo check ±100 µV e, se serve, altra interpolazione (senza ulteriore reref).\n",
    "                            Fatta questa micro-patch, la pipeline è perfettamente allineata alle buone pratiche.\n",
    "                            Buon lavoro e… a domani! 👋\n",
    "\n",
    "                            '''\n",
    "                            \n",
    "                            # >>> PRE-BADS: interpola SEMPRE i canali marcati prima del fit\n",
    "                            pre_bads = list(raw_copy.info.get(\"bads\", []))\n",
    "                            if pre_bads:\n",
    "                                raw_clean = interpolate_selected_channels(\n",
    "                                    raw_in=raw_clean,\n",
    "                                    channels=pre_bads,\n",
    "                                    by=\"name\",          # passiamo i NOMI dei canali\n",
    "                                    reset_bads=True,\n",
    "                                    final_reref=False,  # niente reref qui, lo facciamo subito sotto\n",
    "                                    verbose=True\n",
    "                                )\n",
    "\n",
    "                            # >>> REREF finale (una sola volta qui)\n",
    "                            raw_clean.set_eeg_reference('average', projection=False)\n",
    "\n",
    "                            \n",
    "                            '''QUI FORNISCO UN PICK_CHANNELS DINAMICO ANCHE DURANTE LA SOLA VISUALIZZAZIONE DELLE RICOSTRUZIONI'''\n",
    "                            while True:\n",
    "                                try:\n",
    "                                    max_chan = raw_clean.info[\"nchan\"]  # numero canali totali\n",
    "                                    user_n = input(\n",
    "                                        f\"   → Quanti canali EEG vuoi visualizzare? (1–{max_chan} oppure 'stop' o 'quit' per interrompere): \"\n",
    "                                    ).strip()\n",
    "                                    if user_n.lower() in {\"stop\", \"quit\"}:\n",
    "                                        raise KeyboardInterrupt\n",
    "                                    n_plot = int(user_n)\n",
    "                                    if 1 <= n_plot <= max_chan:\n",
    "                                        break\n",
    "                                    print(f\"   ❌ Inserisci un intero compreso fra 1 e {max_chan}.\")\n",
    "                                except ValueError:\n",
    "                                    print(\"ATTENZIONE ⚠️ Inserisci un numero intero valido.\")\n",
    "                    \n",
    "                            \n",
    "                            picks_channels = list(range(n_plot))  # es. primi N canali\n",
    "\n",
    "                            # --- 4. Plot statico del segnale ricostruito\n",
    "                            plot_static_reconstructed_signal(\n",
    "                                raw_clean=raw_clean,\n",
    "\n",
    "                                #channel_indices=list(range(15)),\n",
    "                                #channel_indices=picks_sources,       \n",
    "                                \n",
    "                                channel_indices=picks_channels,       ### <-- QUI\n",
    "\n",
    "                                start_time=user_input_start,\n",
    "                                end_time=user_input_end,\n",
    "                                task=task,\n",
    "                                subject=subject,\n",
    "                                run=run\n",
    "                            )\n",
    "                            plt.pause(0.1)\n",
    "\n",
    "\n",
    "                            ''' SE NON VOLESSI SALVARE MAI LA FIGURA'''\n",
    "                            #img_bytes = None     # <-- prima di chiedere compare_view\n",
    "\n",
    "\n",
    "                            # --- 4.1 Vuoi confrontare SOURCES + RICOSTRUZIONE in un'unica figura?\n",
    "                            compare_view = input(f\"→ Vuoi confrontare le SOURCES, SEGNALE GREZZO e la RICOSTRUZIONE in un'unica figura? (ok/no/stop/restart): \").strip().lower()\n",
    "                            if compare_view == 'ok':\n",
    "\n",
    "\n",
    "                                #RICORDATI LA FUNZIONE SOPRA SAREBBE:\n",
    "\n",
    "                                #def plot_sources_vs_original_vs_reconstructed(\n",
    "                                        #ica,\n",
    "                                        #raw_for_sources,          # raw usato nel fit ICA (p.e. raw_copy)\n",
    "                                        #raw_original,             # raw originale, PRIMA dell’ICA\n",
    "                                        #raw_clean,                # raw dopo ica.apply(...)\n",
    "                                        #picks_sources, picks_channels,\n",
    "                                        #start_time, end_time,\n",
    "                                        #task=None, subject=None, run=None,\n",
    "                                        #same_scale_eeg=True       # <<<<<<<<<<<<<<  NUOVO TOGGLE\n",
    "                                    #):\n",
    "\n",
    "                                # -----------------------------------------------------------------\n",
    "                                #  chiedi quanti canali EEG mostrare\n",
    "                                while True:\n",
    "                                # vista “comparativa” (stesso range per EEG)\n",
    "                                    try:\n",
    "                                        max_chan = raw.info[\"nchan\"]          # numero canali totali\n",
    "                                        user_n = input(\n",
    "                                            f\"   → Quanti canali EEG vuoi visualizzare? (1–{max_chan} oppure 'stop' o 'quit' per interrompere): \"\n",
    "                                        ).strip()\n",
    "                                        if user_n.lower() in {\"stop\", \"quit\"}:\n",
    "                                            raise KeyboardInterrupt\n",
    "                                        n_plot = int(user_n)\n",
    "                                        if 1 <= n_plot <= max_chan:\n",
    "                                            break\n",
    "                                        print(f\"   ❌ Inserisci un intero compreso fra 1 e {max_chan}.\")\n",
    "                                    except ValueError:\n",
    "                                        print(\"ATTENZIONE ⚠️ Inserisci un numero intero valido.\")\n",
    "                                        \n",
    "                                \n",
    "                                '''QUI FORNISCO UN PICK_CHANNELS CHE SI ADATTA ALLA SCELTA DEL MIO UTENTE'''\n",
    "                                picks_channels = list(range(n_plot))          # es. primi N canali\n",
    "\n",
    "                                #Cosa succede ora\n",
    "                                #PRIMA figura: vedi sources, originale, ricostruito appena applicata l’ICA.\n",
    "\n",
    "                                #Il check ±100 µV segnala eventuali canali “esplosivi”.\n",
    "\n",
    "                                #Puoi interpolarli in automatico (auto), a mano (idx) o saltare (skip).\n",
    "\n",
    "                                #DOPO l’interpolazione (se fatta) hai la SECONDA figura con il segnale aggiornato.\n",
    "\n",
    "                                #Il resto della tua pipeline (scelta compare_view, prompt ICA_confirm, salvataggi)\n",
    "                                #segue identico ma ora lavora sulla versione definitiva di raw_clean.\n",
    "\n",
    "                                # -----------------------------------------------------------------\n",
    "                                #  chiamata al plot (puoi lasciare same_scale_eeg=True o False a piacere)\n",
    "\n",
    "                                # === A) FIGURA PRIMA DEL CHECK / INTERPOLAZIONE ==================\n",
    "                                print(\"\\n📊 Segnale ricostruito PRIMA del check/interpolazione:\")\n",
    "\n",
    "                                img_bytes = plot_sources_vs_original_vs_reconstructed(\n",
    "                                    ica = ica,\n",
    "                                    raw_for_sources = raw_copy, # raw usato nel fit ICA (p.e. raw_copy)\n",
    "                                    raw_original = raw, # raw originale, PRIMA dell’ICA\n",
    "                                    raw_clean = raw_clean, # raw dopo ica.apply(...)\n",
    "                                    picks_sources = picks_sources,\n",
    "                                    picks_channels = picks_channels,\n",
    "                                    start_time = user_input_start, \n",
    "                                    end_time = user_input_end,\n",
    "                                    task=task, \n",
    "                                    subject=subject,\n",
    "                                    run=run,\n",
    "                                    same_scale_eeg=True,\n",
    "                                    return_bytes=False          # <<<<<<<<<<\n",
    "                                )\n",
    "\n",
    "                                # === B) CHECK ampiezze ±100 µV ===================================\n",
    "                                bad_idx, bad_names, _ = check_recon_amplitude_uV(\n",
    "                                    raw_clean, threshold_uV=100.0, picks=None, verbose=True\n",
    "                                )\n",
    "\n",
    "                                # === C) EVENTUALE interpolazione =================================\n",
    "                                if bad_idx:\n",
    "                                    while True:\n",
    "                                        choice = input(\n",
    "                                            f\"\\n→ Canali fuori soglia {bad_names}. Interpolazione?\\n\"\n",
    "                                            \"   'auto'  : interpola quelli fuori soglia\\n\"\n",
    "                                            \"   'idx'   : inserisci manualmente indici\\n\"\n",
    "                                            \"   'skip'  : non interpolare\\n\"\n",
    "                                            \"   'restart' : rifai l'ICA da capo per questa run\\n\"\n",
    "                                            \"> \"\n",
    "                                        ).strip().lower()\n",
    "\n",
    "                                        if choice == \"skip\":\n",
    "                                            break\n",
    "\n",
    "                                        elif choice == \"auto\":\n",
    "                                            raw_clean = interpolate_selected_channels(\n",
    "                                                raw_in=raw_clean,\n",
    "                                                channels=bad_idx,\n",
    "                                                by=\"index\",\n",
    "                                                reset_bads=True,\n",
    "                                                final_reref=False\n",
    "                                            )\n",
    "                                            break\n",
    "\n",
    "                                        elif choice == \"idx\":\n",
    "                                            try:\n",
    "                                                idx_list = [\n",
    "                                                    int(x) for x in input(\"   Indici (es. 0,4,7): \").split(\",\")\n",
    "                                                    if x.strip().isdigit()\n",
    "                                                ]\n",
    "                                                if not idx_list:\n",
    "                                                    print(\"   ❌ Nessun indice valido.\")\n",
    "                                                    continue\n",
    "                                                raw_clean = interpolate_selected_channels(\n",
    "                                                    raw_in=raw_clean,\n",
    "                                                    channels=idx_list,\n",
    "                                                    by=\"index\",\n",
    "                                                    reset_bads=True,\n",
    "                                                    final_reref=False\n",
    "                                                )\n",
    "                                                break\n",
    "                                            except Exception as e:\n",
    "                                                print(\"   Errore:\", e)\n",
    "                                                continue\n",
    "                                        \n",
    "                                        elif choice == \"restart\":\n",
    "                                            print(\"🔄 Rilancio ICA per questa run…\")\n",
    "                                            plt.close('all')\n",
    "                                            clear_output(wait=True)\n",
    "                                            # solleviamo un’eccezione per saltare al try/except esterno\n",
    "                                            raise RuntimeError(\"restart_ica\")\n",
    "                                            \n",
    "                                        else:\n",
    "                                            print(\"   Comando non valido (‘auto’, ‘idx’, ‘skip’).\")\n",
    "                                \n",
    "                                \n",
    "                                #QUESTA PARTE DI RICERCA DELLE BAD CHANNELS LA SPOSTO FUORI DALL' IF_BADX\n",
    "                                \n",
    "                                \n",
    "                                # (facoltativo) ricontrollo\n",
    "                                # 🆕 POST-INTERPOLAZIONE: log canali residui sopra soglia (senza toccare i dati)\n",
    "                                bad_idx_final, bad_names_final, peak_abs_uV = check_recon_amplitude_uV(\n",
    "                                    raw_clean, threshold_uV=100.0, picks=None, verbose=True\n",
    "                                )\n",
    "\n",
    "                                #'''ATTENZIONE QUI MI SALVO I NUOVI CANALI SOPRA SOGLIA ±100 µV ANCHE DOPO INTERPOLAZIONE!!!'''\n",
    "\n",
    "                                # 1) salva sul dict in memoria\n",
    "\n",
    "                                #post_interp_bad_chan_data[task][subject][run] = {\n",
    "                                #    \"bad_idx\": bad_idx_final,\n",
    "                                #    \"bad_names\": bad_names_final,\n",
    "                                #    \"peak_abs_uV\": peak_abs_uV.tolist()  # se è np.array\n",
    "                                #}\n",
    "\n",
    "\n",
    "                                # 2) salva subito su pickle (accoda/merge)\n",
    "                                #append_pickle(\n",
    "                                #    {task: {subject: {run: {\n",
    "                                #        \"bad_idx\": bad_idx_final,\n",
    "                                #        \"bad_names\": bad_names_final,\n",
    "                                #        \"peak_abs_uV\": peak_abs_uV.tolist()\n",
    "                                #    }}}},\n",
    "                                #    post_interp_bad_chan_path,\n",
    "                                #    return_master=False\n",
    "                                #)\n",
    "\n",
    "                                # ✅ PRINT DI CONTROLLO\n",
    "                                #print(f\"📥 Canali post-interpolazione salvati per {task} | {subject} | {run}:\")\n",
    "                                #print(f\"   → bad_names: {bad_names_final}\")\n",
    "                                #print(f\"   → bad_idx  : {bad_idx_final}\")\n",
    "                                #print(f\"   → peak_abs_uV: {np.round(peak_abs_uV[bad_idx_final], 2)} µV\")\n",
    "\n",
    "                                #Cosa succede\n",
    "                                #Calcola max_bad = max(abs(recon[post_bad_idx, :])) per prendere il picco più alto tra i canali “cattivi”.\n",
    "\n",
    "                                #Imposta l’asse Y da –(max_bad + delta_uV) a +(max_bad + delta_uV).\n",
    "\n",
    "                                #Traccia le linee tratteggiate a ±100 µV.\n",
    "\n",
    "                                #In questo modo il grafico “si allarga” esattamente quanto serve a mostrare tutti i picchi residui,\n",
    "                                #con un piccolo margine delta_uV. \n",
    "\n",
    "                                #Se vuoi, puoi anche re-chiamare \n",
    "                                #la variabile end_time = user_input_end – user_input_start per rendere ancora più chiaro che quel parametro è una durata,\n",
    "                                #ma l’alias non impedisce il funzionamento.\n",
    "                                \n",
    "                                \n",
    "                                picks_channels_all = list(range(raw_clean.info['nchan']))\n",
    "                                \n",
    "                                # === D) FIGURA DOPO DEL CHECK / INTERPOLAZIONE ==================\n",
    "                                print(\"\\n📊 Segnale ricostruito DOPO il check/interpolazione:\")\n",
    "                                img_bytes = plot_sources_vs_original_vs_reconstructed_post_interp(\n",
    "                                    ica              = ica,\n",
    "                                    raw_for_sources  = raw_copy,              # raw usato per fit ICA\n",
    "                                    raw_original     = raw,                   # raw prima di ICA\n",
    "                                    raw_clean        = raw_clean,             # raw dopo ica.apply()\n",
    "                                    picks_sources    = picks_sources,\n",
    "                                    \n",
    "                                    #picks_channels   = picks_channels,\n",
    "                                    \n",
    "                                    picks_channels   = picks_channels_all,   # <-- qui TUTTI i canali\n",
    "                                    \n",
    "                                    start_time       = user_input_start,\n",
    "                                    end_time         = user_input_end,        # o come lo chiami tu\n",
    "                                    \n",
    "                                    post_bad_idx     = bad_idx_final,         # <— lista degli indici ancora fuori soglia # indici GLOBALI (ok!)\n",
    "                                    post_bad_names   = bad_names_final,     # mapping per nome (ancora più robusto)\n",
    "                                    \n",
    "                                    threshold_uV     = 100.0,                 # soglia di riferimento\n",
    "                                    delta_uV         = 10.0,                  # margine extra (puoi cambiarlo)\n",
    "                                    same_scale_eeg   = True,\n",
    "                                    task = task,        # ← aggiungi\n",
    "                                    subject =subject,     # ← aggiungi\n",
    "                                    run = run,         # ← aggiungi\n",
    "                                    return_bytes     = True # <<<<<<<<<<\n",
    "                                )\n",
    "\n",
    "\n",
    "                            elif compare_view == 'no':\n",
    "                                print(\"Ok passiamo al salvataggio ICA per questa run\")\n",
    "                                plt.close('all')\n",
    "                                gc.collect()\n",
    "                                # Esci dal loop della run corrente → si salva e continua con la prossima\n",
    "                            \n",
    "                            elif compare_view == \"restart\":\n",
    "                                print(\"🔄 Rilancio ICA per questa run…\")\n",
    "                                plt.close('all')\n",
    "                                clear_output(wait=True)\n",
    "                                # solleviamo un’eccezione per saltare al try/except esterno\n",
    "                                raise RuntimeError(\"restart_ica\")\n",
    "                                            \n",
    "                            else:\n",
    "                                print(\"🛑 Interruzione manuale richiesta. Salvataggio parziale e uscita immediata.\")\n",
    "                                plt.close('all')\n",
    "                                gc.collect()\n",
    "\n",
    "                                #Fa sparire le immagini già disegnate dall’area di output di Jupyter, così il notebook rimane “pulito”.\n",
    "                                clear_output(wait=True)      # <— pulisci l’area di output\n",
    "                                #return cleaned_data, ica_models, bad_components_data, recon_figs_data, post_interp_bad_chan_data # 🧠 STOP TOTALE\n",
    "                                raise KeyboardInterrupt\n",
    "\n",
    "\n",
    "                            if ICA_confirm:\n",
    "                                next_run = input(f\"Posso salvare l'ICA di questa run appena eseguita?\\n\"\n",
    "                                                 f\"Rispondi con:\\n\\n\"\n",
    "                                                 f\"'ok' per continuare\\n\"\n",
    "                                                 f\"'no' per ri-eseguire la run\\n\"\n",
    "                                                 f\"'stop' o 'no stop' per interrompere tutto:\").strip().lower()\n",
    "\n",
    "                                if next_run == 'ok':\n",
    "                                    print(f\"\\n✅ Ok salvo ICA per questa run\")\n",
    "                                    plt.close('all')\n",
    "                                    gc.collect()\n",
    "                                    \n",
    "                                    # Salvo i canali post-interpolazione **solo se ce n’è almeno uno**\n",
    "                                    if bad_idx_final:                       # ← qui il filtro\n",
    "                                        post_interp_bad_chan_data[task][subject][run] = {\n",
    "                                            \"bad_idx\": bad_idx_final,\n",
    "                                            \"bad_names\": bad_names_final,\n",
    "                                            \"peak_abs_uV\": peak_abs_uV.tolist()\n",
    "                                        }\n",
    "                                        append_pickle(\n",
    "                                            {task: {subject: {run: {\n",
    "                                                \"bad_idx\": bad_idx_final,\n",
    "                                                \"bad_names\": bad_names_final,\n",
    "                                                \"peak_abs_uV\": peak_abs_uV.tolist()\n",
    "                                            }}}},\n",
    "                                            post_interp_bad_chan_path,\n",
    "                                            return_master=False\n",
    "                                        )\n",
    "                                        # ✅ PRINT DI CONTROLLO\n",
    "                                        print(f\"📥 Salvati {len(bad_idx_final)} canali post-interpolazione fuori soglia \"\n",
    "                                              f\"per {task} | {subject} | {run}\")\n",
    "                                        print(f\"   → bad_names: {bad_names_final}\")\n",
    "                                        print(f\"   → bad_idx  : {bad_idx_final}\")\n",
    "                                        print(f\"   → peak_abs_uV: {np.round(peak_abs_uV[bad_idx_final], 2)} µV\")\n",
    "                                    else:\n",
    "                                        print(\"✅ Nessun canale oltre soglia dopo l’interpolazione — nulla da salvare\")\n",
    "\n",
    "                                    break  # Esci dal loop della run corrente → si salva e continua con la prossima\n",
    "\n",
    "                                elif next_run in ['stop', 'no stop']:\n",
    "                                    print(\"🛑 Interruzione manuale richiesta. Salvataggio parziale e uscita immediata.\")\n",
    "                                    plt.close('all')\n",
    "                                    gc.collect()\n",
    "\n",
    "                                    #Fa sparire le immagini già disegnate dall’area di output di Jupyter, così il notebook rimane “pulito”.\n",
    "                                    clear_output(wait=True)      # <— pulisci l’area di output\n",
    "                                    #return cleaned_data, ica_models, bad_components_data, recon_figs_data, post_interp_bad_chan_data# 🧠 STOP TOTALE\n",
    "                                    raise KeyboardInterrupt\n",
    "\n",
    "                                else:\n",
    "                                    print(\"🔁 Riprovo ICA per questa run...\")\n",
    "                                    plt.close('all')\n",
    "                                    gc.collect()\n",
    "\n",
    "                                    #Fa sparire le immagini già disegnate dall’area di output di Jupyter, così il notebook rimane “pulito”.\n",
    "                                    clear_output(wait=True)      # <— pulisci l’area di output\n",
    "                        \n",
    "                    except RuntimeError as e:\n",
    "                        if str(e) == \"restart_ica\":\n",
    "\n",
    "                            #Fa sparire le immagini già disegnate dall’area di output di Jupyter, così il notebook rimane “pulito”.\n",
    "                            clear_output(wait=True)      # <— pulisci l’area di output\n",
    "\n",
    "                            # semplicemente ricomincia il while True dall'inizio\n",
    "                            continue\n",
    "                        else:\n",
    "                            # rilancia ogni altro RuntimeError\n",
    "                            raise\n",
    "\n",
    "                # ---------- salvataggio cumulativo ----------\n",
    "                #cleaned_data = append_pickle({task: {subject: {run: (raw_clean, annotations)}}},\n",
    "                #              post_ica_path, return_master=True)\n",
    "                #ica_models = append_pickle({task: {subject: {run: ica}}}, ica_models_path, return_master=True)\n",
    "                \n",
    "                #bad_components_data = append_pickle({task: {subject: {run: list(bad_components_official)}}},\n",
    "                #              bad_components_path, return_master=True)\n",
    "                #recon_figs_data = append_pickle({task: {subject: {run: img_bytes}}}, recon_figs_path, return_master=True)\n",
    "                \n",
    "                append_pickle({task: {subject: {run: (raw_clean, annotations)}}},\n",
    "                              post_ica_path, return_master=False)\n",
    "                append_pickle({task: {subject: {run: ica}}}, ica_models_path, return_master=False)\n",
    "                \n",
    "                append_pickle({task: {subject: {run: list(bad_components_official)}}},\n",
    "                              bad_components_path, return_master=False)\n",
    "                #append_pickle({task: {subject: {run: img_bytes}}}, recon_figs_path, return_master=False)\n",
    "                \n",
    "                \n",
    "                #'''INDENTATE INDIETRO!!!'''\n",
    "\n",
    "                completed_runs.add((task, subject, run))  # ✅ aggiorni il set\n",
    "\n",
    "                # Salva l'ultima run completata nel set\n",
    "                completed_runs = save_completed_runs(completed_runs, completed_runs_file)\n",
    "\n",
    "                print(f\"\\n💻 Task {task}, Subject {subject}, Run {run} salvata localmente nel set delle run completate!\")\n",
    "                \n",
    "\n",
    "                print(f\"\\n📡 Checkpoint salvato per Task: \\033[1m{task}\\033[0m | Subject: \\033[1m{subject}\\033[0m | Run: \\033[1m{run}\\033[0m\")\n",
    "\n",
    "                next_run = input(f\"\\n\\n→ Posso eseguire la prossima run ? Scrivi:\\n\"\n",
    "                                 f\"'ok' per continuare\\n\"\n",
    "                                 f\"'no' se vuoi stoppare qui e proseguire dopo :)\")\n",
    "                \n",
    "                if next_run.lower() == 'no':\n",
    "                    break\n",
    "                    \n",
    "                else:\n",
    "                    plt.close('all')\n",
    "                    gc.collect()\n",
    "\n",
    "                    #Fa sparire le immagini già disegnate dall’area di output di Jupyter, così il notebook rimane “pulito”.\n",
    "                    clear_output(wait=True)      # <— pulisci l’area di output\n",
    "                    \n",
    "            print(f\"\\n\\n✅ Subject \\033[1m{subject}\\033[0m completato ({run_counter}/{total_runs})\")\n",
    "\n",
    "        print(f\"\\n\\n📊 Task \\033[1m{task}\\033[0m completato.\")\n",
    "\n",
    "    print(\"\\n\\n✅ Tutti i dati ICA sono stati elaborati, salvati e inviati al server.\")\n",
    "    plt.close('all')\n",
    "    gc.collect()\n",
    "\n",
    "    #Fa sparire le immagini già disegnate dall’area di output di Jupyter, così il notebook rimane “pulito”.\n",
    "    clear_output(wait=True)      # <— pulisci l’area di output \n",
    "    \n",
    "    #return cleaned_data, ica_models, bad_components_data, recon_figs_data, post_interp_bad_chan_data\n",
    "\n",
    "    return cleaned_data, ica_models, bad_components_data, post_interp_bad_chan_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148f85b2-f771-4fed-85e4-913b27f1a94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Caricare l'intero dizionario annidato con pickle\n",
    "path = '/home/stefano/EEGMMIDB_Analyses/pyprep_outputs/'\n",
    "\n",
    "# Caricare l'intero dizionario annidato con pickle\n",
    "with open(f'{path}EEG_for_ICA.pkl', 'rb') as f:\n",
    "    EEG_for_ICA = pickle.load(f)\n",
    "    \n",
    "# Caricare l'intero dizionario annidato con pickle\n",
    "with open(f'{path}EEG_post_pyprep_data.pkl', 'rb') as f:\n",
    "    EEG_prep_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b500bee1-52fb-4728-9939-116a9f4dbf6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(EEG_for_ICA.keys())\n",
    "print(EEG_for_ICA['task_1'].keys())\n",
    "print(EEG_for_ICA['task_1']['100'].keys())\n",
    "print(type(EEG_for_ICA['task_1']['100'][0][0]))\n",
    "print(type(EEG_for_ICA['task_1']['100'][0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f787d36-399b-4ab7-9fdf-c27c58cbe5ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(EEG_for_ICA.keys())\n",
    "print()\n",
    "print(EEG_for_ICA['task_1'].keys())\n",
    "print()\n",
    "print(EEG_for_ICA['task_1']['100'].keys())\n",
    "print(EEG_for_ICA['task_2']['100'].keys())\n",
    "print(EEG_for_ICA['task_3']['100'].keys())\n",
    "print(EEG_for_ICA['task_4']['100'].keys())\n",
    "print()\n",
    "print()\n",
    "print(type(EEG_for_ICA['task_1']['100']))\n",
    "print(EEG_for_ICA['task_1']['100'].keys())\n",
    "print()\n",
    "print(type(EEG_for_ICA['task_1']['100'][0]))\n",
    "print(len(EEG_for_ICA['task_1']['100'][0]))\n",
    "print(type(EEG_for_ICA['task_1']['100'][0][0]))\n",
    "print(type(EEG_for_ICA['task_1']['100'][0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb43e68-0a7c-4221-98f1-ba90616d90f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(EEG_prep_data.keys())\n",
    "print()\n",
    "print(EEG_prep_data['task_1'].keys())\n",
    "print()\n",
    "print(EEG_prep_data['task_1']['100'].keys())\n",
    "print(EEG_prep_data['task_2']['100'].keys())\n",
    "print(EEG_prep_data['task_3']['100'].keys())\n",
    "print(EEG_prep_data['task_4']['100'].keys())\n",
    "print()\n",
    "print()\n",
    "print(type(EEG_prep_data['task_1']['100']))\n",
    "print(EEG_prep_data['task_1']['100'].keys())\n",
    "print()\n",
    "print(type(EEG_prep_data['task_1']['100'][0]))\n",
    "print(len(EEG_prep_data['task_1']['100'][0]))\n",
    "print(type(EEG_prep_data['task_1']['100'][0][0]))\n",
    "print(type(EEG_prep_data['task_1']['100'][0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebde19d4-1c48-449b-b4d1-20e72a83c0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Aggiungiamo un dizionario dedicato e un nuovo pickle per salvare, per task → subject → run, \n",
    "i canali che restano sopra soglia anche dopo l’interpolazione. \n",
    "\n",
    "\n",
    "Così:\n",
    "\n",
    "tracci sempre i canali residui in un file dedicato,\n",
    "\n",
    "mantieni la shape identica tra soggetti/run,\n",
    "\n",
    "a valle potrai usare np.nanmean / np.nan* oppure scegliere un sottoinsieme comune di canali solo al termine dell’analisi.\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "base_path = \"/home/stefano/EEGMMIDB_Analyses/post_ica_data/\"\n",
    "processed_runs_file = 'processed_ICA_runs_file.pkl'\n",
    "\n",
    "# Definisci le directory per il salvataggio dei vari file\n",
    "post_ica_path = f\"{base_path}post_ica_data.pkl\"\n",
    "ica_models_path = f\"{base_path}ica_models.pkl\"\n",
    "bad_components_path = f\"{base_path}ica_bad_components.pkl\"\n",
    "\n",
    "\n",
    "#recon_figs_path = f\"{base_path}recon_figs.pkl\"\n",
    "\n",
    "# ✅ nuovo pickle per i canali residui post-interpolazione\n",
    "post_interp_bad_chan_path = f\"{base_path}post_interp_bad_chan_data.pkl\"\n",
    "\n",
    "\n",
    "completed_runs_file = base_path + processed_runs_file\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abeafa6b-54f3-49f8-b98f-642f883dfaf0",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "## \n",
    "'''\n",
    "\n",
    "✅ 1. Uso di n_components=0.99\n",
    "Sì, è corretto e consigliato: quando passi n_components=0.99 a mne.preprocessing.ICA, stai dicendo:\n",
    "\n",
    "«Estrai automaticamente il numero minimo di componenti che spiegano il 99% della varianza del segnale».\n",
    "\n",
    "Di solito, con 63 canali, potresti ottenere qualcosa come 25–40 componenti (dipende dal dataset), \n",
    "quindi ti evita di dover esplorare sempre tutte le 63, mantenendo l’analisi più focalizzata e interpretabile.\n",
    "'''\n",
    "\n",
    "#cleaned, models, bads, recon_figs,  post_interp_bad_chan_data = interactive_ica_pipeline(\n",
    "\n",
    "cleaned, models, bads, post_interp_bad_chan_data = interactive_ica_pipeline(\n",
    "    #raw_collection = EEG_data_filtered,\n",
    "    #raw_collection = mini_collection,\n",
    "    \n",
    "    raw_collection = EEG_for_ICA,\n",
    "    \n",
    "    post_ica_path = post_ica_path,\n",
    "    ica_models_path = ica_models_path,\n",
    "    bad_components_path = bad_components_path,\n",
    "\n",
    "    #recon_figs_path = recon_figs_path,\n",
    "    \n",
    "    post_interp_bad_chan_path = post_interp_bad_chan_path,\n",
    "    \n",
    "    show_sources=True,\n",
    "    n_components=0.99, \n",
    "    \n",
    "    resume_from_last= True,\n",
    "    \n",
    "    completed_runs_file = completed_runs_file,\n",
    "    \n",
    "    ICA_confirm = True\n",
    ")\n",
    "\n",
    "\n",
    "#0,1,2,3,8,12,13,15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94294491-9c16-4ad4-9b40-f656d51155bb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### **POST ESECUZIONE ICA: CANCELLARE RUNS PER EVENTUALI RI-ESECUZIONI**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd908b0-46b6-4c82-bd79-bf205e84d838",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Caricare l'intero dizionario annidato con pickle\n",
    "path = '/home/stefano/EEGMMIDB_Analyses/post_ica_data/'\n",
    "\n",
    "# Caricare l'intero dizionario annidato con pickle\n",
    "with open(f'{path}post_ica_data.pkl', 'rb') as f:\n",
    "    EEG_post_ICA = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c5600a-3885-40bf-b005-a1900da49427",
   "metadata": {},
   "outputs": [],
   "source": [
    "EEG_post_ICA.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5647c2b-892c-491c-992e-273acd447d0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "EEG_post_ICA['task_3']['101'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c916d58-407d-49e9-9eea-ba655565c31a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#✅ Codice per rimuovere il soggetto '9' da 'task_2'\n",
    "\n",
    "#EEG_post_ICA['task_3'].pop('101', None)\n",
    "\n",
    "EEG_post_ICA['task_3']['101'].pop(10, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea015ab-b395-4858-8ab5-d03ad27e51a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#type(EEG_for_ICA['task_2']['9'][1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b50713f-ceea-438d-a759-fa8d7cdf4598",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#print(EEG_post_ICA['task_2'].keys()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1765d1d1-4746-4c59-9ec0-0e29f094d675",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Sì — ti basta rimuovere da completed_runs_file (il tuo processed_ICA_runs_file) le tuple corrispondenti, così la pipeline non le salterà con resume_from_last=True.\n",
    "\n",
    "Ecco uno snippet pronto:\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "# runs da rieseguire\n",
    "'''\n",
    "to_remove = {\n",
    "    (\"task_2\", \"9\", 1),\n",
    "    (\"task_2\", \"9\", 5),\n",
    "    (\"task_2\", \"9\", 9),\n",
    "}\n",
    "'''\n",
    "\n",
    "\n",
    "import os, pickle\n",
    "\n",
    "processed_ICA_runs_file = \"/home/stefano/EEGMMIDB_Analyses/post_ica_data/processed_ICA_runs_file.pkl\"  # <— metti il path giusto\n",
    "\n",
    "to_remove = {\n",
    "    (\"task_4\", \"20\", 7)\n",
    "}\n",
    "\n",
    "\n",
    "def remove_runs_from_completed(file_path, items):\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"❌ File non trovato: {file_path}\")\n",
    "        return\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        completed = pickle.load(f)\n",
    "\n",
    "    # di norma è già un set; forziamo comunque\n",
    "    completed = set(completed)\n",
    "    before = len(completed)\n",
    "    completed.difference_update(items)\n",
    "\n",
    "    with open(file_path, \"wb\") as f:\n",
    "        pickle.dump(completed, f)\n",
    "        f.flush(); os.fsync(f.fileno())\n",
    "\n",
    "    print(f\"🧹 Rimosse {before - len(completed)} voci. Rimaste: {len(completed)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80c2a67-851a-4639-86fe-fe3b1f5fc80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_runs_from_completed(processed_ICA_runs_file, to_remove)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e51300-9534-4d32-9b01-7ed358665b60",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### **Post Custom ICA: Data Structure Inspection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3955c3fa-4735-4a80-abac-e6db3000bbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Caricare l'intero dizionario annidato con pickle\n",
    "path = '/home/stefano/EEGMMIDB_Analyses/post_ica_data/'\n",
    "\n",
    "# Caricare l'intero dizionario annidato con pickle\n",
    "with open(f'{path}post_ica_data.pkl', 'rb') as f:\n",
    "    EEG_post_ICA = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa1a206-9e43-43e0-8335-6ac662a6384f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(EEG_post_ICA.keys())\n",
    "print(EEG_post_ICA['task_1'].keys())\n",
    "print(EEG_post_ICA['task_1']['100'].keys())\n",
    "print()\n",
    "print()\n",
    "print(type(EEG_post_ICA['task_1']['100'][0][0]))\n",
    "print(type(EEG_post_ICA['task_1']['100'][0][1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0179ca-b767-4966-a859-3798e6475d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Per verificare che la struttura del dizionario sia corretta e uguale per entrambe le collezioni (raw_collection e raw_collection_unfiltered), \n",
    "possiamo ispezionarla con uno script che:\n",
    "\n",
    "Controlla i livelli del dizionario.\n",
    "Stampa il numero di soggetti per ogni task.\n",
    "Conta il numero di run per ciascun soggetto.\n",
    "Mostra la shape dei dati EEG e delle annotazioni.\n",
    "Verifica che i tipi siano coerenti: mne.io.Raw e np.ndarray.\n",
    "Ecco un codice che puoi lanciare dopo aver caricato i due dizionari da file o averli creati:\n",
    "\n",
    "\n",
    "Possiamo estendere la funzione inspect_raw_collection per:\n",
    "\n",
    "raccogliere tutti i soggetti (subj) e tutte le run (run) disponibili nel collection,\n",
    "mostrarli alla fine con np.unique per avere una lista completa e verificare quali soggetti e run siano presenti \n",
    "in ciascuna struttura (filtrata e non filtrata),\n",
    "eventualmente restituire le liste uniche per confrontarle.\n",
    "\n",
    "\n",
    "Nel tuo caso, gli annotations non sono un oggetto mne.Annotations, ma un array numpy.ndarray con forma (N, 5), dove:\n",
    "\n",
    "N = 30 è il numero di eventi o segmenti annotati (tipicamente i 30 trial della run),\n",
    "e le 5 colonne rappresentano probabilmente attributi di un array fatto così, ad esempio:\n",
    "[  1.    4.1 656.    1.  656. ]\n",
    "\n",
    "\n",
    "Vediamolo passo per passo e confrontiamolo con le informazioni dal paper PMC10998040, \n",
    "in particolare Tabella 2 e le descrizioni relative all’organizzazione temporale dei trial.\n",
    "\n",
    "| Colonna | Significato                        | Esempio                            |\n",
    "| ------- | ---------------------------------- | ---------------------------------- |\n",
    "| `[0]`   | **Etichetta originale** del trial  | `1` (T0), `2` (T1), `3` (T2)       |\n",
    "| `[1]`   | **Durata del trial (secondi)**     | `4.1`                              |\n",
    "| `[2]`   | **Durata in campioni** (`samples`) | `656`                              |\n",
    "| `[3]`   | **Indice di inizio trial**         | `657`                              |\n",
    "| `[4]`   | **Indice di fine trial**           | `1312`                             |\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def inspect_raw_collection(collection, name=\"\"):\n",
    "    print(f\"\\nInspecting structure: \\033[1m{name}\\033[0m\\n\" + \"-\"*50)\n",
    "    \n",
    "    all_subjects = []\n",
    "    all_runs = []\n",
    "\n",
    "    for task, subjects in collection.items():\n",
    "        print(f\"📁 Task: \\033[94m{task}\\033[0m → {len(subjects)} subjects\")\n",
    "        \n",
    "        # Mappa etichette in base al task\n",
    "        if task in [\"task_1\", \"task_2\"]:\n",
    "            label_map = {1: \"T0 (Rest)\", 2: \"T1 (Left Fist)\", 3: \"T2 (Right Fist)\"}\n",
    "        else:\n",
    "            label_map = {1: \"T0 (Rest)\", 2: \"T1 (Both Feet)\", 3: \"T2 (Both Fists)\"}\n",
    "\n",
    "        for subj, runs in subjects.items():\n",
    "            all_subjects.append(subj)\n",
    "            print(f\"  └─ 👤 Subject {subj} → {len(runs)} runs\")\n",
    "            for run, (raw, annotations) in runs.items():\n",
    "                all_runs.append(run)\n",
    "                print(f\"      └─ 🏃‍♂️ Run {run}:\")\n",
    "                print(f\"         ├─ Raw type:      {type(raw)}\")\n",
    "                print(f\"         ├─ Data shape:    {raw.get_data().shape}  (channels x time)\")\n",
    "                print(f\"         ├─ Annotations:   {type(annotations)}, shape={annotations.shape}\")\n",
    "                if isinstance(annotations, np.ndarray):\n",
    "                    print(f\"           ├─ First annotation row: {annotations[0]}\")\n",
    "                    print()\n",
    "                    print(f\"             ├─ Unique stimolo_id [0]: {np.unique(annotations[:, 0])}\")\n",
    "                    print(f\"             ├─ Durata trial secondi [1]: {np.unique(annotations[:, 1])}\")\n",
    "                    print(f\"             ├─ Durata trial in samples [2]: {np.unique(annotations[:, 2])}\\n\")\n",
    "                    print(f\"             ├─ Start sample  [3]: {np.unique(annotations[:, 3])}\\n\")\n",
    "                    print(f\"             └─ End sample [4]: {np.unique(annotations[:, 4])}\\n\")\n",
    "                print(f\"         └─ Duration (s):  {raw.times[-1]:.2f}s\")\n",
    "                \n",
    "            break  # Solo il primo soggetto per ogni task\n",
    "        print()\n",
    "\n",
    "    # Mostra soggetti e run unici\n",
    "    unique_subjects = np.unique(all_subjects)\n",
    "    unique_runs = np.unique(all_runs)\n",
    "\n",
    "    print(f\"\\n📊 \\033[1mRiepilogo {name}\\033[0m\")\n",
    "    print(f\"→ Soggetti unici: {len(unique_subjects)} → {unique_subjects}\")\n",
    "    print(f\"→ Run uniche:     {len(unique_runs)} → {unique_runs}\")\n",
    "    print(\"✓ Done.\\n\")\n",
    "\n",
    "    return unique_subjects, unique_runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e03eabf-3934-4326-bbb6-95b65ec3b6eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#inspect_raw_collection(EEG_data_filtered, \"Filtered\")\n",
    "#inspect_raw_collection(EEG_data_unfiltered, \"Unfiltered (raw original)\")\n",
    "inspect_raw_collection(EEG_post_ICA, \"Post ICA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae031e2-c0e2-45bb-9769-d0107c266c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(EEG_post_ICA['task_1'].keys())\n",
    "print()\n",
    "print(EEG_post_ICA['task_1']['100'].keys())\n",
    "print()\n",
    "print(type(EEG_post_ICA['task_1']['100'][0]))\n",
    "print()\n",
    "print(len(EEG_post_ICA['task_1']['100'][0]))\n",
    "print()\n",
    "print(type(EEG_post_ICA['task_1']['100'][0][0]))\n",
    "print(type(EEG_post_ICA['task_1']['100'][0][1]))\n",
    "print(EEG_post_ICA['task_1']['100'][0][1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d0fc57-c384-4d91-b8c7-1cfa79e13b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(EEG_post_ICA['task_1']['100'][0][1][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792ce93a-d259-4cee-84d4-f018655ffc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "print((EEG_post_ICA['task_1']['100'][0][1][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b722272-fd1e-43ed-8914-cf74082b47f5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### **POST Custom ICA: Istructions to create the New Data Structure before Autoreject Step**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ee065b-88c8-4a34-a9a4-f65f3269cde7",
   "metadata": {},
   "source": [
    "Allora aspetta però...\n",
    "\n",
    "\n",
    " perché allora devo modificare la funzione che mi epoca i dati, partendo però da \n",
    "\n",
    "EEG_post_ICA adesso... perché escludendo la parte di salvataggio degli ICA models ...\n",
    "\n",
    "\n",
    "Originariamente i miei la mia costruzione del set dei dati era questa\n",
    "\n",
    "\n",
    "#Percorso del file di checkpoint\\CHECKPOINT_PATH = Path(\"/home/stefano/EEGMMIDB_Analyses/task_data_ICA.pkl\")\n",
    "CHECKPOINT_PATH = Path(\"/home/stefano/EEGMMIDB_Analyses/task_data_ICA.pkl\")\n",
    "\n",
    "ICA_MODELS_PATH = Path(\"/home/stefano/EEGMMIDB_Analyses/ica_models.pkl\")  # Per salvare gli oggetti ICA\n",
    "\n",
    "CHECKPOINT_PATH.parent.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "\n",
    "#---------------------------------------------------- #\n",
    "#Tabella 2 – mappatura Task  ↔  indice run (0‑based) #\n",
    "#---------------------------------------------------- #\n",
    "TASK_RUNS = {\n",
    "    \"task_1\": [0, 4, 8],    # curated 1, 5, 9\n",
    "    \"task_2\": [1, 5, 9],    # curated 2, 6, 10\n",
    "    \"task_3\": [2, 6, 10],   # curated 3, 7, 11\n",
    "    \"task_4\": [3, 7, 11],   # curated 4, 8, 12\n",
    "}\n",
    "\n",
    "def label_to_Tx(label_num: int) -> str:\n",
    "    \"\"\"Converte la label 1‑12 nei tre gruppi T0/T1/T2.\"\"\"\n",
    "    return [\"T0\", \"T1\", \"T2\"][(label_num - 1) % 3]\n",
    "\n",
    "def to_plain_dict(d):\n",
    "    \"\"\"\n",
    "    Ricorsivamente trasforma defaultdict (e dict) in normali dict,\n",
    "    così da poterlo serializzare con pickle.\n",
    "    \"\"\"\n",
    "    if isinstance(d, defaultdict) or isinstance(d, dict):\n",
    "        return {k: to_plain_dict(v) for k, v in d.items()}\n",
    "    else:\n",
    "        return d\n",
    "\n",
    "\n",
    "def build_task_data(\n",
    "    signal: List[Dict[str, list]],\n",
    "    labels: List[Dict[str, list]],\n",
    "    fs: int = 160,\n",
    "    epoch_len_s: float = 4.0,\n",
    "    drop_shorter: bool = True,\n",
    "    #lowcut: float = 1.0,\n",
    "    #highcut: float = 45.0,\n",
    "    #order: int = 4,\n",
    "    channel_names: List[str] = EEG_channels_names,\n",
    "    checkpoint_every_subject: bool = True\n",
    ") -> Dict[str, Dict[str, Dict[str, Dict[str, np.ndarray]]]]:\n",
    "    \"\"\"\n",
    "    task_data[task][subject][T0|T1|T2]['data'|'labels']\n",
    "\n",
    "    * 'data'   → ndarray (n_trial, 64, 640)\n",
    "    * 'labels' → ndarray (n_trial,)\n",
    "    \"\"\"\n",
    "    epoch_len = int(epoch_len_s * fs)\n",
    "    task_data = defaultdict(\n",
    "        lambda: defaultdict(\n",
    "            lambda: defaultdict(lambda: {\"data\": [], \"labels\": []})\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    ica_models = {}  # Dizionario per salvare gli oggetti ICA per ogni task, soggetto e run\n",
    "    \n",
    "    for task, runs in TASK_RUNS.items():\n",
    "        for r in runs:                               # loop sui run della Table 2 (0‑based)\n",
    "            run_sig   = signal[r]\n",
    "            run_label = labels[r]\n",
    "\n",
    "            for subj_key in run_sig.keys():          # per ogni soggetto\n",
    "                subj_anno_key = subj_key.replace(\"Signal\", \"Annotations\")\n",
    "                \n",
    "                # 1) estrai raw EEG (n° samples di una intera run ,n° elettrodi)\n",
    "                #dim 1: length totale della run\n",
    "                #dim 2: 64 (elettrodi usati durante la rec) \n",
    "                \n",
    "                sig_arr = run_sig[subj_key][0]            # (N, 64)\n",
    "                \n",
    "                \n",
    "                # 2) applica il filtro passa-banda (1-45 Hz) **prima** di fare l’epoching\n",
    "                #    (qui uso i default lowcut=1, highcut=45, order=4)\n",
    "                \n",
    "                #sig_arr = bandpass_filter(sig_arr, fs, lowcut, highcut, order)\n",
    "                \n",
    "                # 3) applico l'ICA ai già filtrati **prima** di fare l’epoching\n",
    "                #    (qui uso i default lowcut=1, highcut=45, order=4)\n",
    "                \n",
    "                # 2) Esegui l'ICA\n",
    "                sig_arr, ica = ICA(sig_arr, fs, channel_names)\n",
    "                \n",
    "                ann_arr = np.asarray(run_label[subj_anno_key][0])\n",
    "\n",
    "                onsets = ann_arr[:, 3].astype(int) - 1    # 0‑based\n",
    "                durs   = ann_arr[:, 2].astype(int)\n",
    "                lbls   = ann_arr[:, 0].astype(int)\n",
    "\n",
    "                subject_id = subj_key.split(\"_\")[1]       # '100', ecc.\n",
    "                \n",
    "                sig_arr = np.array(sig_arr)\n",
    "                                   \n",
    "                for onset, dur, labnum in zip(onsets, durs, lbls):\n",
    "                    if dur < epoch_len and drop_shorter:\n",
    "                        continue\n",
    "                    if onset + epoch_len > sig_arr.shape[0]:\n",
    "                        continue\n",
    "\n",
    "                    # --------- estrazione e TRASPOSTA (64, 640) ---------\n",
    "                    seg = sig_arr[onset : onset + epoch_len, :].T.astype(np.float32)\n",
    "\n",
    "                    Tx = label_to_Tx(labnum)\n",
    "                    td = task_data[task][subject_id][Tx]\n",
    "                    td[\"data\"].append(seg)\n",
    "                    td[\"labels\"].append(labnum)\n",
    "                \n",
    "                # —––––– CHECKPOINT PARZIALE –––––—\n",
    "                #Checkpoint parziale: garantisce che, dopo ogni soggetto, il file contenga già tutti i dati processati fino a lì.\n",
    "                \n",
    "                '''\n",
    "                L’idea di “normalizzare” i tuoi defaultdict prima del dump con una funzione come to_plain_dict è perfettamente valida \n",
    "                e ti permette di tenerti il resto del codice praticamente uguale.\n",
    "                \n",
    "                IO:\n",
    "                \n",
    "                Quindi questo dovrebbe riuscire a salvarmi le varie ICA per ogni soggetto ogni volta \n",
    "                E alla fine impili il tutto insieme e ti salva la struttura completa.\n",
    "                L'idea dovrebbe essere che, salvando ogni soggetto, poi quando devi salvarsi la struttura impilata di tutti i soggetti assieme, \n",
    "                avendo già creato parzialmente la struttura di ogni singolo soggetto, dovrebbe salvarmi con più \"facilità\" la struttura finale risultante ?\n",
    "                \n",
    "                \n",
    "                CHATGPT:\n",
    "                Esatto: l’idea è proprio quella.\n",
    "\n",
    "                Durante il loop, subito dopo aver processato ciascun soggetto (filtro → ICA → epoching), \n",
    "                tu fai un dump parziale di task_data (convertito in dict “plain” per essere serializzabile). \n",
    "                \n",
    "                In questo modo, se il kernel si blocca, hai già su disco il risultato completo fino all’ultimo soggetto “finito”.\n",
    "                Alla fine, una volta terminati tutti i soggetti e fatto lo stacking definitivo (np.stack), fai un ultimo dump di task_data \n",
    "                (sempre convertito in dict), che contiene ora tutta la struttura completa con gli array finali.\n",
    "\n",
    "                Quindi:\n",
    "\n",
    "                Checkpoint parziale\n",
    "\n",
    "                Salvi man mano liste di epoche (\"data\": […], \"labels\": […]) soggetto per soggetto.\n",
    "                Il file cresce soggetto dopo soggetto, ma hai sempre uno stato coerente fino a quel punto.\n",
    "\n",
    "                Checkpoint finale\n",
    "                Sovrascrivi con la versione “impilata” (ndarray) di tutta la struttura.\n",
    "\n",
    "                Questo non “alleggerisce” magicamente il salvataggio finale in termini di complessità algoritmica,\n",
    "                ma ti garantisce di non perdere i dati già elaborati se il processo si interrompe a metà. \n",
    "                \n",
    "                Alla fine, il file conterrà esattamente la stessa cosa che avresti ottenuto facendo un unico dump a lavoro ultimato.\n",
    "                Se poi ti interessa riprendere da un checkpoint intermedio, basta caricare quel file, ricostruire (o estendere) task_data in memoria \n",
    "                e continuare il loop da dove sei arrivato.\n",
    "\n",
    "                In breve:\n",
    "\n",
    "                Sì, checkpoint soggetto-per-soggetto + dump finale ti dà sia sicurezza che la struttura completa, senza perdere nulla.\n",
    "                No, la serializzazione finale non diventa “più semplice” in sé, \n",
    "                ma è garantita dal fatto che usi sempre to_plain_dict al momento del dump, mentre in memoria rimane il defaultdict per un accesso automatico\n",
    "                senza KeyError.\n",
    "\n",
    "                '''\n",
    "                \n",
    "                # —––––– CHECKPOINT PARZIALE –––––—\n",
    "                # Aggiungi l'oggetto ICA al dizionario\n",
    "                ica_models[(task, subj_key, r)] = ica\n",
    "                \n",
    "                \n",
    "                plain = to_plain_dict(task_data)\n",
    "                \n",
    "                if checkpoint_every_subject:\n",
    "                    with open(CHECKPOINT_PATH, \"wb\") as f:\n",
    "                        pickle.dump(plain, f)\n",
    "                        \n",
    "                    # Salva anche gli oggetti ICA separatamente\n",
    "                    with open(ICA_MODELS_PATH, \"wb\") as f:\n",
    "                        pickle.dump(ica_models, f)\n",
    "                    print(f\"[Checkpoint] salvato dopo soggetto \\033[1m{subj_key}\\033[0m\")   \n",
    "                    \n",
    "    # ------ stack finale e conversione a ndarray ------\n",
    "    for task in task_data:\n",
    "        for subj in task_data[task]:\n",
    "            for Tx in task_data[task][subj]:\n",
    "                td = task_data[task][subj][Tx]\n",
    "                if td[\"data\"]:\n",
    "                    td[\"data\"]   = np.stack(td[\"data\"], axis=0)           # (n, 64, 640)\n",
    "                    td[\"labels\"] = np.asarray(td[\"labels\"], dtype=int)    # (n,)\n",
    "                else:  # nessun trial valido\n",
    "                    td[\"data\"]   = np.empty((0, 64, epoch_len), np.float32)\n",
    "                    td[\"labels\"] = np.empty((0,), int)\n",
    "    \n",
    "    plain = to_plain_dict(task_data)\n",
    "    \n",
    "    # —––––– SALVATAGGIO FINALE –––––—\n",
    "    with open(CHECKPOINT_PATH, \"wb\") as f:\n",
    "        pickle.dump(plain, f)\n",
    "        \n",
    "    with open(ICA_MODELS_PATH, \"wb\") as f:\n",
    "        pickle.dump(ica_models, f)\n",
    "        \n",
    "    print(\"[Salvataggio finale] task_data_ICA completo.\")\n",
    "    \n",
    "    return task_data\n",
    "\n",
    "\n",
    "\n",
    "ma il punto è che la costruzione del dataset partiva da 'Signal' e 'Annotations'....\n",
    "\n",
    "Mentre ORA, dobbiamo partire da un dizionario che è EEG_post_ICA, che è dizionario annidato che ha alla fine una tupla formata dai dati (post ICA, ma come ancora unica serie temporale di circa 2 minuti) come primo elemento e le labels come secondo elemento (che contiene tutti i vari metadati per fare la costruzione del dataset)...\n",
    "\n",
    "invece prima  'Signal' e 'Annotations' erano due strutture separate!\n",
    "\n",
    "la difficoltà è questa in sostanza!\n",
    "\n",
    "\n",
    "La mia idea è, partendo questa volta da EEG_post_ICA, vorrei ri-adattare questa filosofia di approccio alla costruzione del dataset usata prima, dove\n",
    "\n",
    "label_to_Tx era stata già fatto quando avevo creato il dataset con il solo filtraggio, per cui quella parte dovrebbe esser ok, nel senso che ho T0, T1 e T2 fatto in questo modo per ogni task\n",
    "\n",
    "\n",
    "La corrispondenza era infatti:\n",
    "\n",
    "Task 1: {1=T0 Rest, 2=T1 Left Fist, 3=T2 Right Fist}\n",
    "\n",
    "Task 2: {4=T0 Rest, 5=T1 Both Feet, 6=T2 Both Fists}\n",
    "\n",
    "Task 3: {7=T0 Rest, 8=T1 Both Fists, 9=T2 Both Feet}\n",
    "\n",
    "Task 4: {10=T0 Rest, 11=T1 Right Fist, 12=T2 Left Fist}\n",
    "\n",
    "\n",
    "Per sicurezza, però, vorrei ri-eseguire lo stesso approccio, ri-usando anche nuovamente label_to_Tx (anche se è stato già usato)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Infatti, mi sono reso conto che, quando visualizzavo la struttura dati di EEG_post_ICA, con questa\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def inspect_raw_collection(collection, name=\"\"):\n",
    "    print(f\"\\nInspecting structure: \\033[1m{name}\\033[0m\\n\" + \"-\"*50)\n",
    "    \n",
    "    all_subjects = []\n",
    "    all_runs = []\n",
    "\n",
    "    for task, subjects in collection.items():\n",
    "        print(f\"📁 Task: \\033[94m{task}\\033[0m → {len(subjects)} subjects\")\n",
    "        \n",
    "        # Mappa etichette in base al task\n",
    "        if task in [\"task_1\", \"task_2\"]:\n",
    "            label_map = {1: \"T0 (Rest)\", 2: \"T1 (Left Fist)\", 3: \"T2 (Right Fist)\"}\n",
    "        else:\n",
    "            label_map = {1: \"T0 (Rest)\", 2: \"T1 (Both Feet)\", 3: \"T2 (Both Fists)\"}\n",
    "\n",
    "        for subj, runs in subjects.items():\n",
    "            all_subjects.append(subj)\n",
    "            print(f\"  └─ 👤 Subject {subj} → {len(runs)} runs\")\n",
    "            for run, (raw, annotations) in runs.items():\n",
    "                all_runs.append(run)\n",
    "                print(f\"      └─ 🏃‍♂️ Run {run}:\")\n",
    "                print(f\"         ├─ Raw type:      {type(raw)}\")\n",
    "                print(f\"         ├─ Data shape:    {raw.get_data().shape}  (channels x time)\")\n",
    "                print(f\"         ├─ Annotations:   {type(annotations)}, shape={annotations.shape}\")\n",
    "                if isinstance(annotations, np.ndarray):\n",
    "                    print(f\"           ├─ First annotation row: {annotations[0]}\")\n",
    "                    print()\n",
    "                    print(f\"             ├─ Unique stimolo_id [0]: {np.unique(annotations[:, 0])}\")\n",
    "                    print(f\"             ├─ Durata trial secondi [1]: {np.unique(annotations[:, 1])}\")\n",
    "                    print(f\"             ├─ Durata trial in samples [2]: {np.unique(annotations[:, 2])}\\n\")\n",
    "                    print(f\"             ├─ Start sample  [3]: {np.unique(annotations[:, 3])}\\n\")\n",
    "                    print(f\"             └─ End sample [4]: {np.unique(annotations[:, 4])}\\n\")\n",
    "                print(f\"         └─ Duration (s):  {raw.times[-1]:.2f}s\")\n",
    "                \n",
    "            break  # Solo il primo soggetto per ogni task\n",
    "        print()\n",
    "\n",
    "    # Mostra soggetti e run unici\n",
    "    unique_subjects = np.unique(all_subjects)\n",
    "    unique_runs = np.unique(all_runs)\n",
    "\n",
    "    print(f\"\\n📊 \\033[1mRiepilogo {name}\\033[0m\")\n",
    "    print(f\"→ Soggetti unici: {len(unique_subjects)} → {unique_subjects}\")\n",
    "    print(f\"→ Run uniche:     {len(unique_runs)} → {unique_runs}\")\n",
    "    print(\"✓ Done.\\n\")\n",
    "\n",
    "    return unique_subjects, unique_runs\n",
    "\n",
    "\n",
    "in realtà se VEDI BENE, si usava un MAPPING, che non mi faceva vedere che IN REALTA' le labels erano ANCORA T0,T1 e T2 per ogni task !\n",
    "\n",
    "Quindi la differenza è che qui, dovrei integrare l'approccio di prima, ma partendo da EEG_post_ICA e costruendo di nuovo un dizionario annidato (MA NON default dict! ed escludendo la parte della ICA e dei checkpoint associati all'ICA, che son stati già fatti) a 4 livelli, dove i livelli erano\n",
    "\n",
    "\n",
    "task, soggetto, condizione sperimentale e poi dentro la suddivisione in due sottochiavi di dati e labels di quella condizione sperimentale lì ...\n",
    "\n",
    "e se possibile anche integrare queste ALTRE funzioni , tra cui:\n",
    "\n",
    "\n",
    "1) 'rename_conditions' che serviva per \n",
    "\n",
    "partire dal mio nuovo EEG_data (il dizionario annidato ottenuto a 4 livelli post-fase di epocatura, ossia con già i dati suddivisi in epoche di 4 secondi per ogni trial), per i dati ogni task, ossia a task_1, task_2 etc.\n",
    "mi andasse a cambiare il nome della chiave del 3° livello, a seconda del task di cui ci si riferisce, per ogni soggetto...\n",
    "\n",
    "ossia, vorrei che le chiavi T0, T1, e T2 prendessero il nome della condizione sperimentale corrente del task. Ad esempio\n",
    "\n",
    "task 1 : \n",
    "\n",
    "T0: rest\n",
    "T1: left_fist\n",
    "T2: right_fist\n",
    "\n",
    "task 2 : \n",
    "\n",
    "T0: rest\n",
    "T1: left_fist\n",
    "T2: right_fist\n",
    "\n",
    "\n",
    "task 3 : \n",
    "\n",
    "T0: rest\n",
    "T1: both_fists\n",
    "T2: both_feet\n",
    "\n",
    "task 4 : \n",
    "\n",
    "T0: rest\n",
    "T1: both_fists\n",
    "T2: both_feet\n",
    "\n",
    "\n",
    "l'esempio di codice era questo:\n",
    "\n",
    "'''\n",
    "Ecco una funzione semplice e rapida che fa esattamente ciò che chiedi: rinomina le chiavi T0, T1 e T2 \n",
    "con il nome esplicito della condizione sperimentale in base al task:\n",
    "'''\n",
    "\n",
    "def rename_conditions(task_data):\n",
    "    # Definisci la mappatura per ciascun task\n",
    "    condition_mapping = {\n",
    "        'task_1': {'T0': 'rest', 'T1': 'left_fist', 'T2': 'right_fist'},\n",
    "        'task_2': {'T0': 'rest', 'T1': 'left_fist', 'T2': 'right_fist'},\n",
    "        'task_3': {'T0': 'rest', 'T1': 'both_fists', 'T2': 'both_feet'},\n",
    "        'task_4': {'T0': 'rest', 'T1': 'both_fists', 'T2': 'both_feet'},\n",
    "    }\n",
    "    \n",
    "    # Nuovo dizionario da restituire con nomi modificati\n",
    "    renamed_data = {}\n",
    "    \n",
    "    # Loop sui task e soggetti per cambiare i nomi delle condizioni\n",
    "    for task, subjects in task_data.items():\n",
    "        renamed_data[task] = {}\n",
    "        mapping = condition_mapping[task]\n",
    "        \n",
    "        for subj, conditions in subjects.items():\n",
    "            renamed_data[task][subj] = {}\n",
    "            for old_cond, data_labels in conditions.items():\n",
    "                new_cond = mapping[old_cond]\n",
    "                renamed_data[task][subj][new_cond] = data_labels\n",
    "    \n",
    "    return renamed_data\n",
    "\n",
    "\n",
    "dove in questo caso 'task_data' sarebbe appunto il nuovo dizionario annidato costruito a partire da EEG_post_ICA\n",
    "\n",
    "2) 'reformat_for_task' che sarebbe funzione che prende in ingresso il tuo EEG_data (post_epocatura -ossia il dizionario a 4 livelli task → subject → condition → {data,labels} ossia sempre il nuovo dizionario annidato costruito a partire da EEG_post_ICA) \n",
    "\n",
    "e lo riformatta in un dizionario di liste di dict, uno per ciascun task:\n",
    "\n",
    "'''\n",
    "\n",
    "def reformat_for_task(task_data):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "      task_data[task][subj][condition] = {\"data\": ndarray, \"labels\": ndarray}\n",
    "    Output:\n",
    "      out[task] = [\n",
    "        { \"<cond>_<subj>\"        : data_array,\n",
    "          \"<cond>_<subj>_labels\": labels_array,\n",
    "          ... per ogni condition e per ogni subj ...\n",
    "        },\n",
    "        ... uno dict per ogni subject ...\n",
    "      ]\n",
    "    \"\"\"\n",
    "    reformatted = {}\n",
    "    for task, subjects in task_data.items():\n",
    "        lst = []\n",
    "        for subj, conds in subjects.items():\n",
    "            rec = {}\n",
    "            for cond, dl in conds.items():\n",
    "                # costruisci le due chiavi\n",
    "                key_data   = f\"{cond}_{subj}\"\n",
    "                key_labels = f\"{cond}_{subj}_labels\"\n",
    "                rec[key_data]   = dl[\"data\"]\n",
    "                rec[key_labels] = dl[\"labels\"]\n",
    "            lst.append(rec)\n",
    "        reformatted[task] = lst\n",
    "    return reformatted\n",
    "\n",
    "dove quindi sempre qui anche \"task_data\" sarebbe appunto il nuovo dizionario annidato costruito a partire da EEG_post_ICA\n",
    "\n",
    "\n",
    "3) una ultima funzione \"preprocess_EEG_labels\" che \n",
    "\n",
    "mi creava una funzione che a partire da questa struttura (dizionario di liste di dizionari, ossia l'output di \"reformat_for_task\" ossia --> reformatted in sostanza) ed iterava su ogni soggetto (ogni indice che qua nell'esempio è lo 0 per indicare il primo soggetto della lista di dizionari) e verificava se nelle chiavi ci fosse '_labels' all'interno della chiave del relativo dizionario ed inoltre doveva vedere se comparissero diverse stringhe al suo interno.\n",
    "\n",
    "\n",
    "Nello specifico: \n",
    "\n",
    "se è 'task_1' o 'task_2' come dizionario di partenza allora dovrebbe vedere se poi all'interno di ogni soggetto sulle chiavi delle labels  (quelle che hanno anche '_labels' al suo interno) ci siano 3 possibili stringhe che sono 'rest' 'left_fist' 'right_fist'\n",
    "\n",
    "\n",
    "se è rest allora le sue labels le rendi dal loro valore corrente a 0\n",
    "se è left_fist allora le sue labels le rendi dal loro valore corrente a 1\n",
    "se è right_fist allora le sue labels le rendi dal loro valore corrente a 2\n",
    "\n",
    "\n",
    "se è 'task_3' o 'task_4' come dizionario di partenza allora dovrebbe vedere se poi all'interno di ogni soggetto sulle chiavi delle labels  (quelle che hanno anche '_labels' al suo interno) ci siano 3 possibili stringhe che sono 'rest' 'both_fists' 'both_feet'\n",
    "\n",
    "\n",
    "se è rest allora le sue labels le rendi dal loro valore corrente a 0\n",
    "se è both_fists allora le sue labels le rendi dal loro valore corrente a 1\n",
    "se è both_feet allora le sue labels le rendi dal loro valore corrente a 2\n",
    "\n",
    "\n",
    "\n",
    "def preprocess_EEG_labels(eeg_data):\n",
    "    \"\"\"\n",
    "    Come prima, ma con filtro Butterworth di ordine 8.\n",
    "    \"\"\"\n",
    "    mapping_12 = {'rest': 0, 'left_fist': 1, 'right_fist': 2}\n",
    "    mapping_34 = {'rest': 0, 'both_fists': 1, 'both_feet': 2}\n",
    "\n",
    "    for task, subjects in eeg_data.items():\n",
    "        if task in ('task_1', 'task_2'):\n",
    "            mapping = mapping_12\n",
    "        elif task in ('task_3', 'task_4'):\n",
    "            mapping = mapping_34\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        for subj in subjects:\n",
    "           \n",
    "            # 1) rimappo le etichette\n",
    "            for key, labels in list(subj.items()):\n",
    "                if key.endswith('_labels'):\n",
    "                    prefix = key.replace('_labels', '').rsplit('_', 1)[0]\n",
    "                    if prefix in mapping:\n",
    "                        subj[key] = np.full(len(labels), mapping[prefix], dtype=int)\n",
    "\n",
    "    return eeg_data\n",
    "\n",
    "\n",
    "\n",
    "ora, dimmi tu che cosa convenga fare tra\n",
    "\n",
    "A) integrare l'approccio di prima, di costruzione del dataset annidato a 4 livelli, ed integrare tutti gli step solo fino a 'reformat_for_task' o se fare 'preprocess_EEG_labels' separatamente.\n",
    "\n",
    "B) fare tutto assieme, mantenendo la logica di salvataggio del dataset già annidato a 4 livelli con i vari checkpoint e l'integrazione di \"rename_conditions\", \"reformat_for_task\" e preprocess_EEG_labels\" tutto in un unico blocco.\n",
    "\n",
    "Propenderei per la B, ma dimmi se sia fattibile, tenendo conto della complessità del task che ti chiedo.\n",
    "\n",
    "Anche perché in realtà poi, alla fine di tutto, io vorrei usare la funzione Autoreject (con libreria ancora da installare) per fare l'ulteriore verifica di artifact rejection dei trial con valori di voltaggio sopra i 100 microvolt, "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78685598-bf72-4a14-a5db-8060aba69d5b",
   "metadata": {},
   "source": [
    "ok per sicurezza, nella table 2 del file pdf https://pmc.ncbi.nlm.nih.gov/articles/PMC10998040/pdf/main.pdf dove si legge a destra \n",
    "\n",
    "\n",
    "\"Curated dataset\" e sotto \"Signal and annotation reference\" dovrebbe riferirsi al numero della run corrispondente, che io già correttamente riformattato durante la creazione del mio dataset già solo filtrato giusto? \n",
    "\n",
    "\n",
    "\n",
    "Sì, il ragionamento è corretto 👍\n",
    "\n",
    "In annotations la prima colonna che vedi (1 nel tuo esempio [1, 4.1, 656., 1., 656.]) è l’ID della classe locale al task (1, 2, 3), non la stringa “T0/T1/T2”. \n",
    "\n",
    "La mappatura label_to_Tx = [\"T0\",\"T1\",\"T2\"][(label-1)%3] serve proprio a trasformare 1→T0, 2→T1, 3→T2 per qualunque task.\n",
    "\n",
    "Le colonne “4.1” e “656” confermano la durata trial e i campioni (a 160 Hz: 4.1 s ↔ 656 campioni; 4.2 s ↔ 672), e gli indici [3]=start, [4]=end sono MATLAB 1-based (da portare a 0-based in Python).\n",
    "\n",
    "In Tabella 2 del paper, la colonna “Signal and annotation reference” indica i run originali da cui sono stati presi segnali e annotazioni per il “curated dataset”. La tua mappatura Python 0-based:\n",
    "\n",
    "task_1 → [0, 4, 8] (corrisponde a 1,5,9 in 1-based)\n",
    "\n",
    "task_2 → [1, 5, 9] (2,6,10)\n",
    "\n",
    "task_3 → [2, 6, 10] (3,7,11)\n",
    "\n",
    "task_4 → [3, 7, 11] (4,8,12)\n",
    "è esattamente l’interpretazione giusta.\n",
    "\n",
    "Se vuoi una mini-verifica runtime (consiglio rapido):\n",
    "\n",
    "raw, ann = EEG_post_ICA['task_1']['100'][0]   # esempio\n",
    "fs = int(raw.info['sfreq'])\n",
    "assert fs == 160\n",
    "\n",
    "labs = ann[:,0].astype(int)\n",
    "durs = ann[:,1]\n",
    "nsmp = ann[:,2].astype(int)\n",
    "on   = ann[:,3].astype(int)\n",
    "off  = ann[:,4].astype(int)\n",
    "\n",
    "#Check coerenza (MATLAB→Python: start dovrebbe essere 1-based)\n",
    "assert np.all((nsmp == (off - on + 1)))\n",
    "assert set(labs) <= {1,2,3}\n",
    "assert set(np.unique(durs)) <= {4.1, 4.2}\n",
    "assert set(np.unique(nsmp)) <= {656, 672}\n",
    "\n",
    "\n",
    "In sintesi: puoi usare tranquillamente label_to_Tx per tornare a T0/T1/T2, e la tua mappatura dei run è allineata a quanto indicato nella tabella “Signal and annotation reference”. Procedi sereno 😉\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68f4401-d4d8-4f95-bd22-e3e53cb6677b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### **POST Custom ICA: Implementation to create the New Data Structure before Autoreject Step**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cfa346-3fda-4fdb-b8ed-a7ca2e06b82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Grande — andiamo con la B: è fattibilissima e ti fa arrivare a \n",
    "\n",
    "un pacchetto coerente “dalla serie continua post-ICA → epoche → dizionari riformattati → label 0/1/2 pronte per Autoreject / ML”.\n",
    "\n",
    "Qui sotto ti lascio tutto il blocco (compatto ma curato) per:\n",
    "\n",
    "epocare da EEG_post_ICA in un dict annidato a 4 livelli\n",
    "task → subject → T0/T1/T2 → {\"data\": (n, ch, t), \"labels\": (n,)}\n",
    "\n",
    "rinominare T0/T1/T2 con i nomi espliciti delle condizioni (per task)\n",
    "\n",
    "riformattare per task in un “dict di liste di dict” (come avevi)\n",
    "\n",
    "rimappare le etichette in 0/1/2 in base ai nomi delle condizioni\n",
    "\n",
    "Include il checkpoint opzionale “per soggetto”.\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "import os, pickle\n",
    "from pathlib import Path\n",
    "from typing import Dict, Tuple\n",
    "import numpy as np\n",
    "import mne\n",
    "\n",
    "# ---------- util ----------\n",
    "\n",
    "'''\n",
    "\n",
    "                                                                    Perché tenere --> label_to_Tx???\n",
    "\n",
    "\n",
    "Mi serve per far 'ritornare' i valori numerici in T0, T1,T2 per ogni task\n",
    "(che è fondamentale poi per fare le modifiche successive con l'aggiunta delle funzioni di integrazione), è corretto il ragionamento?\n",
    "\n",
    "Sì, il ragionamento è giusto ✅\n",
    "\n",
    "Quella riga che hai stampato\n",
    "[1, 4.1, 656., 1., 656.]\n",
    "significa: stimolo_id=1 → in questo dataset 1=T0, 2=T1, 3=T2 (coerente con ciò che avevi visto: np.unique(annotations[:,0]) = [1.,2.,3.]).\n",
    "\n",
    "La funzione\n",
    "\n",
    "def label_to_Tx(label_num: int) -> str:\n",
    "    return [\"T0\",\"T1\",\"T2\"][(int(label_num)-1) % 3]\n",
    "\n",
    "\n",
    "è esattamente ciò che ti serve per ricondurre i numeri a T0/T1/T2.\n",
    "\n",
    "È anche “robusta”: se mai avessi etichette 1..12 (aggregando i 4 task),\n",
    "il modulo % 3 le mappa comunque correttamente:\n",
    "\n",
    "1,4,7,10 → T0\n",
    "\n",
    "2,5,8,11 → T1\n",
    "\n",
    "3,6,9,12 → T2\n",
    "\n",
    "Poi, per task, usi rename_conditions per trasformare T0/T1/T2 nei nomi espliciti (rest/left_fist/right_fist o rest/both_fists/both_feet). Questo è lo step che usa il task.\n",
    "\n",
    "Infine, se vuoi etichette numeriche 0/1/2 per ML/Autoreject, puoi:\n",
    "\n",
    "o usare la tua preprocess_EEG_labels (mappa dai nomi condizione → 0/1/2),\n",
    "\n",
    "oppure, più diretto, salvare subito y = ((label_num-1) % 3) quando epocheggi (ma mantenere prima T0/T1/T2 rende tutto più leggibile).\n",
    "\n",
    "Quindi:\n",
    "Sì, tieni label_to_Tx nello step di epocatura da EEG_post_ICA → T0/T1/T2, poi rename_conditions per i nomi per-task, e opzionalmente preprocess_EEG_labels per ottenere 0/1/2.\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "def label_to_Tx(label_num: int) -> str:\n",
    "    \"\"\"Robusta: gestisce 1..12 o 1..3 → T0/T1/T2.\"\"\"\n",
    "    idx = (int(label_num) - 1) % 3\n",
    "    return [\"T0\", \"T1\", \"T2\"][idx]\n",
    "\n",
    "def _save_checkpoint(obj, path: Path):\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(path, \"wb\") as f:\n",
    "        pickle.dump(obj, f)\n",
    "\n",
    "# ---------- 1) build_task_data: epoche da EEG_post_ICA ----------\n",
    "def build_task_data_from_postICA(\n",
    "    EEG_post_ICA: Dict[str, Dict[str, Dict[int, Tuple[mne.io.BaseRaw, np.ndarray]]]],\n",
    "    epoch_len_s: float = 4.0,\n",
    "    drop_shorter: bool = True,\n",
    "    convert_to_uV: bool = True,\n",
    "    checkpoint_path: Path = None,\n",
    "    checkpoint_every_subject: bool = False,\n",
    ") -> Dict[str, Dict[str, Dict[str, Dict[str, np.ndarray]]]]:\n",
    "    \"\"\"\n",
    "    Output:\n",
    "      task_data[task][subject][T0|T1|T2] = {\n",
    "          \"data\":   ndarray (n_trials, n_chan, epoch_len),\n",
    "          \"labels\": ndarray (n_trials,)  # etichette originali ann_arr[:,0]\n",
    "      }\n",
    "    \"\"\"\n",
    "    task_data: Dict[str, Dict[str, Dict[str, Dict[str, np.ndarray]]]] = {}\n",
    "\n",
    "    for task, subjects in EEG_post_ICA.items():\n",
    "        task_data.setdefault(task, {})\n",
    "        for subj, runs in subjects.items():\n",
    "            # collezioniamo su 3 contenitori (uno per T0/T1/T2)\n",
    "            bins = {k: {\"data\": [], \"labels\": []} for k in (\"T0\", \"T1\", \"T2\")}\n",
    "\n",
    "            # usa un info “template” dal primo run (serve se poi farai EpochsArray)\n",
    "            # (facoltativo; utile in futuro)\n",
    "            first_raw = None\n",
    "\n",
    "            for run_idx, (raw, ann) in sorted(runs.items()):\n",
    "                if first_raw is None:\n",
    "                    first_raw = raw\n",
    "\n",
    "                fs = float(raw.info[\"sfreq\"])\n",
    "                ep_len = int(round(epoch_len_s * fs))\n",
    "\n",
    "                Xv = raw.get_data().T  # (n_times, n_chan), in Volt\n",
    "                n_times = Xv.shape[0]\n",
    "\n",
    "                # ann: (30, 5) = [label, dur_s, dur_samples, start_sample, end_sample] (start 1-based)\n",
    "                onsets = ann[:, 3].astype(int) - 1  # 0-based\n",
    "                durs   = ann[:, 2].astype(int)\n",
    "                labs   = ann[:, 0].astype(int)\n",
    "\n",
    "                for onset, dur, lab in zip(onsets, durs, labs):\n",
    "                    if dur < ep_len and drop_shorter:\n",
    "                        continue\n",
    "                    start = onset\n",
    "                    stop  = onset + ep_len\n",
    "                    if stop > n_times:\n",
    "                        continue\n",
    "\n",
    "                    seg = Xv[start:stop, :]  # (ep_len, n_chan) in Volt\n",
    "                    if convert_to_uV:\n",
    "                        seg = seg * 1e6      # → µV\n",
    "                    seg = seg.T.astype(np.float32)  # (n_chan, ep_len)\n",
    "\n",
    "                    Tx = label_to_Tx(lab)\n",
    "                    bins[Tx][\"data\"].append(seg)\n",
    "                    bins[Tx][\"labels\"].append(int(lab))\n",
    "\n",
    "            # stack per ogni Tx\n",
    "            task_data[task].setdefault(subj, {})\n",
    "            for Tx in (\"T0\", \"T1\", \"T2\"):\n",
    "                if bins[Tx][\"data\"]:\n",
    "                    data = np.stack(bins[Tx][\"data\"], axis=0)              # (n, ch, t)\n",
    "                    labels = np.asarray(bins[Tx][\"labels\"], dtype=int)     # (n,)\n",
    "                else:\n",
    "                    # nessun trial valido di quel tipo\n",
    "                    # per coerenza, usa dimensioni nulle con ep_len dell’ultimo run visto (o default 0)\n",
    "                    # Proviamo a inferire ep_len dal primo run visto\n",
    "                    if \"raw\" in locals() and raw is not None:\n",
    "                        fs = float(raw.info[\"sfreq\"])\n",
    "                        ep_len = int(round(epoch_len_s * fs))\n",
    "                    else:\n",
    "                        ep_len = 0\n",
    "                    data = np.empty((0, raw.info[\"nchan\"], ep_len), dtype=np.float32)\n",
    "                    labels = np.empty((0,), dtype=int)\n",
    "\n",
    "                task_data[task][subj][Tx] = {\"data\": data, \"labels\": labels}\n",
    "\n",
    "            # checkpoint per soggetto (salva *tutto* task_data corrente: semplice e robusto)\n",
    "            if checkpoint_every_subject and checkpoint_path is not None:\n",
    "                _save_checkpoint(task_data, checkpoint_path)\n",
    "\n",
    "    # salvataggio finale (se richiesto)\n",
    "    if checkpoint_path is not None and not checkpoint_every_subject:\n",
    "        _save_checkpoint(task_data, checkpoint_path)\n",
    "\n",
    "    return task_data\n",
    "\n",
    "# ---------- 2) rename_conditions: T0/T1/T2 → nomi espliciti ----------\n",
    "CONDITION_MAPPING = {\n",
    "    # Usa ESATTAMENTE la mappa che hai richiesto tu\n",
    "    'task_1': {'T0': 'rest', 'T1': 'left_fist',  'T2': 'right_fist'},\n",
    "    'task_2': {'T0': 'rest', 'T1': 'left_fist',  'T2': 'right_fist'},\n",
    "    'task_3': {'T0': 'rest', 'T1': 'both_feet', 'T2': 'both_fists'},\n",
    "    'task_4': {'T0': 'rest', 'T1': 'both_feet', 'T2': 'both_fists'},\n",
    "}\n",
    "\n",
    "def rename_conditions(task_data, mapping=CONDITION_MAPPING):\n",
    "    renamed = {}\n",
    "    for task, subjects in task_data.items():\n",
    "        renamed[task] = {}\n",
    "        mp = mapping.get(task, {'T0':'T0','T1':'T1','T2':'T2'})\n",
    "        for subj, conds in subjects.items():\n",
    "            renamed[task][subj] = {}\n",
    "            for old_cond, dl in conds.items():\n",
    "                new_cond = mp.get(old_cond, old_cond)\n",
    "                renamed[task][subj][new_cond] = dl\n",
    "    return renamed\n",
    "\n",
    "# ---------- 3) reformat_for_task ----------\n",
    "def reformat_for_task(task_data):\n",
    "    \"\"\"\n",
    "    Input:  task_data[task][subj][condition] = {\"data\": ndarray, \"labels\": ndarray}\n",
    "    Output: out[task] = [ { \"cond_subj\": data, \"cond_subj_labels\": labels }, ... per subject ... ]\n",
    "    \"\"\"\n",
    "    reformatted = {}\n",
    "    for task, subjects in task_data.items():\n",
    "        lst = []\n",
    "        for subj, conds in subjects.items():\n",
    "            rec = {}\n",
    "            for cond, dl in conds.items():\n",
    "                rec[f\"{cond}_{subj}\"] = dl[\"data\"]\n",
    "                rec[f\"{cond}_{subj}_labels\"] = dl[\"labels\"]\n",
    "            lst.append(rec)\n",
    "        reformatted[task] = lst\n",
    "    return reformatted\n",
    "\n",
    "# ---------- 4) preprocess_EEG_labels: porta a 0/1/2 (per task) ----------\n",
    "def preprocess_EEG_labels(eeg_data_reformatted):\n",
    "    \"\"\"\n",
    "    Rimappa *_labels a {0,1,2} in base al nome della condizione nella chiave.\n",
    "    Segue la tua convenzione richiesta:\n",
    "      - task_1 & task_2: rest=0, left_fist=1, right_fist=2\n",
    "      - task_3 & task_4: rest=0, both_feet=1, both_fists=2\n",
    "    \"\"\"\n",
    "    mapping_12 = {'rest': 0, 'left_fist': 1, 'right_fist': 2}\n",
    "    mapping_34 = {'rest': 0, 'both_feet': 1, 'both_fists': 2}\n",
    "\n",
    "    out = {}\n",
    "    for task, subjects in eeg_data_reformatted.items():\n",
    "        out_list = []\n",
    "        if task in ('task_1', 'task_2'):\n",
    "            mp = mapping_12\n",
    "        elif task in ('task_3', 'task_4'):\n",
    "            mp = mapping_34\n",
    "        else:\n",
    "            mp = {}\n",
    "\n",
    "        for subj_dict in subjects:\n",
    "            rec = {}\n",
    "            for key, val in subj_dict.items():\n",
    "                if key.endswith('_labels'):\n",
    "                    # es: \"left_fist_12_labels\" → condition = \"left_fist\"\n",
    "                    prefix = key[:-7]  # rimuove \"_labels\"\n",
    "                    cond = prefix.rsplit('_', 1)[0]  # rimuove _<subj>\n",
    "                    if cond in mp:\n",
    "                        rec[key] = np.full(len(val), mp[cond], dtype=int)\n",
    "                    else:\n",
    "                        # fallback: lascia intatti se non riconosciuti\n",
    "                        rec[key] = val.astype(int)\n",
    "                else:\n",
    "                    rec[key] = val\n",
    "            out_list.append(rec)\n",
    "        out[task] = out_list\n",
    "\n",
    "    return out\n",
    "\n",
    "# ---------- 5) wrapper \"tutto in uno\" ----------\n",
    "def build_and_format_all(\n",
    "    EEG_post_ICA,\n",
    "    epoch_len_s=4.0,\n",
    "    drop_shorter=True,\n",
    "    convert_to_uV=True,\n",
    "    checkpoint_path: Path = None,\n",
    "    checkpoint_every_subject: bool = False,\n",
    "):\n",
    "    task_data = build_task_data_from_postICA(\n",
    "        EEG_post_ICA=EEG_post_ICA,\n",
    "        epoch_len_s=epoch_len_s,\n",
    "        drop_shorter=drop_shorter,\n",
    "        convert_to_uV=convert_to_uV,\n",
    "        checkpoint_path=checkpoint_path,\n",
    "        checkpoint_every_subject=checkpoint_every_subject,\n",
    "    )\n",
    "    task_data_named = rename_conditions(task_data)\n",
    "    reformatted     = reformat_for_task(task_data_named)\n",
    "    reformatted_y   = preprocess_EEG_labels(reformatted)\n",
    "    return task_data, task_data_named, reformatted, reformatted_y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742277e3-11fa-4472-9ddc-f4c3ba97f234",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### **POST Custom ICA: Implementation for the New Data Structure before Autoreject Step**\n",
    "\n",
    "#### **Example with One TASK, SUBJECT and RUN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905dd4e1-99f6-47b5-9dd3-6f2f16f5d142",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "ok se volessi quindi provare a fare un esempio su un solo task di un solo soggetto e run, \n",
    "E vedere davvero la sola struttura finale che sarebbe \"reformatted_y\" dal tuo esempio\n",
    "\n",
    "\n",
    "\"build_and_format_all\", \n",
    "\n",
    "che cosa dovrei fare? perché il punto è che potrei alla fine ri-sovrascrivere a 'task_data' quello che esce fuori da 'reformatted_y' giusto?\n",
    "\n",
    "\n",
    "\n",
    "Perfetto — facciamo un “mini-giro” su un solo task, un solo soggetto, una sola run e guardiamo solo la struttura finale reformatted_y.\n",
    "Qui sotto trovi uno snippet pronto che:\n",
    "\n",
    "crea un sotto-insieme di EEG_post_ICA (p.es. task_1, soggetto \"1\", run 0),\n",
    "\n",
    "chiama la tua build_and_format_all(...) (quella che abbiamo definito poco fa),\n",
    "\n",
    "stampa esattamente cosa c’è in reformatted_y per quel caso.\n",
    "\n",
    "Nota: lo snippet assume che tu abbia già definite le funzioni:\n",
    "build_and_format_all, build_task_data_postICA, rename_conditions, reformat_for_task, preprocess_EEG_labels.\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8ad5f4-b616-4ada-9e67-3f5fad50cdcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Cosa vedrai\n",
    "\n",
    "In reformatted_y[\"task_1\"][0] troverai coppie di chiavi del tipo:\n",
    "\n",
    "rest_1 e rest_1_labels\n",
    "\n",
    "left_fist_1 e left_fist_1_labels\n",
    "\n",
    "right_fist_1 e right_fist_1_labels\n",
    "\n",
    "Le labels saranno già mappate a 0/1/2 in base al task (per task_1: rest→0, left_fist→1, right_fist→2).\n",
    "\n",
    "Le forme dei dati saranno (n_epoche, n_canali, n_samples) (con n_samples = 4 s × fs), e le labels avranno forma (n_epoche,).\n",
    "'''\n",
    "\n",
    "# === 1) Scegli cosa testare ===\n",
    "test_task    = \"task_1\"\n",
    "test_subject = \"1\"     # stringa, come in EEG_post_ICA\n",
    "test_runs    = [0]     # prova con la run 0\n",
    "\n",
    "# === 2) Crea un sotto-dizionario con SOLO quel caso ===\n",
    "def subset_post_ICA(src, task, subject, runs):\n",
    "    out = {task: {subject: {}}}\n",
    "    for r in runs:\n",
    "        out[task][subject][r] = src[task][subject][r]  # (raw, ann)\n",
    "    return out\n",
    "\n",
    "EEG_subset = subset_post_ICA(EEG_post_ICA, test_task, test_subject, test_runs)\n",
    "\n",
    "# === 3) Esegui la pipeline di epocatura + rinomina condizioni + rimappa labels ===\n",
    "from pathlib import Path\n",
    "# evita di sovrascrivere il checkpoint \"globale\" durante il test\n",
    "CHECKPOINT_TEST = None  # oppure Path(\"/tmp/task_data_postICA_TEST.pkl\")\n",
    "\n",
    "task_data, task_data_named, reformatted, reformatted_y = build_and_format_all(\n",
    "    EEG_subset,\n",
    "    epoch_len_s=4.0,\n",
    "    drop_shorter=True,\n",
    "    convert_to_uV=False,\n",
    "    checkpoint_path=CHECKPOINT_TEST,\n",
    "    checkpoint_every_subject=False,\n",
    ")\n",
    "\n",
    "print(\"\\n[OK] Build & format completati per il subset.\\n\")\n",
    "\n",
    "# === 4) Ispeziona SOLO reformatted_y per quel task/soggetto ===\n",
    "# reformatted_y[task] = [ { \"<cond>_<subj>\": X, \"<cond>_<subj>_labels\": y, ... }, ... ]\n",
    "rec_list = reformatted_y[test_task]\n",
    "assert len(rec_list) == 1, f\"Mi aspettavo 1 soggetto nel subset, trovato {len(rec_list)}\"\n",
    "rec = rec_list[0]\n",
    "\n",
    "print(f\"Struttura reformatted_y[{test_task}] per il soggetto {test_subject}:\")\n",
    "for k, v in rec.items():\n",
    "    # v è un np.ndarray; stampa forma e, se sono labels, le uniche\n",
    "    if k.endswith(\"_labels\"):\n",
    "        import numpy as np\n",
    "        uniq, cnt = np.unique(v, return_counts=True)\n",
    "        print(f\"  {k:>20}  shape={v.shape}  values={dict(zip(uniq.tolist(), cnt.tolist()))}\")\n",
    "    else:\n",
    "        print(f\"  {k:>20}  shape={v.shape}\")\n",
    "\n",
    "# (opzionale) mini sanity check: numero totale epoche attese ~ 29-30 (120s / 4s)\n",
    "n_epochs = sum(v.shape[0] for k,v in rec.items() if not k.endswith(\"_labels\"))\n",
    "print(f\"\\nTotale epoche (tutte le condizioni): {n_epochs}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbe3eb5-75d5-4022-b846-02d23b781ff6",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### **POST Custom ICA: Implementation for the New Data Structure before Autoreject Step, ALL TASKS, SUBJECTS and RUNS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b7d8a8-3476-4c82-ac23-b4a20a86116c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Posso “sovrascrivere” task_data con reformatted_y?\n",
    "\n",
    "Meglio di no 🙂. Sono strutture diverse e servono a scopi diversi:\n",
    "\n",
    "task_data (4 livelli: task→soggetto→T0/T1/T2→{data,labels}) è perfetto per ispezioni “a piramide” e controlli qualitativi.\n",
    "\n",
    "reformatted_y (task→lista di dict per soggetto, con chiavi <cond>_<subj> e <cond>_<subj>_labels) è più comodo per ML e per passaggi successivi \n",
    "(p.es. Autoreject/feature extraction).\n",
    "\n",
    "Tieni entrambi: usa reformatted_y per addestramento/valutazioni e task_data/task_data_named per QC e tracciabilità. Se vuoi, salva reformatted_y in un file a parte \n",
    "(p.es. task_data_postICA_reformatted_y.pkl).\n",
    "\n",
    "Se vuoi, nel prossimo step ti mostro come passare da reformatted_y a un mne.Epochs (per singolo soggetto/task) e applicare Autoreject a livello di epoca.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8352701-53c3-45c0-906b-41c2834fec4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pickle\n",
    "from pathlib import Path\n",
    "from typing import Dict, Tuple\n",
    "import numpy as np\n",
    "import mne\n",
    "\n",
    "# ---------- util ----------\n",
    "def label_to_Tx(label_num: int) -> str:\n",
    "    \"\"\"Robusta: gestisce 1..12 o 1..3 → T0/T1/T2.\"\"\"\n",
    "    idx = (int(label_num) - 1) % 3\n",
    "    return [\"T0\", \"T1\", \"T2\"][idx]\n",
    "\n",
    "def _save_checkpoint(obj, path: Path):\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(path, \"wb\") as f:\n",
    "        pickle.dump(obj, f)\n",
    "\n",
    "# ---------- 1) build_task_data: epoche da EEG_post_ICA ----------\n",
    "def build_task_data_from_postICA(\n",
    "    EEG_post_ICA: Dict[str, Dict[str, Dict[int, Tuple[mne.io.BaseRaw, np.ndarray]]]],\n",
    "    epoch_len_s: float = 4.0,\n",
    "    drop_shorter: bool = True,\n",
    "    convert_to_uV: bool = True,\n",
    "    checkpoint_path: Path = None,\n",
    "    checkpoint_every_subject: bool = False,\n",
    ") -> Dict[str, Dict[str, Dict[str, Dict[str, np.ndarray]]]]:\n",
    "    \"\"\"\n",
    "    Output:\n",
    "      task_data[task][subject][T0|T1|T2] = {\n",
    "          \"data\":   ndarray (n_trials, n_chan, epoch_len),\n",
    "          \"labels\": ndarray (n_trials,)  # etichette originali ann_arr[:,0]\n",
    "      }\n",
    "    \"\"\"\n",
    "    task_data: Dict[str, Dict[str, Dict[str, Dict[str, np.ndarray]]]] = {}\n",
    "\n",
    "    for task, subjects in EEG_post_ICA.items():\n",
    "        task_data.setdefault(task, {})\n",
    "        for subj, runs in subjects.items():\n",
    "            \n",
    "            # collezioniamo su 3 contenitori (uno per T0/T1/T2)\n",
    "            bins = {k: {\"data\": [], \"labels\": []} for k in (\"T0\", \"T1\", \"T2\")}\n",
    "\n",
    "            # usa un info “template” dal primo run (serve se poi farai EpochsArray)\n",
    "            # (facoltativo; utile in futuro)\n",
    "            first_raw = None\n",
    "\n",
    "            for run_idx, (raw, ann) in sorted(runs.items()):\n",
    "                \n",
    "                # contatori drop per questo run\n",
    "                n_dropped_short = 0\n",
    "                n_dropped_edge = 0\n",
    "                \n",
    "                if first_raw is None:\n",
    "                    first_raw = raw\n",
    "\n",
    "                fs = float(raw.info[\"sfreq\"])\n",
    "                ep_len = int(round(epoch_len_s * fs))\n",
    "\n",
    "                Xv = raw.get_data().T  # (n_times, n_chan), in Volt\n",
    "                n_times = Xv.shape[0]\n",
    "\n",
    "                # ann: (30, 5) = [label, dur_s, dur_samples, start_sample, end_sample] (start 1-based)\n",
    "                onsets = ann[:, 3].astype(int) - 1  # 0-based\n",
    "                durs   = ann[:, 2].astype(int)\n",
    "                labs   = ann[:, 0].astype(int)\n",
    "\n",
    "                for onset, dur, lab in zip(onsets, durs, labs):\n",
    "                    \n",
    "                    # 1) evento più corto della finestra richiesta → scarta\n",
    "                    \n",
    "                    if dur < ep_len and drop_shorter:\n",
    "                        n_dropped_short += 1\n",
    "                        continue\n",
    "                    start = onset\n",
    "                    stop  = onset + ep_len\n",
    "                    \n",
    "                    # 2) finestra che esce dalla traccia → scarta\n",
    "                    \n",
    "                    if stop > n_times:\n",
    "                        n_dropped_edge += 1\n",
    "                        continue\n",
    "\n",
    "                    seg = Xv[start:stop, :]  # (ep_len, n_chan) in Volt\n",
    "                    if convert_to_uV:\n",
    "                        seg = seg * 1e6      # → µV\n",
    "                    seg = seg.T.astype(np.float32)  # (n_chan, ep_len)\n",
    "\n",
    "                    Tx = label_to_Tx(lab)\n",
    "                    bins[Tx][\"data\"].append(seg)\n",
    "                    bins[Tx][\"labels\"].append(int(lab))\n",
    "                    \n",
    "                # (facoltativo) log per run\n",
    "                #if (n_dropped_short + n_dropped_edge) > 0:\n",
    "                    #print(f\"[{task} | subj {subj} | run {run_idx}] dropped short={n_dropped_short}, edge={n_dropped_edge}\")\n",
    "\n",
    "            # stack per ogni Tx\n",
    "            task_data[task].setdefault(subj, {})\n",
    "            for Tx in (\"T0\", \"T1\", \"T2\"):\n",
    "                if bins[Tx][\"data\"]:\n",
    "                    data = np.stack(bins[Tx][\"data\"], axis=0)              # (n, ch, t)\n",
    "                    labels = np.asarray(bins[Tx][\"labels\"], dtype=int)     # (n,)\n",
    "                else:\n",
    "                    # nessun trial valido di quel tipo\n",
    "                    # per coerenza, usa dimensioni nulle con ep_len dell’ultimo run visto (o default 0)\n",
    "                    # Proviamo a inferire ep_len dal primo run visto\n",
    "                    \n",
    "                    '''\n",
    "                    Ottima domanda — non sto insinuando che “mancano i dati” del soggetto/run 🙂. \n",
    "                    \n",
    "                    Il mini-fix serve per robustezza in un caso molto specifico: \n",
    "                    quando per una certa condizione (T0/T1/T2) non rimane nessun trial valido dopo i filtri (p.es. drop_shorter=True,\n",
    "                    ultimi eventi troppo vicini alla fine, ecc.). \n",
    "                    \n",
    "                    In quel ramo “nessun trial valido” dobbiamo comunque creare un array vuoto con shape coerente (0, nchan, ep_len).\n",
    "\n",
    "                    Perché cambiare?\n",
    "\n",
    "                    Nel tuo codice “prima”, quel ramo usava la variabile raw (l’ultima vista nel loop). Questo è fragile perché:\n",
    "\n",
    "                    se per qualche motivo il loop non entra mai (soggetto senza run o run vuoti), raw non esiste → UnboundLocalError;\n",
    "\n",
    "                    anche se esiste, non è chiaro da dove provengano nchan ed ep_len (dipendono “per caso” dall’ultimo run iterato).\n",
    "\n",
    "                    Il fix propone di usare first_raw, che memorizziamo appena incontriamo il primo run del soggetto, \n",
    "                    e che rappresenta chiaramente “l’info di riferimento” (n. canali, fs) per costruire le shape anche quando una condizione non ha trial.\n",
    "                    \n",
    "                    Cosa cambia “sul campo”?\n",
    "\n",
    "                    Caso tipico (il tuo): tutte le condizioni hanno >0 trial → non cambia nulla nei risultati; questo ramo non viene nemmeno eseguito.\n",
    "                    Caso limite: una condizione resta con 0 trial (es. hai impostato epoch_len_s più lungo della durata degli eventi,\n",
    "                    oppure gli ultimi eventi non entrano per onset + ep_len > n_times).\n",
    "\n",
    "                    Prima: rischio di errore (o shape incoerenti).\n",
    "                    Dopo: ottieni in modo sicuro data.shape == (0, nchan, ep_len) e labels.shape == (0,), mantenendo la struttura uniforme e senza crash.\n",
    "\n",
    "                    In breve: il fix non cambia i risultati quando i trial ci sono, ma rende la funzione a prova di bomba nel raro caso di condizione vuota. \n",
    "                    Costa zero tenerlo e ti evita sorprese in futuro.\n",
    "\n",
    "                    '''\n",
    "                    \n",
    "                    #if \"raw\" in locals() and raw is not None:\n",
    "                        #fs = float(raw.info[\"sfreq\"])\n",
    "                        #ep_len = int(round(epoch_len_s * fs))\n",
    "                    #else:\n",
    "                        #ep_len = 0\n",
    "                    #data = np.empty((0, raw.info[\"nchan\"], ep_len), dtype=np.float32)\n",
    "                    #labels = np.empty((0,), dtype=int)\n",
    "                    \n",
    "                    if first_raw is not None:\n",
    "                        fs = float(first_raw.info[\"sfreq\"])\n",
    "                        ep_len = int(round(epoch_len_s * fs))\n",
    "                        nchan = first_raw.info[\"nchan\"]\n",
    "                    else:\n",
    "                        ep_len, nchan = 0, 0\n",
    "                    data = np.empty((0, nchan, ep_len), dtype=np.float32)\n",
    "                    labels = np.empty((0,), dtype=int)\n",
    "\n",
    "                task_data[task][subj][Tx] = {\"data\": data, \"labels\": labels}\n",
    "\n",
    "            # checkpoint per soggetto (salva *tutto* task_data corrente: semplice e robusto)\n",
    "            if checkpoint_every_subject and checkpoint_path is not None:\n",
    "                _save_checkpoint(task_data, checkpoint_path)\n",
    "\n",
    "    # salvataggio finale (se richiesto)\n",
    "    if checkpoint_path is not None and not checkpoint_every_subject:\n",
    "        _save_checkpoint(task_data, checkpoint_path)\n",
    "\n",
    "    return task_data\n",
    "\n",
    "# ---------- 2) rename_conditions: T0/T1/T2 → nomi espliciti ----------\n",
    "CONDITION_MAPPING = {\n",
    "    # Usa ESATTAMENTE la mappa che hai richiesto tu\n",
    "    \n",
    "    'task_1': {'T0': 'rest', 'T1': 'left_fist',  'T2': 'right_fist'},\n",
    "    'task_2': {'T0': 'rest', 'T1': 'left_fist',  'T2': 'right_fist'},\n",
    "    'task_3': {'T0': 'rest', 'T1': 'both_fists', 'T2': 'both_feet'},\n",
    "    'task_4': {'T0': 'rest', 'T1': 'both_fists', 'T2': 'both_feet'},\n",
    "}\n",
    "\n",
    "def rename_conditions(task_data, mapping=CONDITION_MAPPING):\n",
    "    renamed = {}\n",
    "    for task, subjects in task_data.items():\n",
    "        renamed[task] = {}\n",
    "        mp = mapping.get(task, {'T0':'T0','T1':'T1','T2':'T2'})\n",
    "        for subj, conds in subjects.items():\n",
    "            renamed[task][subj] = {}\n",
    "            for old_cond, dl in conds.items():\n",
    "                new_cond = mp.get(old_cond, old_cond)\n",
    "                renamed[task][subj][new_cond] = dl\n",
    "    return renamed\n",
    "\n",
    "# ---------- 3) reformat_for_task ----------\n",
    "def reformat_for_task(task_data):\n",
    "    \"\"\"\n",
    "    Input:  task_data[task][subj][condition] = {\"data\": ndarray, \"labels\": ndarray}\n",
    "    Output: out[task] = [ { \"cond_subj\": data, \"cond_subj_labels\": labels }, ... per subject ... ]\n",
    "    \"\"\"\n",
    "    reformatted = {}\n",
    "    for task, subjects in task_data.items():\n",
    "        lst = []\n",
    "        for subj, conds in subjects.items():\n",
    "            rec = {}\n",
    "            for cond, dl in conds.items():\n",
    "                rec[f\"{cond}_{subj}\"] = dl[\"data\"]\n",
    "                rec[f\"{cond}_{subj}_labels\"] = dl[\"labels\"]\n",
    "            lst.append(rec)\n",
    "        reformatted[task] = lst\n",
    "    return reformatted\n",
    "\n",
    "# ---------- 4) preprocess_EEG_labels: porta a 0/1/2 (per task) ----------\n",
    "def preprocess_EEG_labels(eeg_data_reformatted):\n",
    "    \"\"\"\n",
    "    Rimappa *_labels a {0,1,2} in base al nome della condizione nella chiave.\n",
    "    Segue la tua convenzione richiesta:\n",
    "      - task_1 & task_2: rest=0, left_fist=1, right_fist=2\n",
    "      - task_3 & task_4: rest=0, both_fists = 1, both_feet =2\n",
    "    \"\"\"\n",
    "    mapping_12 = {'rest': 0, 'left_fist': 1, 'right_fist': 2}\n",
    "    mapping_34 = {'rest': 0, 'both_fists': 1, 'both_feet': 2}\n",
    "\n",
    "    out = {}\n",
    "    for task, subjects in eeg_data_reformatted.items():\n",
    "        out_list = []\n",
    "        if task in ('task_1', 'task_2'):\n",
    "            mp = mapping_12\n",
    "        elif task in ('task_3', 'task_4'):\n",
    "            mp = mapping_34\n",
    "        else:\n",
    "            mp = {}\n",
    "\n",
    "        for subj_dict in subjects:\n",
    "            rec = {}\n",
    "            for key, val in subj_dict.items():\n",
    "                if key.endswith('_labels'):\n",
    "                    # es: \"left_fist_12_labels\" → condition = \"left_fist\"\n",
    "                    prefix = key[:-7]  # rimuove \"_labels\"\n",
    "                    cond = prefix.rsplit('_', 1)[0]  # rimuove _<subj>\n",
    "                    if cond in mp:\n",
    "                        rec[key] = np.full(len(val), mp[cond], dtype=int)\n",
    "                    else:\n",
    "                        # fallback: lascia intatti se non riconosciuti\n",
    "                        rec[key] = val.astype(int)\n",
    "                else:\n",
    "                    rec[key] = val\n",
    "            out_list.append(rec)\n",
    "        out[task] = out_list\n",
    "\n",
    "    return out\n",
    "\n",
    "# ---------- 5) wrapper \"tutto in uno\" ----------\n",
    "def build_and_format_all(\n",
    "    EEG_post_ICA,\n",
    "    epoch_len_s=4.0,\n",
    "    drop_shorter=True,\n",
    "    convert_to_uV=True,\n",
    "    checkpoint_path: Path = None,\n",
    "    checkpoint_every_subject: bool = False,\n",
    "):\n",
    "    task_data = build_task_data_from_postICA(\n",
    "        EEG_post_ICA=EEG_post_ICA,\n",
    "        epoch_len_s=epoch_len_s,\n",
    "        drop_shorter=drop_shorter,\n",
    "        convert_to_uV=convert_to_uV,\n",
    "        checkpoint_path=checkpoint_path,\n",
    "        checkpoint_every_subject=checkpoint_every_subject,\n",
    "    )\n",
    "    task_data_named = rename_conditions(task_data)\n",
    "    reformatted     = reformat_for_task(task_data_named)\n",
    "    reformatted_y   = preprocess_EEG_labels(reformatted)\n",
    "    return task_data, task_data_named, reformatted, reformatted_y"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f0e319be-72e0-4c30-92aa-e06307d7bc5d",
   "metadata": {
    "tags": []
   },
   "source": [
    "'''\n",
    "PROVA CON UN SOLO SOGGETTO, TASK E RUN\n",
    "ESEGUILO PER VEDERE COME SAREBBE L'OUTPUT\n",
    "'''\n",
    "\n",
    "'''\n",
    "Cosa vedrai\n",
    "\n",
    "In reformatted_y[\"task_1\"][0] troverai coppie di chiavi del tipo:\n",
    "\n",
    "rest_1 e rest_1_labels\n",
    "\n",
    "left_fist_1 e left_fist_1_labels\n",
    "\n",
    "right_fist_1 e right_fist_1_labels\n",
    "\n",
    "Le labels saranno già mappate a 0/1/2 in base al task (per task_1: rest→0, left_fist→1, right_fist→2).\n",
    "\n",
    "Le forme dei dati saranno (n_epoche, n_canali, n_samples) (con n_samples = 4 s × fs), e le labels avranno forma (n_epoche,).\n",
    "'''\n",
    "\n",
    "# === 1) Scegli cosa testare ===\n",
    "test_task    = \"task_1\"\n",
    "test_subject = \"1\"     # stringa, come in EEG_post_ICA\n",
    "test_runs    = [0]     # prova con la run 0\n",
    "\n",
    "# === 2) Crea un sotto-dizionario con SOLO quel caso ===\n",
    "def subset_post_ICA(src, task, subject, runs):\n",
    "    out = {task: {subject: {}}}\n",
    "    for r in runs:\n",
    "        out[task][subject][r] = src[task][subject][r]  # (raw, ann)\n",
    "    return out\n",
    "\n",
    "EEG_subset = subset_post_ICA(EEG_post_ICA, test_task, test_subject, test_runs)\n",
    "\n",
    "# === 3) Esegui la pipeline di epocatura + rinomina condizioni + rimappa labels ===\n",
    "from pathlib import Path\n",
    "# evita di sovrascrivere il checkpoint \"globale\" durante il test\n",
    "CHECKPOINT_TEST = None  # oppure Path(\"/tmp/task_data_postICA_TEST.pkl\")\n",
    "\n",
    "task_data, task_data_named, reformatted, reformatted_y = build_and_format_all(\n",
    "    EEG_subset,\n",
    "    epoch_len_s=4.0,\n",
    "    drop_shorter=True,\n",
    "    convert_to_uV=False,\n",
    "    checkpoint_path=CHECKPOINT_TEST,\n",
    "    checkpoint_every_subject=False,\n",
    ")\n",
    "\n",
    "print(\"\\n[OK] Build & format completati per il subset.\\n\")\n",
    "\n",
    "# === 4) Ispeziona SOLO reformatted_y per quel task/soggetto ===\n",
    "# reformatted_y[task] = [ { \"<cond>_<subj>\": X, \"<cond>_<subj>_labels\": y, ... }, ... ]\n",
    "rec_list = reformatted_y[test_task]\n",
    "assert len(rec_list) == 1, f\"Mi aspettavo 1 soggetto nel subset, trovato {len(rec_list)}\"\n",
    "rec = rec_list[0]\n",
    "\n",
    "print(f\"Struttura reformatted_y[{test_task}] per il soggetto {test_subject}:\")\n",
    "for k, v in rec.items():\n",
    "    # v è un np.ndarray; stampa forma e, se sono labels, le uniche\n",
    "    if k.endswith(\"_labels\"):\n",
    "        import numpy as np\n",
    "        uniq, cnt = np.unique(v, return_counts=True)\n",
    "        print(f\"  {k:>20}  shape={v.shape}  values={dict(zip(uniq.tolist(), cnt.tolist()))}\")\n",
    "    else:\n",
    "        print(f\"  {k:>20}  shape={v.shape}\")\n",
    "\n",
    "# (opzionale) mini sanity check: numero totale epoche attese ~ 29-30 (120s / 4s)\n",
    "n_epochs = sum(v.shape[0] for k,v in rec.items() if not k.endswith(\"_labels\"))\n",
    "print(f\"\\nTotale epoche (tutte le condizioni): {n_epochs}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bfd38a-a9f9-49f8-b9f6-4c0b8029a7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''ESECUZIONE REALE CON TUTTI I SOGGETTI\n",
    "\n",
    "\n",
    "Con quel codice ottieni esattamente ciò che descrivi.\n",
    "\n",
    "build_task_data_from_postICA:\n",
    "\n",
    "epoca i Raw post-ICA (4 s), \n",
    "gestisce l’indicizzazione 1→0, \n",
    "scarta \n",
    "\n",
    "(i) trial troppo corti e \n",
    "(ii) l’eventuale ultimo trial che “sborda” oltre la traccia,\n",
    "\n",
    "e accumula per soggetto tutti i trial delle 3 condizioni (T0/T1/T2) aggregando le run dello stesso task.\n",
    "\n",
    "rename_conditions: rinomina T0/T1/T2 in rest/… a seconda del task.\n",
    "reformat_for_task: produce per ogni task una lista (uno per soggetto) di dict con coppie cond_subj e cond_subj_labels.\n",
    "preprocess_EEG_labels: rimappa le label in 0/1/2 in base alla condizione (schema task 1–2 vs 3–4).\n",
    "\n",
    "Salvi infine reformatted_y in task_data_postICA.pkl: è il formato “pronto” per ML/valutazioni e, se vuoi usare autoreject, puoi ricostruire velocemente mne.\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "CHECKPOINT = Path(\"/home/stefano/EEGMMIDB_Analyses/task_data_postICA.pkl\")\n",
    "\n",
    "task_data, task_data_named, reformatted, reformatted_y = build_and_format_all(\n",
    "    EEG_post_ICA,\n",
    "    epoch_len_s=4.0,\n",
    "    drop_shorter=True,\n",
    "    convert_to_uV=False,                 # utile se poi ragioni in µV\n",
    "    checkpoint_path=CHECKPOINT,         # opzionale\n",
    "    checkpoint_every_subject=True,      # salva dopo ogni soggetto\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85e2c6d-4e32-499a-a77d-138a2160081d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Salvare l'intero dizionario annidato con pickle\n",
    "path = '/home/stefano/EEGMMIDB_Analyses/'\n",
    "\n",
    "# 1) salva i dati preppati (Raw o (Raw, labels))\n",
    "with open(f\"{path}task_data_postICA.pkl\", \"wb\") as f:\n",
    "    pickle.dump(reformatted_y, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18104f6-9a61-4df9-afdc-db47cc540127",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Con il flusso che hai eseguito, il file che salvi/carichi (task_data_postICA.pkl) corrisponde a reformatted_y, cioè:\n",
    "\n",
    "un dict per task → new_EEG_data['task_1'], new_EEG_data['task_2'], …\n",
    "\n",
    "in ciascun task hai una lista con un dict per soggetto\n",
    "\n",
    "dentro il dict del soggetto hai coppie di chiavi per condizione:\n",
    "\n",
    "\"<condizione>_<subjectID>\" → l’array dei dati (shape (n_epoche, n_chan, n_times))\n",
    "\n",
    "\"<condizione>_<subjectID>_labels\" → il vettore etichette (rimappato in 0/1/2)\n",
    "\n",
    "\n",
    "Nella struttura che hai ora (quella salvata come reformatted_y), \n",
    "tutti i trial di uno stesso soggetto per un dato task e una data condizione sono già impilati insieme, indipendentemente dalla run.\n",
    "Quindi, ad es., new_EEG_data['task_1'][i]['rest_1'] contiene tutti i trial “rest” del soggetto 1 nel task 1 (sommando le sue run di quel task).\n",
    "\n",
    "'''\n",
    "\n",
    "import pickle\n",
    "\n",
    "# Caricare l'intero dizionario annidato con pickle\n",
    "path = '/home/stefano/EEGMMIDB_Analyses/'\n",
    "\n",
    "# Caricare l'intero dizionario annidato con pickle\n",
    "with open(f'{path}task_data_postICA.pkl', 'rb') as f:\n",
    "    new_EEG_data = pickle.load(f)\n",
    "    \n",
    "path_ica = '/home/stefano/EEGMMIDB_Analyses/pyprep_outputs/'\n",
    "\n",
    "# Caricare l'intero dizionario annidato con pickle\n",
    "with open(f'{path_ica}EEG_for_ICA.pkl', 'rb') as f:\n",
    "    EEG_for_ICA = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71dba4cb-c306-45cf-a9d5-5bcfe556ffb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_EEG_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08b240c-6ebd-48f6-a215-d5ee08d352a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new_EEG_data['task_1'][0].keys())\n",
    "print(new_EEG_data['task_2'][0].keys())\n",
    "print(new_EEG_data['task_3'][0].keys())\n",
    "print(new_EEG_data['task_4'][0].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8db296-104d-40d3-8f76-d7912e03df0e",
   "metadata": {},
   "source": [
    "#### **AUTOREJECT: Function Application to the New Data Structure Reformatted Post ICA Phase**\n",
    "\n",
    "#### **All TASKS, Subjects & Runs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3addc5-ae68-4903-aa7a-181d88eb2f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Autoreject: #https://autoreject.github.io/stable/index.html\n",
    "\n",
    "Cite\n",
    "[1] Mainak Jas, Denis Engemann, Federico Raimondo, Yousra Bekhti, and Alexandre Gramfort, “Automated rejection and repair of bad trials in MEG/EEG.”\n",
    "In 6th International Workshop on Pattern Recognition in Neuroimaging (PRNI), 2016.\n",
    "\n",
    "[2] Mainak Jas, Denis Engemann, Yousra Bekhti, Federico Raimondo, and Alexandre Gramfort. 2017. “Autoreject: Automated artifact rejection for MEG and EEG data”.\n",
    "NeuroImage, 159, 417-429.\n",
    "'''\n",
    "\n",
    "'''\n",
    "Cosa misura\n",
    "\n",
    "Per ogni epoca e per ogni canale calcola l’ampiezza peak-to-peak (p2p). È una misura robusta dell’escursione del segnale nell’epoca.\n",
    "\n",
    "Soglie “locali” per canale\n",
    "\n",
    "Impara soglie p2p specifiche per canale (non una unica per tutti) in modo data-driven. Lo fa con cross-validation: prova soglie candidate\n",
    "e sceglie quelle che meglio separano epoche “plausibili” da “artefattuali”.\n",
    "\n",
    "Interpolate-o-scarto (ρ, κ)\n",
    "\n",
    "Due iperparametri chiave:\n",
    "\n",
    "n_interpolate (ρ): massimo numero di canali che posso interpolare dentro una singola epoca per “ripararla”.\n",
    "consensus (κ): tolleranza complessiva; se in una epoca i canali che sforano la soglia sono “troppi”, l’epoca viene scartata invece che riparata.\n",
    "\n",
    "AutoReject fa una griglia sui valori che gli passi (es. [1,2,4,8,16] × 0.7) e sceglie la combinazione migliore via CV.\n",
    "\n",
    "Cosa esce\n",
    "\n",
    "Epoche pulite: quelle non scartate; se avevano pochi canali “malati”, quei canali sono interpolati (sferica/3D in base al montage).\n",
    "Epoche scartate: troppe violazioni secondo la κ scelta.\n",
    "\n",
    "Un reject_log per sapere quali epoche sono state scartate e, per le epoche tenute, quali canali sono stati interpolati.\n",
    "Le soglie apprese per canale: ar.threshes_ (in Volt).\n",
    "\n",
    "Perché non è “= ±100 µV”\n",
    "\n",
    "AutoReject non usa una soglia fissa globale (tipo ±100 µV). Stima soglie per canale in base ai tuoi dati (più flessibile).\n",
    "Se vuoi imporre l’equivalente di ±100 µV, usa MNE reject={'eeg': 100e-6} su Epochs. Oppure puoi usare AutoReject ma controllare le soglie apprese (threshes_) \n",
    "e verificarne la coerenza.\n",
    "\n",
    "Parametri che ti interessano davvero\n",
    "\n",
    "n_interpolate: lista di interi. Con 64 canali, una griglia tipica è [1, 2, 4, 8, 16]. Aumentare il massimo → più aggressivo\n",
    "(più canali per epoca possono essere “riparati”).\n",
    "\n",
    "consensus: float in (0,1]. Valori più alti = più tolleranza all’interpolazione (meno scarti, più riparazioni), \n",
    "valori più bassi = più rigore negli scarti. 0.7 è un buon compromesso nella pratica.\n",
    "\n",
    "random_state, n_jobs: riproducibilità e parallelizzazione.\n",
    "\n",
    "verbose: log interno (noi lo teniamo False e stampiamo il nostro riassunto).\n",
    "\n",
    "\n",
    "\n",
    "Hai tenuto i dati in Volt (corretto) e converti le soglie in µV solo per il report: perfetto.\n",
    "Il wrapper costruisce EpochsArray, esegue AutoReject (local), rimpiazza i trial riparati/tenuti e rimuove quelli irrecuperabili, e logga soglie e conteggi. ✅\n",
    "\n",
    "\n",
    "La tua scelta attuale (AutoReject) è locale: stima soglie per canale, di solito migliore per EEG 64ch.\n",
    "\n",
    "Ricordati che consensus ∈ [0, 1]: valori più alti ⇒ più facile scartare l’epoca (meno permissivo); più bassi ⇒ più riparazioni (più permissivo). \n",
    "Il default 0.7 è un buon punto di partenza.\n",
    "\n",
    "'''\n",
    "import numpy as np\n",
    "import mne\n",
    "from copy import deepcopy\n",
    "from autoreject import AutoReject #https://autoreject.github.io/stable/index.html --> https://autoreject.github.io/stable/explanation.html\n",
    "\n",
    "\n",
    "#_find_info_template(...): prende l’info (sfreq, ch_names, tipo canali, montage) dal primo run disponibile di quel task+soggetto. \n",
    "#Serve a costruire Epochs coerenti con i tuoi dati.\n",
    "\n",
    "def _find_info_template(EEG_post_ICA, task, subj_id):\n",
    "    \"\"\"Prende l’info del primo run disponibile per (task, subject).\"\"\"\n",
    "    runs = EEG_post_ICA[task][subj_id]\n",
    "    first_run_idx = sorted(runs.keys())[0]\n",
    "    raw, _ = runs[first_run_idx]\n",
    "    return raw.info.copy()\n",
    "\n",
    "\n",
    "#Verifica che il numero di canali in X combaci con len(info[\"ch_names\"]). Se ok, crea mne.EpochsArray(X, info, tmin). \n",
    "#Nota unità: X è in Volt, che è proprio ciò che vuole AutoReject.\n",
    "\n",
    "def _build_epochs_from_array(X, info, tmin=0.0):\n",
    "    \"\"\"\n",
    "    X: (n_epochs, n_channels, n_times) in Volt\n",
    "    info: mne.Info coerente con X (ch_names, sfreq, ch_types='eeg')\n",
    "    \"\"\"\n",
    "    if X.shape[1] != len(info[\"ch_names\"]):\n",
    "        raise ValueError(f\"Mismatch n_channels: X has {X.shape[1]}, info has {len(info['ch_names'])}\")\n",
    "    return mne.EpochsArray(X, info=info, tmin=tmin, verbose=False)\n",
    "\n",
    "\n",
    "\n",
    "#Se vuoi leggere/stampare le soglie in µV o mV, convertili solo per il report, non per l’input.\n",
    "#Converte le soglie p-p stimate da AutoReject (salvate in Volt) in unità leggibili per report (µV/mV/V). Non tocca i dati, è solo per logging.\n",
    "def _convert_threshes_for_report(threshes_dict, unit=\"uV\"):\n",
    "    \"\"\"\n",
    "    Converte il dict {ch_name: threshold_in_volts} in uV/mV solo per reporting.\n",
    "    unit: \"V\", \"mV\", \"uV\"\n",
    "    \"\"\"\n",
    "    if threshes_dict is None:\n",
    "        return None\n",
    "    if unit == \"V\":\n",
    "        factor = 1.0\n",
    "    elif unit == \"mV\":\n",
    "        factor = 1e3\n",
    "    elif unit == \"uV\":\n",
    "        factor = 1e6\n",
    "    else:\n",
    "        raise ValueError(\"unit must be 'V', 'mV', or 'uV'\")\n",
    "    return {ch: float(thr * factor) for ch, thr in threshes_dict.items()}\n",
    "\n",
    "\n",
    "#apply_autoreject_to_reformatted(...):\n",
    "\n",
    "#copia profonda di new_EEG_data → lavoriamo su una copia e torniamo cleaned.\n",
    "#per ogni task e per ogni soggetto:\n",
    "#recupera subj_id dalla chiave (es. 'rest_1' → '1').\n",
    "#prende l’info (vedi sopra).\n",
    "#per ogni condizione (tutte le chiavi che non finiscono con _labels):\n",
    "#prende X (epoche) e y (etichette corrispondenti).\n",
    "#se vuoto, annota zero e passa oltre.\n",
    "#costruisce EpochsArray(X, info).\n",
    "#istanzia AutoReject(...) con la tua griglia ρ/κ, lo fitta e fa transform(..., return_log=True).\n",
    "#dal reject_log estrae:\n",
    "#bad_epochs → indici da scartare,\n",
    "#bad_channels[i] → canali interpolati nella i-esima epoca tenuta.\n",
    "#aggiorna la struttura copiata (cleaned) con:\n",
    "#dati riparati X_clean e\n",
    "#labels corrispondenti filtrate (y[good_idx]).\n",
    "#salva nel summary i conteggi: epoche in ingresso, tenute, scartate e quante riparate.\n",
    "#ritorna cleaned (stessa forma di new_EEG_data) e summary.\n",
    "\n",
    "'''\n",
    "\n",
    "1) Che cosa significa consensus=0.7?\n",
    "\n",
    "Nel modello “local” di autoreject ci sono due iper-parametri:\n",
    "\n",
    "ρ (rho) = n_interpolate: quanti canali al massimo posso interpolare in un’epoca per ripararla.\n",
    "κ (kappa) = consensus: frazione di sensori “cattivi” oltre la quale l’epoca viene scartata.\n",
    "\n",
    "La regola è (parafraso la doc ufficiale):\n",
    "\n",
    "“Le epoche con più di κ·N canali cattivi (N = #canali) vengono scartate. Per le altre epoche, si interpolano i ρ canali peggiori\n",
    "(se i cattivi sono meno di ρ, si interpolano tutti).” \n",
    "\n",
    "LEGGI QUI SOTTO\n",
    "autoreject.github.io --> https://autoreject.github.io/stable/auto_examples/plot_auto_repair.html\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Quindi, con consensus=0.7 e, ad esempio, 64 canali:\n",
    "\n",
    "scarteresti un’epoca solo se > 44 canali risultano cattivi (0.7·64 ≈ 45).\n",
    "È una soglia molto permissiva: praticamente non scarterai quasi nulla; la pulizia avverrà quasi tutta via interpolazione (limitata da ρ).\n",
    "\n",
    "Di solito si lascia scegliere κ via CV passando una griglia (es. np.linspace(0, 0.4, 5));\n",
    "mettere un singolo valore fisso (0.7) è raro e tendenzialmente troppo “buono”.\n",
    "\n",
    "\n",
    "\n",
    "2) Cosa definisco con n_interpolate=[1, 2, 4, 8, 16]?\n",
    "\n",
    "Questa lista è la griglia di valori candidati per ρ. \n",
    "Autoreject fa cross-validation interna e sceglie ρ* (quanti canali interpolare al massimo per epoca).\n",
    "\n",
    "Se in una certa epoca i canali cattivi sono ≤ ρ* → li interpola tutti.\n",
    "Se i canali cattivi sono > ρ* ma ≤ κ·N → interpola solo i ρ* peggiori e tiene l’epoca.\n",
    "Se i canali cattivi sono > κ·N → scarta l’epoca. \n",
    "\n",
    "autoreject.github.io\n",
    "\n",
    "Nota: perché avvenga davvero la selezione via CV sia per ρ sia per κ, devi passare array/list a entrambi i parametri.\n",
    "Se passi un float singolo a consensus, κ resta fisso e non viene ottimizzato.\n",
    "\n",
    "Consigli pratici per EEG 64 canali\n",
    "\n",
    "Passa griglie, non valori singoli, così lasci ottimizzare al metodo:\n",
    "\n",
    "n_interpolate = [1, 2, 4, 8, 16]\n",
    "consensus     = np.linspace(0.05, 0.4, 8)  # da “severo” a “moderato”\n",
    "\n",
    "\n",
    "κ = 0.7 è di solito troppo alto: finirai per non scartare quasi nulla.\n",
    "\n",
    "Se hai HD-EEG (>=128 canali), puoi estendere n_interpolate (es. includere 32).\n",
    "\n",
    "Controlla i log: se vedi troppe epoche “repaired” con molti canali, prova una griglia di κ un po’ più bassa o limita ρ.\n",
    "'''\n",
    "\n",
    "\n",
    "def apply_autoreject_to_reformatted(\n",
    "    \n",
    "    #Parametri chiave:\n",
    "    #new_EEG_data: la lista di dict per task che hai creato con reformat_for_task (chiavi tipo rest_1, rest_1_labels, ecc.).\n",
    "    #EEG_post_ICA: usato solo per recuperare un info coerente per ogni soggetto/task (non rilegge i dati, prende solo meta-info).\n",
    "    #n_interpolate_grid = griglia per ρ (quanti canali interpolare max per epoca). Se None, useremo [3,4,6,8,10].\n",
    "    #consensus_grid = griglia per κ (frazione di canali “cattivi” oltre cui scartare un’epoca). Se None, calcoliamo in funzione di N canali (vedi sotto).\n",
    "    #n_jobs=-1: sfrutta tutti i core durante la CV interna di AutoReject.\n",
    "    #verbose: stampa o no i riepiloghi per condizione.\n",
    "    \n",
    "    new_EEG_data,\n",
    "    EEG_post_ICA,\n",
    "    \n",
    "    # parametri di default: griglie ρ=3..10 e κ centrato su 12 canali (±2)\n",
    "    n_interpolate_grid=None,     # se None -> [3,4,6,8,10]\n",
    "    consensus_grid=None,         # se None -> np.linspace(10/N, 14/N, 5) calcolato per ogni (task, subj)\n",
    "    cv_max: int = 10,            # ← CV massimo (default AR è 10)\n",
    "    random_state=97,\n",
    "    n_jobs=-1,\n",
    "    verbose=True,\n",
    "):\n",
    "    \"\"\"\n",
    "    new_EEG_data: dict -> task -> list[dict_per_subject]\n",
    "    EEG_post_ICA: per ricavare info (N canali, sfreq, ch_names, ecc.)\n",
    "    Ritorna:\n",
    "      cleaned: stessa struttura con epoche riparate/scartate\n",
    "      summary: log per (task, subject, condition)\n",
    "    \"\"\"\n",
    "    \n",
    "    '''\n",
    "    Clona la struttura di input: modificare “cleaned” non tocca i tuoi dati originali.\n",
    "    summary conterrà, per ciascun task/soggetto/condizione, il conteggio epoche in-kept-drop-repaired e le soglie stimate.\n",
    "    '''\n",
    "    cleaned = deepcopy(new_EEG_data)\n",
    "    summary = {}\n",
    "    \n",
    "    \n",
    "    # ---- contatori globali (tutti i task / soggetti / condizioni) ----\n",
    "    total_in_all = 0            # epoche/trial in ingresso\n",
    "    total_kept_all = 0          # epoche/trial tenute (ripulite)\n",
    "    total_dropped_all = 0       # epoche/trial scartate\n",
    "    total_repaired_all = 0      # epoche/trial tenute ma interpolate (>=1 canale)\n",
    "    \n",
    "    '''\n",
    "    Ciclo per task (task_1 … task_4).\n",
    "    Inizializza la lista di log per quel task.\n",
    "    '''\n",
    "        \n",
    "    for task, subjects in new_EEG_data.items():\n",
    "        summary[task] = []\n",
    "            \n",
    "        '''\n",
    "        Ciclo per soggetto (ogni elemento della lista è il dict relativo a un soggetto).\n",
    "        Prende una chiave dati qualunque (non _labels) per ricavare l’ID soggetto (tutto dopo l’ultimo _).\n",
    "        '''\n",
    "        for si, subj_dict in enumerate(subjects):\n",
    "            # ricava subject id dalla prima chiave dati\n",
    "            any_data_key = next(k for k in subj_dict if not k.endswith('_labels'))\n",
    "            subj_id = any_data_key.rsplit('_', 1)[-1]\n",
    "            \n",
    "            '''\n",
    "            Recupera l’info del primo run di quel (task, soggetto).\n",
    "            N = # canali EEG (serve per trasformare “numero canali cattivi” → frazione per κ).\n",
    "            '''\n",
    "            info = _find_info_template(EEG_post_ICA, task, subj_id)\n",
    "            N = len(info[\"ch_names\"])\n",
    "\n",
    "            # --- griglie default se non specificate ---\n",
    "            \n",
    "            '''\n",
    "            ρ: se non hai passato nulla, usiamo una griglia ragionevole [3,4,6,8,10].\n",
    "            AutoReject farà CV interna e sceglierà il ρ* migliore per questo soggetto+condizione.\n",
    "            '''\n",
    "            rho_grid = n_interpolate_grid if n_interpolate_grid is not None else [3, 4, 6, 8, 10]\n",
    "            \n",
    "            '''\n",
    "            κ: se non hai passato nulla, costruiamo una griglia che corrisponde a ~10–14 canali cattivi → [10/N, 11/N, 12/N, 13/N, 14/N].\n",
    "            Questo centra la CV su “~12 canali” ma le lascia un margine di ±2.\n",
    "            Se vuoi κ fisso (es. 10 canali), passa consensus_grid=[10/N] e stop.\n",
    "            '''\n",
    "            # 12 canali come centro, ±2 di margine per la CV → [10..14]/N\n",
    "            if consensus_grid is None:\n",
    "                low_ch, high_ch, steps = 10, 14, 5\n",
    "                kappa_grid = np.linspace(low_ch / N, high_ch / N, steps)\n",
    "            else:\n",
    "                kappa_grid = consensus_grid  # già frazione\n",
    "                \n",
    "            '''\n",
    "            Prepara il contenitore di log per questo soggetto (poi aggiungeremo condizione per condizione).\n",
    "            '''\n",
    "            \n",
    "            subj_log = {\"subject\": subj_id, \"conditions\": {}}\n",
    "            \n",
    "            '''\n",
    "            Ciclo sulle condizioni di questo soggetto (tutte le chiavi senza _labels).\n",
    "            Recupera la chiave delle etichette corrispondenti.\n",
    "            '''\n",
    "            for key in [k for k in subj_dict if not k.endswith('_labels')]:\n",
    "                cond = key.rsplit('_', 1)[0]            # 'rest_1' -> 'rest'\n",
    "                labels_key = f\"{cond}_{subj_id}_labels\"\n",
    "                \n",
    "                '''\n",
    "                X sono le epoche (già in Volt).\n",
    "                y le etichette integer (0/1/2) che avevi preprocessato.\n",
    "                '''\n",
    "                X = subj_dict[key]                      # (n_epochs, n_chan, n_times) in Volt\n",
    "                y = subj_dict[labels_key]               # (n_epochs,)\n",
    "                \n",
    "                '''\n",
    "                Condizione senza epoche → logga zeri e passa oltre.\n",
    "                '''\n",
    "                if X is None or len(X) == 0:\n",
    "                    subj_log[\"conditions\"][cond] = {\n",
    "                        \"n_in\": 0, \"n_kept\": 0, \"n_dropped\": 0, \"n_repaired\": 0, \"drop_idx\": []\n",
    "                    }\n",
    "                    continue\n",
    "                    \n",
    "                '''\n",
    "                Crea un EpochsArray coerente (stessi canali, sfreq, montaggio dell’info che abbiamo pescato dal run reale).\n",
    "                '''\n",
    "                epochs = _build_epochs_from_array(X, info)\n",
    "                \n",
    "                '''\n",
    "                Instanzia AutoReject in modalità local con le griglie che hai scelto.\n",
    "                fit = CV interna per stimare:\n",
    "                soglie p-p per canale (threshes_),\n",
    "                migliore ρ* dalla griglia,\n",
    "                migliore κ* (se gli hai dato una griglia di frazioni).\n",
    "                transform applica le decisioni: scarta epoche troppo “cattive” (oltre κ*·N) e interpolazione dei canali problematici (fino a ρ*).\n",
    "                '''\n",
    "                \n",
    "                # --- CV sempre attiva e adattiva al #epoche disponibili ---\n",
    "                n_ep = len(epochs)\n",
    "                if n_ep < 2:\n",
    "                    raise ValueError(\n",
    "                        f\"AutoReject richiede almeno 2 epoche per la CV; trovate {n_ep} epoche in \"\n",
    "                        f\"{task} / soggetto {subj_id} / condizione {cond}.\"\n",
    "                    )\n",
    "                \n",
    "                cv_k = min(cv_max, n_ep)  # es. n_ep=8 → cv=8; n_ep>=10 → cv=10\n",
    "                \n",
    "                ar = AutoReject(\n",
    "                    n_interpolate=rho_grid,   # ρ: lista canali max da interpolare\n",
    "                    consensus=kappa_grid,     # κ: frazione di canali cattivi oltre cui scartare\n",
    "                    cv=cv_k,                  # ← usa CV adattiva (sempre attiva)\n",
    "                    \n",
    "                    random_state=random_state,\n",
    "                    n_jobs=n_jobs,\n",
    "                    verbose=False\n",
    "                )\n",
    "                ar.fit(epochs)\n",
    "                epochs_clean, reject_log = ar.transform(epochs, return_log=True)\n",
    "                \n",
    "                '''\n",
    "                Estrae gli indici epoche scartate / tenute.\n",
    "                '''\n",
    "                bad_epochs = reject_log.bad_epochs.astype(bool)\n",
    "                good_idx = np.where(~bad_epochs)[0]\n",
    "                drop_idx = np.where(bad_epochs)[0].tolist()\n",
    "                \n",
    "                '''\n",
    "                Conta quante epoche tenute sono state effettivamente riparate (≥1 canale interpolato).\n",
    "                '''\n",
    "                # epoche tenute ma riparate (>=1 canale interpolato)\n",
    "                repaired = 0\n",
    "                for i in good_idx:\n",
    "                    try:\n",
    "                        if len(reject_log.bad_channels[i]) > 0:\n",
    "                            repaired += 1\n",
    "                    except Exception:\n",
    "                        pass\n",
    "                \n",
    "                '''\n",
    "                Prende i dati puliti (solo epoche tenute) e filtra le etichette sugli stessi indici.\n",
    "                '''\n",
    "                X_clean = epochs_clean.get_data()\n",
    "                y_clean = y[good_idx].astype(int)\n",
    "                \n",
    "                '''\n",
    "                Scrive indietro nella struttura clonata cleaned i dati puliti e le labels corrispondenti.\n",
    "                (Non tocchiamo mai new_EEG_data.)\n",
    "                '''\n",
    "                \n",
    "                cleaned[task][si][key] = X_clean\n",
    "                cleaned[task][si][labels_key] = y_clean\n",
    "                \n",
    "                \n",
    "                # ---- aggiorna contatori globali ----\n",
    "                \n",
    "                total_in_all       += int(len(X))\n",
    "                total_kept_all     += int(len(X_clean))\n",
    "                total_dropped_all  += int(len(drop_idx))\n",
    "                total_repaired_all += int(repaired)\n",
    "                \n",
    "                '''\n",
    "                Recupera dal modello le soglie p-p per canale in Volt e le converte in µV solo per log/report.\n",
    "                '''\n",
    "                ppV = getattr(ar, \"threshes_\", None)            # soglie p-p in Volt\n",
    "                pp_report = _convert_threshes_for_report(ppV, unit=\"uV\")\n",
    "                \n",
    "                \n",
    "                '''\n",
    "                Compila il log per questa condizione:\n",
    "\n",
    "                epoche in ingresso / tenute / scartate,\n",
    "                quante riparate (interpolate),\n",
    "                indici scartati,\n",
    "                soglie p-p per canale (in µV) che AR ha appreso,\n",
    "                griglie usate e # canali (così puoi rileggere i parametri poi).\n",
    "                '''\n",
    "                \n",
    "                subj_log[\"conditions\"][cond] = {\n",
    "                    \"n_in\": int(len(X)),\n",
    "                    \"n_kept\": int(len(X_clean)),\n",
    "                    \"n_dropped\": int(len(drop_idx)),\n",
    "                    \"n_repaired\": int(repaired),\n",
    "                    \"drop_idx\": drop_idx,\n",
    "                    \"pp_thresh_unit\": \"uV\",\n",
    "                    \"pp_thresh\": pp_report,\n",
    "                    \"rho_grid_used\": list(rho_grid),\n",
    "                    \"kappa_grid_used\": [float(x) for x in np.atleast_1d(kappa_grid)],\n",
    "                    \"N_channels\": int(N)\n",
    "                }\n",
    "                \n",
    "                '''\n",
    "                Stampa un riassunto leggibile della condizione.\n",
    "                '''\n",
    "                if verbose:\n",
    "                    print(f\"[{task} | subj {subj_id} | {cond}] \"\n",
    "                          f\"in={len(X):>3d}  kept={len(X_clean):>3d}  \"\n",
    "                          f\"dropped={len(drop_idx):>3d}  repaired={repaired:>3d}\")\n",
    "            \n",
    "            '''\n",
    "            A fine soggetto → aggiunge il log del soggetto alla lista del task.\n",
    "            '''\n",
    "\n",
    "            summary[task].append(subj_log)\n",
    "    \n",
    "    # ---- riepilogo globale finale ----\n",
    "    total_final_all = total_kept_all  # dopo AR, i \"rimasti\" coincidono con i tenuti\n",
    "    if verbose:\n",
    "        pct_kept = 100.0 * total_kept_all / total_in_all if total_in_all else 0.0\n",
    "        pct_drop = 100.0 * total_dropped_all / total_in_all if total_in_all else 0.0\n",
    "        pct_rep_kept = 100.0 * total_repaired_all / total_kept_all if total_kept_all else 0.0\n",
    "        print(\"\\n====== Autoreject — riepilogo globale ======\")\n",
    "        print(f\"Epoche totali (iniziali):            {total_in_all}\")\n",
    "        print(f\"Epoche tenute (finali ripulite):     {total_kept_all}  ({pct_kept:.1f}%)\")\n",
    "        print(f\"Epoche scartate:                     {total_dropped_all}  ({pct_drop:.1f}%)\")\n",
    "        print(f\"Epoche rimaste (finali):             {total_final_all}\")\n",
    "        print(f\"Epoche riparate tra le tenute:       {total_repaired_all}  ({pct_rep_kept:.1f}% delle tenute)\")\n",
    "    \n",
    "    \n",
    "    # (opzionale) salva anche nel summary per uso programmatico\n",
    "    summary[\"_global\"] = {\n",
    "        \"total_in\": int(total_in_all),\n",
    "        \"total_kept\": int(total_kept_all),\n",
    "        \"total_dropped\": int(total_dropped_all),\n",
    "        \"total_final\": int(total_final_all),\n",
    "        \"total_repaired_among_kept\": int(total_repaired_all),\n",
    "    }\n",
    "    \n",
    "    '''\n",
    "    Ritorna:\n",
    "\n",
    "    cleaned: stessa forma di new_EEG_data, ma con i trial riparati/scartati;\n",
    "    summary: log completo per task/soggetto/condizione.\n",
    "    '''\n",
    "    return cleaned, summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76e3bac-232f-459a-9b4a-371bac35aec0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Per “mantenere i valori cercati via CV” basta passare liste (griglie) a n_interpolate_grid (ρ) e a consensus_grid (κ). \n",
    "Così la CV sceglie ρ ∈ {3,4,6,8,10} e κ ∈ {10/N,…,14/N} (N = #canali del soggetto).\n",
    "Al termine vedrai il riepilogo globale stampato (grazie alle aggiunte che hai fatto) e puoi anche leggerlo da summary[\"_global\"].\n",
    "\n",
    "\n",
    "N.B.\n",
    "\n",
    "Sì — l’adattività della CV lo rende più affidabile nel decidere cosa scartare/tenere rispetto a un 10-fold fisso.\n",
    "\n",
    "Perché:\n",
    "\n",
    "N-aware: con poche epoche per (task,soggetto,condizione), un 10-fold è instabile/impossibile; usare cv_k = min(cv_max, n_ep)\n",
    "evita fold “tirati” e soglie rumorose → meno falsi positivi/negativi.\n",
    "\n",
    "Stima delle soglie più stabile: la scelta di ρ (canali da interpolare) e κ (frazione di canali cattivi oltre cui scartare) \n",
    "via griglie + CV si adatta al “regime” del soggetto/condizione, invece di imporre un’unica severità per tutti.\n",
    "\n",
    "Coerenza tra soggetti: la griglia di κ in frazione (basata su N canali) rende paragonabili le decisioni anche se N differisce leggermente.\n",
    "\n",
    "Due note operative:\n",
    "\n",
    "AutoReject lavora a livello di epoca, non “elimina run” in blocco. Se vuoi prendere decisioni a livello run, \n",
    "basta tenere traccia della run originaria di ogni epoca (o lanciare AR separatamente per run) \n",
    "e poi definire un criterio tipo: “scarta la run se >30% epoche droppate o media canali interpolati >5”.\n",
    "\n",
    "Con pochissime epoche (es. 2–3) la CV è comunque rumorosa per natura: l’adattività evita l’errore, \n",
    "ma le soglie restano meno precise. In quei casi puoi restringere le griglie (ρ e κ più corte) per regolarizzare ulteriormente.\n",
    "\n",
    "In sintesi: la tua versione adattiva è un passo avanti in accuratezza e robustezza nella pulizia dei trial; \n",
    "se ti serve una decisione “a run”, aggiungiamo un piccolo punteggio qualità per run e una soglia di esclusione.\n",
    "\n",
    "\n",
    "'''\n",
    "#1) Lasciare che la funzione usi le griglie di default (già centrate su ciò che volevi)\n",
    "\n",
    "cleaned, summary = apply_autoreject_to_reformatted(\n",
    "    new_EEG_data=new_EEG_data,\n",
    "    EEG_post_ICA = EEG_for_ICA,\n",
    "    n_interpolate_grid=None,   # -> usa [3, 4, 6, 8, 10]\n",
    "    consensus_grid=None,       # -> usa np.linspace(10/N, 14/N, 5) per ogni soggetto (≈ 12±2 canali)\n",
    "    cv_max=10,                 # CV fino a 10, poi min con n_ep\n",
    "    n_jobs=-1,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb66e19-380c-4c9b-9fc3-93968f7a01cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('finito')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808b5359-cde2-42cc-92ef-9f06b7a595f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "====== Autoreject — riepilogo globale ======\n",
    "Epoche totali (iniziali):            29430\n",
    "Epoche tenute (finali ripulite):     26093  (88.7%)\n",
    "Epoche scartate:                     3337  (11.3%)\n",
    "Epoche rimaste (finali):             26093\n",
    "Epoche riparate tra le tenute:       0  (0.0% delle tenute)\n",
    "'''\n",
    "\n",
    "\n",
    "type(cleaned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3734ebec-7343-4a82-b9da-ecfc8bd84068",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#cleaned.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8431d5-5feb-41de-9be7-b2e625388b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cleaned['task_1'][0].keys())\n",
    "print(cleaned['task_2'][0].keys())\n",
    "print(cleaned['task_3'][0].keys())\n",
    "print(cleaned['task_4'][0].keys())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53526f3f-9f81-4bc4-a085-21351d102ded",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### **POST AUTOREJECT: Save Post Autoreject Data Structure in compressed format to have the originally desired Data Organization Format**\n",
    "\n",
    "#### **All TASKS, Subjects & Runs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a55d34-eef2-4ac8-a510-abe633841b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Salvare l'intero dizionario annidato con pickle\n",
    "path = '/home/stefano/EEGMMIDB_Analyses/'\n",
    "\n",
    "# 1) salva i dati preppati (Raw o (Raw, labels))\n",
    "with open(f\"{path}final_cleaned_EEG_data.pkl\", \"wb\") as f:\n",
    "    pickle.dump(cleaned, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20bba49-6fea-4c93-b9a9-2477e1a221eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('finito')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15101bc-a5e9-466a-87fd-7a78ebc1a376",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Cosa fa (in breve):\n",
    "\n",
    "salva .npz compresso con una voce per ogni foglia (array dati/labels),\n",
    "ricostruisce la struttura originale (dict → list → dict),\n",
    "confronta shape, dtype e valori di ogni array,\n",
    "solo se tutto coincide elimina il .pkl.\n",
    "Così non cambi versioni di NumPy, non duplichi file grossi, e hai parità garantita tra PKL e NPZ.\n",
    "\n",
    "'''\n",
    "\n",
    "import os, pickle, numpy as np\n",
    "\n",
    "PKL = \"/home/stefano/EEGMMIDB_Analyses/final_cleaned_EEG_data.pkl\"\n",
    "NPZ = \"/home/stefano/EEGMMIDB_Analyses/final_cleaned_EEG_data.npz\"\n",
    "\n",
    "# ---------- 1) Carica il PKL ----------\n",
    "with open(PKL, \"rb\") as f:\n",
    "    orig = pickle.load(f)  # new_EEG_data: dict -> task -> list[dict]\n",
    "\n",
    "# ---------- 2) Appiattisci e salva NPZ ----------\n",
    "def flatten(obj, prefix=\"\"):\n",
    "    \"\"\"\n",
    "    Appiattisce dict/list annidati in un mapping {path: np.ndarray}.\n",
    "    Liste indicizzate con segmenti numerici (es. task_1/0/rest_1).\n",
    "    \"\"\"\n",
    "    out = {}\n",
    "    def _rec(x, path):\n",
    "        if isinstance(x, dict):\n",
    "            for k, v in x.items():\n",
    "                _rec(v, f\"{path}/{k}\" if path else k)\n",
    "        elif isinstance(x, list):\n",
    "            for i, v in enumerate(x):\n",
    "                _rec(v, f\"{path}/{i}\" if path else str(i))\n",
    "        else:\n",
    "            # forza a ndarray (labels/dati sono già array)\n",
    "            v = np.asarray(x) if not isinstance(x, np.ndarray) else x\n",
    "            if not isinstance(v, np.ndarray):\n",
    "                raise TypeError(f\"Foglia non convertibile in ndarray: {path} ({type(x)})\")\n",
    "            out[path] = v\n",
    "    _rec(obj, prefix)\n",
    "    return out\n",
    "\n",
    "flat = flatten(orig)\n",
    "np.savez_compressed(NPZ, **flat)\n",
    "\n",
    "# ---------- 3) Ricostruisci dal NPZ ----------\n",
    "def unflatten_npz_simple(npz_obj):\n",
    "    \"\"\"\n",
    "    Ricostruisce dict -> task -> list[dict] da chiavi tipo: task_1/0/rest_1, task_1/0/rest_1_labels, ...\n",
    "    (esattamente 3 segmenti: task / idx / leaf)\n",
    "    \"\"\"\n",
    "    root = {}\n",
    "    for full_key in npz_obj.files:\n",
    "        segs = full_key.split('/', 2)\n",
    "        if len(segs) != 3:\n",
    "            raise ValueError(f\"Chiave NPZ inattesa (attesi 3 segmenti): {full_key}\")\n",
    "        task, idx_str, leaf = segs\n",
    "        idx = int(idx_str)\n",
    "        root.setdefault(task, [])\n",
    "        while len(root[task]) <= idx:\n",
    "            root[task].append({})\n",
    "        root[task][idx][leaf] = npz_obj[full_key]\n",
    "    return root\n",
    "\n",
    "npz = np.load(NPZ, allow_pickle=False)\n",
    "recon = unflatten_npz_simple(npz)\n",
    "\n",
    "# ---------- 4) Verifica profonda di uguaglianza ----------\n",
    "ok = True\n",
    "\n",
    "# a) ogni task/subject/chiave di orig deve combaciare in recon (shape, dtype, valori)\n",
    "for task in orig:\n",
    "    if task not in recon:\n",
    "        print(\"❌ Manca task in NPZ:\", task); ok = False; continue\n",
    "    if len(orig[task]) != len(recon[task]):\n",
    "        print(f\"❌ Num soggetti diverso per {task}: {len(orig[task])} vs {len(recon[task])}\"); ok = False\n",
    "    for i, rec in enumerate(orig[task]):\n",
    "        if i >= len(recon[task]):\n",
    "            print(f\"❌ Manca soggetto index {i} in {task}\"); ok = False; continue\n",
    "        for k, arr in rec.items():\n",
    "            if k not in recon[task][i]:\n",
    "                print(f\"❌ Manca chiave {task}/{i}/{k} nel NPZ\"); ok = False; continue\n",
    "            arr2 = recon[task][i][k]\n",
    "            if arr.shape != arr2.shape or arr.dtype != arr2.dtype or not np.array_equal(arr, arr2):\n",
    "                print(f\"❌ Mismatch {task}/{i}/{k}: \"\n",
    "                      f\"{arr.shape, arr.dtype} vs {arr2.shape, arr2.dtype}\")\n",
    "                ok = False\n",
    "\n",
    "# b) opzionale: controlla che non ci siano chiavi “extra” nel NPZ\n",
    "for task in recon:\n",
    "    if task not in orig:\n",
    "        print(\"❌ Task extra nel NPZ:\", task); ok = False; continue\n",
    "    if len(recon[task]) != len(orig[task]):\n",
    "        print(f\"❌ Num soggetti diverso per {task} (NPZ→orig): {len(recon[task])} vs {len(orig[task])}\"); ok = False\n",
    "    for i, rec in enumerate(recon[task]):\n",
    "        if i >= len(orig[task]):\n",
    "            print(f\"❌ Soggetto extra index {i} in {task}\"); ok = False; continue\n",
    "        for k in rec.keys():\n",
    "            if k not in orig[task][i]:\n",
    "                print(f\"❌ Chiave extra nel NPZ: {task}/{i}/{k}\"); ok = False\n",
    "\n",
    "print(\"✅ NPZ identico al PKL\" if ok else \"❌ Differenze trovate\")\n",
    "\n",
    "# ---------- 5) Elimina il PKL solo se tutto combacia ----------\n",
    "if ok:\n",
    "    try:\n",
    "        os.remove(PKL)\n",
    "        print(f\"🗑️  Rimosso PKL: {PKL}\\n💾 Mantieni NPZ: {NPZ}\")\n",
    "    except OSError as e:\n",
    "        print(\"⚠️  Non sono riuscito a rimuovere il PKL:\", e)\n",
    "else:\n",
    "    print(\"⛔ Non elimino il PKL: NPZ non perfettamente identico.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f5dd3e-4e7f-4664-8ea4-cb8826dd1196",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Use new_pd_env environment to open npz formatted dataset!\n",
    "\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "NPZ = \"/home/stefano/EEGMMIDB_Analyses/final_cleaned_EEG_data.npz\"\n",
    "npz = np.load(NPZ, allow_pickle=False)\n",
    "\n",
    "def unflatten_npz_simple(npz_obj):\n",
    "    root = {}\n",
    "    for full_key in npz_obj.files:\n",
    "        task, idx_str, leaf = full_key.split('/', 2)\n",
    "        idx = int(idx_str)\n",
    "        root.setdefault(task, [])\n",
    "        while len(root[task]) <= idx:\n",
    "            root[task].append({})\n",
    "        root[task][idx][leaf] = npz_obj[full_key]\n",
    "    return root\n",
    "\n",
    "new_EEG_data = unflatten_npz_simple(npz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0edfb9-82c4-4fff-bf0b-5d4b9a906138",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_EEG_data.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421ddfb2-f2b4-4346-8132-b259c687d2f2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## EEGMMIDB Dataset: Post EEG Preprocessing Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb6e576-72ca-447a-a256-ba6358bf10bb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Modifica della Funzione per la **Rappresentazione Tempo-Frequenza dei miei dati EEG (STFT)** a seconda del Dataset del Task scelto\n",
    "\n",
    "- Task 1: Motor Execution (Open and close right or left fist) - Unilateral - Runs 3, 7, 11 \n",
    "- Task 2: Motor Imagery (Imagine opening and closing right and left fists) - Unilateral - Runs 4, 8, 12 \n",
    "- Task 3: Motor Execution (Open and close both fists and feet) - Bilateral - Runs 5, 9, 13 \n",
    "- Task 4: Motor Imagery (Imagine opening and closing both fists and feet) - Bilateral - Runs 6, 10, 14 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549f5357-070b-423d-97b2-6984b08c5212",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### IO (Modifica della Funzione per la Rappresentazione Tempo-Frequenza dei miei dati EEG (STFT) a seconda del Dataset del Task scelto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149ab8b4-285f-4663-9130-25bc713a00dd",
   "metadata": {
    "tags": []
   },
   "source": [
    "Vorrei semplicemente ri-adattare questo codice, in modo che aggiunta una clause condizione (if statament),  all'inizio del codice che mi consenta di filtrare in base al dizionario del relativo task (da scegliere fornendo quindi un nuovo argomento ad un nuovo parametro da aggiungere nella funzione, che chiameremo 'data_task')..\n",
    "\n",
    "e che ri-esegua però poi, una volta scelto la chiave di primo livello del dizionario corrispondente, associato ai dati del task specifico (i.e., 'task_1', 'task_2', 'task_3', 'task_4'), \n",
    "\n",
    "questa trasformazione dei dati in formato tempo-frequenza dei miei dati EEG, eseguendo quindi una short time fourier transform su finestre consecutivo del mio dato di 4s dei dati di esecuzione del movimento e che quindi mi consenta di ottenere una rappresentazione dello spettrogramma per ogni condizione sperimentale, aggregando così l'informazione spettrale ottenuta da queste finestra consecutive\n",
    "\n",
    "\n",
    "        '''CREAZIONE SPETTROGRAMMI FREQUENZE x TEMPO'''\n",
    "\n",
    "        import numpy as np\n",
    "        import pywt\n",
    "        from scipy.signal import stft\n",
    "\n",
    "        def create_spectograms_from_stft(data, window_size = 50, step_size = 25, fs = 250):\n",
    "\n",
    "            # Dizionario per memorizzare i risultati separati per condizione sperimentale\n",
    "            condition_results = {}\n",
    "\n",
    "            for idx, data_dict in enumerate(data):\n",
    "                print(f\"\\n\\n\\t\\t\\t\\t\\t\\033[1mProcessing Subject {idx + 1}\\033[0m:\\n\")\n",
    "\n",
    "                for condition, value in data_dict.items():\n",
    "                    if '_labels' in condition:\n",
    "                        base_condition = condition.replace('_labels', '')  # Rimuove '_labels'\n",
    "                        condition_key = base_condition\n",
    "                        labels_key = condition\n",
    "                    else:\n",
    "                        base_condition = condition\n",
    "                        condition_key = base_condition\n",
    "                        labels_key = f'{base_condition}_labels'\n",
    "\n",
    "                    # Aggiungi chiavi inizializzate per nuove condizioni\n",
    "                    if '_labels' not in condition and condition_key not in condition_results:\n",
    "                        condition_results[condition_key] = {'spectrograms': [], 'labels': []}\n",
    "\n",
    "                    # Applicazione wavelet solo per array np.ndarray\n",
    "                    if isinstance(value, np.ndarray):\n",
    "                        print(f\"\\nApplicazione STFT per '\\033[1m{condition_key}\\033[0m'\\n\")\n",
    "                        print(f\"\\033[1mShape\\033[0m dei dati per \\033[1m{condition_key}\\033[0m: {value.shape}\")\n",
    "\n",
    "\n",
    "                        # Esegui STFT per ogni canale e trial          \n",
    "\n",
    "                        #La funzione stft di SciPy restituisce uno spettrogramma con la forma (n_frequencies, n_time_steps),\n",
    "                        #quindi:38 corrisponde al numero di bin di frequenza calcolati a partire dalla finestra FFT di 75 punti.\n",
    "\n",
    "                        #Infatti, per una finestra di lunghezza 75, il numero di bin è calcolato (in questo caso, dato che 75 è dispari) come (75 + 1) // 2, ovvero 38.\n",
    "                        #Il numero di passi temporali (n_time_steps) viene invece calcolato in base alla lunghezza del segnale e ai parametri di finestra e overlap.\n",
    "\n",
    "                        #Nel tuo caso, estraendo 250 punti (da 50 a 300) con nperseg=75 e noverlap=25 (cioè con un salto di 50 campioni per finestra), \n",
    "                        #il numero di segmenti dovrebbe essere:\n",
    "                        #1 + [250−75/75-25] = 1 + [175/50]  = 1 + 3 = 4\n",
    "\n",
    "                        #Pertanto, il risultato di stft (cioè Zxx) ha forma (38, 4) e non (4, 38). \n",
    "                        #Se ti aspetti una struttura con l'asse del tempo come terza dimensione (ad esempio, (trial, canali, tempo, frequenze))\n",
    "                        #potresti dover trasporre l'array in modo da scambiare le dimensioni frequenza e tempo.\n",
    "\n",
    "                        '''\n",
    "                        1) crearmi una lista per salvarmi poi tutti gli spettrogrammi di tutti i trials\n",
    "                        2) per il trials corrente mi salvo lo spettrogramma e lo appendo poi ad 1)\n",
    "                        3) converto la lista di tutti gli spettrogrammi di tutti i trials della condizione corrente in array numpy \n",
    "                        4) carico poi l'array numpy dentro il dizionario della condizione corrente dentro la chiave 'spectrograms'\n",
    "                        '''\n",
    "\n",
    "                        all_trial_spectrograms = []\n",
    "\n",
    "                        for trial in range(value.shape[0]):\n",
    "                            single_trial_spectrograms = []  # Lista per memorizzare gli spettrogrammi per il trial corrente\n",
    "\n",
    "                            for channel in range(value.shape[1]):\n",
    "\n",
    "                                single_channel_data = value[trial, channel, 50:300]  # Estrai i dati del singolo canale\n",
    "\n",
    "                                #print(f\"Segment length: {len(single_channel_data)}\")\n",
    "\n",
    "                                '''\n",
    "                                TIENI A MENTE CHE DUE PARAMETRI GESTISCONO IL PADDING QUI AUTOMATICAMENTE, CHE SONO:\n",
    "\n",
    "                                boundary='zeros', \n",
    "                                padded=True,\n",
    "\n",
    "                                PER QUESTO MOTIVO LE FINESTRE SARANNO 11 E NON 9.\n",
    "\n",
    "                                IN QUESTO MODO, SI MIGLIORA LA RISOLUZIONE IN FREQUENZA ALL'INIZIO E FINE DEL SEGNALE (DI 250 PUNTI!)\n",
    "                                ANDANDO IN QUESTO MODO A RIDURRE GLI EFFETTI DI BORDO\n",
    "                                '''\n",
    "\n",
    "                                f, t, Zxx = stft(single_channel_data, fs=fs, window='hann', nperseg = 50, noverlap = 25)\n",
    "\n",
    "                                single_trial_spectrograms.append(Zxx)  # Aggiungi lo spettrogramma calcolato per il canale corrente\n",
    "\n",
    "                            all_trial_spectrograms.append(np.array(single_trial_spectrograms))  # Forma: (numero_canali, frequenze, tempo)\n",
    "\n",
    "                        condition_results[condition_key]['spectrograms'].extend(all_trial_spectrograms)\n",
    "\n",
    "                        # Gestione etichette\n",
    "                        if labels_key in data_dict:\n",
    "                            num_labels = data_dict[labels_key]\n",
    "                            if condition_key in condition_results:\n",
    "                                print(f\"\\nFound labels for condition \\033[1m{labels_key}\\033[0m, length: \\033[1m{len(num_labels)}\\033[0m\\n\")\n",
    "                                condition_results[condition_key]['labels'].extend(num_labels)\n",
    "                    else:\n",
    "                        print(f\"\\033[1m{labels_key}\\033[0m' non è un np.array, non applicare la STFT \")\n",
    "\n",
    "            # Preparazione risultati concatenati\n",
    "            all_subjects_condition_results = {}\n",
    "\n",
    "            for condition_key, results in condition_results.items():\n",
    "                if \"_labels\" in condition_key or len(results['spectrograms']) == 0:  # Verifica che ci siano spettrogrammi\n",
    "                    print(f\"\\nSkipping \\033[1m{labels_key}\\033[0m as it is a label or has no valid data.\")\n",
    "                    continue\n",
    "\n",
    "                wave_condition_name = f'spectrograms_{condition_key}'\n",
    "                print(f\"\\n\\nResults for \\t\\t\\t\\t\\t\\033[1m{wave_condition_name}\\033[0m:\\n\\n\")\n",
    "\n",
    "                # Converti in un array NumPy 3D finale\n",
    "                spectrograms_4d = np.array(results['spectrograms'])  # Forma: (numero_di_trial, numero_canali, frequenze, tempo)\n",
    "                all_subjects_condition_results[wave_condition_name] = {\n",
    "                    'spectrograms_4d': spectrograms_4d,\n",
    "                    'labels': results['labels']\n",
    "                }\n",
    "\n",
    "                print(f\"spectrograms_4d shape: {spectrograms_4d.shape}\")\n",
    "\n",
    "            '''\n",
    "            Quindi alla fine si avrà una shape del tipo (44, 61, 38, 7) dove indica che avrai\n",
    "            uno spettrogramma per ciascun trial, per ciascun canale, \n",
    "            che contiene informazioni sulle bande di frequenza e sui punti temporali. \n",
    "\n",
    "            Questa struttura è perfetta per essere utilizzata come input per una rete neurale convoluzionale (CNN),\n",
    "            poiché la rete può apprendere dalle relazioni spaziali e temporali nei dati.\n",
    "            '''\n",
    "\n",
    "            return all_subjects_condition_results\n",
    "\n",
    "\n",
    "tieni presente che ora, \n",
    "\n",
    "la mia nuova struttura di ingresso è quello che ho appena cambiato, che è molto simile a quella per cui questa funzione era stata adattata...\n",
    "\n",
    "\n",
    "e che è new_EEG_data, che a differenza di quella che vedi nell'immagine (therapist_data) -che era una lista di dizionari... dove per ogni soggetto avevi una serie di chiavi che si riferivano ai dati e labels di una certa condizione sperimentale..-\n",
    "\n",
    "new_EEG_data invece è un dizionario, che ha prima una prima chiave che distingue i dati del relativo task, e poi al suo interno ha la stessa struttura di \"therapist_data\" (vedi immagine), ossia lista di dizionari, che si riferiscono ai dati e labels di ogni condizione sperimentale per ogni soggetto..\n",
    "\n",
    " \n",
    " ora semplicemente new_EEG_data ha un livello in più.. l'idea è che la funzione debba iterare su quel livello e vedere se la chiave sia presente tra quelle che ci si aspetta (ad esempio creando una lista di stringhe che hanno la stesse stringhe di una delle chiavi del primo livello di new_EEG_data, ossia tra   'task_1', 'task_2', 'task_3', 'task_4'..\n",
    "\n",
    "in questo modo, si fa in modo che se esiste una di queste chiavi dentro new_EEG_data, allora poi si itererà per le chiavi del dizionario dei dati di ogni soggetto e si fa la stessa identica procedura che si eseguiva prima.. ottimizzando le modifiche al minimo del codice che ho già creato  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50912048-dfad-45a2-96ca-0f5ab3533c8c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### IO: Domanda su Window Size e Step Size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10e044c-a44f-4657-a833-8e1e875a5fb7",
   "metadata": {},
   "source": [
    "ok ora è una domanda di ragionamento: dato che ho tagliato a 4 secondi il mio dato EEG per tutti i dati di ogni condizione sperimentale e avendo ora i dati quindi di 640 campioni, ma con frequenza di campionamento a 160 Hz...\n",
    "\n",
    "che cosa mi consigli di mettere come window_size e step_size qui?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625a905a-ebda-416d-ab29-695544a259ba",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### CHATGPT: Risposta su Window Size e Step Size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd0aafc-c025-45e1-9ddb-57ca4fb57a3a",
   "metadata": {},
   "source": [
    "Con 640 sample a 160 Hz (→ 4 s di dati) hai una finestra totale piuttosto corta, per cui dovrai bilanciare risoluzione in frequenza vs risoluzione in tempo:\n",
    "    \n",
    "| Scelta  | window_size (campioni) | durata finestra (s) | freq. risoluzione Δf≈1/T (Hz) | step_size (campioni) | overlap (%) |\n",
    "|---------|------------------------|---------------------|-------------------------------|----------------------|-------------|\n",
    "| 1 s     | 160                    | 1,0                 | 1 Hz                          | 80                   | 50 %        |\n",
    "| 0,5 s   | 80                     | 0,5                 | 2 Hz                          | 40                   | 50 %        |\n",
    "| 0,25 s  | 40                     | 0,25                | 4 Hz                          | 20                   | 50 %        |\n",
    "| 2 s     | 320                    | 2,0                 | 0,5 Hz                        | 160                  | 50 %        |\n",
    "\n",
    "\n",
    "Raccomandazioni\n",
    "\n",
    "Se ti interessa studiare bande strette (α, β, γ…), meglio window_size ≥ 1 s (160 campioni), che ti dà Δf ≃ 1 Hz.\n",
    "Se invece vuoi seguire variazioni rapide nel tempo (ad es. transienti > 250 ms), puoi scalare fino a 0.5 s (80 campioni), Δf ≃ 2 Hz.\n",
    "L’overlap al 50 % (step_size = window_size/2) è uno standard che conserva buon compromesso.\n",
    "\n",
    "\n",
    "\n",
    "Esempio concreto\n",
    "\n",
    "\n",
    "**#finestra = 1 secondo, overlap = 50%**\n",
    "window_size = 160\n",
    "step_size   = 80\n",
    "fs          = 160\n",
    "\n",
    "oppure, se ti va di spingerti su tempi più corti:\n",
    "\n",
    "**#finestra = 0.5 secondi, overlap = 50%**\n",
    "window_size =  80\n",
    "step_size   =  40\n",
    "fs          = 160\n",
    "Scegli in base a:\n",
    "\n",
    "1) Δf minima di interesse (ad es. se vuoi separare 8 Hz da 12 Hz serve almeno Δf ≤ 4 Hz, quindi finestra ≥ 0.25 s).\n",
    "2) Temporal resolution desiderata (finestre più corte catturano transitori migliori).\n",
    "\n",
    "In generale per EEG MI io partirei con 1 s (160 campioni) e 50 % overlap, poi sperimenterei con 0.5 s se ti servono finestre più ravvicinate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b6a2bf-045a-4ae4-8c2d-6ee2bcd5e023",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### IMPLEMENTAZIONE -Modifica della Funzione per la Rappresentazione Tempo-Frequenza dei miei dati EEG (STFT) a seconda del Dataset del Task scelto\n",
    "\n",
    "#### **Calcolo Spettrogrammi** All **SINGLE** Subject Data (**TH**) per **Tutte le Condizioni sperimentali**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6829c901-00a9-42c3-b326-7f4e17766c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Library Importing \n",
    "    \n",
    "import os\n",
    "import math\n",
    "import copy as cp \n",
    "\n",
    "import tqdm\n",
    "\n",
    "#import mne \n",
    "import scipy\n",
    "\n",
    "import numpy as np  # NumPy per operazioni numeriche\n",
    "import matplotlib.pyplot as plt  # Matplotlib per la isualizzazione dei dati\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6960621e-b136-4788-98a7-7a68609a28df",
   "metadata": {},
   "source": [
    "import pickle\n",
    "\n",
    "# Caricare l'intero dizionario annidato con pickle\n",
    "path = '/home/stefano/EEGMMIDB_Analyses/'\n",
    "\n",
    "# Caricare l'intero dizionario annidato con pickle\n",
    "#with open(f'{path}new_EEG_data.pkl', 'rb') as f:\n",
    "    #new_EEG_data = pickle.load(f)\n",
    "\n",
    "with open(f'{path}final_cleaned_EEG_data.pkl', 'rb') as f:\n",
    "    new_EEG_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c690f035-d7e3-4893-b343-7d0ad8390842",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Con questo workflow puoi poi caricare in ambiente new_pd_env con:\n",
    "\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "NPZ = \"/home/stefano/EEGMMIDB_Analyses/final_cleaned_EEG_data.npz\"\n",
    "npz = np.load(NPZ, allow_pickle=False)\n",
    "\n",
    "def unflatten_npz_simple(npz_obj):\n",
    "    root = {}\n",
    "    for full_key in npz_obj.files:\n",
    "        task, idx_str, leaf = full_key.split('/', 2)\n",
    "        idx = int(idx_str)\n",
    "        root.setdefault(task, [])\n",
    "        while len(root[task]) <= idx:\n",
    "            root[task].append({})\n",
    "        root[task][idx][leaf] = npz_obj[full_key]\n",
    "    return root\n",
    "\n",
    "new_EEG_data = unflatten_npz_simple(npz)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913e27b9-8e6a-4346-a867-c7d90b087f05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Una volta che hai new_EEG_data = unflatten_npz_simple(npz), puoi contare i trial totali (e fare un riepilogo per task / soggetto / condizione) così:\n",
    "'''\n",
    "\n",
    "def count_trials(new_EEG_data, verbose=True):\n",
    "    \"\"\"\n",
    "    new_EEG_data: dict -> task -> list[dict_per_subject]\n",
    "    Ogni dict_per_subject ha chiavi tipo:\n",
    "      - \"<cond>_<subj>\"           -> array (n_epochs, n_chan, n_times)\n",
    "      - \"<cond>_<subj>_labels\"    -> array (n_epochs,)\n",
    "    Ritorna:\n",
    "      totals:      {\"global\": int, \"tasks\": {task: int}}\n",
    "      per_subj:    {task: {subj_id: int}}\n",
    "      per_cond:    {task: {cond_name: int}}  # cond_name senza _<subj>\n",
    "      problems:    lista di mismatch (dati vs labels mancanti o con len diversa)\n",
    "    \"\"\"\n",
    "    totals = {\"global\": 0, \"tasks\": {}}\n",
    "    per_subj = {}\n",
    "    per_cond = {}\n",
    "    problems = []\n",
    "\n",
    "    for task, subj_list in new_EEG_data.items():\n",
    "        t_total = 0\n",
    "        per_subj[task] = {}\n",
    "        per_cond[task] = {}\n",
    "\n",
    "        for subj_dict in subj_list:\n",
    "            # ricava subject id da una qualsiasi chiave dati (non _labels)\n",
    "            try:\n",
    "                any_key = next(k for k in subj_dict if not k.endswith('_labels'))\n",
    "                subj_id = any_key.rsplit('_', 1)[-1]\n",
    "            except StopIteration:\n",
    "                # soggetto “vuoto”\n",
    "                continue\n",
    "\n",
    "            s_total = 0\n",
    "\n",
    "            # 1) conteggio “ufficiale” dai *_labels\n",
    "            for key, arr in subj_dict.items():\n",
    "                if key.endswith('_labels'):\n",
    "                    # es: \"rest_12_labels\" -> cond_base=\"rest_12\", cond_name=\"rest\"\n",
    "                    cond_base = key[:-7]\n",
    "                    cond_name = cond_base.rsplit('_', 1)[0]\n",
    "                    n = int(arr.shape[0])\n",
    "                    s_total += n\n",
    "                    t_total += n\n",
    "                    totals[\"global\"] += n\n",
    "                    per_cond[task][cond_name] = per_cond[task].get(cond_name, 0) + n\n",
    "\n",
    "            # 2) check coerenza dati vs labels\n",
    "            for key, X in subj_dict.items():\n",
    "                if key.endswith('_labels'):\n",
    "                    continue\n",
    "                labels_key = f\"{key}_labels\"\n",
    "                if labels_key not in subj_dict:\n",
    "                    problems.append(f\"[{task} | subj {subj_id}] manca {labels_key}\")\n",
    "                    continue\n",
    "                y = subj_dict[labels_key]\n",
    "                if getattr(X, \"shape\", (None,))[0] != len(y):\n",
    "                    problems.append(\n",
    "                        f\"[{task} | subj {subj_id} | {key}] \"\n",
    "                        f\"X.shape[0]={getattr(X,'shape',(None,))[0]} vs len(y)={len(y)}\"\n",
    "                    )\n",
    "\n",
    "            per_subj[task][subj_id] = s_total\n",
    "\n",
    "        totals[\"tasks\"][task] = t_total\n",
    "\n",
    "    if verbose:\n",
    "        print(\"\\n====== Riepilogo trials ======\")\n",
    "        print(f\"Totale globale trial: {totals['global']}\")\n",
    "        for task, n in totals[\"tasks\"].items():\n",
    "            print(f\"  - {task}: {n}\")\n",
    "        print(\"\\nPer task e soggetto:\")\n",
    "        for task, d in per_subj.items():\n",
    "            counts = \", \".join([f\"s{subj}: {n}\" for subj, n in sorted(d.items(), key=lambda x: int(x[0]))])\n",
    "            print(f\"  {task}: {counts if counts else '—'}\")\n",
    "        print(\"\\nPer task e condizione (aggregata su soggetti):\")\n",
    "        for task, d in per_cond.items():\n",
    "            counts = \", \".join([f\"{cond}: {n}\" for cond, n in d.items()])\n",
    "            print(f\"  {task}: {counts if counts else '—'}\")\n",
    "        if problems:\n",
    "            print(\"\\n⚠️  Incoerenze trovate:\")\n",
    "            for msg in problems[:10]:\n",
    "                print(\"  -\", msg)\n",
    "            if len(problems) > 10:\n",
    "                print(f\"  ... (+{len(problems)-10} altre)\")\n",
    "\n",
    "    return totals, per_subj, per_cond, problems\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271826ed-ad71-460f-bc9c-88ab68956c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Questo:\n",
    "\n",
    "conta i trial usando le labels (più robuste),\n",
    "\n",
    "fa un check di coerenza con le epoche dati (stesso n_epochs),\n",
    "\n",
    "ti stampa il totale globale, il totale per task, il dettaglio per soggetto e per condizione,\n",
    "\n",
    "riporta eventuali incoerenze (chiavi mancanti o mismatch di lunghezza).\n",
    "\n",
    "'''\n",
    "\n",
    "totals, per_subj, per_cond, problems = count_trials(new_EEG_data, verbose=True)\n",
    "\n",
    "# one-liner \"grezza\" (solo totale), conteggiando direttamente i *_labels:\n",
    "total_trials = sum(\n",
    "    len(subj_dict[k]) \n",
    "    for task in new_EEG_data.values()\n",
    "    for subj_dict in task\n",
    "    for k in subj_dict.keys()\n",
    "    if k.endswith('_labels')\n",
    ")\n",
    "print(\"Totale trial (one-liner):\", total_trials)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b1a28bbb-4be9-41e6-8fd6-2cd5fd7a958b",
   "metadata": {
    "tags": []
   },
   "source": [
    "'''ORIGINAL VERSION\n",
    "\n",
    "\n",
    "\n",
    "'''CREAZIONE SPETTROGRAMMI FREQUENZE x TEMPO'''\n",
    "\n",
    "import numpy as np\n",
    "import pywt\n",
    "from scipy.signal import stft\n",
    "\n",
    "def create_spectograms_from_stft(data, window_size = 50, step_size = 25, fs = 250):\n",
    "    \n",
    "    # Dizionario per memorizzare i risultati separati per condizione sperimentale\n",
    "    condition_results = {}\n",
    "    \n",
    "    for idx, data_dict in enumerate(data):\n",
    "        print(f\"\\n\\n\\t\\t\\t\\t\\t\\033[1mProcessing Subject {idx + 1}\\033[0m:\\n\")\n",
    "\n",
    "        for condition, value in data_dict.items():\n",
    "            if '_labels' in condition:\n",
    "                base_condition = condition.replace('_labels', '')  # Rimuove '_labels'\n",
    "                condition_key = base_condition\n",
    "                labels_key = condition\n",
    "            else:\n",
    "                base_condition = condition\n",
    "                condition_key = base_condition\n",
    "                labels_key = f'{base_condition}_labels'\n",
    "            \n",
    "            # Aggiungi chiavi inizializzate per nuove condizioni\n",
    "            if '_labels' not in condition and condition_key not in condition_results:\n",
    "                condition_results[condition_key] = {'spectrograms': [], 'labels': []}\n",
    "            \n",
    "            # Applicazione wavelet solo per array np.ndarray\n",
    "            if isinstance(value, np.ndarray):\n",
    "                print(f\"\\nApplicazione STFT per '\\033[1m{condition_key}\\033[0m'\\n\")\n",
    "                print(f\"\\033[1mShape\\033[0m dei dati per \\033[1m{condition_key}\\033[0m: {value.shape}\")\n",
    "                \n",
    "                \n",
    "                # Esegui STFT per ogni canale e trial          \n",
    "                \n",
    "                #La funzione stft di SciPy restituisce uno spettrogramma con la forma (n_frequencies, n_time_steps),\n",
    "                #quindi:38 corrisponde al numero di bin di frequenza calcolati a partire dalla finestra FFT di 75 punti.\n",
    "                \n",
    "                #Infatti, per una finestra di lunghezza 75, il numero di bin è calcolato (in questo caso, dato che 75 è dispari) come (75 + 1) // 2, ovvero 38.\n",
    "                #Il numero di passi temporali (n_time_steps) viene invece calcolato in base alla lunghezza del segnale e ai parametri di finestra e overlap.\n",
    "                \n",
    "                #Nel tuo caso, estraendo 250 punti (da 50 a 300) con nperseg=75 e noverlap=25 (cioè con un salto di 50 campioni per finestra), \n",
    "                #il numero di segmenti dovrebbe essere:\n",
    "                #1 + [250−75/75-25] = 1 + [175/50]  = 1 + 3 = 4\n",
    "\n",
    "                #Pertanto, il risultato di stft (cioè Zxx) ha forma (38, 4) e non (4, 38). \n",
    "                #Se ti aspetti una struttura con l'asse del tempo come terza dimensione (ad esempio, (trial, canali, tempo, frequenze))\n",
    "                #potresti dover trasporre l'array in modo da scambiare le dimensioni frequenza e tempo.\n",
    "                \n",
    "                '''\n",
    "                1) crearmi una lista per salvarmi poi tutti gli spettrogrammi di tutti i trials\n",
    "                2) per il trials corrente mi salvo lo spettrogramma e lo appendo poi ad 1)\n",
    "                3) converto la lista di tutti gli spettrogrammi di tutti i trials della condizione corrente in array numpy \n",
    "                4) carico poi l'array numpy dentro il dizionario della condizione corrente dentro la chiave 'spectrograms'\n",
    "                '''\n",
    "                \n",
    "                all_trial_spectrograms = []\n",
    "\n",
    "                for trial in range(value.shape[0]):\n",
    "                    single_trial_spectrograms = []  # Lista per memorizzare gli spettrogrammi per il trial corrente\n",
    "\n",
    "                    for channel in range(value.shape[1]):\n",
    "                        \n",
    "                        single_channel_data = value[trial, channel, 50:300]  # Estrai i dati del singolo canale\n",
    "                        \n",
    "                        #print(f\"Segment length: {len(single_channel_data)}\")\n",
    "                    \n",
    "                        '''\n",
    "                        TIENI A MENTE CHE DUE PARAMETRI GESTISCONO IL PADDING QUI AUTOMATICAMENTE, CHE SONO:\n",
    "                        \n",
    "                        boundary='zeros', \n",
    "                        padded=True,\n",
    "                        \n",
    "                        PER QUESTO MOTIVO LE FINESTRE SARANNO 11 E NON 9.\n",
    "                        \n",
    "                        IN QUESTO MODO, SI MIGLIORA LA RISOLUZIONE IN FREQUENZA ALL'INIZIO E FINE DEL SEGNALE (DI 250 PUNTI!)\n",
    "                        ANDANDO IN QUESTO MODO A RIDURRE GLI EFFETTI DI BORDO\n",
    "                        '''\n",
    "                        \n",
    "                        f, t, Zxx = stft(single_channel_data, fs=fs, window='hann', nperseg = 50, noverlap = 25)\n",
    "                        \n",
    "                        single_trial_spectrograms.append(Zxx)  # Aggiungi lo spettrogramma calcolato per il canale corrente\n",
    "\n",
    "                    all_trial_spectrograms.append(np.array(single_trial_spectrograms))  # Forma: (numero_canali, frequenze, tempo)\n",
    "\n",
    "                condition_results[condition_key]['spectrograms'].extend(all_trial_spectrograms)\n",
    "\n",
    "                # Gestione etichette\n",
    "                if labels_key in data_dict:\n",
    "                    num_labels = data_dict[labels_key]\n",
    "                    if condition_key in condition_results:\n",
    "                        print(f\"\\nFound labels for condition \\033[1m{labels_key}\\033[0m, length: \\033[1m{len(num_labels)}\\033[0m\\n\")\n",
    "                        condition_results[condition_key]['labels'].extend(num_labels)\n",
    "            else:\n",
    "                print(f\"\\033[1m{labels_key}\\033[0m' non è un np.array, non applicare la STFT \")\n",
    "    \n",
    "    # Preparazione risultati concatenati\n",
    "    all_subjects_condition_results = {}\n",
    "\n",
    "    for condition_key, results in condition_results.items():\n",
    "        if \"_labels\" in condition_key or len(results['spectrograms']) == 0:  # Verifica che ci siano spettrogrammi\n",
    "            print(f\"\\nSkipping \\033[1m{labels_key}\\033[0m as it is a label or has no valid data.\")\n",
    "            continue\n",
    "\n",
    "        wave_condition_name = f'spectrograms_{condition_key}'\n",
    "        print(f\"\\n\\nResults for \\t\\t\\t\\t\\t\\033[1m{wave_condition_name}\\033[0m:\\n\\n\")\n",
    "\n",
    "        # Converti in un array NumPy 3D finale\n",
    "        spectrograms_4d = np.array(results['spectrograms'])  # Forma: (numero_di_trial, numero_canali, frequenze, tempo)\n",
    "        all_subjects_condition_results[wave_condition_name] = {\n",
    "            'spectrograms_4d': spectrograms_4d,\n",
    "            'labels': results['labels']\n",
    "        }\n",
    "\n",
    "        print(f\"spectrograms_4d shape: {spectrograms_4d.shape}\")\n",
    "    \n",
    "    '''\n",
    "    Quindi alla fine si avrà una shape del tipo (44, 61, 38, 7) dove indica che avrai\n",
    "    uno spettrogramma per ciascun trial, per ciascun canale, \n",
    "    che contiene informazioni sulle bande di frequenza e sui punti temporali. \n",
    "    \n",
    "    Questa struttura è perfetta per essere utilizzata come input per una rete neurale convoluzionale (CNN),\n",
    "    poiché la rete può apprendere dalle relazioni spaziali e temporali nei dati.\n",
    "    '''\n",
    "    \n",
    "    return all_subjects_condition_results\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e06be32-4a78-4d08-9d65-e09660366fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new_EEG_data['task_2'][2].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01e3a5b-01f7-470d-8a0f-8b28f55b2666",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new_EEG_data['task_1'][0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc6a528-b451-43ab-bab2-e48fe0deb2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new_EEG_data['task_1'][0]['rest_1'].shape)\n",
    "print(new_EEG_data['task_1'][0]['rest_1_labels'])\n",
    "print(new_EEG_data['task_1'][0]['right_fist_1_labels'])\n",
    "print(new_EEG_data['task_1'][0]['left_fist_1_labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10648b6-ef89-4e17-887c-aa85d78db86f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "NEW UPDATED VERSION FOR DATASET MOTOR TASK - TIME x FREQUENCY UFFICIALE\n",
    "\n",
    "Ecco la versione rivista della tua funzione, con in più il parametro data_task che seleziona il sotto-dizionario giusto in base al task\n",
    "(es. \"task_1\", \"task_2\", …) e poi riapplica esattamente la stessa logica di STFT sui soli soggetti di quel task.\n",
    "\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "from scipy.signal import stft\n",
    "\n",
    "\n",
    "def create_spectograms_from_stft(\n",
    "    new_EEG_data: dict,\n",
    "    data_task: str,\n",
    "    window_size: int = 160,\n",
    "    step_size: int = 80,\n",
    "    fs: int = 160\n",
    "):\n",
    "    \"\"\"\n",
    "    new_EEG_data: { task: [ {cond_subj: data, cond_subj_labels: labels,...}, ... ], ... }\n",
    "    data_task:     \"task_1\" / \"task_2\" / \"task_3\" / \"task_4\"\n",
    "    \"\"\"\n",
    "\n",
    "    # --- 1) Filtra sul task richiesto ---\n",
    "    if data_task not in new_EEG_data:\n",
    "        raise KeyError(f\"Task '{data_task}' non trovato in new_EEG_data\")\n",
    "    \n",
    "    data = new_EEG_data[data_task]   # ora 'data' è la lista di dict (un elemento per soggetto)\n",
    "    \n",
    "    # --- 2) stesso codice che avevi prima ---\n",
    "    condition_results = {}\n",
    "    \n",
    "    for idx, data_dict in enumerate(data):\n",
    "        print(f\"\\n\\n\\t\\t\\t\\t\\t\\033[1mProcessing Subject {idx + 1}\\033[0m:\\n\")\n",
    "\n",
    "        for condition, value in data_dict.items():\n",
    "            \n",
    "            # Calcolo condition_key senza '_labels'\n",
    "            if condition.endswith('_labels'):\n",
    "                condition_key = condition[:-7]\n",
    "            else:\n",
    "                condition_key = condition\n",
    "            \n",
    "            # inizializzo sempre la entry\n",
    "            if condition_key not in condition_results:\n",
    "\n",
    "                condition_results[condition_key] = {'spectrograms': [], 'labels': []}\n",
    "            \n",
    "            # ——————————————————————————\n",
    "            # [PATCHED] ramo label\n",
    "            if condition.endswith('_labels'):\n",
    "                \n",
    "                # Converto in lista di interi\n",
    "                #labels = np.asarray(value, dtype=int).tolist()\n",
    "                labels = np.asarray(value, dtype=int)\n",
    "                \n",
    "                print(f\"\\nFound labels for condition \\033[1m{condition}\\033[0m, length: \\033[1m{len(labels)}\\033[0m\\n\")\n",
    "                    \n",
    "                # Uso condition_key (non labels_key!)\n",
    "                condition_results[condition_key]['labels'].extend(labels)\n",
    "                continue   \n",
    "            \n",
    "            '''\n",
    "            Cosa cambia in questo codice\n",
    "            STFT viene eseguita solo su condition che non finiscono con _labels e che sono array 3‑D.\n",
    "\n",
    "            Estensione delle etichette (.extend(num_labels)) viene spostata in un blocco if condition.endswith('_labels'),\n",
    "            dove value è già il np.ndarray mono‑dimensionale delle labels.\n",
    "\n",
    "            In questo modo:\n",
    "\n",
    "            Non tenterai più di indicizzare value[trial, channel, …] su un array 1‑D\n",
    "            Stamperai e accoderai correttamente le etichette nell’array condition_results[...]['labels']\n",
    "            Con queste due modifiche minime tutto tornerà a girare senza ulteriori errori.\n",
    "            '''\n",
    "            \n",
    "            # 1) processa solo i dati (3‑D) non le etichette 1‑D\n",
    "            if isinstance(value, np.ndarray) and value.ndim == 3:\n",
    "    \n",
    "                print(f\"\\nApplicazione STFT per '\\033[1m{condition_key}\\033[0m'\\n\")\n",
    "                print(f\"\\033[1mShape\\033[0m dei dati per \\033[1m{condition_key}\\033[0m: {value.shape}\")\n",
    "                \n",
    "                '''\n",
    "                # Esegui STFT per ogni canale e trial          \n",
    "                \n",
    "                #La funzione stft di SciPy restituisce uno spettrogramma con la forma (n_frequencies, n_time_steps),\n",
    "                #quindi:38 corrisponde al numero di bin di frequenza calcolati a partire dalla finestra FFT di 75 punti.\n",
    "                \n",
    "                #Infatti, per una finestra di lunghezza 75, il numero di bin è calcolato (in questo caso, dato che 75 è dispari) come (75 + 1) // 2, ovvero 38.\n",
    "                #Il numero di passi temporali (n_time_steps) viene invece calcolato in base alla lunghezza del segnale e ai parametri di finestra e overlap.\n",
    "                \n",
    "                #Nel tuo caso, estraendo 250 punti (da 50 a 300) con nperseg=75 e noverlap=25 (cioè con un salto di 50 campioni per finestra), \n",
    "                #il numero di segmenti dovrebbe essere:\n",
    "                #1 + [250−75/75-25] = 1 + [175/50]  = 1 + 3 = 4\n",
    "\n",
    "                #Pertanto, il risultato di stft (cioè Zxx) ha forma (38, 4) e non (4, 38). \n",
    "                #Se ti aspetti una struttura con l'asse del tempo come terza dimensione (ad esempio, (trial, canali, tempo, frequenze))\n",
    "                #potresti dover trasporre l'array in modo da scambiare le dimensioni frequenza e tempo.\n",
    "                \n",
    "                \n",
    "                1) crearmi una lista per salvarmi poi tutti gli spettrogrammi di tutti i trials\n",
    "                2) per il trials corrente mi salvo lo spettrogramma e lo appendo poi ad 1)\n",
    "                3) converto la lista di tutti gli spettrogrammi di tutti i trials della condizione corrente in array numpy \n",
    "                4) carico poi l'array numpy dentro il dizionario della condizione corrente dentro la chiave 'spectrograms'\n",
    "                '''\n",
    "                \n",
    "                all_trial_spectrograms = []\n",
    "                \n",
    "                for trial in range(value.shape[0]):\n",
    "                    single_trial_spectrograms = []\n",
    "                    \n",
    "                    for channel in range(value.shape[1]):\n",
    "                        single_channel_data = value[trial, channel, :640]\n",
    "                        \n",
    "                        #print(f\"Segment length: {len(single_channel_data)}\")\n",
    "                        \n",
    "                        '''\n",
    "                        TIENI A MENTE CHE DUE PARAMETRI GESTISCONO IL PADDING QUI AUTOMATICAMENTE, CHE SONO:\n",
    "                        \n",
    "                        boundary='zeros', \n",
    "                        padded=True,\n",
    "                        \n",
    "                        PER QUESTO MOTIVO LE FINESTRE SARANNO 11 E NON 9.\n",
    "                        \n",
    "                        IN QUESTO MODO, SI MIGLIORA LA RISOLUZIONE IN FREQUENZA ALL'INIZIO E FINE DEL SEGNALE (DI 250 PUNTI!)\n",
    "                        ANDANDO IN QUESTO MODO A RIDURRE GLI EFFETTI DI BORDO\n",
    "                        '''\n",
    "                        \n",
    "                        f, t, Zxx = stft(\n",
    "                            single_channel_data,\n",
    "                            fs=fs,\n",
    "                            window='hann',\n",
    "                            nperseg=window_size,\n",
    "                            noverlap=window_size - step_size\n",
    "                        )\n",
    "                        single_trial_spectrograms.append(Zxx) # Aggiungi lo spettrogramma calcolato per il canale corrente\n",
    "                        \n",
    "                    all_trial_spectrograms.append(np.array(single_trial_spectrograms)) # Forma: (numero_canali, frequenze, tempo)\n",
    "\n",
    "                condition_results[condition_key]['spectrograms'].extend(all_trial_spectrograms)\n",
    "                \n",
    "                \n",
    "                #if labels_key in data_dict:\n",
    "                    #num_labels = data_dict[labels_key] #QUI IN REALTA' SAREBBE GIA' ARRAY NUMPY MA PER IL CODICE CONVIENE RIPORTARLO INT COME LISTA!\n",
    "                    #'''UNICA MODIFICA IMPORTANTE DA FARE --> RIPORTARE A VALORE DI INT COME LISTA DELLE LABELS (IMPORTANTE PER DOPO!)'''\n",
    "                    #num_labels = np.asarray(value).tolist()   # trasforma in lista di int\n",
    "                    #if condition_key in condition_results:\n",
    "                    #    print(f\"\\nFound labels for condition \\033[1m{labels_key}\\033[0m, length: \\033[1m{len(num_labels)}\\033[0m\\n\")\n",
    "                    #    condition_results[condition_key]['labels'].extend(num_labels)\n",
    "                \n",
    "            \n",
    "            else:\n",
    "                print(f\"\\033[1m{condition_key}\\033[0m è np.ndarray di labels, salto STFT\")\n",
    "                        \n",
    "    # --- 3) prepara l'output concatenato ---\n",
    "    \n",
    "    # Preparazione risultati concatenati\n",
    "    all_subjects_condition_results = {}\n",
    "\n",
    "    for condition_key, results in condition_results.items():\n",
    "        if \"_labels\" in condition_key or len(results['spectrograms']) == 0:  # Verifica che ci siano spettrogrammi\n",
    "            print(f\"\\nSkipping \\033[1m{condition_key}\\033[0m as it is a label or has no valid data.\")\n",
    "            continue\n",
    "\n",
    "        wave_condition_name = f'spectrograms_{condition_key}'\n",
    "        print(f\"\\n\\nResults for \\t\\t\\t\\t\\t\\033[1m{wave_condition_name}\\033[0m:\\n\\n\")\n",
    "\n",
    "        # Converti in un array NumPy 3D finale\n",
    "        spectrograms_4d = np.array(results['spectrograms'])  # Forma: (numero_di_trial, numero_canali, frequenze, tempo)\n",
    "        labels = results['labels']\n",
    "        \n",
    "        all_subjects_condition_results[wave_condition_name] = {\n",
    "            'spectrograms_4d': spectrograms_4d,\n",
    "            'labels': labels\n",
    "        }\n",
    "\n",
    "        print(f\"spectrograms_4d shape: {spectrograms_4d.shape}\")\n",
    "    \n",
    "    '''\n",
    "    Quindi alla fine si avrà una shape del tipo (44, 61, 38, 7) dove indica che avrai\n",
    "    uno spettrogramma per ciascun trial, per ciascun canale, \n",
    "    che contiene informazioni sulle bande di frequenza e sui punti temporali. \n",
    "    \n",
    "    Questa struttura è perfetta per essere utilizzata come input per una rete neurale convoluzionale (CNN),\n",
    "    poiché la rete può apprendere dalle relazioni spaziali e temporali nei dati.\n",
    "    '''\n",
    "    \n",
    "    return all_subjects_condition_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcf278e-6f05-4e61-afed-727b66d2f7f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Richiamo della funzione per processare tutti i soggetti e ottenere i risultati per ciascuna condizione\n",
    "\n",
    "'''\n",
    "\n",
    "def create_spectograms_from_stft(\n",
    "    new_EEG_data: dict,\n",
    "    data_task: str,\n",
    "    window_size: int = 160,\n",
    "    step_size: int = 80,\n",
    "    fs: int = 160\n",
    "):\n",
    "'''\n",
    "\n",
    "new_all_subjects_condition_spectrograms_task_1 = create_spectograms_from_stft(new_EEG_data, \n",
    "                                                                             'task_1',\n",
    "                                                                             window_size  = 160,\n",
    "                                                                             step_size = 80,\n",
    "                                                                             fs=160)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94955e98-8b73-409d-a9c1-61716c94827a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('finito')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174126ec-d4dc-467e-bb12-7fbfc2dd9900",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_all_subjects_condition_spectrograms_task_1.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011d6e2f-4e24-4e0d-ac42-4d530e6751c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new_all_subjects_condition_spectrograms_task_1['spectrograms_rest_100']['spectrograms_4d'].shape)\n",
    "print()\n",
    "print(len(new_all_subjects_condition_spectrograms_task_1['spectrograms_rest_100']['labels']))\n",
    "print()\n",
    "print(new_all_subjects_condition_spectrograms_task_1['spectrograms_rest_100']['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119f25ee-b98b-4a1a-a3e9-3dc89d963364",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "base_path = '/home/stefano/Interrogait/all_datas/Spectrograms_motor_tasks/'\n",
    "\n",
    "# Controlla se la cartella esiste, altrimenti la crea\n",
    "if not os.path.exists(base_path):\n",
    "    os.makedirs(base_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4667aa4c-b7c5-47a9-a196-61a38b518a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvare l'intero dizionario annidato con pickle\n",
    "with open(f'{base_path}new_all_subjects_condition_spectrograms_task_1.pkl', 'wb') as f:\n",
    "    pickle.dump(new_all_subjects_condition_spectrograms_task_1, f)\n",
    "    print(f\"✅ Dati salvati in: {base_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1e4b92-3b0a-42c7-8f47-a826269f430c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_all_subjects_condition_spectrograms_task_1.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8864a4c-fb2c-48b4-9c4f-6a6d76778a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_all_subjects_condition_spectrograms_task_1['spectrograms_rest_100'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5403f9-9020-4ca9-bfa8-721e0774f950",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new_all_subjects_condition_spectrograms_task_1['spectrograms_rest_100']['spectrograms_4d'].shape)\n",
    "print(len(new_all_subjects_condition_spectrograms_task_1['spectrograms_rest_100']['labels']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70de6d8b-bbe4-4b59-8573-9dde0f68f571",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Caricare l'intero dizionario annidato con pickle\n",
    "path = '/home/stefano/Interrogait/all_datas/Spectrograms_motor_tasks/'\n",
    "\n",
    "# Caricare l'intero dizionario annidato con pickle\n",
    "with open(f'{path}new_all_subjects_condition_spectrograms_task_1.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a63ddf1-49ad-4333-a705-04b31eb7b0d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b54f048-2996-4d20-8bb3-6aab6bd4f9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data['spectrograms_rest_100'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1efa9f-9ca3-4018-861f-3ba56fb10d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['spectrograms_rest_100'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2e2601-4657-4c22-8ac8-c4e9c61eab6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['spectrograms_rest_100']['spectrograms_4d'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5047defc-6b65-424a-9842-304eb79ce282",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### **Concatenazione** All **SINGLE** Subject **Spectrograms** per **Tutte le Condizioni Sperimentali**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e473dd74-8cf5-4cbc-a73c-951e49d02e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Library Importing \n",
    "    \n",
    "import os\n",
    "import math\n",
    "import copy as cp \n",
    "\n",
    "import tqdm\n",
    "\n",
    "#import mne \n",
    "import scipy\n",
    "\n",
    "import numpy as np  # NumPy per operazioni numeriche\n",
    "import matplotlib.pyplot as plt  # Matplotlib per la isualizzazione dei dati\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import pickle\n",
    "\n",
    "# Caricare l'intero dizionario annidato con pickle\n",
    "path = '/home/stefano/Interrogait/all_datas/Spectrograms_motor_tasks/'\n",
    "\n",
    "# Caricare l'intero dizionario annidato con pickle\n",
    "with open(f'{path}new_all_subjects_condition_spectrograms_task_1.pkl', 'rb') as f:\n",
    "    new_all_subjects_condition_spectrograms_task_1 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498bd82d-1fbf-4aba-87f7-b830780dc6f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#new_all_subjects_condition_spectrograms_task_1.keys()\n",
    "\n",
    "#new_all_subjects_condition_spectrograms_task_1['spectrograms_rest_100'].keys()\n",
    "\n",
    "new_all_subjects_condition_spectrograms_task_1['spectrograms_rest_100']['spectrograms_4d'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814d6a1c-46bd-47ad-a419-d1999c50bf22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Definizione degli indici dei canali desiderati\n",
    "\n",
    "'''TOLGO PER SPETTROGRAMMI FREQUENZE x ELETTRODI'''\n",
    "#selected_channels = [12, 30, 48]  # Indici per Fz, Cz, Pz\n",
    "\n",
    "# Creazione di un dizionario dei dati di tutti i terapisti singolarmente, per salvare gli spettrogrammi calcolati\n",
    "new_single_th_all_extracted_spectrograms_2D_task_1 = {}\n",
    "\n",
    "# Iterazione su tutte le condizioni sperimentali di tutti i soggetti \n",
    "\n",
    "for condition, data in new_all_subjects_condition_spectrograms_task_1.items():\n",
    "    \n",
    "    # Estrarre le etichette per la condizione corrente\n",
    "    labels = data['labels']\n",
    "    \n",
    "    #  Estrarre gli spettrogrammi per la condizione corrente\n",
    "    '''TOLGO PER SPETTROGRAMMI FREQUENZE x ELETTRODI'''\n",
    "    \n",
    "    spectrograms = data['spectrograms_4d']\n",
    "    \n",
    "    #spectrograms = data['spectrograms_3d']\n",
    "    \n",
    "    '''TOLGO PER SPETTROGRAMMI FREQUENZE x ELETTRODI'''\n",
    "    #Selezione dei canali di interesse (Fz, Cz e Pz)\n",
    "    #spectrograms = spectrograms[:, selected_channels, :, :]\n",
    "    \n",
    "    new_single_th_all_extracted_spectrograms_2D_task_1[condition] = {\n",
    "        'spectrograms': spectrograms,\n",
    "        #'delta': delta_reconstruction,\n",
    "        #'coeff_fifth_detail_theta': coeff_fifth_detail_theta, \n",
    "        'labels': labels\n",
    "    }\n",
    "    \n",
    "# Verifica delle dimensioni del risultato estratto per una condizione specifica di ogni soggetto\n",
    "print(f\"\\t\\t\\033[1mEstrazione Spettrogrammi di tutti i terapisti per tutte le condizioni sperimentali\")\n",
    "print(f\"\\n\\n\\t\\t\\t\\t(i.e., \\033[1mnew_single_th_all_extracted_spectrograms_2D_task_1\\033[0m):\\n\")\n",
    "\n",
    "for condition, extracted_data in new_single_th_all_extracted_spectrograms_2D_task_1.items():\n",
    "    \n",
    "    print(f\"Condizione: \\033[1m{condition}\\033[0m, \"\n",
    "          f\"Spectrograms shape: \\033[1m{extracted_data['spectrograms'].shape}\\033[0m, \"\n",
    "          f\"Labels: \\033[1m{len(extracted_data['labels'])}\\033[0m\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fa7c7d-dc81-4e7b-9386-0b2d075d6a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Salvataggio di new_single_th_all_extracted_spectrograms_2D_task_1'''\n",
    "\n",
    "base_path = '/home/stefano/Interrogait/all_datas/Spectrograms_motor_tasks/'\n",
    "\n",
    "\n",
    "# Controlla se la cartella esiste, altrimenti la crea\n",
    "if not os.path.exists(base_path):\n",
    "    os.makedirs(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee05c2a-79c9-4ff3-aed6-84ed32011b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_single_th_all_extracted_spectrograms_2D_task_1.keys()\n",
    "\n",
    "#new_single_th_all_extracted_spectrograms_2D_task_1['spectrograms_rest_100'].keys()\n",
    "\n",
    "new_single_th_all_extracted_spectrograms_2D_task_1['spectrograms_rest_100']['spectrograms'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4b5e36-87c0-4cc3-9250-f60784fd0ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Salvare l'intero dizionario annidato con pickle\n",
    "with open(f'{base_path}new_single_th_all_extracted_spectrograms_2D_task_1.pkl', 'wb') as f:\n",
    "    pickle.dump(new_single_th_all_extracted_spectrograms_2D_task_1, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a7f3a3-4412-4afc-b51b-ca9764b19a78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#print(new_single_th_all_extracted_spectrograms_2D_task_1.keys())\n",
    "#print()\n",
    "print(new_single_th_all_extracted_spectrograms_2D_task_1['spectrograms_rest_100'].keys())\n",
    "print()\n",
    "print(new_single_th_all_extracted_spectrograms_2D_task_1['spectrograms_rest_100']['spectrograms'].shape)\n",
    "print()\n",
    "print(len(new_single_th_all_extracted_spectrograms_2D_task_1['spectrograms_rest_100']['labels']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9e19bc-b220-4ea3-9ab5-d8a46918ee6d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Questa struttura consente di avere i dati degli spettrogrammi correttamente organizzati e concatenati per ogni soggetto,\n",
    "mantenendo la corrispondenza tra dati e etichette per ogni condizione sperimentale\n",
    "\n",
    "Da           \"single_th_all_extracted_reconstructions\"       a           \"subject_level_concatenations_th\"\n",
    "\n",
    "Da           \"new_single_th_all_extracted_reconstructions\"       a       \"new_subject_level_concatenations_th\"\n",
    "\n",
    "Da           \"new_single_th_all_extracted_spectrograms_2D_task_1\"       a       \"new_subject_level_concatenations_spectrograms_th_2D_task_1\"\n",
    "'''\n",
    "\n",
    "\n",
    "# Dizionario per contenere i dati concatenati per ogni soggetto\n",
    "new_subject_level_concatenations_spectrograms_th_2D_task_1 = {}\n",
    "\n",
    "# Variabile per tracciare il soggetto precedente\n",
    "previous_subject_suffix = None\n",
    "\n",
    "print(f\"\\t\\t\\033[1mConcatenazione spettrogrammi 2D per OGNI soggetto di TUTTE le condizioni sperimentali INSIEME\\033[0m\")\n",
    "\n",
    "# Iterazione su tutte le chiavi di new_single_th_all_extracted_spectrograms_2D_task_1\n",
    "for condition, data in new_single_th_all_extracted_spectrograms_2D_task_1.items():\n",
    "    \n",
    "    # Estrazione del suffisso numerico del soggetto\n",
    "    subject_suffix = condition.split('_')[-1]  # Prende solo la parte numerica\n",
    "    \n",
    "    # Creazione del nome della chiave del soggetto specifico\n",
    "    subj_name = f'th_{subject_suffix}'\n",
    "    \n",
    "    # Se stiamo per passare a un nuovo soggetto, concatenare e stampare i risultati del soggetto precedente\n",
    "    if previous_subject_suffix is not None and subject_suffix != previous_subject_suffix:\n",
    "        \n",
    "        print(f\"\\n\\n\\t\\t\\t\\t\\033[1mConcatenazioni per il soggetto corrente ('th_{previous_subject_suffix}'):\\033[0m\\n\")\n",
    "        prev_subject_name = f'th_{previous_subject_suffix}'\n",
    "        levels = new_subject_level_concatenations_spectrograms_th_2D_task_1[prev_subject_name]\n",
    "\n",
    "        # Concatenazione dei dati prima della stampa\n",
    "        spectrograms_concat = np.concatenate(levels['spectrograms'], axis=0)\n",
    "        labels_concat = np.concatenate(levels['labels'], axis=0)\n",
    "\n",
    "        print(f\"Soggetto: \\033[1m{prev_subject_name}\\033[0m, \"\n",
    "              f\"Spettrogrammi shape: \\033[1m{spectrograms_concat.shape}\\033[0m, \"\n",
    "              f\"Labels length: \\033[1m{len(labels_concat)}\\033[0m\")\n",
    "        \n",
    "        # Salvataggio dei dati concatenati nel dizionario\n",
    "        new_subject_level_concatenations_spectrograms_th_2D_task_1[prev_subject_name]['spectrograms'] = spectrograms_concat\n",
    "        new_subject_level_concatenations_spectrograms_th_2D_task_1[prev_subject_name]['labels'] = labels_concat\n",
    "    \n",
    "    # Inizializzare il dizionario per il soggetto specifico se non esiste già\n",
    "    if subj_name not in new_subject_level_concatenations_spectrograms_th_2D_task_1:\n",
    "        new_subject_level_concatenations_spectrograms_th_2D_task_1[subj_name] = {\n",
    "            'spectrograms': [],\n",
    "            'labels': []\n",
    "        }\n",
    "    \n",
    "    # Stampiamo le informazioni per ogni condizione\n",
    "    print(f\"\\n\\n\\nSoggetto: \\033[1m{subj_name}\\033[0m, Condizione: \\033[1m{condition}\\033[0m\")\n",
    "    print(f\"  - Spettrogrammi shape: \\033[1m{data['spectrograms'].shape}\\033[0m\")\n",
    "    print(f\"  - Labels shape: \\033[1m{len(data['labels'])}\\033[0m\")\n",
    "    print(f\"  - Valore unico delle etichette: \\033[1m{np.unique(data['labels'])}\\033[0m\")\n",
    "    \n",
    "    # Concatenazione dei dati\n",
    "    new_subject_level_concatenations_spectrograms_th_2D_task_1[subj_name]['spectrograms'].append(data['spectrograms'])\n",
    "    new_subject_level_concatenations_spectrograms_th_2D_task_1[subj_name]['labels'].append(data['labels'])\n",
    "    \n",
    "    # Aggiorna il soggetto precedente\n",
    "    previous_subject_suffix = subject_suffix\n",
    "\n",
    "# Dopo aver iterato su tutte le condizioni, concatenare e stampare le informazioni dell'ultimo soggetto\n",
    "if previous_subject_suffix is not None:\n",
    "    \n",
    "    last_subject_name = f'th_{previous_subject_suffix}'\n",
    "    levels = new_subject_level_concatenations_spectrograms_th_2D_task_1[last_subject_name]\n",
    "    \n",
    "    print(f\"\\n\\n\\t\\t\\t\\t\\033[1mConcatenazioni per il soggetto corrente ('{last_subject_name}'):\\033[0m\\n\")\n",
    "    \n",
    "    # Concatenazione dei dati dell'ultimo soggetto\n",
    "    spectrograms_concat = np.concatenate(levels['spectrograms'], axis=0)\n",
    "    labels_concat = np.concatenate(levels['labels'], axis=0)\n",
    "    \n",
    "    # Salvataggio dei dati concatenati dell'ultimo soggetto nel dizionario\n",
    "    new_subject_level_concatenations_spectrograms_th_2D_task_1[last_subject_name] = {\n",
    "        'spectrograms': spectrograms_concat,\n",
    "        'labels': labels_concat\n",
    "    }\n",
    "    \n",
    "    print(f\"Soggetto: \\033[1m{last_subject_name}\\033[0m, \"\n",
    "          f\"Spettrogrammi shape: \\033[1m{spectrograms_concat.shape}\\033[0m, \"\n",
    "          f\"Labels length: \\033[1m{len(labels_concat)}\\033[0m\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9364b09-a83b-4709-bcf9-8e31823a4d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''CHIAVI DI TUTTO IL DIZIONARIO '''\n",
    "#subject_level_concatenations_th.keys()\n",
    "\n",
    "\n",
    "new_subject_level_concatenations_spectrograms_th_2D_task_1.keys()\n",
    "\n",
    "\n",
    "#SOGGETTO 1\n",
    "\n",
    "#CHIAVI\n",
    "#subject_level_concatenations_th['th_1'].keys()\n",
    "\n",
    "#DATI\n",
    "#subject_level_concatenations_th['th_1']['theta'].shape\n",
    "\n",
    "#new_subject_level_concatenations_th['th_1']['theta'].shape\n",
    "\n",
    "#subject_level_concatenations_th['th_1']['delta'].shape\n",
    "\n",
    "#LABELS\n",
    "#subject_level_concatenations_th['th_1']['labels'].shape)\n",
    "#type(subject_level_concatenations_th['th_1']['labels'])\n",
    "\n",
    "# Check della concantenazione delle labels TH_1\n",
    "\n",
    "#subject_level_concatenations_th['th_1']['labels'][:42]\n",
    "#subject_level_concatenations_th['th_1']['labels'][41:81]\n",
    "#subject_level_concatenations_th['th_1']['labels'][81:120]\n",
    "#subject_level_concatenations_th['th_1']['labels'][121:164]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fff914-4c70-41a5-ab6c-3f4e2c99e2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#subject_level_concatenations_th['th_15']['labels'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d86276-58df-4fc2-bfb9-2696dff00734",
   "metadata": {},
   "outputs": [],
   "source": [
    "#subject_level_concatenations_th['th_1'].keys()\n",
    "\n",
    "new_subject_level_concatenations_spectrograms_th_2D_task_1['th_1'].keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fea14d4-3937-4173-a52c-d6d9fc47869b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#unique_values, counts = np.unique(subject_level_concatenations_th['th_1']['labels'], return_counts=True)\n",
    "\n",
    "#unique_values, counts = np.unique(new_subject_level_concatenations_th['th_1']['labels'], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d651cde-ee00-49c0-bf0e-bcc18657dcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#unique_values\n",
    "#counts\n",
    "#counts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01bb4e91-229a-4d12-92db-fa1c838d78a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#new_subject_level_concatenations_spectrograms_th_2D_task_1['th_1'].keys()\n",
    "#dict_keys(['spectrograms', 'labels'])\n",
    "\n",
    "new_subject_level_concatenations_spectrograms_th_2D_task_1['th_1']['spectrograms'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21d4535-5ab2-42ce-a95e-c39343e45c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b41f993-d0e5-425e-9340-a69396c1d6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Salvataggio di new_single_th_all_extracted_spectrograms_2D_task_1'''\n",
    "\n",
    "base_path = '/home/stefano/Interrogait/all_datas/Spectrograms_motor_tasks/'\n",
    "\n",
    "# Controlla se la cartella esiste, altrimenti la crea\n",
    "if not os.path.exists(base_path):\n",
    "    os.makedirs(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e873af99-f161-452f-9a17-dbcfd1950aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Salvare l'intero dizionario annidato con pickle\n",
    "with open(f'{base_path}new_subject_level_concatenations_spectrograms_th_2D_task_1.pkl', 'wb') as f:\n",
    "    pickle.dump(new_subject_level_concatenations_spectrograms_th_2D_task_1, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf45d05-7efc-48e1-8f02-b2c1cdec1ede",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### **Concatenazione** All **SINGLE** Subject **Spectrograms (TH)** per **Coppie di Condizioni Sperimentali**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626d7148-44fd-430d-a22b-732545606fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Library Importing \n",
    "    \n",
    "import os\n",
    "import math\n",
    "import copy as cp \n",
    "\n",
    "import tqdm\n",
    "\n",
    "#import mne \n",
    "import scipy\n",
    "\n",
    "import numpy as np  # NumPy per operazioni numeriche\n",
    "import matplotlib.pyplot as plt  # Matplotlib per la isualizzazione dei dati\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a2ec31-f01f-4ced-9e2d-e4afbdaa4df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfb7198-e7cf-492e-bebf-0790f9b2e92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970742c1-c169-4869-8db2-f12b72193eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cd New_Plots_Sliding_Estimator_MNE_1_45_NF/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9500fa5-22da-4400-909c-f7d4d3c7ed7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "base_path = '/home/stefano/Interrogait/all_datas/Spectrograms_motor_tasks/'\n",
    "    \n",
    "# Caricare l'intero dizionario annidato con pickle\n",
    "with open(f'{base_path}new_single_th_all_extracted_spectrograms_2D_task_1.pkl', 'rb') as f:\n",
    "    new_single_th_all_extracted_spectrograms_2D_task_1 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b196705f-6812-4523-b287-4e1beb5993db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#new_single_th_all_extracted_spectrograms_2D_task_1.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af517f6-e07a-4f57-999a-7906b2a56c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_single_th_all_extracted_spectrograms_2D_task_1['spectrograms_rest_100'].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a1b044-f753-491a-a37b-369db8e99d44",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### Spiegazione STEP - Concatenazione All Single Subject Spectrograms (TH) across Couples of Experimental Conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5fe59a6-86ba-4c14-93cc-743174030e80",
   "metadata": {
    "tags": []
   },
   "source": [
    "###### **Concatenazione All Single Subject Data (TH) per Coppie di Condizioni Sperimentali**\n",
    "\n",
    "<br>\n",
    "\n",
    "In questo caso, voglio **trasformare le variabili che contengono i miei dati e labels delle 4 condizioni sperimentali assieme**, in modo **da creare sottoinsiemi per ogni possibile coppia di condizioni sperimentali**. \n",
    "\n",
    "Dunque quello che si dovrà fare **per ogni coppia**:\n",
    "\n",
    "1) **Filtrare i dati e le etichette**:\n",
    "\n",
    "- **Estrarre** i dati associati **SOLO alle DUE condizioni in esame** (ad esempio 0 e 1, oppure 1 e 2).\n",
    "- **Creare un nuovo array di etichette** e **un array di dati** ***corrispondenti*** **SOLO a quelle DUE condizioni**.\n",
    "\n",
    "2) **Ripetere questa operazione per OGNI combinazione**:\n",
    "\n",
    "- **Assicurarsi di considerare tutte le coppie** di condizioni sperimentali **SENZA ripetizioni** (ad esempio, non serve processare sia 0 vs 1 che 1 vs 0, perché sono equivalenti!).\n",
    "\n",
    "3) **Creare quindi una struttura organizzata**, che contenga i dati e le etichette separatamente per ogni coppia, per ciascun livello di ricostruzione (theta, delta, theta_strict).\n",
    "\n",
    "<br>\n",
    "\n",
    "Quindi l'obiettivo è di modificare la procedura in modo da **concatenare SOLO le coppie di condizioni sperimentali per OGNI soggetto**. \n",
    "\n",
    "Per fare questo, possiamo utilizzare un **approccio combinatorio** per generare **tutte le possibili coppie di condizioni**.\n",
    "\n",
    "\n",
    "Per quanto riguarda il calcolo combinatorio, possiamo usare il concetto di combinazioni per selezionare le coppie. \n",
    "Se hai 4 condizioni, il numero di combinazioni di coppie di condizioni (senza ripetizioni) si calcola come:\n",
    "\n",
    "$$\n",
    "\\binom{4}{2} = \\frac{4!}{2!(4-2)!} = 6\n",
    "$$\n",
    "\n",
    "\n",
    "Quindi, con 4 condizioni sperimentali, le combinazioni di coppie di condizioni saranno 6, e queste coppie sono:\n",
    "\n",
    "(condizione 1, condizione 2) = 'baseline vs th_resp'\n",
    "(condizione 1, condizione 3) = 'baseline vs pt_resp'\n",
    "(condizione 1, condizione 4) = 'baseline vs shared_resp'\n",
    "(condizione 2, condizione 3) = 'th_resp vs pt_resp'\n",
    "(condizione 2, condizione 4) = 'th_resp vs shared_resp'\n",
    "(condizione 3, condizione 4) = 'pt_resp vs shared_resp' \n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "Piano di modifiche al codice:\n",
    "\n",
    "1) **Creazione delle coppie di condizioni**: Per ogni soggetto, genereremo tutte le coppie possibili di condizioni sperimentali. Utilizzeremo itertools.combinations per ottenere queste coppie.\n",
    "\n",
    "2) **Concatenazione per ciascuna coppia**: Per ogni coppia di condizioni, concatenare i dati e le etichette delle due condizioni selezionate.\n",
    "\n",
    "3) **Salvataggio delle concatenazioni**: Creeremo un dizionario per ciascuna coppia di condizioni per ogni soggetto.\n",
    "\n",
    "\n",
    "**N.B.**\n",
    "\n",
    "Nel codice che sto creando...\n",
    "\n",
    "Ho fatto in modo che ci sia il modo di capire, **per ogni coppia di condizione sperimentale di dati e labels**, a quali condizione sperimentali di dati e labels ci si riferisca, mi spiego:\n",
    "\n",
    "Sviluppo un **modo \"standardizzato\" per il quale per OGNI coppia di condizione sperimentale, la variabile che conterrà i dati e labels associate, sia chiamata in un certo modo**...\n",
    "\n",
    "E nello specifico **con il nome delle DUE condizioni sperimentali che conterranno quei dati e relative labels**...\n",
    "\n",
    "Del tipo: \n",
    "\n",
    "- se è baseline vs th_resp, la variabile sarà \"baseline_vs_th_resp\"\n",
    "- se è baseline vs pt_resp, la variabile sarà \"baseline_vs_pt_resp\"\n",
    "- se è baseline vs shared_resp, la variabile sarà \"baseline_vs_shared_resp\"\n",
    "\n",
    "\n",
    "Senza contare che, questo **processo di standardizzazione del nome delle variabili**, deve esser fatto **per ogni livello di ricostruzione dei dati (sia 4° e 5° livello a partire dai coefficienti di approssimazione, che dal 5 ° livello dei coefficienti di dettaglio)**..\n",
    "\n",
    "Questo significherebbe che, **per ogni soggetto**, dovrei (o potrei insomma) creare **un dizionario**, che \n",
    "\n",
    "- Contenga delle **sotto-chiavi di secondo ordine** (che son theta, delta e theta_strict) e dentro ognuna di queste\n",
    "- Ci siano contenute **le relative 6 sotto-sotto-chiavi di terzo ordine**, relative ai dati e alle labels associate (anch'esse concatenate ovviamente) delle diverse combinazioni di condizioni sperimentali...\n",
    "\n",
    "\n",
    "Ossia, vogliamo creare un dizionario strutturato che rappresenti ogni combinazione di coppie di condizioni sperimentali per ciascun soggetto, separando i dati e le etichette per i vari livelli di ricostruzione (theta, delta, theta_strict). \n",
    "\n",
    "Ogni combinazione di condizioni sperimentali sarà memorizzata in una chiave strutturata, come ad esempio \"baseline_vs_th_resp\", e all'interno di ciascuna chiave avremo le informazioni per i vari livelli di ricostruzione.\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "#### Esempio di Struttura proposta per il dizionario:\n",
    "\n",
    "\n",
    "- Soggetto: ad esempio \"th_1\".\n",
    "- Livelli di ricostruzione: theta, delta, theta_strict.\n",
    "- Combinazioni di condizioni sperimentali: per ciascun livello di ricostruzione, avremo sotto-chiavi per ogni coppia di condizioni.\n",
    "\n",
    "        new_subject_level_concatenations = {\n",
    "            'th_1': {\n",
    "                'theta': {\n",
    "                    'baseline_vs_th_resp': {'data': np.array([...]), 'labels': np.array([...])},\n",
    "                    'baseline_vs_pt_resp': {'data': np.array([...]), 'labels': np.array([...])},\n",
    "                    'baseline_vs_shared_resp': {'data': np.array([...]), 'labels': np.array([...])},\n",
    "                    # Altre combinazioni...\n",
    "                },\n",
    "                'delta': {\n",
    "                    'baseline_vs_th_resp': {'data': np.array([...]), 'labels': np.array([...])},\n",
    "                    'baseline_vs_pt_resp': {'data': np.array([...]), 'labels': np.array([...])},\n",
    "                    'baseline_vs_shared_resp': {'data': np.array([...]), 'labels': np.array([...])},\n",
    "                    # Altre combinazioni...\n",
    "                },\n",
    "                'theta_strict': {\n",
    "                    'baseline_vs_th_resp': {'data': np.array([...]), 'labels': np.array([...])},\n",
    "                    'baseline_vs_pt_resp': {'data': np.array([...]), 'labels': np.array([...])},\n",
    "                    'baseline_vs_shared_resp': {'data': np.array([...]), 'labels': np.array([...])},\n",
    "                    # Altre combinazioni...\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "\n",
    "<br>\n",
    "\n",
    "**SOTTO-STEP 1: IDENTIFICAZIONE DELLE STRINGA NUMERICHE PER LA CREAZIONE DELLE VARIABILI - FUTURE CHIAVI - CHE CONTENGONO LE COPPIE DI DATI E LABELS DELLE RELATIVE COPPIE DI CONDIZIONI SPERIMENTALI CONSIDERATE NEL CICLO CORRENTE DEL LOOP**\n",
    "\n",
    "Aspetta, ci sono altre cose che dovrebbero esser integrate nel codice...\n",
    "\n",
    "cominciamo dalla prima, che è relativa all' \"inferire\" diciamo il nome da fornire alla variabile che conterrà i dati e labels delle due condizioni sperimentali correnti... e deve esser fatto, a partire dal nome delle chiavi di \n",
    "\n",
    "\"new_single_th_all_extracted_reconstructions\"...\n",
    "\n",
    "ora, le sue chiavi son queste\n",
    "\n",
    "dict_keys(['wave_baseline_1', 'wave_th_resp_1', 'wave_pt_resp_1', 'wave_shared_resp_1', 'wave_baseline_2', 'wave_th_resp_2', 'wave_pt_resp_2', 'wave_shared_resp_2', 'wave_baseline_3', 'wave_th_resp_3', 'wave_pt_resp_3', 'wave_shared_resp_3', 'wave_baseline_4', 'wave_th_resp_4', 'wave_pt_resp_4', 'wave_shared_resp_4', 'wave_baseline_5', 'wave_th_resp_5', 'wave_pt_resp_5', 'wave_shared_resp_5', 'wave_baseline_6', 'wave_th_resp_6', 'wave_pt_resp_6', 'wave_shared_resp_6', 'wave_baseline_7', 'wave_th_resp_7', 'wave_pt_resp_7', 'wave_shared_resp_7', 'wave_baseline_8', 'wave_th_resp_8', 'wave_pt_resp_8', 'wave_shared_resp_8', 'wave_baseline_9', 'wave_th_resp_9', 'wave_pt_resp_9', 'wave_shared_resp_9', 'wave_baseline_10', 'wave_th_resp_10', 'wave_pt_resp_10', 'wave_shared_resp_10', 'wave_baseline_11', 'wave_th_resp_11', 'wave_pt_resp_11', 'wave_shared_resp_11', 'wave_baseline_12', 'wave_th_resp_12', 'wave_pt_resp_12', 'wave_shared_resp_12'])\n",
    "\n",
    "\n",
    "ora, il modo in cui si identifica un certo soggetto (ossia la chiavi di \"primo ordine\" che indentificano il soggetto, ossia ad esempio 'th_1'), dipenderebbe dal numero stringa che c'è alla fine di ogni nome stringa di ogni chiave dentro \"new_single_th_all_extracted_reconstructions\", mi spiego:\n",
    "\n",
    "il codice dovrebbe capire che, ad esempio, solo l'ultima carattere stringa di queste prime 4 chiavi:\n",
    "\n",
    "'wave_baseline_1', 'wave_th_resp_1', 'wave_pt_resp_1', 'wave_shared_resp_1', \n",
    "\n",
    "si riferisca al soggetto 1, ossia al futuro \"th_1\"...\n",
    "\n",
    "\n",
    "per il soggetto 2, sarebbero: \n",
    "\n",
    "'wave_th_resp_2', 'wave_pt_resp_2', 'wave_shared_resp_2', e così via per gli altri soggetti..\n",
    "\n",
    "\n",
    "Facendo attenzione al fatto che, dopo il soggetto 9, ovviamente, si passerà alle decine (a livello numerico), per cui saranno gli ultime due caratteri da considerare per l'identificazione delle sue rispettive chiavi, che in quel caso saranno per il soggetto 10, ossia il futuro th_10\n",
    "\n",
    "'wave_baseline_10', 'wave_th_resp_10', 'wave_pt_resp_10', 'wave_shared_resp_10',\n",
    "\n",
    "Inoltre, poi, per creare le variabili associate alle coppie di dati e labels delle relative condizioni sperimentali, dovrà il codice far in modo che il nome di quella variabile dipenda dalle stringhe sempre che si riferiscono al nome delle due chiavi di \"new_single_th_all_extracted_reconstructions\" da cui preleva i dati e le labels... \n",
    "\n",
    "ad esempio, se deve creare la variabile dei dati 'baseline_vs_th_resp\" del primo soggetto, le chiavi rispettive da cui deve andare a prelevare le stringhe saranno appunto \"'wave_baseline_1'\" e \"'wave_th_resp_1'\"....\n",
    "\n",
    "diciamo che si potrebbe creare una lista di stringhe che sarà del tipo:\n",
    "\n",
    "experimental_conditions = ['baseline', 'th_resp', 'pt_resp', 'shared_resp'], per vedere se una di queste sia dentro la rispettiva chiave di  new_single_th_all_extracted_reconstructions su cui sta iterando, che nel nostro caso di esempio sarebbero sempre\n",
    "\n",
    "'wave_baseline_1' (e da cui vede che c'è la stinga 'baseline')\n",
    "'wave_th_resp_1' (e da cui vede che c'è la stinga 'th_resp')\n",
    "\n",
    "è chiaro?\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "In sostanza, desideri un modo per inferire dinamicamente il nome del soggetto e delle variabili che conterranno i dati e le etichette per ogni combinazione di condizioni, a partire dal nome delle chiavi di new_single_th_all_extracted_reconstructions. Ecco un piano per raggiungere questo obiettivo:\n",
    "\n",
    "Passaggi:\n",
    "\n",
    "- Identificare il soggetto:\n",
    "\n",
    "Le chiavi di new_single_th_all_extracted_reconstructions finiscono con un numero che identifica il soggetto (es. wave_baseline_1, wave_th_resp_1, wave_pt_resp_1).\n",
    "Questo numero può essere estratto dalle ultime cifre della chiave (ad esempio, 1 da wave_baseline_1).\n",
    "La variabile associata a ciascun soggetto sarà chiamata th_X, dove X è il numero del soggetto.\n",
    "\n",
    "- Generare dinamicamente il nome delle variabili:\n",
    "\n",
    "A partire dai nomi delle chiavi, possiamo inferire quale combinazione di condizioni sperimentali stiamo trattando (es. baseline_vs_th_resp).\n",
    "Creeremo una lista delle condizioni (experimental_conditions = ['baseline', 'th_resp', 'pt_resp', 'shared_resp']), quindi esamineremo le chiavi per determinare quali condizioni sono presenti.\n",
    "\n",
    "- Creare il dizionario:\n",
    "\n",
    "A ciascun soggetto verrà associato un dizionario, e per ogni combinazione di condizioni sperimentali, assoceremo i dati e le etichette in una chiave che seguirà la convenzione del tipo baseline_vs_th_resp.\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "Spiegazione:\n",
    "\n",
    "1) Estrazione delle condizioni e soggetto:\n",
    "\n",
    "La chiave, ad esempio wave_baseline_1, viene separata in parti. La parte baseline viene estratta per determinare la condizione, mentre 1 indica il numero del soggetto.\n",
    "Queste informazioni vengono utilizzate per creare il nome del soggetto, th_1.\n",
    "\n",
    "2) Combinazioni di condizioni:\n",
    "\n",
    "La lista experimental_conditions contiene le 4 condizioni: baseline, th_resp, pt_resp, shared_resp.\n",
    "Per ogni soggetto, controlliamo quali condizioni sono disponibili nella chiave (ad esempio, se il soggetto 1 ha wave_baseline_1 e wave_th_resp_1, creiamo la combinazione baseline_vs_th_resp).\n",
    "\n",
    "3) Creazione dinamica delle variabili:\n",
    "\n",
    "Utilizziamo la combinazione di condizioni per generare la chiave della variabile (baseline_vs_th_resp).\n",
    "I dati e le etichette per la combinazione di condizioni vengono estratti e concatenati.\n",
    "\n",
    "\n",
    "4) Risultato finale:\n",
    "\n",
    "La struttura finale del dizionario new_subject_level_concatenations avrà una chiave per ciascun soggetto (th_1, th_2, ecc.), e sotto ogni soggetto ci saranno le combinazioni di condizioni per ciascun livello di ricostruzione (theta, delta, theta_strict), con i dati e le etichette corrispondenti.\n",
    "\n",
    "<br>\n",
    "\n",
    "Esempio di output:\n",
    "\n",
    "    {\n",
    "        'th_1': {\n",
    "            'theta': {\n",
    "                'baseline_vs_th_resp': {'data': np.array([...]), 'labels': np.array([...])},\n",
    "                'baseline_vs_pt_resp': {'data': np.array([...]), 'labels': np.array([...])},\n",
    "                'baseline_vs_shared_resp': {'data': np.array([...]), 'labels': np.array([...])},\n",
    "                'th_resp_vs_pt_resp': {'data': np.array([...]), 'labels': np.array([...])},\n",
    "                # Altre combinazioni...\n",
    "            },\n",
    "            'delta': {\n",
    "                # Stessa struttura per 'delta'\n",
    "            },\n",
    "            'theta_strict': {\n",
    "                # Stessa struttura per 'theta_strict'\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    " \n",
    "Questa struttura ti permetterà di avere un'organizzazione chiara e dinamica dei dati per ogni soggetto e combinazione di condizioni sperimentali.\n",
    " \n",
    " \n",
    "<br>\n",
    "\n",
    "**SOTTO-STEP 2: IDENTIFICAZIONE DELLE STRINGA ALFABETICHE PER LA CREAZIONE DELLE VARIABILI - FUTURE CHIAVI - CHE CONTENGONO IL NOME DELLE DUE COPPIE DI CONDIZIONI SPERIMENTALI DI CUI VENGONO PRELEVATI I DATI E LABELS CONCATENATI E CHE VENGONON CONSIDERATE NEL CICLO CORRENTE DEL LOOP**\n",
    "\n",
    "\n",
    "ok, ora c'è una ultima cosa che mi manca da dirti, che è relativa alla ri-assegnazione del codice numerico associato ad ogni coppia di condizioni sperimentali...\n",
    "\n",
    "nel senso che, originariamente...\n",
    "\n",
    "new_single_th_all_extracted_reconstructions ha queste labels, che se io le vedo avrò \n",
    "\n",
    "per baseline una serie di 0, per th_resp una serie di 1, per pt_resp, una serie di 2 e per shared_resp una serie di 3, in questo modo\n",
    "\n",
    "\n",
    "print(f\"Baseline in TH_1:, {np.unique(new_single_th_all_extracted_reconstructions['wave_baseline_1']['labels'], return_counts = True)}\\n\")\n",
    "print(f\"Th_Resp in TH_1:, {np.unique(new_single_th_all_extracted_reconstructions['wave_th_resp_1']['labels'], return_counts = True)}\\n\")\n",
    "print(f\"Pt_Resp in TH_1:, {np.unique(new_single_th_all_extracted_reconstructions['wave_pt_resp_1']['labels'], return_counts = True)}\\n\")\n",
    "print(f\"Shared_Resp in TH_1:, {np.unique(new_single_th_all_extracted_reconstructions['wave_shared_resp_1']['labels'], return_counts = True)}\\n\")\n",
    "\n",
    "\n",
    "Baseline in TH_1:, (array(['0'], dtype='<U1'), array([51]))\n",
    "\n",
    "Th_Resp in TH_1:, (array(['1'], dtype='<U1'), array([40]))\n",
    "\n",
    "Pt_Resp in TH_1:, (array(['2'], dtype='<U1'), array([40]))\n",
    "\n",
    "Shared_Resp in TH_1:, (array(['3'], dtype='<U1'), array([56]))\n",
    "\n",
    "di conseguenza,  nel tuo codice, ho bisogno che \n",
    "\n",
    "le labels associate a 'cond_1' (quando crei la relativa variabile delle due condizioni sperimentali di cui vengono concatenati i dati e le labels) siano riconvertite sempre in '0', mentre \n",
    "\n",
    "le labels associate a 'cond_2' (quando crei la relativa variabile delle due condizioni sperimentali di cui vengono concatenati i dati e le labels) siano riconvertite sempre in '1'\n",
    "\n",
    "questo aspetto è importante, per quando crei le variabili che conterranno le coppie di dati condizioni sperimentali...\n",
    "\n",
    "ora, nel caso in cui tu stia considerando magari baseline vs le altre condizioni sperimentali, è chiaro che in quel caso specifico, ad esempio, baseline sarà sempre la stringa associata a 'cond_1' e quindi in quel caso sarà sempre 0, e quindi sarebbe apposto..\n",
    "\n",
    "ma per gli altri casi di confronto di baseline rispetto alle altre 3 condizioni sperimentali, è chiaro che se sarà th_resp la condizione di confronto, allora in quel caso di quella specifica variabile, le labels non avranno bisogno di esser diciamo 'ri-convertite' perché già naturalmente diciamo baseline avrà le labels '0' e  e th_resp avrà già '1' (come è già originariamente codificato in 'new_subject_level_concatenations'!)\n",
    "\n",
    "ma nel caso delle altre variabili da creare le labels andranno ovviamente riconvertite! Perché?\n",
    "perché ovviamente nel caso sia la th_resp la 'cond_1', ad esempip, in quel caso, le sue labels (che son  originariamente codificate come '1' in 'new_subject_level_concatenations'!) diveteranno '0', mentre le altre condizioni di confronto, una alla volta, diventeranno '1' invece...\n",
    "\n",
    "\n",
    "è chiara diciamo la logica di ri-assegnazione delle relative labels in sostanza?\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "La **logica di ri-assegnazione delle etichette (labels)** è chiara e posso integrarla nel codice. \n",
    "\n",
    "La logica che stai descrivendo consiste essenzialmente nel **garantire che, quando crei una variabile che contiene dati e etichette per due condizioni sperimentali, le etichette siano sempre \"0\" per la prima condizione (cond_1) e \"1\" per la seconda condizione (cond_2)**, \n",
    "\n",
    "                **INDIPENDENTEMENTE** da come sono originariamente codificate in **\"new_single_th_all_extracted_reconstructions\"!\n",
    "                \n",
    "                \n",
    "\n",
    "Ecco come possiamo procedere:\n",
    "\n",
    "- Identificazione delle condizioni: Come hai descritto, determineremo le due condizioni sperimentali da confrontare, ad esempio \"baseline\" contro \"th_resp\", \"baseline\" contro \"pt_resp\", ecc.\n",
    "\n",
    "- Riconversione delle etichette:\n",
    "\n",
    " - Se la condizione di confronto è \"baseline\" (che è associata a 0), non dobbiamo modificare le etichette.\n",
    " - Se la condizione di confronto non è \"baseline\", dovremo riconvertire le etichette di quella condizione a 0 e le etichette della condizione di confronto a 1.\n",
    "\n",
    "- Struttura del codice: Durante la creazione delle variabili, dovremo controllare quale condizione è la prima (cond_1) e quale è la seconda (cond_2), e applicare questa logica per ri-assegnare le etichette di conseguenza.\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "Inoltre\n",
    "\n",
    "\n",
    "dentro \n",
    "\n",
    "\"# Crea tutte le combinazioni uniche di condizioni sperimentali (es. 'baseline vs th_resp')\n",
    "    condition_pairs = list(itertools.combinations(experimental_conditions, 2))\n",
    "\"\n",
    "\n",
    "Effettivamente vengono create delle tuple di coppie di stringhe che corrispondono a quelle con cui dovrebbero esser create le sotto-sotto-chiavi delle coppie di condizioni sperimentali..\n",
    "\n",
    "tuttavia, è giusto che iteri rispetto a 'condition_pairs', ma deve inserire un qualche controllo anche rispetto a questa cosa:\n",
    "\n",
    "originariamente...\n",
    "\n",
    "new_single_th_all_extracted_reconstructions ha queste labels, che se io le vedo avrò\n",
    "\n",
    "per baseline una serie di 0, per th_resp una serie di 1, per pt_resp, una serie di 2 e per shared_resp una serie di 3, in questo modo\n",
    "\n",
    "print(f\"Baseline in TH_1:, {np.unique(new_single_th_all_extracted_reconstructions['wave_baseline_1']['labels'], return_counts = True)}\\n\") print(f\"Th_Resp in TH_1:, {np.unique(new_single_th_all_extracted_reconstructions['wave_th_resp_1']['labels'], return_counts = True)}\\n\") print(f\"Pt_Resp in TH_1:, {np.unique(new_single_th_all_extracted_reconstructions['wave_pt_resp_1']['labels'], return_counts = True)}\\n\") print(f\"Shared_Resp in TH_1:, {np.unique(new_single_th_all_extracted_reconstructions['wave_shared_resp_1']['labels'], return_counts = True)}\\n\")\n",
    "\n",
    "Baseline in TH_1:, (array(['0'], dtype='<U1'), array([51]))\n",
    "\n",
    "Th_Resp in TH_1:, (array(['1'], dtype='<U1'), array([40]))\n",
    "\n",
    "Pt_Resp in TH_1:, (array(['2'], dtype='<U1'), array([40]))\n",
    "\n",
    "Shared_Resp in TH_1:, (array(['3'], dtype='<U1'), array([56]))\n",
    "\n",
    "di conseguenza, nel tuo codice, ho bisogno che\n",
    "\n",
    "le labels associate a 'cond_1' (quando crei la relativa variabile delle due condizioni sperimentali di cui vengono concatenati i dati e le labels) siano riconvertite sempre in '0', mentre\n",
    "\n",
    "le labels associate a 'cond_2' (quando crei la relativa variabile delle due condizioni sperimentali di cui vengono concatenati i dati e le labels) siano riconvertite sempre in '1'\n",
    "\n",
    "questo aspetto è importante, per quando crei le variabili che conterranno le coppie di dati condizioni sperimentali...\n",
    "\n",
    "ora, nel caso in cui tu stia considerando magari baseline vs le altre condizioni sperimentali, che nel caso di \"condition_pairs\" dovrebbe corrispondere ai primi 3 elementi della sua lista no, perché sarebbero \n",
    "\n",
    "[('baseline', 'th_resp'), \n",
    "    ('baseline', 'pt_resp'), \n",
    "    ('baseline', 'shared_resp'), \n",
    "\n",
    "è chiaro che in quel caso specifico, ad esempio, baseline sarà sempre la stringa associata a 'cond_1' e quindi in quel caso sarà sempre 0, e quindi sarebbe apposto..\n",
    "\n",
    "ma per gli altri casi di confronto di baseline rispetto alle altre 3 condizioni sperimentali, è chiaro che se sarà th_resp la condizione di confronto, allora in quel caso di quella specifica variabile, le labels non avranno bisogno di esser diciamo 'ri-convertite' perché già naturalmente diciamo baseline avrà le labels '0' e e th_resp avrà già '1' (come è già originariamente codificato in 'new_subject_level_concatenations'!)\n",
    "\n",
    "ma nel caso delle altre variabili da creare, che fa riferimento a questi altri elementi di \n",
    "\"condition_pairs\" che è creato nel loop ossia\n",
    "\n",
    "('th_resp', 'pt_resp'), \n",
    "('th_resp', 'shared_resp'), \n",
    "('pt_resp', 'shared_resp')]\n",
    "\n",
    "le labels andranno ovviamente riconvertite! Perché? \n",
    "\n",
    "Perché ovviamente nel caso sia la th_resp la 'cond_1', ad esempio, in quel caso, le sue labels (che son originariamente codificate come '1' in 'new_subject_level_concatenations'!) diventeranno '0',\n",
    "\n",
    "mentre le altre condizioni di confronto, una alla volta, diventeranno '1' invece...\n",
    "\n",
    "è chiara diciamo la logica di ri-assegnazione delle relative labels in sostanza?dentro \"# Crea tutte le combinazioni uniche di condizioni sperimentali (es. 'baseline vs th_resp')\n",
    "    condition_pairs = list(itertools.combinations(experimental_conditions, 2))\n",
    "    \"\n",
    "\n",
    "effettivamente vengono create delle tuple di coppie di stringhe che corrispondono a quelle con cui dovrebbero esser create le sotto-sotto-chiavi delle coppie di condizioni sperimentali..\n",
    "\n",
    "tuttavia, è giusto che iteri rispetto a 'condition_pairs', ma deve inserire un qualche controllo anche rispetto a questa cosa:\n",
    "\n",
    "originariamente...\n",
    "\n",
    "new_single_th_all_extracted_reconstructions ha queste labels, che se io le vedo avrò\n",
    "\n",
    "per baseline una serie di 0, per th_resp una serie di 1, per pt_resp, una serie di 2 e per shared_resp una serie di 3, in questo modo\n",
    "\n",
    "print(f\"Baseline in TH_1:, {np.unique(new_single_th_all_extracted_reconstructions['wave_baseline_1']['labels'], return_counts = True)}\\n\") print(f\"Th_Resp in TH_1:, {np.unique(new_single_th_all_extracted_reconstructions['wave_th_resp_1']['labels'], return_counts = True)}\\n\") print(f\"Pt_Resp in TH_1:, {np.unique(new_single_th_all_extracted_reconstructions['wave_pt_resp_1']['labels'], return_counts = True)}\\n\") print(f\"Shared_Resp in TH_1:, {np.unique(new_single_th_all_extracted_reconstructions['wave_shared_resp_1']['labels'], return_counts = True)}\\n\")\n",
    "\n",
    "Baseline in TH_1:, (array(['0'], dtype='<U1'), array([51]))\n",
    "\n",
    "Th_Resp in TH_1:, (array(['1'], dtype='<U1'), array([40]))\n",
    "\n",
    "Pt_Resp in TH_1:, (array(['2'], dtype='<U1'), array([40]))\n",
    "\n",
    "Shared_Resp in TH_1:, (array(['3'], dtype='<U1'), array([56]))\n",
    "\n",
    "di conseguenza, nel tuo codice, ho bisogno che\n",
    "\n",
    "le labels associate a 'cond_1' (quando crei la relativa variabile delle due condizioni sperimentali di cui vengono concatenati i dati e le labels) siano riconvertite sempre in '0', mentre\n",
    "\n",
    "le labels associate a 'cond_2' (quando crei la relativa variabile delle due condizioni sperimentali di cui vengono concatenati i dati e le labels) siano riconvertite sempre in '1'\n",
    "\n",
    "questo aspetto è importante, per quando crei le variabili che conterranno le coppie di dati condizioni sperimentali...\n",
    "\n",
    "ora, nel caso in cui tu stia considerando magari baseline vs le altre condizioni sperimentali, che nel caso di \"condition_pairs\" dovrebbe corrispondere ai primi 3 elementi della sua lista no, perché sarebbero \n",
    "\n",
    "[('baseline', 'th_resp'), \n",
    "    ('baseline', 'pt_resp'), \n",
    "    ('baseline', 'shared_resp'), \n",
    "\n",
    "è chiaro che in quel caso specifico, ad esempio, baseline sarà sempre la stringa associata a 'cond_1' e quindi in quel caso sarà sempre 0, e quindi sarebbe apposto..\n",
    "\n",
    "ma per gli altri casi di confronto di baseline rispetto alle altre 3 condizioni sperimentali, è chiaro che se sarà th_resp la condizione di confronto, allora in quel caso di quella specifica variabile, le labels non avranno bisogno di esser diciamo 'ri-convertite' perché già naturalmente diciamo baseline avrà le labels '0' e e th_resp avrà già '1' (come è già originariamente codificato in 'new_subject_level_concatenations'!)\n",
    "\n",
    "ma nel caso delle altre variabili da creare, che fa riferimento a questi altri elementi di \n",
    "\"condition_pairs\" che è creato nel loop ossia\n",
    "\n",
    "('th_resp', 'pt_resp'), \n",
    "('th_resp', 'shared_resp'), \n",
    "('pt_resp', 'shared_resp')]\n",
    "\n",
    "le labels andranno ovviamente riconvertite! Perché? \n",
    "\n",
    "Perché ovviamente nel caso sia la th_resp la 'cond_1', ad esempio, in quel caso, le sue labels (che son originariamente codificate come '1' in 'new_subject_level_concatenations'!) diventeranno '0',\n",
    "\n",
    "mentre le altre condizioni di confronto, una alla volta, diventeranno '1' invece...\n",
    "\n",
    "è chiara diciamo la logica di ri-assegnazione delle relative labels in sostanza?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b08ad6-1347-4e4a-b24c-a50bd76412c0",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Implementazione STEP - Concatenazione All Single Subject Spectrograms (TH) across Couples of Experimental Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a5a1b2-8dde-4e02-82b5-a00ef299d45c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_single_th_all_extracted_spectrograms_2D_task_1.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52cde87a-f066-4a6d-b150-c0719e5514e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_single_th_all_extracted_spectrograms_2D_task_1['spectrograms_rest_100'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6819e56-8a8d-4882-a135-344594e4cb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(new_single_th_all_extracted_spectrograms_2D_task_1['spectrograms_rest_100'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d78291-0e9a-4a3a-b86b-d0a33880799b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Rest in TH_1:, {np.unique(new_single_th_all_extracted_spectrograms_2D_task_1['spectrograms_rest_100']['labels'], return_counts = True)}\\n\")\n",
    "print(f\"Left_Fist in TH_1:, {np.unique(new_single_th_all_extracted_spectrograms_2D_task_1['spectrograms_left_fist_100']['labels'], return_counts = True)}\\n\")\n",
    "print(f\"Right_Fist in TH_1:, {np.unique(new_single_th_all_extracted_spectrograms_2D_task_1['spectrograms_right_fist_100']['labels'], return_counts = True)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed41ff74-7705-4855-8a9b-4632d3eb408d",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_single_th_all_extracted_spectrograms_2D_task_1['spectrograms_rest_100'].keys()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "79299a9b-bb31-48d5-9752-3d6e487808d3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "source": [
    "'''CODE IMPLEMENTATION - DESCRIZIONE'''\n",
    "\n",
    "# Lista delle stringhe alfabetiche delle condizioni sperimentali,\n",
    "# da controllare dentro \"new_single_th_all_extracted_reconstructions\", che ha queste chiavi\n",
    "\n",
    "#dict_keys(['wave_baseline_1', 'wave_th_resp_1', 'wave_pt_resp_1', 'wave_shared_resp_1', \n",
    "#'wave_baseline_2', 'wave_th_resp_2', 'wave_pt_resp_2', 'wave_shared_resp_2', \n",
    "#'wave_baseline_3', 'wave_th_resp_3', 'wave_pt_resp_3', 'wave_shared_resp_3', \n",
    "#'wave_baseline_4', 'wave_th_resp_4', 'wave_pt_resp_4', 'wave_shared_resp_4',\n",
    "#'wave_baseline_5', 'wave_th_resp_5', 'wave_pt_resp_5', 'wave_shared_resp_5',\n",
    "#'wave_baseline_6', 'wave_th_resp_6', 'wave_pt_resp_6', 'wave_shared_resp_6',\n",
    "#'wave_baseline_7', 'wave_th_resp_7', 'wave_pt_resp_7', 'wave_shared_resp_7',\n",
    "#'wave_baseline_8', 'wave_th_resp_8', 'wave_pt_resp_8', 'wave_shared_resp_8',\n",
    "#'wave_baseline_9', 'wave_th_resp_9', 'wave_pt_resp_9', 'wave_shared_resp_9',\n",
    "#'wave_baseline_10', 'wave_th_resp_10', 'wave_pt_resp_10', 'wave_shared_resp_10',\n",
    "#'wave_baseline_11', 'wave_th_resp_11', 'wave_pt_resp_11', 'wave_shared_resp_11',\n",
    "#'wave_baseline_12', 'wave_th_resp_12', 'wave_pt_resp_12', 'wave_shared_resp_12'])\n",
    "#\n",
    "\n",
    "import itertools\n",
    "import numpy as np\n",
    "\n",
    "experimental_conditions = ['baseline', 'th_resp', 'pt_resp', 'shared_resp']\n",
    "\n",
    "# Nuova variabile per memorizzare i risultati di dati e labels concatenati di coppie di condizioni sperimentali\n",
    "new_subject_level_concatenations_coupled_exp_th = {}\n",
    "\n",
    "# Loop su tutte le chiavi del dizionario iniziale\n",
    "for key in new_single_th_all_extracted_reconstructions.keys():\n",
    "    \n",
    "    '''\n",
    "    Identificazione dinamica delle stringhe numeriche per creare \n",
    "    le chiavi e i nomi delle variabili delle coppie di condizioni sperimentali\n",
    "       \n",
    "    Gestione della stringa numerica che rappresenta un soggetto identificato con ANCHE decine (due cifre):\n",
    "    Aggiunta di una logica che riconosca identificatori numerici di ANCHE due cifre e li gestisca correttamente\n",
    "    '''\n",
    "    \n",
    "    # Identifica il numero del soggetto, considerando sia una cifra che due cifre\n",
    "    \n",
    "    '''\n",
    "    Spiegazione \n",
    "    \n",
    "    1) Gestione delle stringhe numeriche: La logica per estrarre il numero del soggetto usa key.split('_') \n",
    "    per individuare l'ultima parte della chiave\n",
    "    \n",
    "    2) Si verifica se questa parte è composta esclusivamente da cifre con .isdigit()\n",
    "    Questo gestisce sia numeri a una cifra (es. '1') che a due cifre (es. '12')\n",
    "    \n",
    "    '''\n",
    "    key_parts = key.split('_')\n",
    "    subject_number = key_parts[-1] if key_parts[-1].isdigit() else None  # Verifica se è numerico\n",
    "    \n",
    "    # Verifica che il numero del soggetto sia valido\n",
    "    if subject_number is None:\n",
    "        continue  # Salta chiavi non valide\n",
    "    \n",
    "    subject_key = f\"th_{subject_number}\"  # Es. 'th_1' o 'th_12'\n",
    "    \n",
    "    # Inizializza il dizionario per il soggetto se non esiste\n",
    "    \n",
    "    #'''Nuova variabile per appendere i dati e labels concatenati di coppie di condizioni sperimentali:\n",
    "\n",
    "    #I risultati vengono salvati in una nuova variabile denominata \"new_subject_level_concatenations_coupled_exp_th\",\n",
    "    #dove la struttura è analoga a quella precedente, ma separata per scopi distinti.\n",
    "    #'''\n",
    "    \n",
    "    if subject_key not in new_subject_level_concatenations_coupled_exp_th:\n",
    "        new_subject_level_concatenations_coupled_exp_th[subject_key] = {'theta': {}, 'delta': {}, 'theta_strict': {}}\n",
    "    \n",
    "    '''\n",
    "    Qui, creo tutte le combinazioni possibili di coppie di condizioni sperimentali \n",
    "    \n",
    "    In questo caso, applico le regole del calcolo combinatorio, per il quale se hai 4 condizioni,\n",
    "    il numero di combinazioni di coppie di condizioni (senza ripetizioni) si calcola come:\n",
    "    \n",
    "    $$\n",
    "    \\binom{4}{2} = \\frac{4!}{2!(4-2)!} = 6\n",
    "    $$\n",
    "\n",
    "    Quindi, con 4 condizioni sperimentali, le combinazioni di coppie di condizioni saranno 6, e queste coppie sono:\n",
    "\n",
    "    (condizione 1, condizione 2) = 'baseline vs th_resp'\n",
    "    (condizione 1, condizione 3) = 'baseline vs pt_resp'\n",
    "    (condizione 1, condizione 4) = 'baseline vs shared_resp'\n",
    "    (condizione 2, condizione 3) = 'th_resp vs pt_resp'\n",
    "    (condizione 2, condizione 4) = 'th_resp vs shared_resp'\n",
    "    (condizione 3, condizione 4) = 'pt_resp vs shared_resp' \n",
    "\n",
    "    '''\n",
    "    \n",
    "     # Crea tutte le combinazioni uniche di condizioni sperimentali (es. 'baseline vs th_resp')\n",
    "    condition_pairs = list(itertools.combinations(experimental_conditions, 2))\n",
    "    \n",
    "    #print(f\"Condition Pairs are: {condition_pairs}\")\n",
    "    #Condition Pairs are: [('baseline', 'th_resp'), \n",
    "    #('baseline', 'pt_resp'), \n",
    "    #('baseline', 'shared_resp'), \n",
    "    #('th_resp', 'pt_resp'), \n",
    "    #('th_resp', 'shared_resp'), \n",
    "    #('pt_resp', 'shared_resp')]\n",
    "\n",
    "    \n",
    "    # Loop sulle combinazioni\n",
    "    for cond_1, cond_2 in condition_pairs:\n",
    "        \n",
    "            # Crea il nome della variabile per la combinazione\n",
    "            condition_pair_key = f\"{cond_1}_vs_{cond_2}\"\n",
    "            \n",
    "            # Ottieni i dati e le etichette delle due condizioni per ogni livello\n",
    "            for level in ['theta', 'delta', 'theta_strict']:\n",
    "                \n",
    "                # Ottieni i dati e le etichette delle due condizioni\n",
    "                data_cond_1 = new_single_th_all_extracted_reconstructions.get(f\"wave_{cond_1}_{subject_number}\", {}).get(level)\n",
    "                print(f\"data_cond_1 is {cond_1}\\n\")\n",
    "                labels_cond_1 = new_single_th_all_extracted_reconstructions.get(f\"wave_{cond_1}_{subject_number}\", {}).get('labels')\n",
    "                #print(f\"data_cond_1 is {current_condition}\\n\"\n",
    "\n",
    "                data_cond_2 = new_single_th_all_extracted_reconstructions.get(f\"wave_{cond_2}_{subject_number}\", {}).get(level)\n",
    "                print(f\"data_cond_2 is {cond_2}\\n\")\n",
    "                labels_cond_2 = new_single_th_all_extracted_reconstructions.get(f\"wave_{cond_2}_{subject_number}\", {}).get('labels')\n",
    "\n",
    "                # Verifica che i dati siano validi\n",
    "                if data_cond_1 is None or labels_cond_1 is None or data_cond_2 is None or labels_cond_2 is None:\n",
    "                    continue  # Salta combinazioni incomplete\n",
    "\n",
    "                # Riassegna le etichette per garantire che \"cond_1\" = 0 e \"cond_2\" = 1\n",
    "                labels_cond_1 = np.zeros_like(labels_cond_1)  # Tutte 0\n",
    "                labels_cond_2 = np.ones_like(labels_cond_2)   # Tutte 1\n",
    "\n",
    "                # Concatenazione dei dati e delle etichette\n",
    "                concatenated_data = np.vstack((data_cond_1, data_cond_2))\n",
    "                concatenated_labels = np.hstack((labels_cond_1, labels_cond_2))\n",
    "\n",
    "                # Salva i risultati nella struttura\n",
    "                new_subject_level_concatenations_coupled_exp_th[subject_key][level][condition_pair_key] = {\n",
    "                   'data': concatenated_data,\n",
    "                   'labels': concatenated_labels}\n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "id": "faadf735-c1af-4bb4-8a52-7537f06f8852",
   "metadata": {
    "tags": []
   },
   "source": [
    "'''CODE IMPLEMENTATION - PRACTICAL CODE VERSION 1 - SENZA CONSIDERAZIONE DI CHIAVE 'COEFF_FIFTH_DETAIL_THETA'''\n",
    "\n",
    "# Lista delle stringhe alfabetiche delle condizioni sperimentali,\n",
    "# da controllare dentro \"new_single_th_all_extracted_reconstructions\", che ha queste chiavi\n",
    "\n",
    "#dict_keys(['wave_baseline_1', 'wave_th_resp_1', 'wave_pt_resp_1', 'wave_shared_resp_1', \n",
    "#'wave_baseline_2', 'wave_th_resp_2', 'wave_pt_resp_2', 'wave_shared_resp_2', \n",
    "#'wave_baseline_3', 'wave_th_resp_3', 'wave_pt_resp_3', 'wave_shared_resp_3', \n",
    "#'wave_baseline_4', 'wave_th_resp_4', 'wave_pt_resp_4', 'wave_shared_resp_4',\n",
    "#'wave_baseline_5', 'wave_th_resp_5', 'wave_pt_resp_5', 'wave_shared_resp_5',\n",
    "#'wave_baseline_6', 'wave_th_resp_6', 'wave_pt_resp_6', 'wave_shared_resp_6',\n",
    "#'wave_baseline_7', 'wave_th_resp_7', 'wave_pt_resp_7', 'wave_shared_resp_7',\n",
    "#'wave_baseline_8', 'wave_th_resp_8', 'wave_pt_resp_8', 'wave_shared_resp_8',\n",
    "#'wave_baseline_9', 'wave_th_resp_9', 'wave_pt_resp_9', 'wave_shared_resp_9',\n",
    "#'wave_baseline_10', 'wave_th_resp_10', 'wave_pt_resp_10', 'wave_shared_resp_10',\n",
    "#'wave_baseline_11', 'wave_th_resp_11', 'wave_pt_resp_11', 'wave_shared_resp_11',\n",
    "#'wave_baseline_12', 'wave_th_resp_12', 'wave_pt_resp_12', 'wave_shared_resp_12'])\n",
    "#\n",
    "\n",
    "import itertools\n",
    "import numpy as np\n",
    "\n",
    "experimental_conditions = ['baseline', 'th_resp', 'pt_resp', 'shared_resp']\n",
    "\n",
    "# Nuova variabile per memorizzare i risultati di dati e labels concatenati di coppie di condizioni sperimentali\n",
    "new_subject_level_concatenations_coupled_exp_th = {}\n",
    "\n",
    "# Loop su tutte le chiavi del dizionario iniziale\n",
    "for key in new_single_th_all_extracted_reconstructions.keys():\n",
    "    \n",
    "    '''\n",
    "    Identificazione dinamica delle stringhe numeriche per creare \n",
    "    le chiavi e i nomi delle variabili delle coppie di condizioni sperimentali\n",
    "       \n",
    "    Gestione della stringa numerica che rappresenta un soggetto identificato con ANCHE decine (due cifre):\n",
    "    Aggiunta di una logica che riconosca identificatori numerici di ANCHE due cifre e li gestisca correttamente\n",
    "    '''\n",
    "    \n",
    "    # Identifica il numero del soggetto, considerando sia una cifra che due cifre\n",
    "    \n",
    "    '''\n",
    "    Spiegazione \n",
    "    \n",
    "    1) Gestione delle stringhe numeriche: La logica per estrarre il numero del soggetto usa key.split('_') \n",
    "    per individuare l'ultima parte della chiave\n",
    "    \n",
    "    2) Si verifica se questa parte è composta esclusivamente da cifre con .isdigit()\n",
    "    Questo gestisce sia numeri a una cifra (es. '1') che a due cifre (es. '12')\n",
    "    \n",
    "    '''\n",
    "    key_parts = key.split('_')\n",
    "    subject_number = key_parts[-1] if key_parts[-1].isdigit() else None  # Verifica se è numerico\n",
    "    \n",
    "    # Verifica che il numero del soggetto sia valido\n",
    "    if subject_number is None:\n",
    "        continue  # Salta chiavi non valide\n",
    "    \n",
    "    subject_key = f\"th_{subject_number}\"  # Es. 'th_1' o 'th_12'\n",
    "    \n",
    "    # Inizializza il dizionario per il soggetto se non esiste\n",
    "    \n",
    "    #'''Nuova variabile per appendere i dati e labels concatenati di coppie di condizioni sperimentali:\n",
    "\n",
    "    #I risultati vengono salvati in una nuova variabile denominata \"new_subject_level_concatenations_coupled_exp_th\",\n",
    "    #dove la struttura è analoga a quella precedente, ma separata per scopi distinti.\n",
    "    #'''\n",
    "    \n",
    "    if subject_key not in new_subject_level_concatenations_coupled_exp_th:\n",
    "        new_subject_level_concatenations_coupled_exp_th[subject_key] = {'theta': {}, 'delta': {}, 'coeff_fifth_detail_theta': {}}\n",
    "    \n",
    "    '''\n",
    "    Qui, creo tutte le combinazioni possibili di coppie di condizioni sperimentali \n",
    "    \n",
    "    In questo caso, applico le regole del calcolo combinatorio, per il quale se hai 4 condizioni,\n",
    "    il numero di combinazioni di coppie di condizioni (senza ripetizioni) si calcola come:\n",
    "    \n",
    "    $$\n",
    "    \\binom{4}{2} = \\frac{4!}{2!(4-2)!} = 6\n",
    "    $$\n",
    "\n",
    "    Quindi, con 4 condizioni sperimentali, le combinazioni di coppie di condizioni saranno 6, e queste coppie sono:\n",
    "\n",
    "    (condizione 1, condizione 2) = 'baseline vs th_resp'\n",
    "    (condizione 1, condizione 3) = 'baseline vs pt_resp'\n",
    "    (condizione 1, condizione 4) = 'baseline vs shared_resp'\n",
    "    (condizione 2, condizione 3) = 'th_resp vs pt_resp'\n",
    "    (condizione 2, condizione 4) = 'th_resp vs shared_resp'\n",
    "    (condizione 3, condizione 4) = 'pt_resp vs shared_resp' \n",
    "\n",
    "    '''\n",
    "    \n",
    "    # Crea tutte le combinazioni uniche di condizioni sperimentali (es. 'baseline vs th_resp')\n",
    "    condition_pairs = list(itertools.combinations(experimental_conditions, 2))\n",
    "    \n",
    "    #print(f\"Condition Pairs are: {condition_pairs}\")\n",
    "    #Condition Pairs are: [('baseline', 'th_resp'), \n",
    "    #('baseline', 'pt_resp'), \n",
    "    #('baseline', 'shared_resp'), \n",
    "    #('th_resp', 'pt_resp'), \n",
    "    #('th_resp', 'shared_resp'), \n",
    "    #('pt_resp', 'shared_resp')]\n",
    "\n",
    "    \n",
    "    # Loop sulle combinazioni\n",
    "    for cond_1, cond_2 in condition_pairs:\n",
    "        \n",
    "            # Crea il nome della variabile per la combinazione\n",
    "            condition_pair_key = f\"{cond_1}_vs_{cond_2}\"\n",
    "            \n",
    "            # Ottieni i dati e le etichette delle due condizioni per ogni livello\n",
    "            for level in ['theta', 'delta', 'coeff_fifth_detail_theta']:\n",
    "                \n",
    "                # Ottieni i dati e le etichette delle due condizioni\n",
    "                data_cond_1 = new_single_th_all_extracted_reconstructions.get(f\"wave_{cond_1}_{subject_number}\", {}).get(level)\n",
    "                print(f\"data_cond_1 is {cond_1}\\n\")\n",
    "                labels_cond_1 = new_single_th_all_extracted_reconstructions.get(f\"wave_{cond_1}_{subject_number}\", {}).get('labels')\n",
    "                #print(f\"data_cond_1 is {current_condition}\\n\"\n",
    "\n",
    "                data_cond_2 = new_single_th_all_extracted_reconstructions.get(f\"wave_{cond_2}_{subject_number}\", {}).get(level)\n",
    "                print(f\"data_cond_2 is {cond_2}\\n\")\n",
    "                labels_cond_2 = new_single_th_all_extracted_reconstructions.get(f\"wave_{cond_2}_{subject_number}\", {}).get('labels')\n",
    "\n",
    "                # Verifica che i dati siano validi\n",
    "                if data_cond_1 is None or labels_cond_1 is None or data_cond_2 is None or labels_cond_2 is None:\n",
    "                    continue  # Salta combinazioni incomplete\n",
    "\n",
    "                # Riassegna le etichette per garantire che \"cond_1\" = 0 e \"cond_2\" = 1\n",
    "                labels_cond_1 = np.zeros_like(labels_cond_1, dtype=int)  # Tutte 0\n",
    "                labels_cond_2 = np.ones_like(labels_cond_2, dtype=int)   # Tutte 1\n",
    "\n",
    "                # Concatenazione dei dati e delle etichette\n",
    "                concatenated_data = np.vstack((data_cond_1, data_cond_2))\n",
    "                concatenated_labels = np.hstack((labels_cond_1, labels_cond_2))\n",
    "\n",
    "                # Salva i risultati nella struttura\n",
    "                new_subject_level_concatenations_coupled_exp_th[subject_key][level][condition_pair_key] = {\n",
    "                   'data': concatenated_data,\n",
    "                   'labels': concatenated_labels}\n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "id": "e27c9b38-43fe-44bf-b264-0f041f4cbc95",
   "metadata": {
    "tags": []
   },
   "source": [
    "'''CLEARER VERSION WITHOUT COMPLICATED PRINTS'''\n",
    "\n",
    "import itertools\n",
    "import numpy as np\n",
    "\n",
    "experimental_conditions = ['baseline', 'th_resp', 'pt_resp', 'shared_resp']\n",
    "\n",
    "# Nuova variabile per memorizzare i risultati di dati e labels concatenati di coppie di condizioni sperimentali\n",
    "new_subject_level_concatenations_coupled_exp_th = {}\n",
    "\n",
    "# Loop su tutte le chiavi del dizionario iniziale\n",
    "for key in new_single_th_all_extracted_reconstructions.keys():\n",
    "\n",
    "    key_parts = key.split('_')\n",
    "    subject_number = key_parts[-1] if key_parts[-1].isdigit() else None  # Verifica se è numerico\n",
    "    \n",
    "    # Verifica che il numero del soggetto sia valido\n",
    "    if subject_number is None:\n",
    "        continue  # Salta chiavi non valide\n",
    "    \n",
    "    subject_key = f\"th_{subject_number}\"  # Es. 'th_1' o 'th_12'\n",
    "\n",
    "    # Inizializza la struttura se non esiste ancora\n",
    "    if subject_key not in new_subject_level_concatenations_coupled_exp_th:\n",
    "        new_subject_level_concatenations_coupled_exp_th[subject_key] = {'theta': {}, 'delta': {}, 'theta_strict': {}}\n",
    "    \n",
    "    # Crea tutte le combinazioni uniche di condizioni sperimentali (es. 'baseline vs th_resp')\n",
    "    condition_pairs = list(itertools.combinations(experimental_conditions, 2))\n",
    "\n",
    "    # Loop sulle combinazioni\n",
    "    for cond_1, cond_2 in condition_pairs:\n",
    "        \n",
    "        # Crea il nome della variabile per la combinazione\n",
    "        condition_pair_key = f\"{cond_1}_vs_{cond_2}\"\n",
    "        \n",
    "        # Ottieni i dati e le etichette delle due condizioni per ogni livello\n",
    "        for level in ['theta', 'delta', 'coeff_fifth_detail_theta']:\n",
    "            \n",
    "            # Gestisci il caso per 'coeff_fifth_detail_theta'\n",
    "            if level == 'coeff_fifth_detail_theta':\n",
    "                # Ottieni i dati e le etichette per il livello coeff_fifth_detail_theta\n",
    "                data_cond_1 = new_single_th_all_extracted_reconstructions.get(f\"wave_{cond_1}_{subject_number}\", {}).get(level)\n",
    "                #print(f\"data_cond_1 is {cond_1} (coeff_fifth_detail_theta)\\n\")\n",
    "                labels_cond_1 = new_single_th_all_extracted_reconstructions.get(f\"wave_{cond_1}_{subject_number}\", {}).get('labels')\n",
    "                \n",
    "                data_cond_2 = new_single_th_all_extracted_reconstructions.get(f\"wave_{cond_2}_{subject_number}\", {}).get(level)\n",
    "                #print(f\"data_cond_2 is {cond_2} (coeff_fifth_detail_theta)\\n\")\n",
    "                labels_cond_2 = new_single_th_all_extracted_reconstructions.get(f\"wave_{cond_2}_{subject_number}\", {}).get('labels')\n",
    "            else:\n",
    "                # Ottieni i dati e le etichette per gli altri livelli (theta, delta)\n",
    "                data_cond_1 = new_single_th_all_extracted_reconstructions.get(f\"wave_{cond_1}_{subject_number}\", {}).get(level)\n",
    "                #rint(f\"data_cond_1 is {cond_1}\\n\")\n",
    "                labels_cond_1 = new_single_th_all_extracted_reconstructions.get(f\"wave_{cond_1}_{subject_number}\", {}).get('labels')\n",
    "                \n",
    "                data_cond_2 = new_single_th_all_extracted_reconstructions.get(f\"wave_{cond_2}_{subject_number}\", {}).get(level)\n",
    "                #print(f\"data_cond_2 is {cond_2}\\n\")\n",
    "                labels_cond_2 = new_single_th_all_extracted_reconstructions.get(f\"wave_{cond_2}_{subject_number}\", {}).get('labels')\n",
    "\n",
    "            # Verifica che i dati siano validi\n",
    "            if data_cond_1 is None or labels_cond_1 is None or data_cond_2 is None or labels_cond_2 is None:\n",
    "                continue  # Salta combinazioni incomplete\n",
    "\n",
    "            # Riassegna le etichette per garantire che \"cond_1\" = 0 e \"cond_2\" = 1\n",
    "            labels_cond_1 = np.zeros_like(labels_cond_1, dtype=int)  # Tutte 0\n",
    "            labels_cond_2 = np.ones_like(labels_cond_2, dtype=int)   # Tutte 1\n",
    "\n",
    "            # Concatenazione dei dati e delle etichette\n",
    "            concatenated_data = np.vstack((data_cond_1, data_cond_2))\n",
    "            concatenated_labels = np.hstack((labels_cond_1, labels_cond_2))\n",
    "\n",
    "            # Salva i risultati nella struttura\n",
    "            if level == 'coeff_fifth_detail_theta':\n",
    "                # Salva i dati sotto 'theta_strict' per 'coeff_fifth_detail_theta'\n",
    "                new_subject_level_concatenations_coupled_exp_th[subject_key]['theta_strict'][condition_pair_key] = {\n",
    "                    'data': concatenated_data,\n",
    "                    'labels': concatenated_labels}\n",
    "            else:\n",
    "                # Salva i dati sotto i livelli 'theta' o 'delta'\n",
    "                new_subject_level_concatenations_coupled_exp_th[subject_key][level][condition_pair_key] = {\n",
    "                    'data': concatenated_data,\n",
    "                    'labels': concatenated_labels}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0601eea9-30ab-4a3b-8bfb-7d3985287cfe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''DETAILED VERSION WITH COMPLICATED PRINTS\n",
    "\n",
    "    CORREZIONE UFFICIALE PER SPETTROGRAMS\n",
    "'''\n",
    "\n",
    "\n",
    "import itertools\n",
    "import numpy as np\n",
    "\n",
    "# Definizione delle condizioni sperimentali\n",
    "#experimental_conditions = ['baseline', 'th_resp', 'pt_resp', 'shared_resp']\n",
    "\n",
    "'''UNICA MODIFICA PER DATASET MOTOR TASK'''\n",
    "experimental_conditions = ['rest', 'left_fist', 'right_fist']\n",
    "\n",
    "# Variabile per tenere traccia del soggetto corrente (per output facoltativo)\n",
    "last_subject_key = None\n",
    "\n",
    "# Dizionario per tenere traccia delle combinazioni già elaborate per ogni soggetto (evitare duplicati)\n",
    "printed_combinations = {}\n",
    "\n",
    "# Nuovo dizionario per memorizzare i risultati concatenati per coppia di condizioni per ogni soggetto\n",
    "new_subject_level_concatenations_spectrograms_coupled_exp_th_task_1 = {}\n",
    "\n",
    "# Itera su tutte le chiavi del dizionario di partenza\n",
    "for key in new_single_th_all_extracted_spectrograms_2D_task_1.keys():\n",
    "    # Esempio di key: \"spectrograms_baseline_1\", \"spectrograms_th_resp_1\", etc.\n",
    "    key_parts = key.split('_')\n",
    "    subject_number = key_parts[-1] if key_parts[-1].isdigit() else None\n",
    "    if subject_number is None:\n",
    "        continue  # Salta eventuali chiavi non valide\n",
    "    \n",
    "    # Crea il nome del soggetto (es. \"th_1\")\n",
    "    subject_key = f\"th_{subject_number}\"\n",
    "    \n",
    "    # Se cambiamo soggetto, stampiamo (facoltativo)\n",
    "    if subject_key != last_subject_key:\n",
    "        if last_subject_key is not None:\n",
    "            print(\"\\n\" + \"-\" * 50 + f\" END OF {last_subject_key.upper()} \" + \"-\" * 50 + \"\\n\")\n",
    "        print(f\"\\nProcessing Subject: {subject_key}\\n\" + \"=\" * 80)\n",
    "        printed_combinations[subject_key] = set()  # Inizializza il set per il soggetto corrente\n",
    "    last_subject_key = subject_key\n",
    "\n",
    "    # Inizializza la struttura per il soggetto se non esiste già\n",
    "    if subject_key not in new_subject_level_concatenations_spectrograms_coupled_exp_th_task_1:\n",
    "        new_subject_level_concatenations_spectrograms_coupled_exp_th_task_1[subject_key] = {}\n",
    "\n",
    "    # Crea tutte le combinazioni uniche di condizioni sperimentali (es. \"baseline_vs_th_resp\")\n",
    "    condition_pairs = list(itertools.combinations(experimental_conditions, 2))\n",
    "    \n",
    "    # Loop sulle coppie di condizioni\n",
    "    for cond_1, cond_2 in condition_pairs:\n",
    "        condition_pair_key = f\"{cond_1}_vs_{cond_2}\"\n",
    "        if condition_pair_key in printed_combinations[subject_key]:\n",
    "            continue  # Salta se già elaborata per questo soggetto\n",
    "        \n",
    "        print(f\"\\n\\tCreation of Coupled Condition: \\033[1m{condition_pair_key}\\033[0m\")\n",
    "        printed_combinations[subject_key].add(condition_pair_key)\n",
    "        \n",
    "        # Estrai i dati e le etichette per la prima condizione\n",
    "        data_cond_1 = new_single_th_all_extracted_spectrograms_2D_task_1.get(f\"spectrograms_{cond_1}_{subject_number}\", {}).get('spectrograms')\n",
    "        labels_cond_1 = new_single_th_all_extracted_spectrograms_2D_task_1.get(f\"spectrograms_{cond_1}_{subject_number}\", {}).get('labels')\n",
    "        \n",
    "        # Estrai i dati e le etichette per la seconda condizione\n",
    "        data_cond_2 = new_single_th_all_extracted_spectrograms_2D_task_1.get(f\"spectrograms_{cond_2}_{subject_number}\", {}).get('spectrograms')\n",
    "        labels_cond_2 = new_single_th_all_extracted_spectrograms_2D_task_1.get(f\"spectrograms_{cond_2}_{subject_number}\", {}).get('labels')\n",
    "        \n",
    "        # Salta la coppia se uno dei dati non è presente\n",
    "        if data_cond_1 is None or labels_cond_1 is None or data_cond_2 is None or labels_cond_2 is None:\n",
    "            continue\n",
    "        \n",
    "        # Riassegna le etichette: tutti 0 per cond_1, tutti 1 per cond_2\n",
    "        labels_cond_1 = np.zeros_like(labels_cond_1, dtype=int)\n",
    "        labels_cond_2 = np.ones_like(labels_cond_2, dtype=int)\n",
    "        \n",
    "        # Concatenazione dei dati (verticale) e delle etichette (orizzontale)\n",
    "        concatenated_data = np.concatenate((data_cond_1, data_cond_2), axis=0)\n",
    "        concatenated_labels = np.concatenate((labels_cond_1, labels_cond_2), axis=0)\n",
    "        \n",
    "        # Salva il risultato per questa coppia nel dizionario del soggetto\n",
    "        new_subject_level_concatenations_spectrograms_coupled_exp_th_task_1[subject_key][condition_pair_key] = {\n",
    "            'data': concatenated_data,\n",
    "            'labels': concatenated_labels\n",
    "        }\n",
    "        \n",
    "        print(f\"Condition pair '{condition_pair_key}' for subject {subject_key} => Data shape: {concatenated_data.shape}, Labels length: {len(concatenated_labels)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064fcada-60ff-4e89-8de8-93bd0d3eb8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('finito')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00909d49-d5a9-459d-a75c-fa428fc36585",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\t\\t\\t\\t\\033[1mStructure of new_subject_level_concatenations_spectrograms_coupled_exp_th_task_1\\033[0m: \\n\")\n",
    "print(f\"\\033[1mFirst Order Keys\\033[0m: {new_subject_level_concatenations_spectrograms_coupled_exp_th_task_1.keys()}\\n\")\n",
    "print(f\"\\033[1mSecond Order Keys\\033[0m: {new_subject_level_concatenations_spectrograms_coupled_exp_th_task_1['th_1'].keys()}\\n\")\n",
    "print(f\"\\033[1mThird Order Keys\\033[0m: \\n{new_subject_level_concatenations_spectrograms_coupled_exp_th_task_1['th_1']['rest_vs_left_fist'].keys()}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a21e12-c81a-4f25-9921-00190c18b90c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''VERIFICO CHE LA CONCATENAZIONE SIA AVVENUTA CORRETTAMENTE!\n",
    "\n",
    "    CORREZIONE UFFICIALE PER SPETTROGRAMS\n",
    "'''\n",
    "\n",
    "print(\"\\tNOW, LET US SEE IF THE CONCATENATIONS RESPECT THE ORIGINAL SHAPES FOR EVERY COUPLED EXPERIMENTAL CONDITION!\")\n",
    "print(\"\\tFOR THE 1°ST SUBJECT: CHECK IF THE SUM OF INDIVIDUAL EXP COND SHAPE MATCHES THE COUPLED COND CONCATENATION SHAPE:\\n\\n\")\n",
    "\n",
    "print(\"\\033[1mINDIVIDUAL EXP COND SHAPE OF FIRST SUBJECT\\033[0m:\")\n",
    "\n",
    "# Verifica delle dimensioni originali per le singole condizioni sperimentali\n",
    "\n",
    "#for cond in ['baseline', 'th_resp', 'pt_resp', 'shared_resp']:\n",
    "for cond in ['rest', 'left_fist', 'right_fist']:    \n",
    "    \n",
    "    key = f'spectrograms_{cond}_1'\n",
    "    if key in new_single_th_all_extracted_spectrograms_2D_task_1:\n",
    "        unique_labels, counts = np.unique(new_single_th_all_extracted_spectrograms_2D_task_1[key]['labels'], return_counts=True)\n",
    "        print(f\"{cond.capitalize()} in TH_1: {unique_labels}, Counts: {counts}\\n\")\n",
    "    else:\n",
    "        print(f\"Warning: {key} not found in new_single_th_all_extracted_spectrograms_2D_task_1\\n\")\n",
    "\n",
    "# Seleziona il primo soggetto (ad esempio, 'th_1')\n",
    "subject_key = 'th_1'\n",
    "\n",
    "# Itera per ogni coppia di condizioni sperimentali direttamente (senza livelli)\n",
    "for condition_pair_key, data_labels in new_subject_level_concatenations_spectrograms_coupled_exp_th_task_1.get(subject_key, {}).items():\n",
    "    \n",
    "    # Estrarre dati e labels dalla struttura corretta\n",
    "    data = data_labels['data']\n",
    "    labels = data_labels['labels']\n",
    "\n",
    "    # Stampare il nome della coppia di condizioni e le loro dimensioni\n",
    "    print(f\"Condition Pair: \\033[1m{condition_pair_key}\\033[0m\")\n",
    "    \n",
    "    if data is not None and labels is not None:\n",
    "        print(f\"  Data Shape: {data.shape}\")\n",
    "        print(f\"  Labels Shape: {labels.shape}\")\n",
    "    else:\n",
    "        print(\"  Missing data or labels!\")\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb9726d-c75d-4103-9378-0a8a389d4346",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.unique(new_subject_level_concatenations_spectrograms_coupled_exp_th_task_1['th_1']['rest_vs_left_fist']['labels'], return_counts = True))\n",
    "print(np.unique(new_subject_level_concatenations_spectrograms_coupled_exp_th_task_1['th_1']['rest_vs_right_fist']['labels'], return_counts = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975150c9-61aa-43b4-aaa0-192f2e72850f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\t\\t\\t\\033[1mREST_VS_LEFT_FIST\\033[0m\\n\")\n",
    "print(new_subject_level_concatenations_spectrograms_coupled_exp_th_task_1['th_1']['rest_vs_left_fist']['labels'][:44])\n",
    "print(new_subject_level_concatenations_spectrograms_coupled_exp_th_task_1['th_1']['rest_vs_left_fist']['labels'][44:])\n",
    "print()\n",
    "print()\n",
    "print(f\"\\t\\t\\t\\033[1mREST_VS_RIGHT_FIST\\033[0m\\n\")\n",
    "print(new_subject_level_concatenations_spectrograms_coupled_exp_th_task_1['th_1']['rest_vs_right_fist']['labels'][:44])\n",
    "print(new_subject_level_concatenations_spectrograms_coupled_exp_th_task_1['th_1']['rest_vs_right_fist']['labels'][44:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eedfd131-60a2-4bbf-ba19-cc6a38a77936",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### STEP - Salvataggio Dataset di All Single Therapists EEG Data Spectrograms across Couples of Experimental Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe049fe-da29-4491-931b-bcd4b7e49de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca2bf24-a95f-44e9-bc44-4aa3ff44de18",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '/home/stefano/Interrogait/all_datas/Spectrograms_motor_tasks/'\n",
    "\n",
    "# Controlla se la cartella esiste, altrimenti la crea\n",
    "if not os.path.exists(base_path):\n",
    "    os.makedirs(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04aa7dd3-7545-4c05-a313-e6cb1082065d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Salvare l'intero dizionario annidato con pickle\n",
    "with open(f'{base_path}new_subject_level_concatenations_spectrograms_coupled_exp_th_task_1.pkl', 'wb') as f:\n",
    "    pickle.dump(new_subject_level_concatenations_spectrograms_coupled_exp_th_task_1, f)\n",
    "    print(f\"✅ Dati salvati in: {base_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4757300-e0ee-4cb8-9c8d-3ab2ca7c5111",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### **Concatenazione** **ALL** Single Subject **Spectrograms (TH)** per **Coppie di Condizioni Sperimentali INSIEME**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439c88ef-77e7-48f8-ba67-20331a1b325d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Library Importing \n",
    "    \n",
    "import os\n",
    "import math\n",
    "import copy as cp \n",
    "\n",
    "import tqdm\n",
    "\n",
    "#import mne \n",
    "import scipy\n",
    "\n",
    "import numpy as np  # NumPy per operazioni numeriche\n",
    "import matplotlib.pyplot as plt  # Matplotlib per la isualizzazione dei dati\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import pickle\n",
    "\n",
    "import os \n",
    "\n",
    "base_path = '/home/stefano/Interrogait/all_datas/Spectrograms_motor_tasks/'\n",
    "\n",
    "# Controlla se la cartella esiste, altrimenti la crea\n",
    "if not os.path.exists(base_path):\n",
    "    os.makedirs(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a50fbb-215d-40ce-a323-3b3eac890945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caricare l'intero dizionario annidato con pickle\n",
    "with open(f'{base_path}/new_subject_level_concatenations_spectrograms_coupled_exp_th_task_1.pkl', 'rb') as f:\n",
    "    new_subject_level_concatenations_spectrograms_coupled_exp_th_task_1 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae08f814-f389-47c9-814a-28e7949e52f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_subject_level_concatenations_spectrograms_coupled_exp_th.keys()\n",
    "#new_subject_level_concatenations_spectrograms_coupled_exp_th['th_1'].keys()\n",
    "#new_subject_level_concatenations_spectrograms_coupled_exp_th['th_1']['theta'].keys()\n",
    "#new_subject_level_concatenations_spectrograms_coupled_exp_th['th_1']['theta']['baseline_vs_th_resp'].keys()\n",
    "#np.unique(new_subject_level_concatenations_spectrograms_coupled_exp_th['th_1']['theta']['baseline_vs_th_resp']['labels'], return_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91c4615-f65c-497a-aa8e-7c701c0565dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(new_subject_level_concatenations_spectrograms_coupled_exp_th_task_1['th_1']['rest_vs_left_fist']['labels'], return_counts = True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0c573c61-7942-4b56-accb-889bf56f9fb6",
   "metadata": {
    "tags": []
   },
   "source": [
    "##NEW OFFICIAL VERSION!\n",
    "\n",
    "#SENZA DICT_NAME!\n",
    "\n",
    "\n",
    "'''CODICE DI PARTENZA PER MODIFICHE A SPETTROGRAMMI'''\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def concatenate_all_single_subj_wavelets_coupled_experimental_conditions_th(data_structure, wavelet_levels, conditions):\n",
    "    \n",
    "    \"\"\"\n",
    "    Concatena i dati e le etichette per ogni condizione sperimentale da una struttura dati con un livello in più,\n",
    "    dove questo livello rappresenta le diverse coppie di condizioni sperimentali iterate nel ciclo ossia\n",
    "    \n",
    "    'baseline_vs_th_resp', 'baseline_vs_pt_resp', 'baseline_vs_shared_resp', \n",
    "    'th_resp_vs_pt_resp', 'th_resp_vs_shared_resp', 'pt_resp_vs_shared_resp'\n",
    "    \n",
    "    ordinandoli anche per etichetta.\n",
    "    \n",
    "    Questo perché ogni array di labels avrà sempre o 0 od 1 come etichette,\n",
    "    dato che son coppie di condizioni sperimentali\n",
    "\n",
    "    Parameters:\n",
    "        data_structure (dict): La struttura dati di input che contiene i dati per soggetti e condizioni.\n",
    "        conditions (list): Le condizioni sperimentali (chiavi del secondo livello) da processare.\n",
    "        \n",
    "\n",
    "    Returns:\n",
    "        dict: Un dizionario contenente i nuovi dizionari con \n",
    "        i dati concatenati e le etichette per ogni coppia di condizioni sperimentali\n",
    "    \n",
    "    \"\"\"\n",
    "        \n",
    "        \n",
    "    # Dizionario per contenere i dati concatenati di tutti i soggetti\n",
    "    all_subj_data_by_coupled_cond = {}\n",
    "    \n",
    "    # Itera su ogni livello di ricostruzione wavelet ('theta', 'delta', 'theta_strict')\n",
    "    \n",
    "    for reconstruction_level in wavelet_levels:\n",
    "        \n",
    "        all_subj_data_by_coupled_cond[reconstruction_level] = {}  # Struttura annidata per livello\n",
    "\n",
    "        # Itera su ogni coppia di condizioni sperimentali\n",
    "        for condition_pair in conditions:\n",
    "            \n",
    "            #Dizionari per raccogliere dati e labels ordinati per ogni coppia di condizioni sperimentali\n",
    "            # che è dinamico, per ogni coppia di condizioni sperimentali \n",
    "            #(quindi si ricreeranno passando alla condizione sperimentale successiva!)\n",
    "            \n",
    "            data_by_label = {}\n",
    "            labels_by_label = {}\n",
    "            shape_labels_per_subject = {0: [], 1: []}  # Inizializza il dizionario per 0 e 1\n",
    "\n",
    "            # Itera su tutti i soggetti\n",
    "            # In questo caso, itera sulle chiavi di ogni soggetto\n",
    "\n",
    "            # Quindi prenderà, per la relativa coppia di condizioni sperimentali di ogni soggetto,\n",
    "            # i dati e le labels di quel soggetto, per quella relativa coppia di condizioni sperimentali\n",
    "            \n",
    "            for subject_key in data_structure.keys():\n",
    "                \n",
    "                # Controlla se il livello di ricostruzione esiste per il soggetto\n",
    "                if reconstruction_level not in data_structure[subject_key]:\n",
    "                    continue\n",
    "                    \n",
    "                # Controlla se il livello di ricostruzione esiste per il soggetto\n",
    "                if condition_pair not in data_structure[subject_key][reconstruction_level]:\n",
    "                    continue\n",
    "                \n",
    "                # Qui estrae i dati e le labels per questa condizione sperimentale di quel soggettio lì\n",
    "                subject_data = data_structure[subject_key][reconstruction_level][condition_pair]['data']\n",
    "                subject_labels = data_structure[subject_key][reconstruction_level][condition_pair]['labels']\n",
    "                \n",
    "                # Trova le etichette uniche e gli indici corrispondenti per quella coppia di condizioni sperimentali lì,\n",
    "                # Ossia, potrà trovare gli 0 e gli 1 \n",
    "                \n",
    "                unique_labels = np.unique(subject_labels)\n",
    "                \n",
    "                #A quel punto, per ognuna delle due labels trovate per quella coppia di condizioni sperimentali lì\n",
    "                #Che saranno sempre o 0 o 1\n",
    "                \n",
    "                for label in unique_labels:\n",
    "                    \n",
    "                    # Trova gli indici dei dati corrispondenti a questa etichetta\n",
    "                    # Una volta per lo 0 ed una volta per l' 1\n",
    "                    \n",
    "                    label_indices = np.where(subject_labels == label)[0]\n",
    "                    \n",
    "                    # A quel punto, estrae i dati e le labels per questi indici\n",
    "                    # Una volta per lo 0 ed una volta per l' 1\n",
    "                    \n",
    "                    data_for_label = subject_data[label_indices]\n",
    "                    labels_for_label = subject_labels[label_indices]\n",
    "                    \n",
    "                    # A quel punto, per ogni soggetto, per ogni condzione sperimentale, \n",
    "                    # per quelle due labels là (sempre presenti, per ogni coppia di condizioni sperimentali)\n",
    "                    # Una volta per lo 0 ed una volta per l' 1\n",
    "\n",
    "                    #Andrà a creare per ogni etichetta, una chiave che si chiamerà \n",
    "                    #o 0 od 1 (inizialmente, vuoto -> perché deve esser inizializzato)\n",
    "                    #E poi, dopo, ci appenderà le labels \n",
    "                     # Una volta per lo 0 ed una volta per l' 1\n",
    "                    #  Di quel soggetto per quella coppia di condizioni sperimentali iterate a quel momento\n",
    "                    \n",
    "                    #Aggiunge ai dizionari globali, creando la chiave se non esiste\n",
    "                    if label not in data_by_label:\n",
    "                        data_by_label[label] = []\n",
    "                        labels_by_label[label] = []\n",
    "\n",
    "                    data_by_label[label].append(data_for_label)\n",
    "                    labels_by_label[label].append(labels_for_label)\n",
    "                    \n",
    "                    # **Salva la shape delle etichette per il soggetto corrente**\n",
    "                    shape_labels_per_subject[label].append(labels_for_label.shape[0]) # Aggiungi solo la dimensione (numero di etichette)\n",
    "                    \n",
    "                    '''PRINT PER CHECK LABELS DI OGNI SOGGETTO PER OGNI COPPIA DI CONDIZIONE CONDIZIONI SPERIMENTALI''' \n",
    "                    #print(f\"Soggetto: \\033[1m{subject_key}\\033[0m, Livello: \\033[1m{reconstruction_level}\\033[0m, Condizione: \\033[1m{condition_pair}\\033[0m, \"\n",
    "                    #      f\"Etichetta: \\033[1m{label}\\033[0m, Shape: \\033[1m{labels_for_label.shape[0]}\\033[0m\")\n",
    "                    \n",
    "                    # **Aggiungi un print di controllo per ogni soggetto**\n",
    "                    #print(f\"Soggetto: \\033[1m{subject_key}\\033[1m, Livello: {reconstruction_level}, Condizione: {condition_pair}, Etichetta: {label}, Shape: {labels_for_label.shape[0]}\")\n",
    "            \n",
    "            \n",
    "            #*** *** *** *** *** *** *** *** *** *** *** *** *** *** ***\n",
    "            \n",
    "            # Dopodiché, vado a creare invece i dizionari che conterranno\n",
    "            # Le concatenazioni, di dati e labels corrispondenti, di tutti i soggetti per cui l'etichetta era \n",
    "            # o 0 od 1 \n",
    "\n",
    "            # Di conseguenza, qui dentro dovrei avere, per ogni coppia di condizioni sperimentali\n",
    "            # Tutti gli 0 ed 1 (ed i relativi dati corrispondenti)\n",
    "            # di tutti i soggetti, ma concatenati\n",
    "\n",
    "            concatenated_data_by_label = {}\n",
    "            concatenated_labels_by_label = {}\n",
    "\n",
    "            #for label in data_by_label.keys():\n",
    "            #    if len(data_by_label[label]) > 0:  # Evita errori di concatenazione\n",
    "            #        concatenated_data_by_label[label] = np.vstack(data_by_label[label])\n",
    "            #        concatenated_labels_by_label[label] = np.hstack(labels_by_label[label])\n",
    "            \n",
    "            for label in data_by_label.keys():\n",
    "                concatenated_data_by_label[label] = np.vstack(data_by_label[label])\n",
    "                concatenated_labels_by_label[label] = np.hstack(labels_by_label[label])\n",
    "\n",
    "                # **Calcolare la shape totale delle etichette**\n",
    "                #total_labels_0 = np.sum(1 for subject_labels in labels_by_label[label] if 0 in subject_labels)\n",
    "                #total_labels_1 = np.sum(1 for subject_labels in labels_by_label[label] if 1 in subject_labels)\n",
    "                #total_labels = total_labels_0 + total_labels_1\n",
    "\n",
    "                # **Determinare gli indici delle etichette 0 e 1 nell'array finale**\n",
    "\n",
    "                # Gli indici delle etichette 0\n",
    "                indices_labels_0 = np.where(concatenated_labels_by_label[label] == 0)[0]\n",
    "\n",
    "                # Gli indici delle etichette 1\n",
    "                indices_labels_1 = np.where(concatenated_labels_by_label[label] == 1)[0]\n",
    "                \n",
    "                # Indici iniziale e finale per le etichette 0 e 1\n",
    "                start_idx_0 = indices_labels_0[0] if len(indices_labels_0) > 0 else None\n",
    "                end_idx_0 = indices_labels_0[-1] if len(indices_labels_0) > 0 else None\n",
    "                start_idx_1 = indices_labels_1[0] if len(indices_labels_1) > 0 else None\n",
    "                end_idx_1 = indices_labels_1[-1] if len(indices_labels_1) > 0 else None\n",
    "\n",
    "\n",
    "                # **Print finale per verificare la concatenazione per ogni label**\n",
    "                #print(f\"\\nCondizione: \\033[1m{condition_pair}\\033[0m, Etichetta: {label}\")\n",
    "                #print(f\"  - Shape dei dati concatenati per \\033[1m{label}\\033[0m: {concatenated_data_by_label[label].shape}\")\n",
    "                #print(f\"  - Shape delle etichette concatenate per \\033[1m{label}\\033[0m: {concatenated_labels_by_label[label].shape}\")\n",
    "\n",
    "                # **Stampa la lista delle shapes delle etichette per ogni soggetto per questa etichetta**\n",
    "                #print(f\"\\n  - Shape delle etichette per soggetto (per etichetta {label}): {shape_labels_per_subject[label]}\\n\")\n",
    "\n",
    "\n",
    "                # **Stampa il conteggio totale delle etichette**\n",
    "                #print(f\"\\n  - Totale delle etichette 0: {total_labels_0}\")\n",
    "                #print(f\"  - Totale delle etichette 1: {total_labels_1}\")\n",
    "                #print(f\"  - Totale delle etichette per la condizione: {total_labels}\\n\")\n",
    "\n",
    "                # **Stampa gli indici per le etichette 0 e 1**\n",
    "                # **OSSIA --> Stampa gli indici per l'etichetta corrente**\n",
    "\n",
    "                #if label == 0:\n",
    "                #    print(f\"\\n  - Indici per etichetta 0: Inizio = {start_idx_0}, Fine = {end_idx_0}\")\n",
    "                #else:\n",
    "                #    print(f\"  - Indici per etichetta 1: Inizio = {start_idx_1}, Fine = {end_idx_1}\\n\")\n",
    "\n",
    "\n",
    "                #print(f\"\\n  - Indici per etichetta 0: Inizio = {start_idx_0}, Fine = {end_idx_0}\")\n",
    "                #print(f\"  - Indici per etichetta 1: Inizio = {start_idx_1}, Fine = {end_idx_1}\")\n",
    "\n",
    "\n",
    "            #ARRIVATI FINO A QUI, abbiamo che siccome stiamo iterando prima per tutti gli 0 e poi per tutti gli 1\n",
    "            #Significa che, assumendo che siamo dentro 'baseline_vs_th_resp' e che \n",
    "\n",
    "            #'baseline' sia rappresentato dalle etichette 0\n",
    "            #'th_resp' sia rappresentato dalle etichette 1\n",
    "\n",
    "            #Al PRIMO ciclo avrò che:\n",
    "\n",
    "            #con concatenated_data_by_label[label] ho solo concatenato tutti i dati (di 'baseline' per 'baseline_vs_th_resp' di tutti i soggetti)\n",
    "            #con concatenated_labels_by_label[label] ho solo concatenato tutti gli 0 (di 'baseline' per 'baseline_vs_th_resp'di tutti i soggetti)\n",
    "\n",
    "            #Al SECONDO ciclo avrò che:\n",
    "\n",
    "            #con concatenated_data_by_label[label] ho solo concatenato tutti i dati (di 'th_resp' per 'baseline_vs_th_resp'  di tutti i soggetti)\n",
    "            #con concatenated_labels_by_label[label] ho solo concatenato tutti gli 0 (di 'th_resp' per 'baseline_vs_th_resp' di tutti i soggetti)\n",
    "\n",
    "            #Quindi mi manca ancora \n",
    "\n",
    "            #A) CONCATENARE I DATI:\n",
    "\n",
    "            #1)prima tutti i dati (di 'baseline' per 'baseline_vs_th_resp' di tutti i soggetti) \n",
    "\n",
    "            #CON\n",
    "\n",
    "            #2)tutti i dati (di 'th_resp' per 'baseline_vs_th_resp'  di tutti i soggetti)\n",
    "\n",
    "            #che verrà fatto dentro all_data (che è anch'esso una variabile dinamica!)\n",
    "\n",
    "            #B) CONCATENARE LE LABELS:\n",
    "\n",
    "            #1)prima tutti le labels (di 'baseline' per 'baseline_vs_th_resp' di tutti i soggetti) \n",
    "\n",
    "            #CON\n",
    "\n",
    "            #2)tutti le labels (di 'th_resp' per 'baseline_vs_th_resp' di tutti i soggetti)\n",
    "\n",
    "            #che verrà fatto dentro all_labels (che è anch'esso una variabile dinamica!)\n",
    "\n",
    "            # Liste per raccogliere dati e labels di tutte le etichette\n",
    "\n",
    "            # Qui dentro, invece, dov con\n",
    "            \n",
    "            all_data = []\n",
    "            all_labels = []\n",
    "\n",
    "            for label in concatenated_data_by_label.keys():\n",
    "                all_data.append(concatenated_data_by_label[label])\n",
    "                all_labels.append(concatenated_labels_by_label[label])\n",
    "            \n",
    "            #Alla fine, qui dentro avrò che, PER OGNI COPPIA DI CONDIZIONI SPERIMENTALI\n",
    "\n",
    "\n",
    "            #'final_data' dovrebbe avere \n",
    "                #- prima tutti i dati di tutti i soggetti associati all'etichetta 0 \n",
    "                #- e poi tutti i dati di tutti i soggetti associati all'etichetta 1\n",
    "\n",
    "            #'final_labels' dovrebbe avere \n",
    "                #- prima tutte le labels di tutti i soggetti associati all'etichetta 0\n",
    "                #- e poi tutte tutte le labels di tutti soggetti associati all'etichetta 1...\n",
    "                \n",
    "            if all_data:  # Evita errori di concatenazione se non ci sono dati\n",
    "                final_data = np.vstack(all_data)\n",
    "                final_labels = np.hstack(all_labels)\n",
    "                \n",
    "                all_subj_data_by_coupled_cond[reconstruction_level][condition_pair] = {\n",
    "                    'data': final_data,\n",
    "                    'labels': final_labels\n",
    "                }\n",
    "                \n",
    "\n",
    "    #print(\"\\n\\033[1mIntervalli di indici per ciascuna etichetta nei sotto-dizionari:\\033[0m\\n\")\n",
    "\n",
    "    #for reconstruction_level, conditions_dict in all_subj_data_by_coupled_cond.items():\n",
    "    #    for condition_pair, value in conditions_dict.items():\n",
    "    #        labels = value['labels']\n",
    "    #        unique_labels = np.unique(labels)\n",
    "    #        total_labels = 0\n",
    "\n",
    "    #        print(f\"\\nLivello Wavelet: {reconstruction_level}, Condizione: {condition_pair}\")\n",
    "    #        for label in unique_labels:\n",
    "    #            label_indices = np.where(labels == label)[0]\n",
    "    #            start_idx = label_indices[0] if len(label_indices) > 0 else None\n",
    "    #            end_idx = label_indices[-1] if len(label_indices) > 0 else None\n",
    "    #            total_labels += len(label_indices)\n",
    "\n",
    "    #            print(f\"  Etichetta \\033[1m{label}\\033[0m: Indici \\033[1m{start_idx}-{end_idx}\\033[0m \"\n",
    "    #                  f\"(Totale Etichette: \\033[1m{len(label_indices)}\\033[0m)\")\n",
    "\n",
    "    #        print(f\"Totale etichette (0 e 1): \\033[1m{total_labels}\\033[0m\\n\")\n",
    "\n",
    "    return all_subj_data_by_coupled_cond\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3b40a5-dcec-4c4e-98f9-7de869f90fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''CODICE UFFICIALE CON MODIFICHE A SPETTROGRAMMI'''\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def concatenate_all_subjects_coupled_spectrogram_conditions_th(data_structure, conditions):\n",
    "    \n",
    "    \"\"\"\n",
    "    Concatena globalmente i dati e le etichette per ogni coppia di condizioni sperimentali\n",
    "    a partire dalla struttura 'new_subject_level_concatenations_spectrograms_coupled_exp_th'.\n",
    "    I dati di ogni soggetto (già raggruppati per coppia di condizioni) vengono ulteriormente \n",
    "    concatenati per ottenere un unico array globale per ogni coppia.\n",
    "    \n",
    "    Parameters:\n",
    "        data_structure (dict): Struttura dati con chiavi per soggetto (es. 'th_1', 'th_2', ...)\n",
    "                               e, per ciascun soggetto, chiavi per ciascuna coppia di condizioni sperimentali.\n",
    "        condition_pairs (list): Lista di coppie di condizioni sperimentali (es. 'baseline_vs_th_resp', ...)\n",
    "        \n",
    "    Returns:\n",
    "        dict: Un dizionario globale in cui ogni chiave è una coppia di condizioni e il valore\n",
    "              è un dizionario con 'data' e 'labels' concatenati globalmente (da tutti i soggetti).\n",
    "    \"\"\"\n",
    "        \n",
    "    # Dizionario per contenere i dati concatenati di tutti i soggetti\n",
    "    all_subj_data_by_coupled_cond = {}\n",
    "\n",
    "    # Itera su ogni coppia di condizioni sperimentali\n",
    "    for condition_pair in conditions:\n",
    "\n",
    "        #Dizionari per raccogliere dati e labels ordinati per ogni coppia di condizioni sperimentali\n",
    "        # che è dinamico, per ogni coppia di condizioni sperimentali \n",
    "        #(quindi si ricreeranno passando alla condizione sperimentale successiva!)\n",
    "\n",
    "        data_by_label = {}\n",
    "        labels_by_label = {}\n",
    "        shape_labels_per_subject = {0: [], 1: []}  # Inizializza il dizionario per 0 e 1\n",
    "\n",
    "        # Itera su tutti i soggetti\n",
    "        # In questo caso, itera sulle chiavi di ogni soggetto\n",
    "\n",
    "        # Quindi prenderà, per la relativa coppia di condizioni sperimentali di ogni soggetto,\n",
    "        # i dati e le labels di quel soggetto, per quella relativa coppia di condizioni sperimentali\n",
    "\n",
    "        for subject_key in data_structure.keys():\n",
    "\n",
    "            # Controlla se il livello di ricostruzione esiste per il soggetto\n",
    "            if condition_pair not in data_structure[subject_key]:\n",
    "                continue\n",
    "\n",
    "            # Qui estrae i dati e le labels per questa condizione sperimentale di quel soggettio lì\n",
    "            subject_data = data_structure[subject_key][condition_pair]['data']\n",
    "            subject_labels = data_structure[subject_key][condition_pair]['labels']\n",
    "\n",
    "            # Trova le etichette uniche e gli indici corrispondenti per quella coppia di condizioni sperimentali lì,\n",
    "            # Ossia, potrà trovare gli 0 e gli 1 \n",
    "\n",
    "            unique_labels = np.unique(subject_labels)\n",
    "\n",
    "            #A quel punto, per ognuna delle due labels trovate per quella coppia di condizioni sperimentali lì\n",
    "            #Che saranno sempre o 0 o 1\n",
    "\n",
    "            for label in unique_labels:\n",
    "\n",
    "                # Trova gli indici dei dati corrispondenti a questa etichetta\n",
    "                # Una volta per lo 0 ed una volta per l' 1\n",
    "\n",
    "                label_indices = np.where(subject_labels == label)[0]\n",
    "\n",
    "                # A quel punto, estrae i dati e le labels per questi indici\n",
    "                # Una volta per lo 0 ed una volta per l' 1\n",
    "\n",
    "                data_for_label = subject_data[label_indices]\n",
    "                labels_for_label = subject_labels[label_indices]\n",
    "\n",
    "                # A quel punto, per ogni soggetto, per ogni condzione sperimentale, \n",
    "                # per quelle due labels là (sempre presenti, per ogni coppia di condizioni sperimentali)\n",
    "                # Una volta per lo 0 ed una volta per l' 1\n",
    "\n",
    "                #Andrà a creare per ogni etichetta, una chiave che si chiamerà \n",
    "                #o 0 od 1 (inizialmente, vuoto -> perché deve esser inizializzato)\n",
    "                #E poi, dopo, ci appenderà le labels \n",
    "                 # Una volta per lo 0 ed una volta per l' 1\n",
    "                #  Di quel soggetto per quella coppia di condizioni sperimentali iterate a quel momento\n",
    "\n",
    "                #Aggiunge ai dizionari globali, creando la chiave se non esiste\n",
    "                if label not in data_by_label:\n",
    "                    data_by_label[label] = []\n",
    "                    labels_by_label[label] = []\n",
    "\n",
    "                data_by_label[label].append(data_for_label)\n",
    "                labels_by_label[label].append(labels_for_label)\n",
    "\n",
    "                # **Salva la shape delle etichette per il soggetto corrente**\n",
    "                shape_labels_per_subject[label].append(labels_for_label.shape[0]) # Aggiungi solo la dimensione (numero di etichette)\n",
    "\n",
    "                '''PRINT PER CHECK LABELS DI OGNI SOGGETTO PER OGNI COPPIA DI CONDIZIONE CONDIZIONI SPERIMENTALI''' \n",
    "                #print(f\"Soggetto: \\033[1m{subject_key}\\033[0m, Livello: \\033[1m{reconstruction_level}\\033[0m, Condizione: \\033[1m{condition_pair}\\033[0m, \"\n",
    "                #      f\"Etichetta: \\033[1m{label}\\033[0m, Shape: \\033[1m{labels_for_label.shape[0]}\\033[0m\")\n",
    "\n",
    "                # **Aggiungi un print di controllo per ogni soggetto**\n",
    "                #print(f\"Soggetto: \\033[1m{subject_key}\\033[1m, Livello: {reconstruction_level}, Condizione: {condition_pair}, Etichetta: {label}, Shape: {labels_for_label.shape[0]}\")\n",
    "\n",
    "            \n",
    "        #*** *** *** *** *** *** *** *** *** *** *** *** *** *** ***\n",
    "\n",
    "        # Dopodiché, vado a creare invece i dizionari che conterranno\n",
    "        # Le concatenazioni, di dati e labels corrispondenti, di tutti i soggetti per cui l'etichetta era \n",
    "        # o 0 od 1 \n",
    "\n",
    "        # Di conseguenza, qui dentro dovrei avere, per ogni coppia di condizioni sperimentali\n",
    "        # Tutti gli 0 ed 1 (ed i relativi dati corrispondenti)\n",
    "        # di tutti i soggetti, ma concatenati\n",
    "\n",
    "        concatenated_data_by_label = {}\n",
    "        concatenated_labels_by_label = {}\n",
    "\n",
    "        #for label in data_by_label.keys():\n",
    "        #    if len(data_by_label[label]) > 0:  # Evita errori di concatenazione\n",
    "        #        concatenated_data_by_label[label] = np.vstack(data_by_label[label])\n",
    "        #        concatenated_labels_by_label[label] = np.hstack(labels_by_label[label])\n",
    "            \n",
    "        for label in data_by_label.keys():\n",
    "            concatenated_data_by_label[label] = np.vstack(data_by_label[label])\n",
    "            concatenated_labels_by_label[label] = np.hstack(labels_by_label[label])\n",
    "\n",
    "            # **Calcolare la shape totale delle etichette**\n",
    "            #total_labels_0 = np.sum(1 for subject_labels in labels_by_label[label] if 0 in subject_labels)\n",
    "            #total_labels_1 = np.sum(1 for subject_labels in labels_by_label[label] if 1 in subject_labels)\n",
    "            #total_labels = total_labels_0 + total_labels_1\n",
    "\n",
    "            # **Determinare gli indici delle etichette 0 e 1 nell'array finale**\n",
    "\n",
    "            # Gli indici delle etichette 0\n",
    "            indices_labels_0 = np.where(concatenated_labels_by_label[label] == 0)[0]\n",
    "\n",
    "            # Gli indici delle etichette 1\n",
    "            indices_labels_1 = np.where(concatenated_labels_by_label[label] == 1)[0]\n",
    "\n",
    "            # Indici iniziale e finale per le etichette 0 e 1\n",
    "            start_idx_0 = indices_labels_0[0] if len(indices_labels_0) > 0 else None\n",
    "            end_idx_0 = indices_labels_0[-1] if len(indices_labels_0) > 0 else None\n",
    "            start_idx_1 = indices_labels_1[0] if len(indices_labels_1) > 0 else None\n",
    "            end_idx_1 = indices_labels_1[-1] if len(indices_labels_1) > 0 else None\n",
    "\n",
    "\n",
    "            # **Print finale per verificare la concatenazione per ogni label**\n",
    "            #print(f\"\\nCondizione: \\033[1m{condition_pair}\\033[0m, Etichetta: {label}\")\n",
    "            #print(f\"  - Shape dei dati concatenati per \\033[1m{label}\\033[0m: {concatenated_data_by_label[label].shape}\")\n",
    "            #print(f\"  - Shape delle etichette concatenate per \\033[1m{label}\\033[0m: {concatenated_labels_by_label[label].shape}\")\n",
    "\n",
    "            # **Stampa la lista delle shapes delle etichette per ogni soggetto per questa etichetta**\n",
    "            #print(f\"\\n  - Shape delle etichette per soggetto (per etichetta {label}): {shape_labels_per_subject[label]}\\n\")\n",
    "\n",
    "\n",
    "            # **Stampa il conteggio totale delle etichette**\n",
    "            #print(f\"\\n  - Totale delle etichette 0: {total_labels_0}\")\n",
    "            #print(f\"  - Totale delle etichette 1: {total_labels_1}\")\n",
    "            #print(f\"  - Totale delle etichette per la condizione: {total_labels}\\n\")\n",
    "\n",
    "            # **Stampa gli indici per le etichette 0 e 1**\n",
    "            # **OSSIA --> Stampa gli indici per l'etichetta corrente**\n",
    "\n",
    "            #if label == 0:\n",
    "            #    print(f\"\\n  - Indici per etichetta 0: Inizio = {start_idx_0}, Fine = {end_idx_0}\")\n",
    "            #else:\n",
    "            #    print(f\"  - Indici per etichetta 1: Inizio = {start_idx_1}, Fine = {end_idx_1}\\n\")\n",
    "\n",
    "\n",
    "            #print(f\"\\n  - Indici per etichetta 0: Inizio = {start_idx_0}, Fine = {end_idx_0}\")\n",
    "            #print(f\"  - Indici per etichetta 1: Inizio = {start_idx_1}, Fine = {end_idx_1}\")\n",
    "\n",
    "\n",
    "        #ARRIVATI FINO A QUI, abbiamo che siccome stiamo iterando prima per tutti gli 0 e poi per tutti gli 1\n",
    "        #Significa che, assumendo che siamo dentro 'baseline_vs_th_resp' e che \n",
    "\n",
    "        #'baseline' sia rappresentato dalle etichette 0\n",
    "        #'th_resp' sia rappresentato dalle etichette 1\n",
    "\n",
    "        #Al PRIMO ciclo avrò che:\n",
    "\n",
    "        #con concatenated_data_by_label[label] ho solo concatenato tutti i dati (di 'baseline' per 'baseline_vs_th_resp' di tutti i soggetti)\n",
    "        #con concatenated_labels_by_label[label] ho solo concatenato tutti gli 0 (di 'baseline' per 'baseline_vs_th_resp'di tutti i soggetti)\n",
    "\n",
    "        #Al SECONDO ciclo avrò che:\n",
    "\n",
    "        #con concatenated_data_by_label[label] ho solo concatenato tutti i dati (di 'th_resp' per 'baseline_vs_th_resp'  di tutti i soggetti)\n",
    "        #con concatenated_labels_by_label[label] ho solo concatenato tutti gli 0 (di 'th_resp' per 'baseline_vs_th_resp' di tutti i soggetti)\n",
    "\n",
    "        #Quindi mi manca ancora \n",
    "\n",
    "        #A) CONCATENARE I DATI:\n",
    "\n",
    "        #1)prima tutti i dati (di 'baseline' per 'baseline_vs_th_resp' di tutti i soggetti) \n",
    "\n",
    "        #CON\n",
    "\n",
    "        #2)tutti i dati (di 'th_resp' per 'baseline_vs_th_resp'  di tutti i soggetti)\n",
    "\n",
    "        #che verrà fatto dentro all_data (che è anch'esso una variabile dinamica!)\n",
    "\n",
    "        #B) CONCATENARE LE LABELS:\n",
    "\n",
    "        #1)prima tutti le labels (di 'baseline' per 'baseline_vs_th_resp' di tutti i soggetti) \n",
    "\n",
    "        #CON\n",
    "\n",
    "        #2)tutti le labels (di 'th_resp' per 'baseline_vs_th_resp' di tutti i soggetti)\n",
    "\n",
    "        #che verrà fatto dentro all_labels (che è anch'esso una variabile dinamica!)\n",
    "\n",
    "        # Liste per raccogliere dati e labels di tutte le etichette\n",
    "\n",
    "        # Qui dentro, invece, dov con\n",
    "\n",
    "        all_data = []\n",
    "        all_labels = []\n",
    "\n",
    "        for label in concatenated_data_by_label.keys():\n",
    "            all_data.append(concatenated_data_by_label[label])\n",
    "            all_labels.append(concatenated_labels_by_label[label])\n",
    "\n",
    "        #Alla fine, qui dentro avrò che, PER OGNI COPPIA DI CONDIZIONI SPERIMENTALI\n",
    "\n",
    "\n",
    "        #'final_data' dovrebbe avere \n",
    "            #- prima tutti i dati di tutti i soggetti associati all'etichetta 0 \n",
    "            #- e poi tutti i dati di tutti i soggetti associati all'etichetta 1\n",
    "\n",
    "        #'final_labels' dovrebbe avere \n",
    "            #- prima tutte le labels di tutti i soggetti associati all'etichetta 0\n",
    "            #- e poi tutte tutte le labels di tutti soggetti associati all'etichetta 1...\n",
    "\n",
    "        if all_data:  # Evita errori di concatenazione se non ci sono dati\n",
    "            final_data = np.vstack(all_data)\n",
    "            final_labels = np.hstack(all_labels)\n",
    "\n",
    "            all_subj_data_by_coupled_cond[condition_pair] = {\n",
    "                'data': final_data,\n",
    "                'labels': final_labels\n",
    "            }\n",
    "            \n",
    "    return all_subj_data_by_coupled_cond\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e029022a-b96b-4625-b53c-433923252ab0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Parametri\n",
    "\n",
    "\n",
    "#conditions = ['baseline_vs_th_resp', 'baseline_vs_pt_resp', 'baseline_vs_shared_resp',\n",
    "#              'th_resp_vs_pt_resp', 'th_resp_vs_shared_resp', 'pt_resp_vs_shared_resp']\n",
    "\n",
    "    \n",
    "conditions = ['rest_vs_left_fist', 'rest_vs_right_fist', 'left_fist_vs_right_fist']\n",
    "\n",
    "\n",
    "# Chiamata alla funzione, qui definisco a mano il nome della variabile (i.e., \n",
    "new_all_th_concat_spectrograms_coupled_exp_task_1 = concatenate_all_subjects_coupled_spectrogram_conditions_th(\n",
    "    data_structure=new_subject_level_concatenations_spectrograms_coupled_exp_th_task_1,\n",
    "    conditions=conditions\n",
    ")\n",
    "\n",
    "#print(\"\\n\\033[1mIntervalli di indici per ciascuna etichetta nei sotto-dizionari:\\033[0m\\n\")\n",
    "\n",
    "\n",
    "for condition_pair, value in new_all_th_concat_spectrograms_coupled_exp_task_1.items():\n",
    "    labels = value['labels']\n",
    "    unique_labels = np.unique(labels)\n",
    "    total_labels = 0\n",
    "\n",
    "    #print(f\"\\nCondizione: \\033[1m{condition_pair}\\033[0m\")\n",
    "    for label in unique_labels:\n",
    "        label_indices = np.where(labels == label)[0]\n",
    "        start_idx = label_indices[0] if len(label_indices) > 0 else None\n",
    "        end_idx = label_indices[-1] if len(label_indices) > 0 else None\n",
    "        total_labels += len(label_indices)\n",
    "\n",
    "        #print(f\"  Etichetta \\033[1m{label}\\033[0m: Indici \\033[1m{start_idx}-{end_idx}\\033[0m \"\n",
    "        #      f\"(Totale Etichette: \\033[1m{len(label_indices)}\\033[0m)\")\n",
    "\n",
    "    #print(f\"Totale etichette (0 e 1): \\033[1m{total_labels}\\033[0m\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ac8b17-4603-4bc0-87d9-113701f8edbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('finito')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf27ef5-17ac-4da7-9cca-b4832552018a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_all_th_concat_spectrograms_coupled_exp_task_1.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0dceea-d5da-4de8-8fbc-708fee87e905",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.unique(new_all_th_concat_spectrograms_coupled_exp_task_1['rest_vs_left_fist']['labels'], return_counts = True))\n",
    "print()\n",
    "print(np.unique(new_all_th_concat_spectrograms_coupled_exp_task_1['rest_vs_right_fist']['labels'], return_counts = True))\n",
    "print()\n",
    "print(np.unique(new_all_th_concat_spectrograms_coupled_exp_task_1['left_fist_vs_right_fist']['labels'], return_counts = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5723245-231b-4b07-8852-588cd0434451",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Ecco un piccolo snippet che, per ciascuna coppia di condizioni in new_all_th_concat_spectrograms_coupled_exp_task_1, \n",
    "stampa per ogni valore di label (0 e 1) l’indice di partenza e quello di fine nel vettore labels:\n",
    "\n",
    "Come funziona\n",
    "\n",
    "np.unique(labels) restituisce i valori distinti (ad es. [0, 1]).\n",
    "\n",
    "Per ciascun valore val, np.where(labels == val)[0] trova tutti gli indici in cui labels è uguale a val.\n",
    "\n",
    "Con .min() e .max() ricavi il primo e l’ultimo indice di ciascun blocco.\n",
    "\n",
    "Se vuoi anche vedere tutte le sott‐sequenze (ad es. se le label non sono concatenate in un unico blocco), \n",
    "puoi invece usare [itertools.groupby] o scorrere i idxs alla ricerca di “buchi”. \n",
    "\n",
    "Ma nel tuo caso — visto che hai prima aggiunto tutti gli zero e poi tutti gli uno — vedrai sempre un singolo intervallo per ciascuna label.\n",
    "\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "for cond_pair, payload in new_all_th_concat_spectrograms_coupled_exp_task_1.items():\n",
    "    labels = np.array(payload['labels'])\n",
    "    print(f\"\\n=== {cond_pair} ===\")\n",
    "    for val in np.unique(labels):\n",
    "        idxs = np.where(labels == val)[0]\n",
    "        start, end = idxs.min(), idxs.max()\n",
    "        print(f\"  label {val}: indices {start} → {end} (count = {len(idxs)})\")\n",
    "        \n",
    "print()\n",
    "print()\n",
    "for cond_pair, cond_data in new_all_th_concat_spectrograms_coupled_exp_task_1.items():\n",
    "    data = cond_data['data']      # shape: (n_trials, ...)\n",
    "    labels = cond_data['labels']  # shape: (n_trials,)\n",
    "    print(f\"{cond_pair}:\")\n",
    "    print(f\"  data shape  = {data.shape}\")\n",
    "    print(f\"  labels len  = {len(labels)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b2159c-a25a-4147-8b62-d299cfaae7b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for cond_pair, cond_data in new_all_th_concat_spectrograms_coupled_exp_task_1.items():\n",
    "    data = cond_data['data']      # shape: (n_trials, ...)\n",
    "    labels = cond_data['labels']  # shape: (n_trials,)\n",
    "    print(f\"{cond_pair}:\")\n",
    "    print(f\"  data shape  = {data.shape}\")\n",
    "    print(f\"  labels len  = {len(labels)}\\n\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ff93bc6e-52b1-4f3b-bb31-b787be81aec3",
   "metadata": {
    "tags": []
   },
   "source": [
    "##NEW OFFICIAL VERSION!\n",
    "\n",
    "#CON DICT_NAME!\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def concatenate_all_single_subj_wavelets_coupled_experimental_conditions_th(data_structure, wavelet_levels, conditions, prefix):\n",
    "    \n",
    "    \"\"\"\n",
    "    Concatena i dati e le etichette per ogni condizione sperimentale da una struttura dati con un livello in più,\n",
    "    dove questo livello rappresenta le diverse coppie di condizioni sperimentali iterate nel ciclo ossia\n",
    "    \n",
    "    'baseline_vs_th_resp', 'baseline_vs_pt_resp', 'baseline_vs_shared_resp', \n",
    "    'th_resp_vs_pt_resp', 'th_resp_vs_shared_resp', 'pt_resp_vs_shared_resp'\n",
    "    \n",
    "    ordinandoli anche per etichetta.\n",
    "    \n",
    "    Questo perché ogni array di labels avrà sempre o 0 od 1 come etichette,\n",
    "    dato che son coppie di condizioni sperimentali\n",
    "\n",
    "    Parameters:\n",
    "        data_structure (dict): La struttura dati di input che contiene i dati per soggetti e condizioni.\n",
    "        conditions (list): Le condizioni sperimentali (chiavi del secondo livello) da processare.\n",
    "        prefix (str): Il prefisso del nome dinamico del dizionario.\n",
    "        \n",
    "\n",
    "    Returns:\n",
    "        dict: Un dizionario contenente i nuovi dizionari con \n",
    "        i dati concatenati e le etichette per ogni coppia di condizioni sperimentali\n",
    "    \n",
    "    \"\"\"\n",
    "        \n",
    "        \n",
    "    # Dizionario per contenere i dati concatenati di tutti i soggetti\n",
    "    all_subj_data_by_coupled_cond = {}\n",
    "    \n",
    "    # Itera su ogni livello di ricostruzione wavelet ('theta', 'delta', 'theta_strict')\n",
    "    \n",
    "    for reconstruction_level in wavelet_levels:\n",
    "        \n",
    "        all_subj_data_by_coupled_cond[reconstruction_level] = {}  # Struttura annidata per livello\n",
    "\n",
    "        # Itera su ogni coppia di condizioni sperimentali\n",
    "        for condition_pair in conditions:\n",
    "            \n",
    "            #Dizionari per raccogliere dati e labels ordinati per ogni coppia di condizioni sperimentali\n",
    "            # che è dinamico, per ogni coppia di condizioni sperimentali \n",
    "            #(quindi si ricreeranno passando alla condizione sperimentale successiva!)\n",
    "            \n",
    "            data_by_label = {}\n",
    "            labels_by_label = {}\n",
    "            shape_labels_per_subject = {0: [], 1: []}  # Inizializza il dizionario per 0 e 1\n",
    "\n",
    "            # Itera su tutti i soggetti\n",
    "            # In questo caso, itera sulle chiavi di ogni soggetto\n",
    "\n",
    "            # Quindi prenderà, per la relativa coppia di condizioni sperimentali di ogni soggetto,\n",
    "            # i dati e le labels di quel soggetto, per quella relativa coppia di condizioni sperimentali\n",
    "            \n",
    "            for subject_key in data_structure.keys():\n",
    "                \n",
    "                # Controlla se il livello di ricostruzione esiste per il soggetto\n",
    "                if reconstruction_level not in data_structure[subject_key]:\n",
    "                    continue\n",
    "                    \n",
    "                # Controlla se il livello di ricostruzione esiste per il soggetto\n",
    "                if condition_pair not in data_structure[subject_key][reconstruction_level]:\n",
    "                    continue\n",
    "                \n",
    "                # Qui estrae i dati e le labels per questa condizione sperimentale di quel soggettio lì\n",
    "                subject_data = data_structure[subject_key][reconstruction_level][condition_pair]['data']\n",
    "                subject_labels = data_structure[subject_key][reconstruction_level][condition_pair]['labels']\n",
    "                \n",
    "                # Trova le etichette uniche e gli indici corrispondenti per quella coppia di condizioni sperimentali lì,\n",
    "                # Ossia, potrà trovare gli 0 e gli 1 \n",
    "                \n",
    "                unique_labels = np.unique(subject_labels)\n",
    "                \n",
    "                #A quel punto, per ognuna delle due labels trovate per quella coppia di condizioni sperimentali lì\n",
    "                #Che saranno sempre o 0 o 1\n",
    "                \n",
    "                for label in unique_labels:\n",
    "                    \n",
    "                    # Trova gli indici dei dati corrispondenti a questa etichetta\n",
    "                    # Una volta per lo 0 ed una volta per l' 1\n",
    "                    \n",
    "                    label_indices = np.where(subject_labels == label)[0]\n",
    "                    \n",
    "                    # A quel punto, estrae i dati e le labels per questi indici\n",
    "                    # Una volta per lo 0 ed una volta per l' 1\n",
    "                    \n",
    "                    data_for_label = subject_data[label_indices]\n",
    "                    labels_for_label = subject_labels[label_indices]\n",
    "                    \n",
    "                    # A quel punto, per ogni soggetto, per ogni condzione sperimentale, \n",
    "                    # per quelle due labels là (sempre presenti, per ogni coppia di condizioni sperimentali)\n",
    "                    # Una volta per lo 0 ed una volta per l' 1\n",
    "\n",
    "                    #Andrà a creare per ogni etichetta, una chiave che si chiamerà \n",
    "                    #o 0 od 1 (inizialmente, vuoto -> perché deve esser inizializzato)\n",
    "                    #E poi, dopo, ci appenderà le labels \n",
    "                     # Una volta per lo 0 ed una volta per l' 1\n",
    "                    #  Di quel soggetto per quella coppia di condizioni sperimentali iterate a quel momento\n",
    "                    \n",
    "                    #Aggiunge ai dizionari globali, creando la chiave se non esiste\n",
    "                    if label not in data_by_label:\n",
    "                        data_by_label[label] = []\n",
    "                        labels_by_label[label] = []\n",
    "\n",
    "                    data_by_label[label].append(data_for_label)\n",
    "                    labels_by_label[label].append(labels_for_label)\n",
    "                    \n",
    "                    # **Salva la shape delle etichette per il soggetto corrente**\n",
    "                    shape_labels_per_subject[label].append(labels_for_label.shape[0]) # Aggiungi solo la dimensione (numero di etichette)\n",
    "\n",
    "                    #print(f\"Soggetto: {subject_key}, Livello: {reconstruction_level}, Condizione: {condition_pair}, \"\n",
    "                    #      f\"Etichetta: {label}, Shape: {labels_for_label.shape[0]}\")\n",
    "                    \n",
    "                    # **Aggiungi un print di controllo per ogni soggetto**\n",
    "                    print(f\"Soggetto: {subject_key}, Livello: {reconstruction_level}, Condizione: {condition_pair}, Etichetta: {label}, Shape: {labels_for_label.shape[0]}\")\n",
    "            \n",
    "            \n",
    "            #*** *** *** *** *** *** *** *** *** *** *** *** *** *** ***\n",
    "            \n",
    "            # Dopodiché, vado a creare invece i dizionari che conterranno\n",
    "            # Le concatenazioni, di dati e labels corrispondenti, di tutti i soggetti per cui l'etichetta era \n",
    "            # o 0 od 1 \n",
    "\n",
    "            # Di conseguenza, qui dentro dovrei avere, per ogni coppia di condizioni sperimentali\n",
    "            # Tutti gli 0 ed 1 (ed i relativi dati corrispondenti)\n",
    "            # di tutti i soggetti, ma concatenati\n",
    "\n",
    "            concatenated_data_by_label = {}\n",
    "            concatenated_labels_by_label = {}\n",
    "\n",
    "            #for label in data_by_label.keys():\n",
    "            #    if len(data_by_label[label]) > 0:  # Evita errori di concatenazione\n",
    "            #        concatenated_data_by_label[label] = np.vstack(data_by_label[label])\n",
    "            #        concatenated_labels_by_label[label] = np.hstack(labels_by_label[label])\n",
    "            \n",
    "            for label in data_by_label.keys():\n",
    "                concatenated_data_by_label[label] = np.vstack(data_by_label[label])\n",
    "                concatenated_labels_by_label[label] = np.hstack(labels_by_label[label])\n",
    "\n",
    "                # **Calcolare la shape totale delle etichette**\n",
    "                #total_labels_0 = np.sum(1 for subject_labels in labels_by_label[label] if 0 in subject_labels)\n",
    "                #total_labels_1 = np.sum(1 for subject_labels in labels_by_label[label] if 1 in subject_labels)\n",
    "                #total_labels = total_labels_0 + total_labels_1\n",
    "\n",
    "                # **Determinare gli indici delle etichette 0 e 1 nell'array finale**\n",
    "\n",
    "                # Gli indici delle etichette 0\n",
    "                indices_labels_0 = np.where(concatenated_labels_by_label[label] == 0)[0]\n",
    "\n",
    "                # Gli indici delle etichette 1\n",
    "                indices_labels_1 = np.where(concatenated_labels_by_label[label] == 1)[0]\n",
    "                \n",
    "                # Indici iniziale e finale per le etichette 0 e 1\n",
    "                start_idx_0 = indices_labels_0[0] if len(indices_labels_0) > 0 else None\n",
    "                end_idx_0 = indices_labels_0[-1] if len(indices_labels_0) > 0 else None\n",
    "                start_idx_1 = indices_labels_1[0] if len(indices_labels_1) > 0 else None\n",
    "                end_idx_1 = indices_labels_1[-1] if len(indices_labels_1) > 0 else None\n",
    "\n",
    "\n",
    "                # **Print finale per verificare la concatenazione per ogni label**\n",
    "                #print(f\"\\nCondizione: \\033[1m{condition_pair}\\033[0m, Etichetta: {label}\")\n",
    "                #print(f\"  - Shape dei dati concatenati per \\033[1m{label}\\033[0m: {concatenated_data_by_label[label].shape}\")\n",
    "                #print(f\"  - Shape delle etichette concatenate per \\033[1m{label}\\033[0m: {concatenated_labels_by_label[label].shape}\")\n",
    "\n",
    "                # **Stampa la lista delle shapes delle etichette per ogni soggetto per questa etichetta**\n",
    "                #print(f\"\\n  - Shape delle etichette per soggetto (per etichetta {label}): {shape_labels_per_subject[label]}\\n\")\n",
    "\n",
    "\n",
    "                # **Stampa il conteggio totale delle etichette**\n",
    "                #print(f\"\\n  - Totale delle etichette 0: {total_labels_0}\")\n",
    "                #print(f\"  - Totale delle etichette 1: {total_labels_1}\")\n",
    "                #print(f\"  - Totale delle etichette per la condizione: {total_labels}\\n\")\n",
    "\n",
    "                # **Stampa gli indici per le etichette 0 e 1**\n",
    "                # **OSSIA --> Stampa gli indici per l'etichetta corrente**\n",
    "\n",
    "                #if label == 0:\n",
    "                #    print(f\"\\n  - Indici per etichetta 0: Inizio = {start_idx_0}, Fine = {end_idx_0}\")\n",
    "                #else:\n",
    "                #    print(f\"  - Indici per etichetta 1: Inizio = {start_idx_1}, Fine = {end_idx_1}\\n\")\n",
    "\n",
    "\n",
    "                #print(f\"\\n  - Indici per etichetta 0: Inizio = {start_idx_0}, Fine = {end_idx_0}\")\n",
    "                #print(f\"  - Indici per etichetta 1: Inizio = {start_idx_1}, Fine = {end_idx_1}\")\n",
    "\n",
    "\n",
    "            #ARRIVATI FINO A QUI, abbiamo che siccome stiamo iterando prima per tutti gli 0 e poi per tutti gli 1\n",
    "            #Significa che, assumendo che siamo dentro 'baseline_vs_th_resp' e che \n",
    "\n",
    "            #'baseline' sia rappresentato dalle etichette 0\n",
    "            #'th_resp' sia rappresentato dalle etichette 1\n",
    "\n",
    "            #Al PRIMO ciclo avrò che:\n",
    "\n",
    "            #con concatenated_data_by_label[label] ho solo concatenato tutti i dati (di 'baseline' per 'baseline_vs_th_resp' di tutti i soggetti)\n",
    "            #con concatenated_labels_by_label[label] ho solo concatenato tutti gli 0 (di 'baseline' per 'baseline_vs_th_resp'di tutti i soggetti)\n",
    "\n",
    "            #Al SECONDO ciclo avrò che:\n",
    "\n",
    "            #con concatenated_data_by_label[label] ho solo concatenato tutti i dati (di 'th_resp' per 'baseline_vs_th_resp'  di tutti i soggetti)\n",
    "            #con concatenated_labels_by_label[label] ho solo concatenato tutti gli 0 (di 'th_resp' per 'baseline_vs_th_resp' di tutti i soggetti)\n",
    "\n",
    "            #Quindi mi manca ancora \n",
    "\n",
    "            #A) CONCATENARE I DATI:\n",
    "\n",
    "            #1)prima tutti i dati (di 'baseline' per 'baseline_vs_th_resp' di tutti i soggetti) \n",
    "\n",
    "            #CON\n",
    "\n",
    "            #2)tutti i dati (di 'th_resp' per 'baseline_vs_th_resp'  di tutti i soggetti)\n",
    "\n",
    "            #che verrà fatto dentro all_data (che è anch'esso una variabile dinamica!)\n",
    "\n",
    "            #B) CONCATENARE LE LABELS:\n",
    "\n",
    "            #1)prima tutti le labels (di 'baseline' per 'baseline_vs_th_resp' di tutti i soggetti) \n",
    "\n",
    "            #CON\n",
    "\n",
    "            #2)tutti le labels (di 'th_resp' per 'baseline_vs_th_resp' di tutti i soggetti)\n",
    "\n",
    "            #che verrà fatto dentro all_labels (che è anch'esso una variabile dinamica!)\n",
    "\n",
    "            # Liste per raccogliere dati e labels di tutte le etichette\n",
    "\n",
    "            # Qui dentro, invece, dov con\n",
    "            \n",
    "            all_data = []\n",
    "            all_labels = []\n",
    "\n",
    "            for label in concatenated_data_by_label.keys():\n",
    "                all_data.append(concatenated_data_by_label[label])\n",
    "                all_labels.append(concatenated_labels_by_label[label])\n",
    "            \n",
    "            #Alla fine, qui dentro avrò che, PER OGNI COPPIA DI CONDIZIONI SPERIMENTALI\n",
    "\n",
    "\n",
    "            #'final_data' dovrebbe avere \n",
    "                #- prima tutti i dati di tutti i soggetti associati all'etichetta 0 \n",
    "                #- e poi tutti i dati di tutti i soggetti associati all'etichetta 1\n",
    "\n",
    "            #'final_labels' dovrebbe avere \n",
    "                #- prima tutte le labels di tutti i soggetti associati all'etichetta 0\n",
    "                #- e poi tutte tutte le labels di tutti soggetti associati all'etichetta 1...\n",
    "                \n",
    "            if all_data:  # Evita errori di concatenazione se non ci sono dati\n",
    "                final_data = np.vstack(all_data)\n",
    "                final_labels = np.hstack(all_labels)\n",
    "                \n",
    "                # Nome dinamico del dizionario\n",
    "                dict_name = f\"{prefix}{reconstruction_level}_{condition_pair}\"\n",
    "                \n",
    "                #all_subj_data_by_coupled_cond[reconstruction_level][condition_pair] = {\n",
    "                #    'data': final_data,\n",
    "                #    'labels': final_labels\n",
    "                #}\n",
    "                \n",
    "                all_subj_data_by_coupled_cond[dict_name]= {\n",
    "                    'data': final_data,\n",
    "                    'labels': final_labels\n",
    "                }\n",
    "                \n",
    "\n",
    "    print(\"\\n\\033[1mIntervalli di indici per ciascuna etichetta nei sotto-dizionari:\\033[0m\\n\")\n",
    "\n",
    "    for reconstruction_level, conditions_dict in all_subj_data_by_coupled_cond.items():\n",
    "        for condition_pair, value in conditions_dict.items():\n",
    "            labels = value['labels']\n",
    "            unique_labels = np.unique(labels)\n",
    "            total_labels = 0\n",
    "\n",
    "            print(f\"\\nLivello Wavelet: {reconstruction_level}, Condizione: {condition_pair}\")\n",
    "            for label in unique_labels:\n",
    "                label_indices = np.where(labels == label)[0]\n",
    "                start_idx = label_indices[0] if len(label_indices) > 0 else None\n",
    "                end_idx = label_indices[-1] if len(label_indices) > 0 else None\n",
    "                total_labels += len(label_indices)\n",
    "\n",
    "                print(f\"  Etichetta \\033[1m{label}\\033[0m: Indici \\033[1m{start_idx}-{end_idx}\\033[0m \"\n",
    "                      f\"(Totale Etichette: \\033[1m{len(label_indices)}\\033[0m)\")\n",
    "\n",
    "            print(f\"Totale etichette (0 e 1): \\033[1m{total_labels}\\033[0m\\n\")\n",
    "\n",
    "    return all_subj_data_by_coupled_cond\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "361ed9ab-c3a0-448f-bac3-ec3f664f1414",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Parametri\n",
    "conditions = ['baseline_vs_th_resp', 'baseline_vs_pt_resp', 'baseline_vs_shared_resp',\n",
    "              'th_resp_vs_pt_resp', 'th_resp_vs_shared_resp', 'pt_resp_vs_shared_resp']\n",
    "\n",
    "\n",
    "wavelet_levels = ['theta', 'delta', 'theta_strict']\n",
    "\n",
    "prefix = \"new_all_th_concat_reconstructions_\"\n",
    "\n",
    "# Chiamata alla funzione\n",
    "new_concatenated_dictionaries = concatenate_all_single_subj_wavelets_coupled_experimental_conditions_th(\n",
    "    data_structure=new_subject_level_concatenations_coupled_exp_th,\n",
    "    wavelet_levels = wavelet_levels,\n",
    "    conditions=conditions,\n",
    "    prefix=prefix\n",
    ")\n",
    "\n",
    "# Stampa i risultati per verifica\n",
    "#print('\\n\\033[1mRISULTATO FINALE TUTTI I SOGGETTI TH\\033[0m') \n",
    "#for key, value in new_concatenated_dictionaries.items():\n",
    "#    print(f\"{key}:\")\n",
    "#    print(f\"  Dati: {value['data'].shape}\")\n",
    "#    print(f\"  Labels: {value['labels'].shape}\")\n",
    "\n",
    "\n",
    "print(\"\\n\\033[1mIntervalli di indici per ciascuna etichetta nei sotto-dizionari:\\033[0m\\n\")\n",
    "\n",
    "for dict_name, value in new_concatenated_dictionaries.items():\n",
    "    labels = value['labels']\n",
    "    unique_labels = np.unique(labels)\n",
    "    total_labels = 0\n",
    "\n",
    "    print(f\"\\nDizionario: {dict_name}\")  # Stampa il nome dinamico del dizionario\n",
    "    for label in unique_labels:\n",
    "        label_indices = np.where(labels == label)[0]\n",
    "        start_idx = label_indices[0] if len(label_indices) > 0 else None\n",
    "        end_idx = label_indices[-1] if len(label_indices) > 0 else None\n",
    "        total_labels += len(label_indices)\n",
    "\n",
    "        print(f\"  Etichetta \\033[1m{label}\\033[0m: Indici \\033[1m{start_idx}-{end_idx}\\033[0m \"\n",
    "              f\"(Totale Etichette: \\033[1m{len(label_indices)}\\033[0m)\")\n",
    "\n",
    "    print(f\"Totale etichette (0 e 1): \\033[1m{total_labels}\\033[0m\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b070175-6cc6-4707-809b-7ca8e32c171c",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### STEP - Salvataggio Dataset di **All Single Therapists** EEG Data Spectrograms across **Couples of Experimental Conditions** INSIEME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f124d9-3bce-4cc4-9c6c-2b24793c74e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8022d57-c295-4a20-8875-347640d31bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e6e16f-53d8-4124-ba17-373e3f201e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '/home/stefano/Interrogait/all_datas/Spectrograms_motor_tasks/'\n",
    "\n",
    "# Controlla se la cartella esiste, altrimenti la crea\n",
    "if not os.path.exists(base_path):\n",
    "    os.makedirs(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0a9b39-9e87-4247-9121-1c0d12e2048b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Salvare l'intero dizionario annidato con pickle\n",
    "with open(f'{base_path}new_all_th_concat_spectrograms_coupled_exp_task_1.pkl', 'wb') as f:\n",
    "    pickle.dump(new_all_th_concat_spectrograms_coupled_exp_task_1, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8cf86e9-b52f-40e6-a325-88895c9f2085",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Modifica della Funzione per la **Rappresentazione Frequenza-Elettrodi dei miei dati EEG** a seconda del Dataset del Task scelto\n",
    "\n",
    "- Task 1: Motor Execution (Open and close right or left fist) - Unilateral - Runs 3, 7, 11 \n",
    "- Task 2: Motor Imagery (Imagine opening and closing right and left fists) - Unilateral - Runs 4, 8, 12 \n",
    "- Task 3: Motor Execution (Open and close both fists and feet) - Bilateral - Runs 5, 9, 13 \n",
    "- Task 4: Motor Imagery (Imagine opening and closing both fists and feet) - Bilateral - Runs 6, 10, 14 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c3eea4-89d1-4e1e-a46f-db2e58f1762f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### IMPLEMENTAZIONE -Modifica della Funzione per la Rappresentazione Frequenza-Elettrodi dei miei dati EEG a seconda del Dataset del Task scelto\n",
    "\n",
    "\n",
    "#### **Calcolo Spettrogrammi** All **SINGLE** Subject Data (**TH**) per **Tutte le Condizioni sperimentali**"
   ]
  },
  {
   "cell_type": "raw",
   "id": "500e9b58-2ad5-4cdf-b606-bd2873ee3f68",
   "metadata": {},
   "source": [
    "import pickle\n",
    "\n",
    "# Caricare l'intero dizionario annidato con pickle\n",
    "path = '/home/stefano/EEGMMIDB_Analyses/'\n",
    "\n",
    "# Caricare l'intero dizionario annidato con pickle\n",
    "with open(f'{path}new_EEG_data.pkl', 'rb') as f:\n",
    "    new_EEG_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd16bf7-363b-4111-b89b-c44eb1584c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Con questo workflow puoi poi caricare in ambiente new_pd_env con:\n",
    "\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "NPZ = \"/home/stefano/EEGMMIDB_Analyses/final_cleaned_EEG_data.npz\"\n",
    "npz = np.load(NPZ, allow_pickle=False)\n",
    "\n",
    "def unflatten_npz_simple(npz_obj):\n",
    "    root = {}\n",
    "    for full_key in npz_obj.files:\n",
    "        task, idx_str, leaf = full_key.split('/', 2)\n",
    "        idx = int(idx_str)\n",
    "        root.setdefault(task, [])\n",
    "        while len(root[task]) <= idx:\n",
    "            root[task].append({})\n",
    "        root[task][idx][leaf] = npz_obj[full_key]\n",
    "    return root\n",
    "\n",
    "new_EEG_data = unflatten_npz_simple(npz)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ca09cd6c-87d9-4ef5-98fe-d51b84f6f444",
   "metadata": {
    "tags": []
   },
   "source": [
    "'''\n",
    "\n",
    "NEW UPDATED VERSION FOR DATASET MOTOR TASK - TIME x FREQUENCY UFFICIALE \n",
    "\n",
    "Ecco la versione rivista della tua funzione, con in più il parametro data_task che seleziona il sotto-dizionario giusto in base al task\n",
    "(es. \"task_1\", \"task_2\", …) e poi riapplica esattamente la stessa logica di STFT sui soli soggetti di quel task.\n",
    "\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "from scipy.signal import stft\n",
    "\n",
    "\n",
    "def create_spectograms_from_stft(\n",
    "    new_EEG_data: dict,\n",
    "    data_task: str,\n",
    "    window_size: int = 160,\n",
    "    step_size: int = 80,\n",
    "    fs: int = 160\n",
    "):\n",
    "    \"\"\"\n",
    "    new_EEG_data: { task: [ {cond_subj: data, cond_subj_labels: labels,...}, ... ], ... }\n",
    "    data_task:     \"task_1\" / \"task_2\" / \"task_3\" / \"task_4\"\n",
    "    \"\"\"\n",
    "\n",
    "    # --- 1) Filtra sul task richiesto ---\n",
    "    if data_task not in new_EEG_data:\n",
    "        raise KeyError(f\"Task '{data_task}' non trovato in new_EEG_data\")\n",
    "    \n",
    "    data = new_EEG_data[data_task]   # ora 'data' è la lista di dict (un elemento per soggetto)\n",
    "    \n",
    "    # --- 2) stesso codice che avevi prima ---\n",
    "    condition_results = {}\n",
    "    \n",
    "    for idx, data_dict in enumerate(data):\n",
    "        print(f\"\\n\\n\\t\\t\\t\\t\\t\\033[1mProcessing Subject {idx + 1}\\033[0m:\\n\")\n",
    "\n",
    "        for condition, value in data_dict.items():\n",
    "            \n",
    "            # Calcolo condition_key senza '_labels'\n",
    "            if condition.endswith('_labels'):\n",
    "                condition_key = condition[:-7]\n",
    "            else:\n",
    "                condition_key = condition\n",
    "            \n",
    "            # inizializzo sempre la entry\n",
    "            if condition_key not in condition_results:\n",
    "\n",
    "                condition_results[condition_key] = {'spectrograms': [], 'labels': []}\n",
    "            \n",
    "            # ——————————————————————————\n",
    "            # [PATCHED] ramo label\n",
    "            if condition.endswith('_labels'):\n",
    "                \n",
    "                # Converto in lista di interi\n",
    "                #labels = np.asarray(value, dtype=int).tolist()\n",
    "                labels = np.asarray(value, dtype=int)\n",
    "                \n",
    "                print(f\"\\nFound labels for condition \\033[1m{condition}\\033[0m, length: \\033[1m{len(labels)}\\033[0m\\n\")\n",
    "                    \n",
    "                # Uso condition_key (non labels_key!)\n",
    "                condition_results[condition_key]['labels'].extend(labels)\n",
    "                continue   \n",
    "            \n",
    "            '''\n",
    "            Cosa cambia in questo codice\n",
    "            STFT viene eseguita solo su condition che non finiscono con _labels e che sono array 3‑D.\n",
    "\n",
    "            Estensione delle etichette (.extend(num_labels)) viene spostata in un blocco if condition.endswith('_labels'),\n",
    "            dove value è già il np.ndarray mono‑dimensionale delle labels.\n",
    "\n",
    "            In questo modo:\n",
    "\n",
    "            Non tenterai più di indicizzare value[trial, channel, …] su un array 1‑D\n",
    "            Stamperai e accoderai correttamente le etichette nell’array condition_results[...]['labels']\n",
    "            Con queste due modifiche minime tutto tornerà a girare senza ulteriori errori.\n",
    "            '''\n",
    "            \n",
    "            # 1) processa solo i dati (3‑D) non le etichette 1‑D\n",
    "            if isinstance(value, np.ndarray) and value.ndim == 3:\n",
    "    \n",
    "                print(f\"\\nApplicazione STFT per '\\033[1m{condition_key}\\033[0m'\\n\")\n",
    "                print(f\"\\033[1mShape\\033[0m dei dati per \\033[1m{condition_key}\\033[0m: {value.shape}\")\n",
    "                \n",
    "                '''\n",
    "                # Esegui STFT per ogni canale e trial          \n",
    "                \n",
    "                #La funzione stft di SciPy restituisce uno spettrogramma con la forma (n_frequencies, n_time_steps),\n",
    "                #quindi:38 corrisponde al numero di bin di frequenza calcolati a partire dalla finestra FFT di 75 punti.\n",
    "                \n",
    "                #Infatti, per una finestra di lunghezza 75, il numero di bin è calcolato (in questo caso, dato che 75 è dispari) come (75 + 1) // 2, ovvero 38.\n",
    "                #Il numero di passi temporali (n_time_steps) viene invece calcolato in base alla lunghezza del segnale e ai parametri di finestra e overlap.\n",
    "                \n",
    "                #Nel tuo caso, estraendo 250 punti (da 50 a 300) con nperseg=75 e noverlap=25 (cioè con un salto di 50 campioni per finestra), \n",
    "                #il numero di segmenti dovrebbe essere:\n",
    "                #1 + [250−75/75-25] = 1 + [175/50]  = 1 + 3 = 4\n",
    "\n",
    "                #Pertanto, il risultato di stft (cioè Zxx) ha forma (38, 4) e non (4, 38). \n",
    "                #Se ti aspetti una struttura con l'asse del tempo come terza dimensione (ad esempio, (trial, canali, tempo, frequenze))\n",
    "                #potresti dover trasporre l'array in modo da scambiare le dimensioni frequenza e tempo.\n",
    "                \n",
    "                \n",
    "                1) crearmi una lista per salvarmi poi tutti gli spettrogrammi di tutti i trials\n",
    "                2) per il trials corrente mi salvo lo spettrogramma e lo appendo poi ad 1)\n",
    "                3) converto la lista di tutti gli spettrogrammi di tutti i trials della condizione corrente in array numpy \n",
    "                4) carico poi l'array numpy dentro il dizionario della condizione corrente dentro la chiave 'spectrograms'\n",
    "                '''\n",
    "                \n",
    "                all_trial_spectrograms = []\n",
    "                \n",
    "                for trial in range(value.shape[0]):\n",
    "                    single_trial_spectrograms = []\n",
    "                    \n",
    "                    for channel in range(value.shape[1]):\n",
    "                        single_channel_data = value[trial, channel, :640]\n",
    "                        \n",
    "                        #print(f\"Segment length: {len(single_channel_data)}\")\n",
    "                        \n",
    "                        '''\n",
    "                        TIENI A MENTE CHE DUE PARAMETRI GESTISCONO IL PADDING QUI AUTOMATICAMENTE, CHE SONO:\n",
    "                        \n",
    "                        boundary='zeros', \n",
    "                        padded=True,\n",
    "                        \n",
    "                        PER QUESTO MOTIVO LE FINESTRE SARANNO 11 E NON 9.\n",
    "                        \n",
    "                        IN QUESTO MODO, SI MIGLIORA LA RISOLUZIONE IN FREQUENZA ALL'INIZIO E FINE DEL SEGNALE (DI 250 PUNTI!)\n",
    "                        ANDANDO IN QUESTO MODO A RIDURRE GLI EFFETTI DI BORDO\n",
    "                        '''\n",
    "                        \n",
    "                        f, t, Zxx = stft(\n",
    "                            single_channel_data,\n",
    "                            fs=fs,\n",
    "                            window='hann',\n",
    "                            nperseg=window_size,\n",
    "                            noverlap=window_size - step_size\n",
    "                        )\n",
    "                        single_trial_spectrograms.append(Zxx) # Aggiungi lo spettrogramma calcolato per il canale corrente\n",
    "                        \n",
    "                    all_trial_spectrograms.append(np.array(single_trial_spectrograms)) # Forma: (numero_canali, frequenze, tempo)\n",
    "\n",
    "                condition_results[condition_key]['spectrograms'].extend(all_trial_spectrograms)\n",
    "                \n",
    "                \n",
    "                #if labels_key in data_dict:\n",
    "                    #num_labels = data_dict[labels_key] #QUI IN REALTA' SAREBBE GIA' ARRAY NUMPY MA PER IL CODICE CONVIENE RIPORTARLO INT COME LISTA!\n",
    "                    #'''UNICA MODIFICA IMPORTANTE DA FARE --> RIPORTARE A VALORE DI INT COME LISTA DELLE LABELS (IMPORTANTE PER DOPO!)'''\n",
    "                    #num_labels = np.asarray(value).tolist()   # trasforma in lista di int\n",
    "                    #if condition_key in condition_results:\n",
    "                    #    print(f\"\\nFound labels for condition \\033[1m{labels_key}\\033[0m, length: \\033[1m{len(num_labels)}\\033[0m\\n\")\n",
    "                    #    condition_results[condition_key]['labels'].extend(num_labels)\n",
    "                \n",
    "            \n",
    "            else:\n",
    "                print(f\"\\033[1m{condition_key}\\033[0m è np.ndarray di labels, salto STFT\")\n",
    "                        \n",
    "    # --- 3) prepara l'output concatenato ---\n",
    "    \n",
    "    # Preparazione risultati concatenati\n",
    "    all_subjects_condition_results = {}\n",
    "\n",
    "    for condition_key, results in condition_results.items():\n",
    "        if \"_labels\" in condition_key or len(results['spectrograms']) == 0:  # Verifica che ci siano spettrogrammi\n",
    "            print(f\"\\nSkipping \\033[1m{condition_key}\\033[0m as it is a label or has no valid data.\")\n",
    "            continue\n",
    "\n",
    "        wave_condition_name = f'spectrograms_{condition_key}'\n",
    "        print(f\"\\n\\nResults for \\t\\t\\t\\t\\t\\033[1m{wave_condition_name}\\033[0m:\\n\\n\")\n",
    "\n",
    "        # Converti in un array NumPy 3D finale\n",
    "        spectrograms_4d = np.array(results['spectrograms'])  # Forma: (numero_di_trial, numero_canali, frequenze, tempo)\n",
    "        labels = results['labels']\n",
    "        \n",
    "        all_subjects_condition_results[wave_condition_name] = {\n",
    "            'spectrograms_4d': spectrograms_4d,\n",
    "            'labels': labels\n",
    "        }\n",
    "\n",
    "        print(f\"spectrograms_4d shape: {spectrograms_4d.shape}\")\n",
    "    \n",
    "    '''\n",
    "    Quindi alla fine si avrà una shape del tipo (44, 61, 38, 7) dove indica che avrai\n",
    "    uno spettrogramma per ciascun trial, per ciascun canale, \n",
    "    che contiene informazioni sulle bande di frequenza e sui punti temporali. \n",
    "    \n",
    "    Questa struttura è perfetta per essere utilizzata come input per una rete neurale convoluzionale (CNN),\n",
    "    poiché la rete può apprendere dalle relazioni spaziali e temporali nei dati.\n",
    "    '''\n",
    "    \n",
    "    return all_subjects_condition_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec55f283-9ccc-4b35-98ba-293a7c4d5405",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "CREAZIONE SPETTROGRAMMI ELETTRODI x FREQUENZE - VERSIONE UFFICIALE\n",
    "\n",
    "\n",
    "\n",
    "NEW UPDATED VERSION FOR DATASET MOTOR TASK - FREQUENCY x CHANNELS UFFICIALE \n",
    "\n",
    "Ecco la versione rivista della tua funzione, con in più il parametro data_task che seleziona il sotto-dizionario giusto in base al task\n",
    "(es. \"task_1\", \"task_2\", …) e poi riapplica esattamente la stessa logica di STFT sui soli soggetti di quel task.\n",
    "\n",
    "\n",
    "\n",
    "Ti propongo una versione modificata della funzione che, per ogni soggetto e condizione, \n",
    "calcola la potenza spettrale tramite una FFT (usando np.fft.rfft) per ogni canale su un segmento specifico del segnale,\n",
    "media i risultati sui trial e costruisce un’unica immagine 2D con:\n",
    "\n",
    "Asse 0 (righe): vettore delle frequenze (ottenuto dalla FFT)\n",
    "Asse 1 (colonne): elettrodi\n",
    "\n",
    "In questo modo, per ogni soggetto e condizione avrai un’unica immagine in cui ogni “colonna” (cioè ogni elettrodo) \n",
    "mostra il vettore 1D delle potenze spettrali, come richiesto per poter interpretare successivamente il Grad-CAM.\n",
    "\n",
    "\n",
    "\n",
    "Spiegazione delle modifiche\n",
    "\n",
    "FFT anziché STFT:\n",
    "Al posto di calcolare una STFT e poi aggregare nel tempo, ora per ogni canale si esegue una FFT sul segmento selezionato\n",
    "(da segment_start a segment_end). La funzione np.fft.rfft restituisce solo i componenti a frequenza non negativa.\n",
    "\n",
    "Aggregazione sui trial:\n",
    "\n",
    "Per ciascun soggetto e condizione, \n",
    "i risultati della FFT ( = vettori di potenza spettrale), \n",
    "ossia il vettore ottenuto da ogni canale, viene impilato \n",
    "in modo da ottenere l'immagine di un trial. \n",
    " \n",
    "Ogni immagine rappresenta la potenza spettrale raccolta dalla FFT di ogni elettrodo di quel trial, e ogni immagine viene memorizzata separatamente.\n",
    "\n",
    "Formazione dell’immagine:\n",
    "I vettori di potenza di ciascun elettrodo vengono “impilati” in modo tale che, \n",
    "dopo la trasposizione, le righe rappresentino le frequenze e le colonne gli elettrodi. \n",
    "\n",
    "Questo formato permette al Grad-CAM di indicare quali frequenze e quali elettrodi risultano più discriminanti.\n",
    "\n",
    "Questa funzione dovrebbe rispondere alle richieste del tuo supervisore, generando per ogni soggetto e condizione una sola immagine interpretabile con il Grad-CAM.\n",
    "\n",
    "\n",
    "La funzione è stata progettata per rispettare quanto richiesto da Nicola. \n",
    "\n",
    "In particolare:\n",
    "\n",
    "Calcolo per ogni elettrodo: Per ciascun canale (elettrodo) viene calcolata la FFT sul segmento specificato (da segment_start a segment_end), \n",
    "ottenendo un vettore 1D con la potenza spettrale in funzione della frequenza.\n",
    "\n",
    "Aggregazione sui trial: \n",
    "\n",
    "Per ciascun soggetto e condizione, \n",
    "i risultati della FFT ( = vettori di potenza spettrale), \n",
    "ossia il vettore ottenuto da ogni canale, viene impilato \n",
    "in modo da ottenere l'immagine di un trial. \n",
    " \n",
    "Ogni immagine rappresenta la potenza spettrale raccolta dalla FFT di ogni elettrodo di quel trial, e ogni immagine viene memorizzata separatamente.\n",
    "\n",
    " \n",
    "Creazione dell'immagine: \n",
    "\n",
    "Questi vettori, NON concatenati ma organizzati in colonne, vengono trasposti in modo da avere \n",
    "\n",
    "    - le righe rappresentanti le frequenze\n",
    "    - le colonne gli elettrodi \n",
    "    \n",
    "Così si ottiene, per ogni soggetto (e per ogni condizione) una singola immagine, \n",
    "che permette al Grad-CAM di evidenziare quali elettrodi (e quali frequenze) siano determinanti nel processo decisionale.\n",
    "\n",
    "Se questo è esattamente quanto intendeva Nicola (\"l'immagine sarebbe una sola per ogni soggetto\" ottenuta raggruppando i vettori di ogni elettrodo), \n",
    "allora la funzione è adattata correttamente.\n",
    "\n",
    "\n",
    "---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ----\n",
    "RISULTATO FINALE:\n",
    "\n",
    "1) Una immagine per ogni trial:\n",
    "La variabile trial_power calcola la potenza spettrale per ciascun trial e la salva come una singola immagine (2D). \n",
    "    Queste immagini sono salvate nel dizionario condition_results[condition_key]['fft_images'] una per ciascun trial.\n",
    "\n",
    "2) Shape dell'immagine:\n",
    "Ogni immagine ha la forma (n_freq, n_channels), dove:\n",
    "\n",
    "- n_freq è il numero di frequenze calcolato con np.fft.rfft.\n",
    "- n_channels è il numero di elettrodi.\n",
    "\n",
    "3) Etichette:\n",
    "Se sono presenti le etichette per la condizione, vengono associate correttamente e stampate, come nel codice originale.\n",
    "\n",
    "4) Dizionario finale:\n",
    "Alla fine, il dizionario all_subjects_condition_results contiene un array 3D per ogni condizione (uno per ogni trial), con la forma \n",
    "    (n_trials, n_freq, n_channels).\n",
    "\n",
    "Questo codice ora mantiene la logica originale di creare una immagine per ogni trial, mentre applica la FFT per calcolare la potenza spettrale. \n",
    "\n",
    "---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ----\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "#Ecco la versione rivista della tua funzione, con in più il parametro data_task che seleziona il sotto-dizionario giusto in base al task\n",
    "#(es. \"task_1\", \"task_2\", …) e poi riapplica esattamente la stessa logica di STFT sui soli soggetti di quel task.\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def create_spectrograms_from_fft_images_of_electrodes(\n",
    "    new_EEG_data: dict,\n",
    "    data_task: str,\n",
    "    segment_start: int = 0,\n",
    "    segment_end: int = 640,\n",
    "    fs: int = 160,\n",
    "    max_freq_bins: int = 45\n",
    "):\n",
    "    \n",
    "    \"\"\"\n",
    "    Per ogni soggetto e condizione, calcola le immagini della potenza spettrale per ciascun elettrodo \n",
    "    usando la FFT (np.fft.rfft) sul segmento definito del segnale (per esempio l'intero trial).\n",
    "    \n",
    "    Per ogni trial, viene calcolata la FFT per ogni canale, ottenendo un vettore 1D di potenza spettrale.\n",
    "    Viene poi tagliato lo spettro per mantenere solo le prime 'max_freq_bins' frequenze.\n",
    "    \n",
    "    Ogni trial genera un'immagine 2D (righe: frequenze, colonne: elettrodi) che viene memorizzata separatamente.\n",
    "    \n",
    "    Parameters:\n",
    "        data (list di dict): Ogni dict corrisponde a un soggetto e contiene le condizioni sperimentali\n",
    "                              (chiavi con dati in formato np.array di shape (n_trials, n_channels, n_timepoints))\n",
    "                              e, eventualmente, le relative etichette (con chiave condition_labels).\n",
    "        segment_start (int): Indice iniziale del segmento da analizzare.\n",
    "        segment_end (int): Indice finale del segmento da analizzare.\n",
    "        fs (int): Frequenza di campionamento.\n",
    "        max_freq_bins (int): Numero massimo di frequenze da mantenere (ad es. le prime 45 frequenze).\n",
    "    \n",
    "    Returns:\n",
    "        dict: Un dizionario in cui per ogni condizione sono memorizzati:\n",
    "              - 'spectrograms_3d': array 3D contenente le immagini per ogni trial (shape: n_trials x max_freq_bins x n_channels)\n",
    "              - 'labels': etichette associate (se presenti)\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    new_EEG_data: { \n",
    "      task: [ {cond_subj: np.ndarray, cond_subj_labels: np.ndarray, ...},  # subj1\n",
    "               { ... },  # subj2\n",
    "               ... ],\n",
    "      ...\n",
    "    }\n",
    "    data_task:     \"task_1\" / \"task_2\" / \"task_3\" / \"task_4\"\n",
    "    \n",
    "    Ritorna:\n",
    "      { 'cond': {\n",
    "           'spectrograms_3d': ndarray(n_trials_tot, n_freq_bins, n_channels),\n",
    "           'labels':         ndarray(n_trials_tot,)\n",
    "         },\n",
    "        ...\n",
    "      }\n",
    "    \"\"\"\n",
    "    # --- 1) Filtra sul task richiesto ---\n",
    "    if data_task not in new_EEG_data:\n",
    "        raise KeyError(f\"Task '{data_task}' non trovato in new_EEG_data\")\n",
    "    data = new_EEG_data[data_task]  # lista di dict, uno per soggetto\n",
    "\n",
    "    \n",
    "\n",
    "    # --- 2) corpo originale, invariato ---\n",
    "\n",
    "    # Dizionario per memorizzare i risultati per ciascuna condizione sperimentale\n",
    "    condition_results = {}\n",
    "    \n",
    "    for idx, data_dict in enumerate(data):\n",
    "        \n",
    "\n",
    "        print(f\"\\n\\n\\t\\t\\t\\t\\t\\033[1mProcessing Subject {idx + 1}\\033[0m:\\n\")\n",
    "\n",
    "        for condition, value in data_dict.items():\n",
    "            \n",
    "            # Calcolo condition_key senza '_labels'\n",
    "            if condition.endswith('_labels'):\n",
    "                condition_key = condition[:-7]\n",
    "            else:\n",
    "                condition_key = condition\n",
    "            \n",
    "            # inizializzo sempre la entry\n",
    "            if condition_key not in condition_results:\n",
    "\n",
    "                condition_results[condition_key] = {'fft_images': [], 'labels': []}\n",
    "    \n",
    "            \n",
    "            # ——————————————————————————\n",
    "            # [PATCHED] ramo label\n",
    "            if condition.endswith('_labels'):\n",
    "                \n",
    "                # Converto in lista di interi\n",
    "                #labels = np.asarray(value, dtype=int).tolist()\n",
    "                labels = np.asarray(value, dtype=int)\n",
    "                \n",
    "                print(f\"\\nFound labels for condition \\033[1m{condition}\\033[0m, length: \\033[1m{len(labels)}\\033[0m\\n\")\n",
    "                    \n",
    "                # Uso condition_key (non labels_key!)\n",
    "                condition_results[condition_key]['labels'].extend(labels)\n",
    "                continue\n",
    "            \n",
    "            '''\n",
    "            In pratica\n",
    "            Riga 1: if not condition.endswith('_labels') and isinstance(value, np.ndarray):\n",
    "            → processa solo i dati (n_trials, n_chan, n_time)\n",
    "\n",
    "            Riga 2: elif condition.endswith('_labels') and isinstance(value, np.ndarray):\n",
    "            → processa solo le labels (n_trials,)\n",
    "\n",
    "            Riga 3: else:\n",
    "            → tutto il resto viene ignorato\n",
    "\n",
    "            Con questo schema le tue fft‐images useranno solo gli array 3‑D, e le labels verranno raccolte nel punto giusto, \n",
    "            senza mai andare a indicizzare una shape non valida.\n",
    "            '''\n",
    "            \n",
    "            #OLD VERSION --> vecchia versione: processi ogni np.ndarray, incluso quello 1‑D delle labels\n",
    "            #if isinstance(value, np.ndarray):\n",
    "            \n",
    "            # 1) FFT SOLO su array 3‑D (i dati veri)\n",
    "            #if not condition.endswith('_labels') and isinstance(value, np.ndarray):\n",
    "            \n",
    "            # 1) processa solo i dati (3‑D) non le etichette 1‑D\n",
    "            if isinstance(value, np.ndarray) and value.ndim == 3:\n",
    "                \n",
    "                # … STFT sul valore 3‑D …\n",
    "                print(f\"\\nApplicazione FFT per '\\033[1m{condition_key}\\033[0m'\\n\")\n",
    "                print(f\"\\033[1mShape\\033[0m dei dati per \\033[1m{condition_key}\\033[0m: {value.shape}\")\n",
    "                \n",
    "                # Presupponiamo che 'value' abbia forma: (n_trials, n_channels, n_timepoints)\n",
    "                n_trials, n_channels, _ = value.shape\n",
    "                \n",
    "                N = segment_end - segment_start  # lunghezza del segmento analizzato\n",
    "                \n",
    "                n_freq = N // 2 + 1  # np.fft.rfft restituisce n_freq = N//2 + 1\n",
    "                \n",
    "                # Determina il numero di frequenze da utilizzare (taglia lo spettro)\n",
    "                effective_freq_bins = min(n_freq, max_freq_bins)\n",
    "                \n",
    "                # Itera su ogni trial e ogni canale per calcolare la potenza spettrale\n",
    "                for trial in range(n_trials):\n",
    "                    \n",
    "                    #trial_power = np.zeros((n_channels, n_freq))  # Matrice per la potenza per ogni trial\n",
    "                    trial_power = np.zeros((n_channels, effective_freq_bins))  # Matrice per la potenza per ogni trial\n",
    "                    \n",
    "                    for channel in range(n_channels):\n",
    "                        \n",
    "                        # Estrai il segmento del segnale\n",
    "                        single_channel_data = value[trial, channel, segment_start:segment_end]\n",
    "                        \n",
    "                        # Calcola la FFT (solo componenti a frequenza non negativa)\n",
    "                        # -> https://numpy.org/doc/stable/reference/generated/numpy.fft.rfft.html\n",
    "                        fft_vals = np.fft.rfft(single_channel_data)\n",
    "                        \n",
    "                        # Calcola la potenza spettrale (modulo al quadrato)\n",
    "                        power = np.abs(fft_vals) ** 2\n",
    "                        \n",
    "                        #trial_power[channel] = power\n",
    "                        \n",
    "                        trial_power[channel] = power[:effective_freq_bins]\n",
    "                    \n",
    "                    # Trasponi in modo che le righe siano le frequenze e le colonne gli elettrodi\n",
    "                    fft_image = trial_power.T  # shape: (n_freq, n_channels)\n",
    "                    #print(f\"FFT image shape for trial {trial + 1} of condition '{condition_key}': {fft_image.shape}\")\n",
    "                    \n",
    "                    # Salva l'immagine per il trial corrente\n",
    "                    #Ogni trial genera una sua immagine della potenza spettrale che viene memorizzata separatamente!\n",
    "                    condition_results[condition_key]['fft_images'].append(fft_image)\n",
    "                \n",
    "                # Gestione delle etichette se presenti                \n",
    "                #if labels_key in data_dict:\n",
    "                    #num_labels = data_dict[labels_key] #QUI IN REALTA' SAREBBE GIA' ARRAY NUMPY MA PER IL CODICE CONVIENE RIPORTARLO INT COME LISTA!\n",
    "                    #'''UNICA MODIFICA IMPORTANTE DA FARE --> RIPORTARE A VALORE DI INT COME LISTA DELLE LABELS (IMPORTANTE PER DOPO!)'''\n",
    "                    #num_labels = np.asarray(value).tolist()   # trasforma in lista di int\n",
    "                    #if condition_key in condition_results:\n",
    "                    #    print(f\"\\nFound labels for condition \\033[1m{labels_key}\\033[0m, length: \\033[1m{len(num_labels)}\\033[0m\\n\")\n",
    "                    #    condition_results[condition_key]['labels'].extend(num_labels)\n",
    "                \n",
    "            else:\n",
    "                #print(f\"\\033[1m{labels_key}\\033[0m non è un np.ndarray, non applicare la FFT\")\n",
    "                print(f\"\\033[1m{condition_key}\\033[0m è np.ndarray di labels, salto FFT\")    \n",
    "    \n",
    "    # Riorganizza i risultati in un dizionario finale\n",
    "    all_subjects_condition_results = {}\n",
    "    for condition_key, results in condition_results.items():\n",
    "        if \"_labels\" in condition_key or len(results['fft_images']) == 0:\n",
    "            print(f\"\\nSkipping \\033[1m{condition_key}\\033[0m as it is a label or has no valid data.\")\n",
    "            continue\n",
    "        \n",
    "        wave_condition_name = f'spectrograms_{condition_key}'\n",
    "        print(f\"\\n\\nResults for \\t\\t\\t\\t\\t\\033[1m{wave_condition_name}\\033[0m:\\n\\n\")\n",
    "        \n",
    "        # Ogni trial produce un'immagine 2D di shape (n_freq, n_channels)\n",
    "        spectrograms_3d = np.array(results['fft_images'])\n",
    "        all_subjects_condition_results[wave_condition_name] = {\n",
    "            'spectrograms_3d': spectrograms_3d,\n",
    "            'labels': results['labels']\n",
    "        }\n",
    "        print(f\"spectrograms_3d shape for {wave_condition_name}: {spectrograms_3d.shape}\")\n",
    "    \n",
    "    return all_subjects_condition_results\n",
    "\n",
    "\n",
    "#new_all_subjects_condition_spectrograms_th = create_spectrograms_from_fft_images_of_electrodes (therapists_data, segment_start = 50, segment_end = 300, fs=250, max_freq_bins=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89967ab-f373-4f13-8a04-81d6b7c5363d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "def create_spectrograms_from_fft_images_of_electrodes(\n",
    "    new_EEG_data: dict,\n",
    "    data_task: str,\n",
    "    segment_start: int = 0,\n",
    "    segment_end: int = 640,\n",
    "    fs: int = 160,\n",
    "    max_freq_bins: int = 45\n",
    "):\n",
    "    \n",
    "'''\n",
    "\n",
    "new_all_subjects_condition_spectrograms_task_1 = create_spectrograms_from_fft_images_of_electrodes(new_EEG_data,\n",
    "                                                                                                   'task_1',\n",
    "                                                                                                   segment_start = 0,\n",
    "                                                                                                   segment_end = 640,\n",
    "                                                                                                   fs=160,\n",
    "                                                                                                   max_freq_bins=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9190be24-5b03-4814-ab1d-04225ed944df",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('finito')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46f92f7-e9ed-4221-82cd-4025066d568e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_all_subjects_condition_spectrograms_task_1.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37d3c3b-7394-429b-a33a-7c944fb36331",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new_all_subjects_condition_spectrograms_task_1['spectrograms_rest_100']['spectrograms_3d'].shape)\n",
    "print()\n",
    "print(len(new_all_subjects_condition_spectrograms_task_1['spectrograms_rest_100']['labels']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1ddc0c-2c08-4fd9-8afd-dd00df7567c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "base_path = '/home/stefano/Interrogait/all_datas/Spectrograms_channels_frequencies_motor_tasks/'\n",
    "\n",
    "# Controlla se la cartella esiste, altrimenti la crea\n",
    "if not os.path.exists(base_path):\n",
    "    os.makedirs(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef61dad5-bda7-4fb6-9384-bef05cf269c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvare l'intero dizionario annidato con pickle\n",
    "with open(f'{base_path}new_all_subjects_condition_spectrograms_task_1.pkl', 'wb') as f:\n",
    "    pickle.dump(new_all_subjects_condition_spectrograms_task_1, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec13905-c236-4ad6-8181-f3d897501057",
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_all_subjects_condition_spectrograms_task_1.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50849fcd-ee1b-43c0-920d-07c90fd9c89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_all_subjects_condition_spectrograms_task_1['spectrograms_baseline_1'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131b0a7c-63ed-45d3-a54c-2827bc4195e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_all_subjects_condition_spectrograms_task_1['spectrograms_baseline_1']['spectrograms_3d'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90947991-ea35-4cd4-98a6-18b49592afb4",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### **Creazione Immagine 2D Grid EEG** per All **SINGLE** Subject **Spectrograms** per **Tutte le Condizioni Sperimentali**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9984ba3d-24e8-4149-ac79-d6695dba69c4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### **Richiesta Fatta a ChatGPT**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75664521-79e2-47a8-8f57-0f5e9e90b0bf",
   "metadata": {},
   "source": [
    "Ok ora per dirti, sto cercando di capire che step devo fare per creare questa immagine 2D...\n",
    "\n",
    "inizialmente usavo questa funzione per calcolarmi la rappresentazione frequenza-elettrodi dell'immagine\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def create_spectrograms_from_fft_images_of_electrodes(\n",
    "    new_EEG_data: dict,\n",
    "    data_task: str,\n",
    "    segment_start: int = 0,\n",
    "    segment_end: int = 640,\n",
    "    fs: int = 160,\n",
    "    max_freq_bins: int = 45\n",
    "):\n",
    "    \n",
    "    \"\"\"\n",
    "    Per ogni soggetto e condizione, calcola le immagini della potenza spettrale per ciascun elettrodo \n",
    "    usando la FFT (np.fft.rfft) sul segmento definito del segnale (per esempio l'intero trial).\n",
    "    \n",
    "    Per ogni trial, viene calcolata la FFT per ogni canale, ottenendo un vettore 1D di potenza spettrale.\n",
    "    Viene poi tagliato lo spettro per mantenere solo le prime 'max_freq_bins' frequenze.\n",
    "    \n",
    "    Ogni trial genera un'immagine 2D (righe: frequenze, colonne: elettrodi) che viene memorizzata separatamente.\n",
    "    \n",
    "    Parameters:\n",
    "        data (list di dict): Ogni dict corrisponde a un soggetto e contiene le condizioni sperimentali\n",
    "                              (chiavi con dati in formato np.array di shape (n_trials, n_channels, n_timepoints))\n",
    "                              e, eventualmente, le relative etichette (con chiave condition_labels).\n",
    "        segment_start (int): Indice iniziale del segmento da analizzare.\n",
    "        segment_end (int): Indice finale del segmento da analizzare.\n",
    "        fs (int): Frequenza di campionamento.\n",
    "        max_freq_bins (int): Numero massimo di frequenze da mantenere (ad es. le prime 45 frequenze).\n",
    "    \n",
    "    Returns:\n",
    "        dict: Un dizionario in cui per ogni condizione sono memorizzati:\n",
    "              - 'spectrograms_3d': array 3D contenente le immagini per ogni trial (shape: n_trials x max_freq_bins x n_channels)\n",
    "              - 'labels': etichette associate (se presenti)\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    new_EEG_data: { \n",
    "      task: [ {cond_subj: np.ndarray, cond_subj_labels: np.ndarray, ...},  # subj1\n",
    "               { ... },  # subj2\n",
    "               ... ],\n",
    "      ...\n",
    "    }\n",
    "    data_task:     \"task_1\" / \"task_2\" / \"task_3\" / \"task_4\"\n",
    "    \n",
    "    Ritorna:\n",
    "      { 'cond': {\n",
    "           'spectrograms_3d': ndarray(n_trials_tot, n_freq_bins, n_channels),\n",
    "           'labels':         ndarray(n_trials_tot,)\n",
    "         },\n",
    "        ...\n",
    "      }\n",
    "    \"\"\"\n",
    "    # --- 1) Filtra sul task richiesto ---\n",
    "    if data_task not in new_EEG_data:\n",
    "        raise KeyError(f\"Task '{data_task}' non trovato in new_EEG_data\")\n",
    "    data = new_EEG_data[data_task]  # lista di dict, uno per soggetto\n",
    "\n",
    "    \n",
    "\n",
    "    # --- 2) corpo originale, invariato ---\n",
    "\n",
    "    # Dizionario per memorizzare i risultati per ciascuna condizione sperimentale\n",
    "    condition_results = {}\n",
    "    \n",
    "    for idx, data_dict in enumerate(data):\n",
    "        \n",
    "\n",
    "        print(f\"\\n\\n\\t\\t\\t\\t\\t\\033[1mProcessing Subject {idx + 1}\\033[0m:\\n\")\n",
    "\n",
    "        for condition, value in data_dict.items():\n",
    "            \n",
    "            # Calcolo condition_key senza '_labels'\n",
    "            if condition.endswith('_labels'):\n",
    "                condition_key = condition[:-7]\n",
    "            else:\n",
    "                condition_key = condition\n",
    "            \n",
    "            # inizializzo sempre la entry\n",
    "            if condition_key not in condition_results:\n",
    "\n",
    "                condition_results[condition_key] = {'fft_images': [], 'labels': []}\n",
    "    \n",
    "            \n",
    "            # ——————————————————————————\n",
    "            # [PATCHED] ramo label\n",
    "            if condition.endswith('_labels'):\n",
    "                \n",
    "                # Converto in lista di interi\n",
    "                #labels = np.asarray(value, dtype=int).tolist()\n",
    "                labels = np.asarray(value, dtype=int)\n",
    "                \n",
    "                print(f\"\\nFound labels for condition \\033[1m{condition}\\033[0m, length: \\033[1m{len(labels)}\\033[0m\\n\")\n",
    "                    \n",
    "                # Uso condition_key (non labels_key!)\n",
    "                condition_results[condition_key]['labels'].extend(labels)\n",
    "                continue\n",
    "            \n",
    "            '''\n",
    "            In pratica\n",
    "            Riga 1: if not condition.endswith('_labels') and isinstance(value, np.ndarray):\n",
    "            → processa solo i dati (n_trials, n_chan, n_time)\n",
    "\n",
    "            Riga 2: elif condition.endswith('_labels') and isinstance(value, np.ndarray):\n",
    "            → processa solo le labels (n_trials,)\n",
    "\n",
    "            Riga 3: else:\n",
    "            → tutto il resto viene ignorato\n",
    "\n",
    "            Con questo schema le tue fft‐images useranno solo gli array 3‑D, e le labels verranno raccolte nel punto giusto, \n",
    "            senza mai andare a indicizzare una shape non valida.\n",
    "            '''\n",
    "            \n",
    "            #OLD VERSION --> vecchia versione: processi ogni np.ndarray, incluso quello 1‑D delle labels\n",
    "            #if isinstance(value, np.ndarray):\n",
    "            \n",
    "            # 1) FFT SOLO su array 3‑D (i dati veri)\n",
    "            #if not condition.endswith('_labels') and isinstance(value, np.ndarray):\n",
    "            \n",
    "            # 1) processa solo i dati (3‑D) non le etichette 1‑D\n",
    "            if isinstance(value, np.ndarray) and value.ndim == 3:\n",
    "                \n",
    "                # … STFT sul valore 3‑D …\n",
    "                print(f\"\\nApplicazione FFT per '\\033[1m{condition_key}\\033[0m'\\n\")\n",
    "                print(f\"\\033[1mShape\\033[0m dei dati per \\033[1m{condition_key}\\033[0m: {value.shape}\")\n",
    "                \n",
    "                # Presupponiamo che 'value' abbia forma: (n_trials, n_channels, n_timepoints)\n",
    "                n_trials, n_channels, _ = value.shape\n",
    "                \n",
    "                N = segment_end - segment_start  # lunghezza del segmento analizzato\n",
    "                \n",
    "                n_freq = N // 2 + 1  # np.fft.rfft restituisce n_freq = N//2 + 1\n",
    "                \n",
    "                # Determina il numero di frequenze da utilizzare (taglia lo spettro)\n",
    "                effective_freq_bins = min(n_freq, max_freq_bins)\n",
    "                \n",
    "                # Itera su ogni trial e ogni canale per calcolare la potenza spettrale\n",
    "                for trial in range(n_trials):\n",
    "                    \n",
    "                    #trial_power = np.zeros((n_channels, n_freq))  # Matrice per la potenza per ogni trial\n",
    "                    trial_power = np.zeros((n_channels, effective_freq_bins))  # Matrice per la potenza per ogni trial\n",
    "                    \n",
    "                    for channel in range(n_channels):\n",
    "                        \n",
    "                        # Estrai il segmento del segnale\n",
    "                        single_channel_data = value[trial, channel, segment_start:segment_end]\n",
    "                        \n",
    "                        # Calcola la FFT (solo componenti a frequenza non negativa)\n",
    "                        # -> https://numpy.org/doc/stable/reference/generated/numpy.fft.rfft.html\n",
    "                        fft_vals = np.fft.rfft(single_channel_data)\n",
    "                        \n",
    "                        # Calcola la potenza spettrale (modulo al quadrato)\n",
    "                        power = np.abs(fft_vals) ** 2\n",
    "                        #trial_power[channel] = power\n",
    "                        trial_power[channel] = power[:effective_freq_bins]\n",
    "                    \n",
    "                    # Trasponi in modo che le righe siano le frequenze e le colonne gli elettrodi\n",
    "                    fft_image = trial_power.T  # shape: (n_freq, n_channels)\n",
    "                    #print(f\"FFT image shape for trial {trial + 1} of condition '{condition_key}': {fft_image.shape}\")\n",
    "                    \n",
    "                    # Salva l'immagine per il trial corrente\n",
    "                    #Ogni trial genera una sua immagine della potenza spettrale che viene memorizzata separatamente!\n",
    "                    condition_results[condition_key]['fft_images'].append(fft_image)\n",
    "                \n",
    "                # Gestione delle etichette se presenti                \n",
    "                #if labels_key in data_dict:\n",
    "                    #num_labels = data_dict[labels_key] #QUI IN REALTA' SAREBBE GIA' ARRAY NUMPY MA PER IL CODICE CONVIENE RIPORTARLO INT COME LISTA!\n",
    "                    #'''UNICA MODIFICA IMPORTANTE DA FARE --> RIPORTARE A VALORE DI INT COME LISTA DELLE LABELS (IMPORTANTE PER DOPO!)'''\n",
    "                    #num_labels = np.asarray(value).tolist()   # trasforma in lista di int\n",
    "                    #if condition_key in condition_results:\n",
    "                    #    print(f\"\\nFound labels for condition \\033[1m{labels_key}\\033[0m, length: \\033[1m{len(num_labels)}\\033[0m\\n\")\n",
    "                    #    condition_results[condition_key]['labels'].extend(num_labels)\n",
    "                \n",
    "            else:\n",
    "                #print(f\"\\033[1m{labels_key}\\033[0m non è un np.ndarray, non applicare la FFT\")\n",
    "                print(f\"\\033[1m{condition_key}\\033[0m è np.ndarray di labels, salto FFT\")    \n",
    "    \n",
    "    # Riorganizza i risultati in un dizionario finale\n",
    "    all_subjects_condition_results = {}\n",
    "    for condition_key, results in condition_results.items():\n",
    "        if \"_labels\" in condition_key or len(results['fft_images']) == 0:\n",
    "            print(f\"\\nSkipping \\033[1m{condition_key}\\033[0m as it is a label or has no valid data.\")\n",
    "            continue\n",
    "        \n",
    "        wave_condition_name = f'spectrograms_{condition_key}'\n",
    "        print(f\"\\n\\nResults for \\t\\t\\t\\t\\t\\033[1m{wave_condition_name}\\033[0m:\\n\\n\")\n",
    "        \n",
    "        # Ogni trial produce un'immagine 2D di shape (n_freq, n_channels)\n",
    "        spectrograms_3d = np.array(results['fft_images'])\n",
    "        all_subjects_condition_results[wave_condition_name] = {\n",
    "            'spectrograms_3d': spectrograms_3d,\n",
    "            'labels': results['labels']\n",
    "        }\n",
    "        print(f\"spectrograms_3d shape for {wave_condition_name}: {spectrograms_3d.shape}\")\n",
    "    \n",
    "    return all_subjects_condition_results\n",
    "\n",
    "\n",
    "ora, io mi ero caricato già la lista degli elettrodi nella directory del file da remoto\n",
    "\n",
    "\n",
    "import pickle\n",
    "\n",
    "#Caricare l'intero dizionario annidato con pickle\n",
    "path = '/home/stefano/EEGMMIDB_Analyses/'\n",
    "\n",
    "#Caricare l'intero dizionario annidato con pickle\n",
    "with open(f'{path}EEG_channels_names.pkl', 'rb') as f:\n",
    "    EEG_channels_names = pickle.load(f)\n",
    "\n",
    "\n",
    "#Supponendo che EEG_channels_names sia la tua lista originale\n",
    "EEG_channels_names = [ch.rstrip('.') for ch in EEG_channels_names]\n",
    "print(EEG_channels_names, end = '')\n",
    "\n",
    "e veniva fuori questa lista alla fine..\n",
    "\n",
    "['Fc5', 'Fc3', 'Fc1', 'Fcz', 'Fc2', 'Fc4', 'Fc6', 'C5', 'C3', 'C1', 'Cz', 'C2', 'C4', 'C6', 'Cp5', 'Cp3', 'Cp1', 'Cpz', 'Cp2', 'Cp4', 'Cp6', 'Fp1', 'Fpz', 'Fp2', 'Af7', 'Af3', 'Afz', 'Af4', 'Af8', 'F7', 'F5', 'F3', 'F1', 'Fz', 'F2', 'F4', 'F6', 'F8', 'Ft7', 'Ft8', 'T7', 'T8', 'T9', 'T10', 'Tp7', 'Tp8', 'P7', 'P5', 'P3', 'P1', 'Pz', 'P2', 'P4', 'P6', 'P8', 'Po7', 'Po3', 'Poz', 'Po4', 'Po8', 'O1', 'Oz', 'O2', 'Iz']\n",
    "\n",
    "ora, per costruire la griglia, devo però riprendere questa lista che ho salvato e \n",
    "fornirla come input alla funzione che creerà l'immagine della griglia stessa...\n",
    "questa funzione da creare, dovrà creare la griglia confrontando \n",
    "\n",
    "il valore stringa di ogni elettrodo nella lista degli elettrodi del file .xlsx  con il valore stringa degli elettrodi nelle righe del campo 'Electrode' del file .xlsx (forse questo dovrò esser caricato come pandas dataframe alla fine..)\n",
    "\n",
    "e vedere se c'è corrispondenza. \n",
    "\n",
    "Nel caso non ci sia, il nome delle righe del campo 'Electrode' del file .xlsx (ossia le stringhe associate ad ogni elettrodo) devono essere uguali (in caso non lo fossero già) a quelli di ogni elettrodo nella lista degli elettrodi del file .xlsx ..\n",
    "\n",
    "una volta che son uguali.. da quello che ho capito.. io dovrei praticamente\n",
    "\n",
    "1) riprendere la struttura dati che ho usato per salvare gli spettrogrammi di ogni ogni soggetto (la funzione di cui sopra) e\n",
    "\n",
    "2) andare a prelevare rispetto ad ogni elettrodo il valore della sua coordinata sull'asse x ed y (presenti nei campi grid_x e grid_y del file xlsx) ed apporli dentro all'immagine griglia da creare.\n",
    "\n",
    "3) associare a quell'elettrodo là poi il valore della potenza totale (derivabile semplicemente dal valore che c'è dentro la struttura dati che ho salvato per salvarmi la potenza di ogni elettrodo durante la costruzione dello spettrogramma per ogni canale)...\n",
    "\n",
    "4) non so si possa al tempo stesso salvare o un'altra griglia od in un semplice dizionario, che invece semplicemente salvi anziché il valore della potenza totale per l'i-esimo elettrodo,  il valore della stringa associata all'elettrodo nella sua relativa combinazione della coordinata x ed y corrispondente, in modo che poi successivamente io sappia per successive analisi capire come ricostruire il nome dell'elettrodo a partire dalle sue coordinate nell'immagine a griglia.\n",
    "\n",
    "Se vedi, inoltre, nel file .xlsx, ci sono alcune righe del campo 'Electrode' che hanno scritto 'EMPTY'.. ecco, in quei casi lì, non c'è un elettrodo, però in quel set di coordinate corrispondente anziché mettere il valore della potenza (che in quel caso appunto non c'è) ci si dovrà mettere 0 ovviamente (perché appunto non c'è nessun elettrodo)..\n",
    "\n",
    "tieni presente che questo è stato fatto per creare una griglia \"quadrata\" con una disposizione in 2D degli elettrodi, dato che poi verrà passata come immagine dentro ad una rete CNN2D_LSTM...\n",
    "\n",
    "è tutto chiaro più o meno?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a129b85a-a817-45d3-9473-67762509ac83",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### **CHATGPT**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bebe767-4fc5-4c0b-bab3-c918f6af9257",
   "metadata": {},
   "source": [
    "Perfetto, la struttura del file .xlsx è chiara. Il DataFrame ha:\n",
    "\n",
    "Colonna 'Electrode' con i nomi dei canali EEG (e anche alcuni placeholder tipo 'EMPTY').\n",
    "\n",
    "Colonne 'grid_x' e 'grid_y' che definiscono la posizione 2D dell'elettrodo nell’immagine.\n",
    "\n",
    "✅ Riepilogo chiaro dei passaggi da fare:\n",
    "1. Allineamento dei nomi\n",
    "Normalizza i nomi degli elettrodi:\n",
    "\n",
    "Elimina maiuscole/minuscole (upper() o lower()).\n",
    "\n",
    "Rimuovi punti o simboli se presenti (rstrip('.') lo fai già).\n",
    "\n",
    "Verifica che i nomi della tua lista EEG_channels_names combacino con quelli del file .xlsx.\n",
    "\n",
    "2. Creazione dell'immagine 2D\n",
    "Per ciascun trial:\n",
    "\n",
    "Inizializza una griglia 2D vuota di dimensioni coerenti (es. 9x9) → magari come np.zeros((9,9)) o direttamente da grid_x e grid_y normalizzati.\n",
    "\n",
    "Per ogni riga del .xlsx:\n",
    "\n",
    "Se 'Electrode' è 'EMPTY': metti 0 in quella posizione (griglia vuota).\n",
    "\n",
    "Se è un elettrodo valido:\n",
    "\n",
    "Trova il suo indice nella lista EEG_channels_names per accedere al valore di potenza.\n",
    "\n",
    "Inserisci quel valore nella posizione (grid_y, grid_x).\n",
    "\n",
    "🔁 Opzionale: Dizionario per mappare coordinate → nome elettrodo\n",
    "Per esempio:\n",
    "\n",
    "python\n",
    "Copia\n",
    "Modifica\n",
    "coordinate_to_electrode = {(y, x): name}\n",
    "Utile per sapere quale elettrodo si trova in quale posizione della griglia.\n",
    "\n",
    "🔜 Prossimo passo\n",
    "Vuoi che ti costruisca io una funzione Python che:\n",
    "\n",
    "Prende in input:\n",
    "\n",
    "Il dataframe .xlsx,\n",
    "\n",
    "La lista EEG_channels_names,\n",
    "\n",
    "Un vettore di potenze (es. da uno spettrogramma fft_image per un trial),\n",
    "\n",
    "Restituisce:\n",
    "\n",
    "L’immagine 2D completa (con 0 dove non ci sono elettrodi),\n",
    "\n",
    "Un dizionario (y, x) → 'Electrode'?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4c4075-1807-467b-966e-1b040f264ea9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### **IO**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584d605a-b11e-41c9-b8f1-e17656c46e1b",
   "metadata": {},
   "source": [
    "Semplicemente in \n",
    "\n",
    "1. Allineamento dei nomi\n",
    "\n",
    "Verifica che i nomi della tua lista EEG_channels_names combacino con quelli del file .xlsx, se nel file .xlsx non combaciano per lo stesso elettrodo allora semplicemente cambiali e rendili come quelli della lista EEG_channels_names \n",
    "\n",
    "2. Creazione dell'immagine 2D\n",
    "\n",
    "Per ciascun trial (? o se può fare prima?) \n",
    "\n",
    "Inizializza una griglia 2D vuota, pari al numero di elettrodi della lista EEG_channels_names\n",
    "\n",
    "Per ogni riga del .xlsx:\n",
    "\n",
    "Associa ad ogni riga del campo 'Electrode' una posizione dell'elettrodo trovato, in base alle coordinate (ai valori) che si trovano nella stessa riga al campo 'grid_x' e 'grid_y'\n",
    "\n",
    "N.B. tieni presente che, se ho capito bene, per disporre gli elettrodi nella griglia 2D, l'ordine degli assi è 'asse y' (grid_y) e asse x (grid_x), quindi fai attenzione a prendere prima il valore dell'asse y e poi quello dell'asse x (controllando il nome del campo nel file .xlsx, che sarebbero 'grid_y' e 'grid_x'!).\n",
    "\n",
    "Ora, fai attenzione che son stati messi anche degli altri valori nel campo 'Electrode' del file .xlsx che non sono degli elettrodi, ma che servivano per costruire l'immagine a griglia 2D come immagine quadrata.\n",
    " \n",
    "Se in 'Electrode' c'è un valore che è uguale ad 'EMPTY': allora metti 0 in quella posizione della griglia 2D (anzichè il valore della potenza del segnale, che ovviamente non c'è perché appunto non c'era nessun elettrodo) \n",
    "\n",
    "Altrimenti, se in 'Electrode' c'è un valore che è diverso da  'EMPTY', allora significa che là ci sarà  un elettrodo valido. \n",
    "Quindi, allora, a quel punto, trova per quell'elettrodo il suo indice nella lista EEG_channels_names per poter accedere al suo relativo valore di potenza tramite indicizzazione corrispondente all'interno della matrice dei dati, che costituisce le informazioni frequenza x canali del trial EEG corrente iterato e inserisci quel valore di potenza totale in quella posizione (grid_y, grid_x) dell'elettrodo trovato.\n",
    "\n",
    "in questo modo, potrei avere a partire dalla stessa (o da una copia se è più sensato) struttura dati di partenza (la struttura dati che fornisco in input alla funzione) una griglia 2D quadrata con la disposizione degli elettrodi secondo le sue relative coordinate ed in sua corrispondenza il solo valore della potenza totale per quell'elettrodo nella sua posizione al trial corrente...\n",
    "\n",
    "In questo modo alla fine, dovrei avere una stessa struttura dati di quella fornita in input, ma dove ogni trial sarebbe una griglia 2D quadrata, con una posizione approssimata degli elettrodi in base alle coordinate fornite e con, a quella posizione corrispondente (tramite il set di coordinate del relativo elettrodo estrapolate dal file xlsx), la potenza totale ottenuta in quel trial corrente per quell'elettrodo...\n",
    "\n",
    "giusto?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f373669-610e-4f48-b017-03a816a62b85",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### **CHATGPT**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c310871-ca21-4d7f-ab46-3a29ae925680",
   "metadata": {},
   "source": [
    "Sì, hai perfettamente centrato la logica. Riassumo e confermo i passaggi con massima chiarezza:\n",
    "\n",
    "✅ OBIETTIVO:\n",
    "Costruire una nuova rappresentazione dei dati EEG per trial, dove:\n",
    "\n",
    "Ogni trial → un’immagine 2D quadrata.\n",
    "\n",
    "Ogni posizione (grid_y, grid_x) nella griglia corrisponde:\n",
    "\n",
    "a un elettrodo → valore della potenza totale in quel trial.\n",
    "\n",
    "a un placeholder ‘EMPTY’ → valore 0.\n",
    "\n",
    "✅ STEP DETTAGLIATI\n",
    "🔹 1. Allineamento nomi\n",
    "Carichi il file .xlsx con le colonne Electrode, grid_x, grid_y.\n",
    "\n",
    "Per ogni riga:\n",
    "\n",
    "Se Electrode non è in EEG_channels_names, ma è chiaramente lo stesso canale con nomi diversi (es. fc1 vs Fc1), lo sostituisci con il nome giusto.\n",
    "\n",
    "Se Electrode == 'EMPTY', lo lasci.\n",
    "\n",
    "🔹 2. Per ogni trial (meglio farlo per trial perché i valori cambiano nel tempo):\n",
    "Inizializzi una griglia 2D vuota (es. np.zeros((grid_height, grid_width))) → che rappresenta la \"mappa\" da riempire.\n",
    "\n",
    "Per ogni riga del .xlsx:\n",
    "\n",
    "Se Electrode == 'EMPTY':\n",
    "\n",
    "Aggiungi 0 nella griglia in posizione (grid_y, grid_x).\n",
    "\n",
    "Se Electrode è valido:\n",
    "\n",
    "Ottieni l’indice dell’elettrodo nella lista EEG_channels_names.\n",
    "\n",
    "Preleva il valore corrispondente nella matrice spettrogramma (frequenze x canali).\n",
    "\n",
    "Calcola la potenza totale per quell’elettrodo: ad esempio con np.sum(fft_image[:, idx]).\n",
    "\n",
    "Inserisci il valore in (grid_y, grid_x).\n",
    "\n",
    "✅ OUTPUT\n",
    "Per ogni condizione sperimentale avrai:\n",
    "\n",
    "Una struttura del tipo:\n",
    "\n",
    "python\n",
    "Copia\n",
    "Modifica\n",
    "{\n",
    "  'condizione_X': {\n",
    "      'images_2d': [griglia_trial1, griglia_trial2, ...],  # shape es. (n_trials, 9, 9)\n",
    "      'labels': [...],\n",
    "  },\n",
    "  ...\n",
    "}\n",
    "✅ BONUS (facoltativo)\n",
    "Se vuoi mantenere una mappa inversa:\n",
    "\n",
    "python\n",
    "Copia\n",
    "Modifica\n",
    "coordinate_to_electrode = {(grid_y, grid_x): 'Cz', ...}\n",
    "così puoi risalire all’elettrodo da una posizione nella griglia.\n",
    "\n",
    "🔜 Pronto a scriverti la funzione?\n",
    "Vuoi che ti costruisca subito:\n",
    "\n",
    "una funzione convert_fft_to_2d_grid() che:\n",
    "\n",
    "prende uno fft_image, il DataFrame .xlsx, la lista EEG_channels_names,\n",
    "\n",
    "e restituisce la griglia 2D?\n",
    "\n",
    "Così possiamo anche usarla in un ciclo per costruire tutte le immagini di tutti i trial. Fammi un cenno e procedo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490b9127-3003-4a3b-8538-600b29c080fb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### **IO**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af24ef4d-81b3-44b1-b080-9b5ba7149487",
   "metadata": {},
   "source": [
    "Vorrei che prendesse la struttura dati che gli fornisco in input, il file .xlxs e la lista EEG_channels_names...\n",
    "\n",
    "tipo così\n",
    "\n",
    "\n",
    "#Caricare l'intero dizionario annidato con pickle\n",
    "path_data = '/home/stefano/Interrogait/all_datas/Spectrograms_channels_frequencies_motor_tasks/'\n",
    "\n",
    "#Caricare file xlsx con pickle\n",
    "path_xlsx = '/home/stefano/'\n",
    "\n",
    "#Caricare file canali EEG con pickle\n",
    "path_channels = '/home/stefano/EEGMMIDB_Analyses/\n",
    "\n",
    "#Caricare l'intero dizionario annidato con pickle\n",
    "with open(f'{path_data}new_all_subjects_condition_spectrograms_task_1.pkl', 'rb') as f:\n",
    "    new_all_subjects_condition_spectrograms_task_1 = pickle.load(f)\n",
    "    \n",
    "#Caricare l'intero dizionario annidato con pickle\n",
    "with open(f'{path_xlsx}EEG_grid.xlsx.pkl', 'rb') as f:\n",
    "    EEG_file = pickle.load(f)\n",
    "    \n",
    "#Caricare l'intero dizionario annidato con pickle\n",
    "with open(f'{path_channels}EEG_channels_names.pkl.pkl', 'rb') as f:\n",
    "    EEG_channels = pickle.load(f)\n",
    "    \n",
    "\n",
    "Da quella struttura dati di ingresso, credo convenga che\n",
    "\n",
    "1) si faccia una copia \n",
    "\n",
    "2) e poi costruisca per ogni soggetto e per ogni trial la griglia 2D con le coordinate e la potenza totale in sua corrispondenza come ti ho detto per ogni trial..\n",
    "\n",
    "\n",
    "Però in modo che semplicemente poi la struttura dati ritornata in output sia praticamente la stessa  di quella di partenza, con la differenza che, ad ogni trial, io abbia la griglia 2D quadrata, con gli elettrodi posti nelle coordinate corrispondenti ed il valore della potenza totale in sua corrispondenza\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6349bb63-22a9-4812-9ba9-ddc321e7d7ef",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### **Implementazione Immagine Griglia 2D - Step Creazione Set Canali Giusto**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f75fc6-befb-4e44-9e9c-acf77a83cfd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "import pandas as pd\n",
    "\n",
    "# Caricare l'intero dizionario annidato con pickle\n",
    "path_data = '/home/stefano/Interrogait/all_datas/Spectrograms_channels_frequencies_motor_tasks/'\n",
    "\n",
    "# Caricare file canali EEG con pickle\n",
    "path_channels = '/home/stefano/EEGMMIDB_Analyses/'\n",
    "\n",
    "# Caricare l'intero dizionario annidato con pickle\n",
    "with open(f'{path_data}new_all_subjects_condition_spectrograms_task_1.pkl', 'rb') as f:\n",
    "    new_all_subjects_condition_spectrograms_task_1 = pickle.load(f)\n",
    "    \n",
    "# Caricare l'intero dizionario annidato con pickle\n",
    "with open(f'{path_channels}EEG_channels_names.pkl', 'rb') as f:\n",
    "    old_EEG_channels = pickle.load(f)\n",
    "    \n",
    "# Caricare file xlsx con pickle\n",
    "path_xlsx = '/home/stefano/EEG_grid.xlsx'\n",
    "\n",
    "# Caricare l'intero dizionario annidato con pickle\n",
    "#with open(f'{path_xlsx}EEG_grid.xlsx', 'rb') as f:\n",
    "#    EEG_file = pd.read_excel(f)\n",
    "\n",
    "# Caricamento del file in un DataFrame\n",
    "EEG_file = pd.read_excel(path_xlsx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58abd326-0ec7-4e73-9e84-92e9d93fc973",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EEG_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79c4081-29cc-4e22-b246-8455f7feca2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(old_EEG_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4cb7d74-8f25-4ae6-9c24-61a23893dba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Elettrodi del Dataset Originario\n",
    "\n",
    "https://physionet.org/content/eegmmidb/1.0.0/ - Sezione Montage\n",
    "\n",
    "\n",
    "Il montaggio specifica chiaramente che:\n",
    "\n",
    "Sono esclusi: Nz, F9, F10, FT9, FT10, A1, A2, TP9, TP10, P9, P10\n",
    "'''\n",
    "\n",
    "print(old_EEG_channels, end = '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947caf66-f6cd-413a-b9f6-81a9b1d45fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(old_EEG_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add3aff0-3669-4653-b7cc-6b2462f8b9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# supponendo che EEG_channels_names sia la tua lista originale\n",
    "\n",
    "\n",
    "old_EEG_channels = [ch.rstrip('.') for ch in EEG_channels]\n",
    "\n",
    "\n",
    "# supponendo che EEG_channels_names sia la tua lista originale\n",
    "#EEG_channels_names = [ch.rstrip('.') for ch in EEG_channels_names]\n",
    "#print(EEG_channels_names, end = '')\n",
    "\n",
    "\n",
    "print(old_EEG_channels, end = '')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a699c3f1-05b9-46df-a340-248918da1cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "Rendo la lista elettrodi trovata nel file brain vision qui sopra come quella del file xlsx\n",
    "'''\n",
    "\n",
    "\n",
    "#Questo è l'ordine sul file excel, escludendo al momento i valori EMPTY...\n",
    "\n",
    "'''\n",
    "filtered_electrodes_xlsx_file = [\n",
    "    'AF7', 'Fp1', 'AFz', 'Fpz', 'Fp2', 'AF8',\n",
    "    'F7', 'F5', 'F3', 'F1', 'Fz', 'F2', 'F4', 'F6', 'F8',\n",
    "    'FT7', 'FC5', 'FC3', 'FC1', 'FCz', 'FC2', 'FC4', 'FC6', 'FT8',\n",
    "    'T7', 'C5', 'C3', 'C1', 'Cz', 'C2', 'C4', 'C6', 'T8',\n",
    "    'TP7', 'CP5', 'CP3', 'CP1', 'CPz', 'CP2', 'CP4', 'CP6', 'TP8',\n",
    "    'P7', 'P5', 'P3', 'P1', 'Pz', 'P2', 'P4', 'P6', 'P8',\n",
    "    'PO7', 'PO3', 'POz', 'PO4', 'PO8',\n",
    "    'O1', 'Oz', 'O2',\n",
    "    'Iz']\n",
    "    \n",
    "'''\n",
    "\n",
    "#Ora, invece, vado a ri-ordinare la tua lista originale secondo la stessa sequenza di riferimento del file brain vision ossia questa\n",
    "#(i.e., old_EEG_channels)\n",
    "\n",
    "'''\n",
    "['Fc5', 'Fc3', 'Fc1', 'Fcz', 'Fc2', 'Fc4', 'Fc6', 'C5', 'C3', 'C1', 'Cz', 'C2', 'C4', 'C6', 'Cp5', 'Cp3', 'Cp1', 'Cpz', 'Cp2', 'Cp4', \n",
    "'Cp6', 'Fp1', 'Fpz', 'Fp2', 'Af7', 'Af3', 'Afz', 'Af4', 'Af8', 'F7', 'F5', 'F3', 'F1', 'Fz', 'F2', 'F4', 'F6', 'F8', 'Ft7', 'Ft8', 'T7', 'T8', 'T9',\n",
    "'T10', 'Tp7', 'Tp8', 'P7', 'P5', 'P3', 'P1', 'Pz', 'P2', 'P4', 'P6', 'P8', 'Po7', 'Po3', 'Poz', 'Po4', 'Po8', 'O1', 'Oz', 'O2', 'Iz']\n",
    "'''\n",
    "\n",
    "#ma mantenendo la capitalizzazione originale della tua lista creata sul file excel\n",
    "\n",
    "'''\n",
    "filtered_electrodes_xlsx_file = [\n",
    "    'AF7', 'Fp1', 'AFz', 'Fpz', 'Fp2', 'AF8',\n",
    "    'F7', 'F5', 'F3', 'F1', 'Fz', 'F2', 'F4', 'F6', 'F8',\n",
    "    'FT7', 'FC5', 'FC3', 'FC1', 'FCz', 'FC2', 'FC4', 'FC6', 'FT8',\n",
    "    'T7', 'C5', 'C3', 'C1', 'Cz', 'C2', 'C4', 'C6', 'T8',\n",
    "    'TP7', 'CP5', 'CP3', 'CP1', 'CPz', 'CP2', 'CP4', 'CP6', 'TP8',\n",
    "    'P7', 'P5', 'P3', 'P1', 'Pz', 'P2', 'P4', 'P6', 'P8',\n",
    "    'PO7', 'PO3', 'POz', 'PO4', 'PO8',\n",
    "    'O1', 'Oz', 'O2',\n",
    "    'Iz']\n",
    "'''\n",
    "\n",
    "ordered_electrodes = [\n",
    "    'FC5', 'FC3', 'FC1', 'FCz', 'FC2', 'FC4', 'FC6',\n",
    "    'C5', 'C3', 'C1', 'Cz', 'C2', 'C4', 'C6',\n",
    "    'CP5', 'CP3', 'CP1', 'CPz', 'CP2', 'CP4', 'CP6',\n",
    "    'Fp1', 'Fpz', 'Fp2',\n",
    "    'AF7', 'AFz', 'AF8',\n",
    "    'F7', 'F5', 'F3', 'F1', 'Fz', 'F2', 'F4', 'F6', 'F8',\n",
    "    'FT7', 'FT8',\n",
    "    'T7', 'T8',\n",
    "    'TP7', 'TP8',\n",
    "    'P7', 'P5', 'P3', 'P1', 'Pz', 'P2', 'P4', 'P6', 'P8',\n",
    "    'PO7', 'PO3', 'POz', 'PO4', 'PO8',\n",
    "    'O1', 'Oz', 'O2',\n",
    "    'Iz'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f057ae87-667f-4476-8f90-225b3a1e5183",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "path = '/home/stefano/EEGMMIDB_Analyses/'\n",
    "\n",
    "# Salvare l'intero dizionario annidato con pickle\n",
    "with open(f'{path}ordered_electrodes.pkl', 'wb') as f:\n",
    "    pickle.dump(ordered_electrodes, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49b860c-9676-49ea-bc8e-c9fee114f515",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### **IO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfebf36-56af-4a3c-a53c-8890ec4a3b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Mi spieghi meglio questo passaggio?\n",
    "\n",
    "✅ 1) Perché np.sum(fft_image, axis=0) e non un ciclo?\n",
    "Hai scritto:\n",
    "\n",
    "“per ogni canale c, la potenza totale è np.sum(fft_image[:, c])”\n",
    "\n",
    "Sì, questo è vero.\n",
    "Ma invece di fare:\n",
    "\n",
    "python\n",
    "Copia\n",
    "Modifica\n",
    "total_power = []\n",
    "for c in range(n_channels):\n",
    "    total_power.append(np.sum(fft_image[:, c]))\n",
    "puoi usare vectorizzazione con NumPy:\n",
    "\n",
    "python\n",
    "Copia\n",
    "Modifica\n",
    "total_power = np.sum(fft_image, axis=0)  # shape: (n_channels,)\n",
    "È esattamente equivalente — solo molto più veloce ed efficiente.\n",
    "Quindi:\n",
    "\n",
    "fft_image[:, c] → fetta per un solo canale\n",
    "\n",
    "np.sum(fft_image, axis=0) → somma di tutti i canali in una sola riga\n",
    "\n",
    "✅ Conclusione: non è una contraddizione, è solo una scrittura più efficiente e direttamente vettoriale.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04faff4-dfa8-44bb-867a-5b71b9788f92",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### **CHATGPT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5beeebf-c667-4804-9648-4efe7af41a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ChatGPT ha detto:\n",
    "Sì, te lo spiego con un esempio chiaro per visualizzare il concetto.\n",
    "\n",
    "✅ CONTEXTO\n",
    "Hai una matrice fft_image di forma (n_freqs, n_channels), ad esempio:\n",
    "\n",
    "python\n",
    "Copia\n",
    "Modifica\n",
    "fft_image.shape == (45, 64)  # 45 frequenze, 64 canali\n",
    "Ogni colonna rappresenta un elettrodo (canale), e ogni riga una frequenza.\n",
    "\n",
    "🎯 OBIETTIVO\n",
    "Per ogni canale (cioè per ogni colonna), vuoi calcolare:\n",
    "\n",
    "La somma dei valori su tutte le frequenze\n",
    "\n",
    "In altre parole:\n",
    "Per ogni canale c, vuoi:\n",
    "\n",
    "python\n",
    "Copia\n",
    "Modifica\n",
    "np.sum(fft_image[:, c])  # somma verticale, lungo le frequenze\n",
    "🐌 MODO LENTO (con ciclo for)\n",
    "python\n",
    "Copia\n",
    "Modifica\n",
    "n_channels = fft_image.shape[1]\n",
    "total_power = []\n",
    "\n",
    "for c in range(n_channels):\n",
    "    total_power.append(np.sum(fft_image[:, c]))\n",
    "\n",
    "# total_power sarà una lista lunga 64 (n_channels)\n",
    "Questo funziona, ma è lento e meno elegante.\n",
    "\n",
    "🚀 MODO VELOCE (vettoriale con NumPy)\n",
    "python\n",
    "Copia\n",
    "Modifica\n",
    "total_power = np.sum(fft_image, axis=0)\n",
    "Questo fa la stessa cosa, ma:\n",
    "\n",
    "Lo fa tutto in un colpo solo\n",
    "\n",
    "È scritto in una sola riga\n",
    "\n",
    "Usa le ottimizzazioni interne di NumPy (molto più veloce in pratica)\n",
    "\n",
    "🧠 Come funziona axis=0?\n",
    "axis=0 significa: somma lungo le righe (cioè sulle frequenze)\n",
    "\n",
    "Risultato: ottieni un array con una somma per ogni colonna → un valore per ogni canale\n",
    "\n",
    "📊 Visualizzazione semplice:\n",
    "Immagina fft_image così:\n",
    "\n",
    "markdown\n",
    "Copia\n",
    "Modifica\n",
    "      Canale_1  Canale_2  Canale_3\n",
    "Freq1     2         4         6\n",
    "Freq2     3         5         7\n",
    "Freq3     1         2         3\n",
    "Se fai:\n",
    "\n",
    "python\n",
    "Copia\n",
    "Modifica\n",
    "np.sum(fft_image, axis=0)\n",
    "Ottieni:\n",
    "\n",
    "python\n",
    "Copia\n",
    "Modifica\n",
    "[2+3+1, 4+5+2, 6+7+3] = [6, 11, 16]\n",
    "Esattamente come se avessi iterato su ogni colonna con un ciclo.\n",
    "\n",
    "✅ Conclusione\n",
    "np.sum(fft_image, axis=0) è il modo idiomatico, efficiente e leggibile per ottenere la potenza totale per canale a partire da una matrice frequenza x canali.\n",
    "\n",
    "Vuoi che ti mostri anche l'equivalenza con codice pratico in Python per verificarlo con np.allclose?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b217ae6-3adb-454a-94f7-80ea33fbe5eb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### **IO**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214020b2-701d-4a89-8f85-0562f86e27f4",
   "metadata": {},
   "source": [
    "Sì, mostrami anche l'equivalenza con codice pratico in Python per verificarlo con np.allclose?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6010e6a6-0d2a-4907-851d-c88284b6737a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### **CHATGPT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8a6d21-93bb-4ddb-92b8-ce49e25d860d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Simula una matrice FFT: 45 frequenze x 64 canali\n",
    "np.random.seed(42)\n",
    "fft_image = np.random.rand(45, 64)\n",
    "\n",
    "# Metodo 1: con ciclo (manuale)\n",
    "manual_power = []\n",
    "for c in range(fft_image.shape[1]):\n",
    "    manual_power.append(np.sum(fft_image[:, c]))\n",
    "manual_power = np.array(manual_power)\n",
    "\n",
    "# Metodo 2: con vectorizzazione\n",
    "vectorized_power = np.sum(fft_image, axis=0)\n",
    "\n",
    "# Verifica che i due metodi siano equivalenti\n",
    "are_equal = np.allclose(manual_power, vectorized_power)\n",
    "\n",
    "manual_power[:5], vectorized_power[:5], are_equal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7c7876-67e2-40fc-8bc8-adfefea25ce3",
   "metadata": {},
   "source": [
    "Ecco il risultato del confronto tra i due metodi:\n",
    "\n",
    "🎯 I primi 5 valori (identici):\n",
    "Metodo manuale (ciclo):\n",
    "\n",
    "csharp\n",
    "Copia\n",
    "Modifica\n",
    "[23.0585, 25.0655, 20.1955, 20.4349, 21.2330]\n",
    "Metodo vettoriale (con np.sum(axis=0)):\n",
    "\n",
    "csharp\n",
    "Copia\n",
    "Modifica\n",
    "[23.0585, 25.0655, 20.1955, 20.4349, 21.2330]\n",
    "✅ Verifica finale:\n",
    "python\n",
    "Copia\n",
    "Modifica\n",
    "np.allclose(manual_power, vectorized_power) → True\n",
    "Quindi i due metodi sono numericamente equivalenti, ma il secondo è:\n",
    "\n",
    "più elegante\n",
    "\n",
    "più veloce\n",
    "\n",
    "più adatto a dati grandi\n",
    "\n",
    "Se vuoi, posso anche mostrarti quanto tempo impiegano entrambi su matrici più grandi (%timeit). Vuoi vedere anche questo benchmark?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb984b2-8b79-44f1-a3ca-e376b654a6a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a7f5210a-a142-4fef-b34d-e70c7ab4fb9c",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### **Implementazione Immagine Griglia 2D - Step Creazione Griglia vera e propria**\n",
    "\n",
    "1) **Creazione Griglia Dati EEG + Griglia Labels Coordinate Elettrodiche**\n",
    "2) **Salvataggio Griglia Dati EEG + Griglia Labels Coordinate Elettrodiche**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b584eb79-2c4d-425b-8933-fefa7d9fb1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "import pandas as pd\n",
    "\n",
    "# Caricare l'intero dizionario annidato con pickle\n",
    "path_data = '/home/stefano/Interrogait/all_datas/Spectrograms_channels_frequencies_motor_tasks/'\n",
    "\n",
    "# Caricare file canali EEG con pickle\n",
    "path_channels = '/home/stefano/EEGMMIDB_Analyses/'\n",
    "\n",
    "# Caricare l'intero dizionario annidato con pickle\n",
    "with open(f'{path_data}new_all_subjects_condition_spectrograms_task_1.pkl', 'rb') as f:\n",
    "    new_all_subjects_condition_spectrograms_task_1 = pickle.load(f)\n",
    "    \n",
    "# Caricare l'intero dizionario annidato con pickle\n",
    "with open(f'{path_channels}ordered_electrodes.pkl', 'rb') as f:\n",
    "    EEG_channels = pickle.load(f)\n",
    "    \n",
    "    \n",
    "# Caricare file xlsx con pickle\n",
    "path_xlsx = '/home/stefano/EEGMMIDB_Analyses/EEG_grid.xlsx'\n",
    "\n",
    "# Caricamento del file in un DataFrame\n",
    "EEG_file = pd.read_excel(path_xlsx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8830e7-5fa8-41d3-b393-08a8ec4c19f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_all_subjects_condition_spectrograms_task_1['spectrograms_rest_100'].keys()\n",
    "new_all_subjects_condition_spectrograms_task_1['spectrograms_rest_100']['spectrograms_3d'].shape"
   ]
  },
  {
   "cell_type": "raw",
   "id": "afdf6713-0966-4f2c-b20a-d650043ccfc0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "'''\n",
    "\n",
    "La funzione aggiornata convert_fft_images_to_2d_grids() ora:\n",
    "\n",
    "Allinea correttamente i nomi dei canali nel file .xlsx alla lista EEG_channels_names, tenendo conto della capitalizzazione.\n",
    "Segnala eventuali nomi mancanti con un messaggio di warning.\n",
    "Genera una griglia 2D per ogni trial, con le potenze totali posizionate correttamente.\n",
    "\n",
    "\n",
    "L’immagine da cui si ispira la generazione dell'immagine 2D è chiaramente una griglia 9x9,\n",
    "con gli elettrodi disposti in celle regolari e alcune caselle vuote (placeholder).\n",
    "\n",
    "✅ Sì, la griglia costruita dal codice corrisponde correttamente a questa rappresentazione se:\n",
    "\n",
    "Usi il file .xlsx che assegna le coordinate (grid_y, grid_x) ad ogni elettrodo (inclusi gli 'EMPTY').\n",
    "Imposti grid_shape = (9, 9) o lo ricavi automaticamente come ti ho suggerito.\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "def convert_fft_images_to_2d_grids(\n",
    "    original_data: dict,\n",
    "    eeg_grid_df: pd.DataFrame,\n",
    "    eeg_channels_names: list,\n",
    "    grid_shape: tuple = (9, 9)\n",
    "):\n",
    "    \"\"\"\n",
    "    Converte spettrogrammi frequenza x canali in immagini 2D (griglia quadrata) per ogni trial,\n",
    "    dove la posizione (y, x) viene determinata dalle coordinate nel file .xlsx, e il valore\n",
    "    è la potenza totale per ciascun elettrodo.\n",
    "\n",
    "    Args:\n",
    "        original_data (dict): struttura come new_all_subjects_condition_spectrograms_task_1\n",
    "        eeg_grid_df (pd.DataFrame): contiene colonne ['Electrode', 'grid_x', 'grid_y']\n",
    "        eeg_channels_names (list): lista dei nomi canali EEG (es. ['Fc1', 'Cz', ...])\n",
    "        grid_shape (tuple): dimensioni della griglia finale (default 9x9)\n",
    "\n",
    "    Returns:\n",
    "        dict: stessa struttura dati di original_data, ma con immagini 2D per trial\n",
    "    \"\"\"\n",
    "    updated_data = {}\n",
    "\n",
    "    # Normalizza i nomi degli elettrodi nella lista canali\n",
    "    eeg_channels_names = [ch.rstrip('.') for ch in eeg_channels_names]\n",
    "\n",
    "    # Crea un mapping case-insensitive per il match\n",
    "    channel_map = {ch.upper(): ch for ch in eeg_channels_names}\n",
    "\n",
    "    # Copia e normalizza il DataFrame\n",
    "    df_copy = eeg_grid_df.copy()\n",
    "    df_copy['Electrode'] = df_copy['Electrode'].astype(str).str.strip().str.upper()\n",
    "\n",
    "    # Sostituisci i nomi nel DataFrame con quelli standard (case-correct)\n",
    "    for idx, elec in df_copy['Electrode'].items():\n",
    "        if elec in channel_map:\n",
    "            df_copy.at[idx, 'Electrode'] = channel_map[elec]\n",
    "        elif elec == 'EMPTY':\n",
    "            continue\n",
    "        else:\n",
    "            print(f\"⚠️ Attenzione: '{elec}' non trovato in EEG_channels_names.\")\n",
    "\n",
    "    # Itera su tutte le condizioni\n",
    "    for condition, cond_data in original_data.items():\n",
    "        spectros = cond_data['spectrograms_3d']  # shape: (n_trials, n_freqs, n_channels)\n",
    "        labels = cond_data['labels']\n",
    "        n_trials, _, _ = spectros.shape\n",
    "\n",
    "        images_2d = []\n",
    "        \n",
    "        \n",
    "        '''\n",
    "        Nella tua funzione FFT:\n",
    "        \n",
    "        fft_image = trial_power.T  # shape: (n_freq, n_channels)\n",
    "        \n",
    "        Ogni fft_image rappresenta la potenza spettrale (cioè |FFT|²) per:\n",
    "        Righe = frequenze (es. 45 bins)\n",
    "        Colonne = canali EEG (elettrodi)\n",
    "        \n",
    "        Quindi, per ogni canale c, la potenza totale è:\n",
    "        \n",
    "        total_power_c = np.sum(fft_image[:, c])\n",
    "        \n",
    "        Cosa fa la funzione convert_fft_images_to_2d_grids?\n",
    "        \n",
    "        total_power_per_channel = np.sum(fft_image, axis=0)  # somma lungo l'asse delle frequenze\n",
    "        \n",
    "        Quindi estrae la potenza totale aggregando i valori di frequenza.\n",
    "        Questo non è un calcolo superfluo, perché:\n",
    "        \n",
    "        Il dato originale fft_image ha frequenza x canale\n",
    "        L’immagine griglia vuole invece 1 solo valore per canale (asse z), da associare alla posizione (x, y)\n",
    "        \n",
    "        In sintesi:\n",
    "        \n",
    "        ✔ La potenza totale non è esplicitamente salvata, ma è immediatamente disponibile e si ottiene con una semplice np.sum(..., axis=0)\n",
    "        ✔ Quello che fa la funzione è semplicemente riassumere le righe (frequenze) → potenza totale per elettrodo\n",
    "        \n",
    "        ❌ Non c’è duplicazione inutile: questo passaggio è necessario per ridurre 2D (f x ch) → 1D (ch)\n",
    "        \n",
    "        Se un giorno volessi invece usare solo una banda (es. theta, alpha…), \n",
    "        potresti filtrare fft_image prima di fare np.sum, selezionando solo alcune righe (frequenze).\n",
    "        \n",
    "        Vuoi che ti mostri come farlo con una banda specifica (es. 4-7 Hz)?\n",
    "\n",
    "        '''\n",
    "        \n",
    "        for trial_idx in range(n_trials):\n",
    "            fft_image = spectros[trial_idx]\n",
    "            \n",
    "            # Calcolo della potenza totale per canale (sommando sulle frequenze)\n",
    "            total_power_per_channel = np.sum(fft_image, axis=0)\n",
    "\n",
    "            # Inizializza immagine 2D vuota\n",
    "            grid_2d = np.zeros(grid_shape)\n",
    "\n",
    "            for _, row in df_copy.iterrows():\n",
    "                electrode = row['Electrode']\n",
    "                y, x = int(row['grid_y']), int(row['grid_x'])\n",
    "\n",
    "                if electrode == 'EMPTY':\n",
    "                    grid_2d[y, x] = 0\n",
    "                elif electrode in eeg_channels_names:\n",
    "                    ch_index = eeg_channels_names.index(electrode)\n",
    "                    grid_2d[y, x] = total_power_per_channel[ch_index]\n",
    "                else:\n",
    "                    grid_2d[y, x] = 0  # fallback in caso di mismatch\n",
    "\n",
    "            images_2d.append(grid_2d)\n",
    "\n",
    "        # Salva la nuova struttura\n",
    "        updated_data[condition] = {\n",
    "            'spectrograms_2d': np.array(images_2d),  # shape: (n_trials, grid_y, grid_x)\n",
    "            'labels': labels\n",
    "        }\n",
    "\n",
    "    return updated_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "12dc1aad-fa14-4b95-9b39-f64ee853eefb",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "'''\n",
    "CON COMMENTI ANCORA NON CANCELLATI\n",
    "'''\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "'''\n",
    "\n",
    "La funzione aggiornata convert_fft_images_to_2d_grids() ora:\n",
    "\n",
    "Allinea correttamente i nomi dei canali nel file .xlsx alla lista EEG_channels_names, tenendo conto della capitalizzazione.\n",
    "Segnala eventuali nomi mancanti con un messaggio di warning.\n",
    "Genera una griglia 2D per ogni trial, con le potenze totali posizionate correttamente.\n",
    "\n",
    "\n",
    "L’immagine da cui si ispira la generazione dell'immagine 2D è chiaramente una griglia 9x9,\n",
    "con gli elettrodi disposti in celle regolari e alcune caselle vuote (placeholder).\n",
    "\n",
    "✅ Sì, la griglia costruita dal codice corrisponde correttamente a questa rappresentazione se:\n",
    "\n",
    "Usi il file .xlsx che assegna le coordinate (grid_y, grid_x) ad ogni elettrodo (inclusi gli 'EMPTY').\n",
    "Imposti grid_shape = (9, 9) o lo ricavi automaticamente come ti ho suggerito.\n",
    "\n",
    "\n",
    "✅ Caso di default:\n",
    "bandpass=None\n",
    "\n",
    "👉 La funzione userà:\n",
    "\n",
    "total_power_per_channel = np.sum(fft_image, axis=0)\n",
    "\n",
    "Quindi calcolerà la potenza totale sommando su tutte le frequenze disponibili dello spettro.\n",
    "\n",
    "✅ Caso con filtraggio in banda:\n",
    "bandpass=(4, 7)\n",
    "\n",
    "👉 Verranno usati solo i bin di frequenza compresi tra 4 e 7 Hz, estraendo:\n",
    "\n",
    "\n",
    "band_power = fft_image[freq_mask, :]\n",
    "total_power_per_channel = np.sum(band_power, axis=0)\n",
    "\n",
    "In questo modo ottieni la potenza nella banda specificata, per ogni canale.\n",
    "\n",
    "    ✅ Cosa fa internamente\n",
    "    Calcola le frequenze corrispondenti ai bin della rfft con:\n",
    "\n",
    "    freqs = np.fft.rfftfreq(n_fft_points, d=1/fs)\n",
    "    Applica un filtro logico per tenere solo i bin della banda desiderata.\n",
    "\n",
    "    Somma solo quelle righe (frequenze) in fft_image[freq_mask, :].\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "def convert_fft_images_to_2d_grids(\n",
    "    original_data: dict,\n",
    "    eeg_grid_df: pd.DataFrame,\n",
    "    eeg_channels_names: list,\n",
    "    grid_shape: tuple = (9, 9),\n",
    "    fs: int = 160,\n",
    "    n_fft_points: int = 640,\n",
    "    bandpass: tuple = None  # es. (4, 7)\n",
    "):\n",
    "    \"\"\"\n",
    "    Converte spettrogrammi frequenza x canali in immagini 2D (griglia quadrata) per ogni trial,\n",
    "    dove la posizione (y, x) viene determinata dalle coordinate nel file .xlsx, e il valore\n",
    "    è la potenza totale o di banda per ciascun elettrodo.\n",
    "\n",
    "    \n",
    "    Args:\n",
    "        original_data (dict): struttura come new_all_subjects_condition_spectrograms_task_1\n",
    "        eeg_grid_df (pd.DataFrame): contiene colonne ['Electrode', 'grid_x', 'grid_y']\n",
    "        eeg_channels_names (list): lista dei nomi canali EEG, già in forma compatibile\n",
    "        grid_shape (tuple): dimensioni della griglia finale (default 9x9)\n",
    "        fs (int): frequenza di campionamento (Hz)\n",
    "        n_fft_points (int): numero di punti FFT (lunghezza del segmento analizzato)\n",
    "        bandpass (tuple): banda di frequenze (min, max), es. (4, 7); se None → totale\n",
    "\n",
    "\n",
    "    Returns:\n",
    "        dict: struttura con immagini 2D per ogni trial\n",
    "    \"\"\"\n",
    "    updated_data = {}\n",
    "    \n",
    "    \n",
    "    # Normalizza i nomi degli elettrodi nella lista canali\n",
    "    #eeg_channels_names = [ch.rstrip('.') for ch in eeg_channels_names]\n",
    "    #channel_map = {ch.upper(): ch for ch in eeg_channels_names}\n",
    "    \n",
    "    #print(channel_map)\n",
    "    \n",
    "    #df_copy = eeg_grid_df.copy()\n",
    "    #df_copy['Electrode'] = df_copy['Electrode'].astype(str).str.strip().str.upper()\n",
    "\n",
    "    #for idx, elec in df_copy['Electrode'].items():\n",
    "        #if elec in channel_map:\n",
    "            #df_copy.at[idx, 'Electrode'] = channel_map[elec]\n",
    "        #elif elec == 'EMPTY':\n",
    "            #continue\n",
    "        #else:\n",
    "            #print(f\"\\n⚠️ Attenzione: '{elec}' non trovato in EEG_channels_names.\")\n",
    "    \n",
    "        # Dopo la normalizzazione, controlla se ci sono elettrodi non usati\n",
    "        #elettrodi_excel = set(df_copy['Electrode'].unique())\n",
    "        #elettrodi_utilizzati = set(eeg_channels_names)\n",
    "        #elettrodi_excel.discard('EMPTY')\n",
    "\n",
    "        #non_trovati = elettrodi_excel - elettrodi_utilizzati\n",
    "        #if non_trovati:\n",
    "            #print(\"\\n🚨 Elettrodi nel file Excel ma non trovati nei dati EEG:\")\n",
    "            #print(sorted(non_trovati))\n",
    "            \n",
    "    # Crea una copia del DataFrame per sicurezza\n",
    "    df_copy = eeg_grid_df.copy()\n",
    "    df_copy['Electrode'] = df_copy['Electrode'].astype(str).str.strip()\n",
    "\n",
    "    # Controllo elettrodi non trovati\n",
    "    unique_electrodes = set(df_copy['Electrode'].unique())\n",
    "    unique_electrodes.discard('EMPTY')\n",
    "    not_found = unique_electrodes - set(eeg_channels_names)\n",
    "    if not_found:\n",
    "        print(\"\\n🚨 Elettrodi nel file Excel ma non trovati nei dati EEG:\")\n",
    "        print(sorted(not_found))\n",
    "\n",
    "    \n",
    "    # Calcola i bin delle frequenze solo una volta se necessario\n",
    "    if bandpass is not None:\n",
    "        freqs = np.fft.rfftfreq(n_fft_points, d=1/fs)\n",
    "        freq_mask = (freqs >= bandpass[0]) & (freqs <= bandpass[1])\n",
    "\n",
    "    for condition, cond_data in original_data.items():\n",
    "        spectros = cond_data['spectrograms_3d']  # shape: (n_trials, n_freqs, n_channels)\n",
    "        labels = cond_data['labels']\n",
    "        n_trials, n_freqs, n_channels = spectros.shape\n",
    "\n",
    "        images_2d = []\n",
    "        \n",
    "        '''\n",
    "        Nella tua funzione FFT:\n",
    "        \n",
    "        fft_image = trial_power.T  # shape: (n_freq, n_channels)\n",
    "        \n",
    "        Ogni fft_image rappresenta la potenza spettrale (cioè |FFT|²) per:\n",
    "        Righe = frequenze (es. 45 bins)\n",
    "        Colonne = canali EEG (elettrodi)\n",
    "        \n",
    "        Quindi, per ogni canale c, la potenza totale è:\n",
    "        \n",
    "        total_power_c = np.sum(fft_image[:, c])\n",
    "        \n",
    "        Cosa fa la funzione convert_fft_images_to_2d_grids?\n",
    "        \n",
    "        total_power_per_channel = np.sum(fft_image, axis=0)  # somma lungo l'asse delle frequenze\n",
    "        \n",
    "        Quindi estrae la potenza totale aggregando i valori di frequenza.\n",
    "        Questo non è un calcolo superfluo, perché:\n",
    "        \n",
    "        Il dato originale fft_image ha frequenza x canale\n",
    "        L’immagine griglia vuole invece 1 solo valore per canale (asse z), da associare alla posizione (x, y)\n",
    "        \n",
    "        In sintesi:\n",
    "        \n",
    "        ✔ La potenza totale non è esplicitamente salvata, ma è immediatamente disponibile e si ottiene con una semplice np.sum(..., axis=0)\n",
    "        ✔ Quello che fa la funzione è semplicemente riassumere le righe (frequenze) → potenza totale per elettrodo\n",
    "        \n",
    "        ❌ Non c’è duplicazione inutile: questo passaggio è necessario per ridurre 2D (f x ch) → 1D (ch)\n",
    "\n",
    "        '''\n",
    "        \n",
    "        for trial_idx in range(n_trials):\n",
    "            fft_image = spectros[trial_idx]  # (n_freqs, n_channels)\n",
    "\n",
    "            # Banda specifica?\n",
    "            if bandpass is not None:\n",
    "                band_power = fft_image[freq_mask, :]  # (n_selected_freqs, n_channels)\n",
    "                total_power_per_channel = np.sum(band_power, axis=0)\n",
    "            else:\n",
    "                total_power_per_channel = np.sum(fft_image, axis=0)\n",
    "\n",
    "            grid_2d = np.zeros(grid_shape)\n",
    "\n",
    "            for _, row in df_copy.iterrows():\n",
    "                electrode = row['Electrode']\n",
    "                y, x = int(row['grid_y']), int(row['grid_x'])\n",
    "\n",
    "                if electrode == 'EMPTY':\n",
    "                    grid_2d[y, x] = 0\n",
    "                    \n",
    "                elif electrode in eeg_channels_names:\n",
    "                    ch_index = eeg_channels_names.index(electrode)\n",
    "                    grid_2d[y, x] = total_power_per_channel[ch_index]\n",
    "                else:\n",
    "                    grid_2d[y, x] = 0\n",
    "\n",
    "            images_2d.append(grid_2d)\n",
    "\n",
    "        updated_data[condition] = {\n",
    "            'spectrograms_2d': np.array(images_2d),\n",
    "            'labels': labels\n",
    "        }\n",
    "\n",
    "    return updated_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9febc3-7858-4808-940c-129566f3faec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "'''\n",
    "\n",
    "La funzione aggiornata convert_fft_images_to_2d_grids() ora:\n",
    "\n",
    "Allinea correttamente i nomi dei canali nel file .xlsx alla lista EEG_channels_names, \n",
    "tenendo conto della capitalizzazione.\n",
    "Segnala eventuali nomi mancanti con un messaggio di warning.\n",
    "Genera una griglia 2D per ogni trial, con le potenze totali posizionate correttamente.\n",
    "\n",
    "\n",
    "L’immagine da cui si ispira la generazione dell'immagine 2D è chiaramente una griglia 9x9,\n",
    "con gli elettrodi disposti in celle regolari e alcune caselle vuote (placeholder).\n",
    "\n",
    "✅ Sì, la griglia costruita dal codice corrisponde correttamente a questa rappresentazione se:\n",
    "\n",
    "Usi il file .xlsx che assegna le coordinate (grid_y, grid_x) ad ogni elettrodo (inclusi gli 'EMPTY').\n",
    "Imposti grid_shape = (9, 9) o lo ricavi automaticamente come ti ho suggerito.\n",
    "\n",
    "\n",
    "✅ Caso di default:\n",
    "bandpass=None\n",
    "\n",
    "👉 La funzione userà:\n",
    "\n",
    "total_power_per_channel = np.sum(fft_image, axis=0)\n",
    "\n",
    "Quindi calcolerà la potenza totale sommando su tutte le frequenze disponibili dello spettro.\n",
    "\n",
    "✅ Caso con filtraggio in banda:\n",
    "bandpass=(4, 7)\n",
    "\n",
    "👉 Verranno usati solo i bin di frequenza compresi tra 4 e 7 Hz, estraendo:\n",
    "\n",
    "\n",
    "band_power = fft_image[freq_mask, :]\n",
    "total_power_per_channel = np.sum(band_power, axis=0)\n",
    "\n",
    "In questo modo ottieni la potenza nella banda specificata, per ogni canale.\n",
    "\n",
    "    ✅ Cosa fa internamente\n",
    "    Calcola le frequenze corrispondenti ai bin della rfft con:\n",
    "\n",
    "    freqs = np.fft.rfftfreq(n_fft_points, d=1/fs)\n",
    "    Applica un filtro logico per tenere solo i bin della banda desiderata.\n",
    "\n",
    "    Somma solo quelle righe (frequenze) in fft_image[freq_mask, :].\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "def convert_fft_images_to_2d_grids_all_freqs(\n",
    "    original_data: dict,\n",
    "    eeg_grid_df: pd.DataFrame,\n",
    "    eeg_channels_names: list,\n",
    "    grid_shape: tuple = (9, 9),\n",
    "    fs: int = 160,\n",
    "    n_fft_points: int = 640\n",
    "    #bandpass: tuple = None  # es. (4, 7)\n",
    "):\n",
    "    \"\"\"\n",
    "    Converte spettrogrammi frequenza x canali in immagini 2D (griglia quadrata) per banda di frequenza, dove \n",
    "    \n",
    "    1) ogni trial è una griglia 9x9x N_bande con i valori di potenza totale per elettrodo.\n",
    "    2) la posizione (y, x) viene determinata dalle coordinate nel file .xlsx e il valore\n",
    "    \n",
    "    è la potenza totale rispetto alla banda di frequenza per ciascun elettrodo.\n",
    "    \n",
    "    Inoltre, restituisce una griglia fissa con le etichette degli elettrodi.\n",
    "    \n",
    "    Args:\n",
    "        original_data (dict): struttura come new_all_subjects_condition_spectrograms_task_1\n",
    "        eeg_grid_df (pd.DataFrame): contiene colonne ['Electrode', 'grid_x', 'grid_y']\n",
    "        eeg_channels_names (list): lista dei nomi canali EEG, già in forma compatibile\n",
    "        grid_shape (tuple): dimensioni della griglia finale (default 9x9)\n",
    "        fs (int): frequenza di campionamento (Hz)\n",
    "        n_fft_points (int): numero di punti FFT (lunghezza del segmento analizzato)\n",
    "        bandpass (tuple): banda di frequenze (min, max), es. (4, 7); se None → totale\n",
    "        .\n",
    "\n",
    "    Returns:\n",
    "        tuple:\n",
    "            - dict: struttura con immagini 2D per ogni trial\n",
    "            - np.ndarray: griglia 2D con etichette degli elettrodi (stringhe)\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    # Definizione delle bande EEG\n",
    "    bands = {\n",
    "        #'delta': (0.5, 4),\n",
    "        'delta': (1, 4),\n",
    "        'theta': (4, 8),\n",
    "        'alpha': (8, 13),\n",
    "        'beta':  (13, 30),\n",
    "        'gamma': (30, 45)\n",
    "    }\n",
    "    \n",
    "    updated_data = {}\n",
    "                \n",
    "    # Crea una copia del DataFrame per sicurezza\n",
    "    df_copy = eeg_grid_df.copy()\n",
    "    df_copy['Electrode'] = df_copy['Electrode'].astype(str).str.strip()\n",
    "\n",
    "    # Controllo elettrodi non trovati\n",
    "    unique_electrodes = set(df_copy['Electrode'].unique())\n",
    "    unique_electrodes.discard('EMPTY')\n",
    "    not_found = unique_electrodes - set(eeg_channels_names)\n",
    "    \n",
    "    if not_found:\n",
    "        print(\"\\n🚨 Elettrodi nel file Excel ma non trovati nei dati EEG:\")\n",
    "        print(sorted(not_found))\n",
    "    \n",
    "    # Griglia delle etichette\n",
    "    \n",
    "    label_grid = np.full(grid_shape, '', dtype=object)\n",
    "    \n",
    "    '''\n",
    "    Dal contenuto del file Excel è evidente che le colonne grid_x e grid_y contengono coordinate normalizzate nell'intervallo da 0.0 a 1.0.\n",
    "    Queste coordinate sono suddivise con uno step di 1/8 = 0.125, coerente con una griglia 9x9 (quindi 9 posizioni da 0.0 a 1.0).\n",
    "    \n",
    "    Cosa significa\n",
    "    \n",
    "    Per posizionare correttamente gli elettrodi su una griglia 2D di shape (9, 9):\n",
    "    \n",
    "    Devi moltiplicare le coordinate normalizzate per grid_size - 1 e convertirle a interi, ossia così:\n",
    "    \n",
    "    x = int(round(row['grid_x'] * (grid_shape[1] - 1)))\n",
    "    y = int(round(row['grid_y'] * (grid_shape[0] - 1)))\n",
    "    \n",
    "    N.B.\n",
    "    \n",
    "    Se vuoi costruire una matrice 2D indicizzata (es. grid[y, x]) per usarla come immagine 2D o input per modelli CNN:\n",
    "    \n",
    "    → Devi usare indici interi\n",
    "    \n",
    "    Quindi sì, devi fare:\n",
    "    \n",
    "    x = int(round(row['grid_x'] * (grid_shape[1] - 1)))\n",
    "    y = int(round(row['grid_y'] * (grid_shape[0] - 1)))\n",
    "    \n",
    "    Questo perché una matrice NumPy grid_2d[y, x] non può accettare float come indici    \n",
    "    '''\n",
    "    \n",
    "    # Mappa che associa ad ogni elettrodo la sua coordinate intere nella griglia\n",
    "    electrode_grid_map = {}  \n",
    "  \n",
    "    for _, row in df_copy.iterrows():\n",
    "        elec = row['Electrode']\n",
    "        \n",
    "        '''ATTENZIONE CHE VA MODIFICATO SIA PER CREAZIONE MAPPA DEGLI ELETTRODI'''\n",
    "        #y, x = int(row['grid_y']), int(row['grid_x'])\n",
    "        \n",
    "        x = int(round(row['grid_x'] * (grid_shape[1] - 1)))\n",
    "        y = int(round(row['grid_y'] * (grid_shape[0] - 1)))\n",
    "    \n",
    "        label_grid[y, x] = '' if elec == 'EMPTY' else elec\n",
    "        print(f\"Elettrodo: {elec} → (y = {y}, x = {x})\")\n",
    "        \n",
    "        '''\n",
    "        label_grid → serve per etichettare visivamente le posizioni (es. nel plot, mostrare \"Fz\", \"Cz\", ecc.).\n",
    "        electrode_grid_map → mappa solo gli elettrodi reali, e ti dice dove piazzare/recuperare i valori nella griglia.\n",
    "        grid_2d (Griglia numerica) → in corrispondenza degli EMPTY, si assegnano valori 0 (come già fai con grid_2d[y, x] = 0).\n",
    "        \n",
    "        \n",
    "        Quindi: vanno tenuti gli EMPTY nella mappa?\n",
    "        \n",
    "        Risposta breve:\n",
    "        \n",
    "        No, non vanno tenuti in electrode_grid_map, \n",
    "        perché questa serve solo a mappare i canali effettivi (cioè quelli per cui hai dati).\n",
    "        \n",
    "        Sì, vanno mantenuti in grid_2d e label_grid, \n",
    "        perché servono a preservare la forma della griglia (9x9) e garantire che:\n",
    "        \n",
    "        la CNN o i plot ricevano input a griglia completa (senza buchi),\n",
    "        le posizioni senza elettrodi siano rappresentate (con valore 0),\n",
    "        la normalizzazione congiunta consideri anche questi zeri, che sono parte delle immagini.\n",
    "        \n",
    "        ✅ Cosa fare (in sintesi):\n",
    "        \n",
    "        Mantieni gli EMPTY in label_grid, grid_2d, e nelle heatmap → così la griglia resta coerente.\n",
    "        Non includerli in electrode_grid_map → perché non rappresentano un elettrodo reale.\n",
    "        Quando normalizzi o plotti, non ignorare gli zeri: sono significativi, servono a evitare buchi nella griglia.\n",
    "\n",
    "        '''\n",
    "        \n",
    "        if elec != 'EMPTY':\n",
    "            electrode_grid_map[elec] = (y, x)\n",
    "    \n",
    "    # Calcola i bin delle frequenze solo una volta se necessario\n",
    "    \n",
    "    # https://numpy.org/doc/2.1/reference/generated/numpy.fft.rfftfreq.html\n",
    "    \n",
    "    '''\n",
    "    Nella tua funzione create_spectrograms_from_fft_images_of_electrodes() tagli già lo spettro FFT\n",
    "    ai primi max_freq_bins (es. 45), quindi l'output finale ha solo 45 frequenze.\n",
    "    \n",
    "    Di conseguenza, la tua funzione non può usare direttamente:\n",
    "    \n",
    "    freqs = np.fft.rfftfreq(n_fft_points, d=1/fs)\n",
    "    \n",
    "    per costruire le maschere, perché fft_image.shape[0] == 45, mentre np.fft.rfftfreq(640, d=1/160) ti dà 321 frequenze!\n",
    "    \n",
    "    Soluzione consigliata: usare solo i primi max_freq_bins del vettore delle frequenze\n",
    "    \n",
    "    Passaggi:\n",
    "    \n",
    "    1) Genera solo i primi max_freq_bins del vettore delle frequenze:\n",
    "    \n",
    "    max_freq_bins = original_data[list(original_data.keys())[0]]['spectrograms_3d'].shape[1]\n",
    "    \n",
    "    all_freqs = np.fft.rfftfreq(n_fft_points, d=1/fs)[:max_freq_bins]\n",
    "    \n",
    "    \n",
    "    2) Costruisci le maschere band_masks in base a queste:\n",
    "    \n",
    "    band_masks = {band: (all_freqs >= f_range[0]) & (all_freqs <= f_range[1]) for band, f_range in bands.items()}\n",
    "    '''\n",
    "    \n",
    "    max_freq_bins = original_data[list(original_data.keys())[0]]['spectrograms_3d'].shape[1]\n",
    "    \n",
    "    '''\n",
    "    Funzione --> np.fft.rfftfreq   https://numpy.org/doc/2.1/reference/generated/numpy.fft.rfftfreq.html\n",
    "    \n",
    "    \n",
    "    Questa funzione serve per calcolare le frequenze associate ai coefficienti della trasformata di Fourier reale (RFFT), \n",
    "    ovvero numpy.fft.rfft\n",
    "    \n",
    "    Parametri:\n",
    "    n (int):\n",
    "    Il numero di campioni del segnale in input. È la lunghezza del segnale su cui verrà calcolata la trasformata.\n",
    "    \n",
    "    d (float, opzionale):\n",
    "    Il passo temporale tra due campioni (cioè 1 / frequenza di campionamento). Il valore di default è 1.0.\n",
    "    \n",
    "    Quindi Serve proprio per calcolare le frequenze corrispondenti ai coefficienti della trasformata di Fourier reale (RFFT), \n",
    "    in modo da sapere a quali frequenze corrispondono i valori presenti nello spettrogramma.\n",
    "    \n",
    "    In questo caso, \n",
    "    la trasformata di Fourier è stata fatta su finestre di lunghezza n_fft_points = 640, a frequenza di campionamento fs = 160 Hz.\n",
    "    \n",
    "    Nello specifico, \n",
    "    \n",
    "    produce un array all_freqs contenente le frequenze in Hz associate ai bins FFT\n",
    "    (cioè agli \"indici\" lungo l'asse delle frequenze nel tuo spettrogramma)\n",
    "    Ho poi tagliato questo array per tenerne solo i primi max_freq_bins valori (es. 45), \n",
    "    perché il tuo spettrogramma è stato già troncato a 45 frequenze.\n",
    "    \n",
    "    Perché è importante?\n",
    "    \n",
    "    Il tuo spettrogramma spectros ha shape:\n",
    "    \n",
    "    (n_trials, n_freqs, n_channels)\n",
    "    \n",
    "    E n_freqs è tipicamente molto più piccolo di n_fft_points // 2 + 1. Quindi hai bisogno di sapere:\n",
    "    👉 \"A quale frequenza reale corrisponde la riga i di questo spettrogramma tagliato?\"\n",
    "    \n",
    "    La funzione rfftfreq ti dà questa corrispondenza.\n",
    "    \n",
    "    \n",
    "    🧩 Uso nella tua funzione\n",
    "    \n",
    "    Hai un dizionario di bande EEG come:\n",
    "    \n",
    "    bands = {\n",
    "    'delta': (0.5, 4),\n",
    "    'theta': (4, 8),\n",
    "    ...\n",
    "    }\n",
    "    \n",
    "    Poi costruisci una maschera per ciascuna banda:\n",
    "    \n",
    "    band_masks = {band: (all_freqs >= f_range[0]) & (all_freqs <= f_range[1]) for band, f_range in bands.items()}\n",
    "    Queste maschere (True/False) ti dicono quali righe del tuo spettrogramma corrispondono a una certa banda di frequenza.\n",
    "    \n",
    "    Poi puoi fare:\n",
    "    \n",
    "    band_power = fft_image[mask, :]  # somma solo le righe corrispondenti alla banda e \n",
    "    ottenere la potenza totale nella banda per ogni canale EEG\n",
    "    \n",
    "    Quindi in sostanza\n",
    "    \n",
    "    La riga:\n",
    "    \n",
    "    all_freqs = np.fft.rfftfreq(n_fft_points, d=1/fs)[:max_freq_bins]\n",
    "    \n",
    "    serve a trovare i valori in Hz associati ai coefficienti dello spettro.\n",
    "    Senza questa riga, non potresti sapere quali righe dello spettrogramma appartengono a quale banda (delta, theta, ecc.),\n",
    "    perché lo spettrogramma è indicizzato per riga (0, 1, 2, ...), non in Hz.\n",
    "    '''\n",
    "    \n",
    "    #Sintesi: \n",
    "    #'all_freqs' serve per trovare i coefficienti della FFT associati allo specifico range di frequenze massime \n",
    "    #a cui era già stato filtrato il mio segnale (45Hz) \n",
    "    #Dopodiché, poi faccio una sotto-selezione di questi coefficienti rispetto alla specifica banda, \n",
    "    #con delle maschere booleane che mi sanno estrarre l'indice dei relativi coefficienti associati a quella banda di frequenza corrente \n",
    "    #e da quelle poi si crea le griglie con la potenza relativa alla banda di frequenza estratta\n",
    "    \n",
    "    all_freqs = np.fft.rfftfreq(n_fft_points, d=1/fs)[:max_freq_bins]\n",
    "    \n",
    "    # Maschere di frequenza per ciascuna banda\n",
    "    \n",
    "    #freq_mask = (freqs >= bandpass[0]) & (freqs <= bandpass[1])\n",
    "    band_masks = {band: (all_freqs >= f_range[0]) & (all_freqs <= f_range[1]) for band, f_range in bands.items()}\n",
    "    \n",
    "    for condition, cond_data in original_data.items():\n",
    "        spectros = cond_data['spectrograms_3d']  # shape: (n_trials, n_freqs, n_channels)\n",
    "        labels = cond_data['labels']\n",
    "        n_trials, n_freqs, n_channels = spectros.shape\n",
    "\n",
    "        images_3d = []\n",
    "        \n",
    "        '''\n",
    "        Nella tua funzione FFT:\n",
    "        \n",
    "        fft_image = trial_power.T  # shape: (n_freq, n_channels)\n",
    "        \n",
    "        Ogni fft_image rappresenta la potenza spettrale (cioè |FFT|²) per:\n",
    "        Righe = frequenze (es. 45 bins)\n",
    "        Colonne = canali EEG (elettrodi)\n",
    "        \n",
    "        Quindi, per ogni canale c, la potenza totale è:\n",
    "        \n",
    "        total_power_c = np.sum(fft_image[:, c])\n",
    "        \n",
    "        Cosa fa la funzione convert_fft_images_to_2d_grids?\n",
    "        \n",
    "        total_power_per_channel = np.sum(fft_image, axis=0)  # somma lungo l'asse delle frequenze\n",
    "        \n",
    "        Quindi estrae la potenza totale aggregando i valori di frequenza.\n",
    "        Questo non è un calcolo superfluo, perché:\n",
    "        \n",
    "        Il dato originale fft_image ha frequenza x canale\n",
    "        L’immagine griglia vuole invece 1 solo valore per canale (asse z), da associare alla posizione (x, y)\n",
    "        \n",
    "        In sintesi:\n",
    "        \n",
    "        ✔ La potenza totale non è esplicitamente salvata, ma è immediatamente disponibile e si ottiene con una semplice np.sum(..., axis=0)\n",
    "        ✔ Quello che fa la funzione è semplicemente riassumere le righe (frequenze) → potenza totale per elettrodo\n",
    "        \n",
    "        ❌ Non c’è duplicazione inutile: questo passaggio è necessario per ridurre 2D (f x ch) → 1D (ch)\n",
    "\n",
    "        '''\n",
    "        \n",
    "        for trial_idx in range(n_trials):\n",
    "            fft_image = spectros[trial_idx]  # (n_freqs, n_channels)\n",
    "            \n",
    "            band_grids = []\n",
    "\n",
    "            # Banda specifica\n",
    "            \n",
    "            for band_name, mask in band_masks.items():\n",
    "                band_power = fft_image[mask, :]  # (n_freqs_in_band, n_channels)\n",
    "            \n",
    "                total_power_per_channel = np.sum(band_power, axis=0)\n",
    "         \n",
    "                grid_2d = np.zeros(grid_shape)\n",
    "\n",
    "                for _, row in df_copy.iterrows():\n",
    "                    electrode = row['Electrode']\n",
    "\n",
    "                    '''ATTENZIONE CHE VA MODIFICATO ANCHE QUI, PER L'ASSEGNAZIONE DELLA POTENZA TOTALE AL RELATIVO ELETTRODO!'''\n",
    "                    #y, x = int(row['grid_y']), int(row['grid_x'])\n",
    "\n",
    "                    x = int(round(row['grid_x'] * (grid_shape[1] - 1)))\n",
    "                    y = int(round(row['grid_y'] * (grid_shape[0] - 1)))\n",
    "\n",
    "                    if electrode == 'EMPTY':\n",
    "                        grid_2d[y, x] = 0\n",
    "\n",
    "                    elif electrode in eeg_channels_names:\n",
    "                        ch_index = eeg_channels_names.index(electrode)\n",
    "                        grid_2d[y, x] = total_power_per_channel[ch_index]\n",
    "                    else:\n",
    "                        grid_2d[y, x] = 0\n",
    "\n",
    "            \n",
    "                band_grids.append(grid_2d)\n",
    "            \n",
    "            # Stack delle 5 griglie su ultima dimensione → (9, 9, 5)\n",
    "            trial_tensor = np.stack(band_grids, axis=-1)\n",
    "            images_3d.append(trial_tensor)\n",
    "\n",
    "        '''ATTENZIONE CHE QUI CONVIENE TENERE LA STESSA CHIAVE DEL DIZIONARIO - spectrograms_3d (anziché  spectrograms_2d)-\n",
    "        PER LE SUCCESSIVE ANALISI, ANCHE SE SI TRATTA DELLA GRIGLIA 2D ASSOCIATA AD OGNI TRIAL'''\n",
    "        \n",
    "        updated_data[condition] = {\n",
    "            \n",
    "            #spectrograms_2d\n",
    "            'spectrograms_3d': np.array(images_3d), #(n_trials, 9, 9, 5)\n",
    "            'labels': labels\n",
    "        }\n",
    "\n",
    "    return updated_data, label_grid, electrode_grid_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4eb8a12-9786-4da4-8627-43bde6e1a702",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "new_all_subjects_condition_spectrograms_task_1 = convert_fft_images_to_2d_grids(original_data: dict,\n",
    "                                                                                eeg_grid_df: pd.DataFrame,\n",
    "                                                                                eeg_channels_names: list,\n",
    "                                                                                grid_shape: tuple = (9, 9),\n",
    "                                                                                fs: int = 160,\n",
    "                                                                                n_fft_points: int = 640,\n",
    "                                                                                bandpass: tuple = None  # es. (4, 7)\n",
    "'''                                                                                \n",
    "\n",
    "new_all_subjects_condition_spectrograms_task_1, label_grid, electrode_grid_map = convert_fft_images_to_2d_grids_all_freqs(new_all_subjects_condition_spectrograms_task_1,\n",
    "                                                                                EEG_file,\n",
    "                                                                                EEG_channels,\n",
    "                                                                                grid_shape = (9, 9),\n",
    "                                                                                fs = 160,\n",
    "                                                                                n_fft_points = 640\n",
    "                                                                                )  # or band-specific (4, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f162d9-d17d-465f-8b90-1285e74be127",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_all_subjects_condition_spectrograms_task_1['spectrograms_rest_100']['spectrograms_3d'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95bd576-b7d7-49c6-a5c1-ad90aa9efe73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "power_values = new_all_subjects_condition_spectrograms_task_1[\"spectrograms_left_fist_100\"][\"spectrograms_3d\"][0][:, :, 0]\n",
    "print(\"Min:\", power_values.min(), \"Max:\", power_values.max())\n",
    "\n",
    "#new_all_subjects_condition_spectrograms_task_1.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a89273c-3279-4c11-ba86-7e81aa1f45c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_trial_grid_multiband(trial_tensor, band_names=None, title_prefix=\"Trial\", cmap=\"viridis\"):\n",
    "    \"\"\"\n",
    "    Visualizza le 5 bande di un trial come 5 heatmap (una per banda),\n",
    "    usando la stessa scala di colori per tutte le bande.\n",
    "    \n",
    "    Args:\n",
    "        trial_tensor (np.ndarray): (9, 9, 5) → griglia 2D + bande\n",
    "        band_names (list): nomi delle bande (es. ['delta', 'theta', ...])\n",
    "        title_prefix (str): prefisso per il titolo\n",
    "        cmap (str): colormap da usare\n",
    "    \"\"\"\n",
    "    n_bands = trial_tensor.shape[-1]\n",
    "    \n",
    "    if band_names is None:\n",
    "        band_names = [f\"Band {i}\" for i in range(n_bands)]\n",
    "\n",
    "    # Calcola min e max globali per normalizzare la scala colori\n",
    "    vmin = np.min(trial_tensor)\n",
    "    vmax = np.max(trial_tensor)\n",
    "\n",
    "    fig, axes = plt.subplots(1, n_bands, figsize=(3*n_bands, 3))\n",
    "    fig.suptitle(f\"{title_prefix}: Griglie di potenza per banda\", fontsize=14)\n",
    "\n",
    "    for i in range(n_bands):\n",
    "        ax = axes[i]\n",
    "        im = ax.imshow(trial_tensor[:, :, i], cmap=cmap, origin='upper', vmin=vmin, vmax=vmax)\n",
    "        ax.set_title(band_names[i])\n",
    "        ax.axis('off')\n",
    "        plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39341967-e6de-414e-9d0d-3430ba5e5753",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial = new_all_subjects_condition_spectrograms_task_1[\"spectrograms_left_fist_100\"][\"spectrograms_3d\"][0]  # (9, 9, 5)\n",
    "band_names = ['delta', 'theta', 'alpha', 'beta', 'gamma']\n",
    "plot_trial_grid_multiband(trial, band_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b188fb-f8a9-477d-bc5f-b1b72bf067cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#electrode_grid_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f864ba77-daac-4670-a4ce-222d768ae751",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "base_path = '/home/stefano/Interrogait/all_datas/Spectrograms_channels_frequencies_motor_tasks/'\n",
    "\n",
    "# Controlla se la cartella esiste, altrimenti la crea\n",
    "if not os.path.exists(base_path):\n",
    "    os.makedirs(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795dc312-eaa8-45ee-80d8-d3dbce9cac45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvare l'intero dizionario annidato con pickle\n",
    "with open(f'{base_path}new_all_subjects_condition_spectrograms_task_1_2d_grid_multiband.pkl', 'wb') as f:\n",
    "    pickle.dump(new_all_subjects_condition_spectrograms_task_1, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94543a2-9b70-460a-854c-6612eb54901c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "path = '/home/stefano/EEGMMIDB_Analyses/'\n",
    "\n",
    "# Salvare l'intero dizionario annidato con pickle\n",
    "with open(f'{path}final_EEG_electrodes_grid.pkl', 'wb') as f:\n",
    "    pickle.dump(label_grid, f)\n",
    "    \n",
    "\n",
    "# Salvare l'intero dizionario annidato con pickle\n",
    "with open(f'{path}electrode_grid_map.pkl', 'wb') as f:\n",
    "    pickle.dump(electrode_grid_map, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47754fe-e196-41d2-9cd0-f4ffa65d62a6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### **Implementazione Immagine Griglia 2D** \n",
    "\n",
    "1) **Check Posizionamento Etichette degli Elettrodi su Griglia 2D**\n",
    "2) **Check Valore 0 a Etichette degli Elettrodi Vuoti (i.e., gli EMPTY) su Griglia 2D**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86600bad-14fb-4489-aa13-84c3141c7c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d569d6c-22e0-4809-8ce1-b05081a58f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Se vuoi costruire una matrice 2D indicizzata (es. grid[y, x]) per usarla come immagine 2D o input per modelli CNN:\n",
    "\n",
    "→ Devi usare indici interi\n",
    "\n",
    "Quindi sì, devi fare:\n",
    "\n",
    "x = int(round(row['grid_x'] * (grid_shape[1] - 1)))\n",
    "y = int(round(row['grid_y'] * (grid_shape[0] - 1)))\n",
    "\n",
    "Questo perché una matrice NumPy grid_2d[y, x] non può accettare float come indici\n",
    "'''\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_eeg_grid_labels(label_grid: np.ndarray, title: str = \"Posizione elettrodi sulla griglia EEG\"):\n",
    "    \"\"\"\n",
    "    Visualizza una griglia 2D con le etichette degli elettrodi (senza potenza).\n",
    "    \n",
    "    Args:\n",
    "        label_grid (np.ndarray): Griglia 2D (grid_y x grid_x) con stringhe degli elettrodi.\n",
    "        title (str): Titolo del grafico.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    ax.set_title(title)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "    # Disegna la griglia e annota le etichette\n",
    "    for y in range(label_grid.shape[0]):\n",
    "        for x in range(label_grid.shape[1]):\n",
    "            label = label_grid[y, x]\n",
    "            rect = plt.Rectangle((x, y), 1, 1, fill=False, edgecolor='gray', lw=1)\n",
    "            ax.add_patch(rect)\n",
    "            if label != '':\n",
    "                ax.text(x + 0.5, y + 0.5, label, ha='center', va='center', fontsize=8)\n",
    "\n",
    "    ax.set_xlim(0, label_grid.shape[1])\n",
    "    ax.set_ylim(label_grid.shape[0], 0)  # Inverti y per avere origine in alto a sinistra\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b8f372-5a2c-468e-b59d-9c563e3e37fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_eeg_grid_labels(label_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc8e210-51e8-48b1-b3ae-93f348077e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Come accedere a tutte le posizioni EMPTY\n",
    "Puoi usare la label_grid, che ha lo stesso shape (9, 9) della matrice di potenza grid_2d.\n",
    "'''\n",
    "\n",
    "empty_mask = (label_grid == '')\n",
    "empty_positions = np.argwhere(empty_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d172f2-23d3-4ca7-9f83-712a234c4650",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Questo mostrerà tutti gli slot EMPTY e la relativa potenza (che sarà 0 se il tutto è coerente)\n",
    "'''\n",
    "\n",
    "for y, x in empty_positions:\n",
    "    print(f\"EMPTY @ (y={y}, x={x}) → Potenza: {power_values[y, x]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1648ce-a710-4e3f-85ee-26b8ef605e2d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### **Implementazione Immagine Griglia 2D** \n",
    "\n",
    "1) **Check Posizionamento Etichette degli Elettrodi su Griglia 2D**\n",
    "2) **Check Valore Potenza Totale ad Etichette degli Elettrodi VERI su Griglia 2D**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b08e59-cf5b-4029-9096-bba6d42786ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "✅ plot_eeg_grid_image(trial_2d_image)\n",
    "Mostra visivamente una griglia 2D EEG generata per un trial.\n",
    "\n",
    "Puoi usarla ad esempio così:\n",
    "\n",
    "plot_eeg_grid_image(new_data_2d['condition_name']['spectrograms_2d'][0])\n",
    "\n",
    "Oppure, per iterare su più condizioni e trial:\n",
    "\n",
    "for cond, data in new_data_2d.items():\n",
    "    plot_eeg_grid_image(data['spectrograms_2d'][0], title=f\"Condizione: {cond} - Trial 0\")\n",
    "    break  # Rimuovi il break per vederle tutte\n",
    "\n",
    "Fammi sapere se vuoi anche:\n",
    "\n",
    "Annotare gli elettrodi sulla griglia.\n",
    "\n",
    "Salvare le immagini .png.\n",
    "\n",
    "Ottenere un confronto tra immagine generata e immagine esempio (EEG_grid_map). \n",
    "\n",
    "❗Nota:\n",
    "Se hai valori negativi o zero nella griglia, la scala logaritmica li ignorerà o li \"appiattirà\" a un minimo (eps) per evitare errori.\n",
    "\n",
    "Se vuoi forzare una normalizzazione identica per tutti i trial, puoi impostare vmin e vmax manualmente.\n",
    "\n",
    "Fammi sapere se vuoi anche:\n",
    "\n",
    "Annotare i valori numerici in ciascuna cella\n",
    "\n",
    "Plottare la differenza tra due condizioni\n",
    "\n",
    "Salvare direttamente i plot come file .png\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_eeg_grid_image(trial_2d_image: np.ndarray, title: str = \"EEG Power Grid (Trial)\"):\n",
    "    \"\"\"\n",
    "    Visualizza un'immagine 2D (griglia EEG) di un singolo trial.\n",
    "\n",
    "    Args:\n",
    "        trial_2d_image (np.ndarray): Array 2D (grid_y x grid_x) con i valori di potenza.\n",
    "        title (str): Titolo del grafico.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(trial_2d_image, cmap='viridis', origin='upper')\n",
    "    plt.colorbar(label=\"Potenza Totale\")\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd588b2-bb27-4be2-bc9b-ada0df336232",
   "metadata": {},
   "outputs": [],
   "source": [
    "#▶️ 1. Per plottare il primo trial di una condizione:\n",
    "plot_eeg_grid_image(new_all_subjects_condition_spectrograms_task_1[\"spectrograms_left_fist_100\"][\"spectrograms_3d\"][0], title=\"Condizione: Left Fist - Trial 0\")\n",
    "\n",
    "#▶️ 2. Per plottare il primo trial di tutte le condizioni:\n",
    "#for cond, data in new_all_subjects_condition_spectrograms_task_1.items():\n",
    "#    plot_eeg_grid_image(data['spectrograms_2d'][0], title=f\"Condizione: {cond} - Trial 0\")\n",
    "#    break  # 🔁 rimuovi questo break per vedere tutte le condizioni\n",
    "    \n",
    "#▶️ 3. Per plottare più trial di una condizione:\n",
    "\n",
    "#for i, trial_image in enumerate(new_all_subjects_condition_spectrograms_task_1[\"spectrograms_left_fist_100\"][\"spectrograms_2d\"][:5]):  # primi 5 trial\n",
    "#    plot_eeg_grid_image(trial_image, title=f\"Condizione: spectrograms_left_fist_100 - Trial {i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc300e6-7f99-4408-8923-1a5a5f014a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "power_values = new_all_subjects_condition_spectrograms_task_1[\"spectrograms_left_fist_100\"][\"spectrograms_3d\"][1]\n",
    "print(\"Min:\", power_values.min(), \"Max:\", power_values.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1411d8ca-b765-4948-9b0c-a270704cbf88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#🔄 Se vuoi aggiungere le etichette degli elettrodi sulla griglia:\n",
    "\n",
    "def plot_eeg_grid_with_labels(trial_2d_image: np.ndarray, label_grid: np.ndarray, title: str = \"Condizione: Left Fist - Trial 0\"):\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(trial_2d_image, cmap='viridis', origin='upper')\n",
    "    for y in range(label_grid.shape[0]):\n",
    "        for x in range(label_grid.shape[1]):\n",
    "            label = label_grid[y, x]\n",
    "            if label != \"\":\n",
    "                plt.text(x, y, label, ha='center', va='center', color='white', fontsize=8)\n",
    "    plt.colorbar(label=\"Potenza Totale\")\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56e286e-1b24-4cbd-85b3-9f9fec63912c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_eeg_grid_with_labels(new_all_subjects_condition_spectrograms_task_1[\"spectrograms_left_fist_100\"][\"spectrograms_3d\"][0], label_grid)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "92c74ab5-1a24-4b5b-8aa0-72198c7c7050",
   "metadata": {
    "tags": []
   },
   "source": [
    "'''\n",
    "Forse bisogna usare una scala logaritmica per notare le differenze?\n",
    "perché ad esempio ora le vedo così e sembra apparentemente che non ci sia alcuna differenza...\n",
    "\n",
    "Hai assolutamente ragione 💡: se tutti i valori della griglia sono molto piccoli e simili tra loro, una colormap lineare come viridis può\n",
    "renderli visivamente indistinguibili. In questi casi è molto utile usare una scala logaritmica per evidenziare meglio le differenze.\n",
    "'''\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "def plot_eeg_grid_image_log_scale(\n",
    "    trial_2d_image: np.ndarray, \n",
    "    title: str = \"EEG Power Grid (Trial)\",\n",
    "    log_scale: bool = True,\n",
    "    vmin: float = None,\n",
    "    vmax: float = None\n",
    "):\n",
    "    \"\"\"\n",
    "    Visualizza un'immagine 2D (griglia EEG) di un singolo trial, con opzione per scala logaritmica.\n",
    "\n",
    "    Args:\n",
    "        trial_2d_image (np.ndarray): Array 2D (grid_y x grid_x) con i valori di potenza.\n",
    "        title (str): Titolo del grafico.\n",
    "        log_scale (bool): Se True, usa scala logaritmica per il colore.\n",
    "        vmin (float): Valore minimo per la scala dei colori.\n",
    "        vmax (float): Valore massimo per la scala dei colori.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(6, 6))\n",
    "\n",
    "    if log_scale:\n",
    "        eps = 1e-12  # per evitare log(0)\n",
    "        image = np.where(trial_2d_image > 0, trial_2d_image, eps)\n",
    "        norm = LogNorm(vmin=vmin or image.min(), vmax=vmax or image.max())\n",
    "        plt.imshow(image, cmap='viridis', origin='upper', norm=norm)\n",
    "    else:\n",
    "        plt.imshow(trial_2d_image, cmap='viridis', origin='upper', vmin=vmin, vmax=vmax)\n",
    "\n",
    "    plt.colorbar(label=\"Potenza Totale (log)\" if log_scale else \"Potenza Totale\")\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "24455b91-4e64-4ce4-b14f-8776033257ce",
   "metadata": {
    "tags": []
   },
   "source": [
    "plot_eeg_grid_image_log_scale(new_all_subjects_condition_spectrograms_task_1[\"spectrograms_left_fist_100\"][\"spectrograms_2d\"][0], title=\"Condizione: Left Fist - Trial 0\", log_scale=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8612f96b-e8f5-46fe-9eee-bcb3c409ddf1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### **Concatenazione** All **SINGLE** Subject **Spectrograms** per **Tutte le Condizioni Sperimentali**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846f664f-3d33-457b-8535-80d5650a276a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Library Importing \n",
    "    \n",
    "import os\n",
    "import math\n",
    "import copy as cp \n",
    "\n",
    "import tqdm\n",
    "\n",
    "#import mne \n",
    "import scipy\n",
    "\n",
    "import numpy as np  # NumPy per operazioni numeriche\n",
    "import matplotlib.pyplot as plt  # Matplotlib per la isualizzazione dei dati\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import pickle\n",
    "\n",
    "# Caricare l'intero dizionario annidato con pickle\n",
    "path = '/home/stefano/Interrogait/all_datas/Spectrograms_channels_frequencies_motor_tasks/'\n",
    "\n",
    "# Caricare l'intero dizionario annidato con pickle\n",
    "\n",
    "with open(f'{path}new_all_subjects_condition_spectrograms_task_1_2d_grid_multiband.pkl', 'rb') as f:\n",
    "    new_all_subjects_condition_spectrograms_task_1 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8beec2de-211c-430a-9134-d17472e54093",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_all_subjects_condition_spectrograms_task_1.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cf1f68-22a7-48bc-a5f2-69784e90da7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Definizione degli indici dei canali desiderati\n",
    "\n",
    "'''TOLGO PER SPETTROGRAMMI FREQUENZE x ELETTRODI'''\n",
    "#selected_channels = [12, 30, 48]  # Indici per Fz, Cz, Pz\n",
    "\n",
    "# Creazione di un dizionario dei dati di tutti i terapisti singolarmente, per salvare gli spettrogrammi calcolati\n",
    "new_single_th_all_extracted_spectrograms_2D_task_1 = {}\n",
    "\n",
    "# Iterazione su tutte le condizioni sperimentali di tutti i soggetti \n",
    "\n",
    "for condition, data in new_all_subjects_condition_spectrograms_task_1.items():\n",
    "    \n",
    "    # Estrarre le etichette per la condizione corrente\n",
    "    labels = data['labels']\n",
    "    \n",
    "    #  Estrarre gli spettrogrammi per la condizione corrente\n",
    "    '''TOLGO PER SPETTROGRAMMI FREQUENZE x ELETTRODI'''\n",
    "    #spectrograms = data['spectrograms_4d']\n",
    "    \n",
    "    spectrograms = data['spectrograms_3d']\n",
    "    \n",
    "    '''TOLGO PER SPETTROGRAMMI FREQUENZE x ELETTRODI'''\n",
    "    #Selezione dei canali di interesse (Fz, Cz e Pz)\n",
    "    #spectrograms = spectrograms[:, selected_channels, :, :]\n",
    "    \n",
    "    new_single_th_all_extracted_spectrograms_2D_task_1[condition] = {\n",
    "        'spectrograms': spectrograms,\n",
    "        #'delta': delta_reconstruction,\n",
    "        #'coeff_fifth_detail_theta': coeff_fifth_detail_theta, \n",
    "        'labels': labels\n",
    "    }\n",
    "    \n",
    "# Verifica delle dimensioni del risultato estratto per una condizione specifica di ogni soggetto\n",
    "print(f\"\\t\\t\\033[1mEstrazione Spettrogrammi di tutti i terapisti per tutte le condizioni sperimentali\")\n",
    "print(f\"\\n\\n\\t\\t\\t\\t(i.e., \\033[1mnew_single_th_all_extracted_spectrograms_2D_task_1\\033[0m):\\n\")\n",
    "\n",
    "for condition, extracted_data in new_single_th_all_extracted_spectrograms_2D_task_1.items():\n",
    "    \n",
    "    print(f\"Condizione: \\033[1m{condition}\\033[0m, \"\n",
    "          f\"Spectrograms shape: \\033[1m{extracted_data['spectrograms'].shape}\\033[0m, \"\n",
    "          f\"Labels: \\033[1m{len(extracted_data['labels'])}\\033[0m\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b1c833-225f-4939-80ff-779a3377e1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Salvataggio di new_single_th_all_extracted_spectrograms_2D_task_1'''\n",
    "\n",
    "base_path = '/home/stefano/Interrogait/all_datas/Spectrograms_channels_frequencies_motor_tasks/'\n",
    "\n",
    "\n",
    "# Controlla se la cartella esiste, altrimenti la crea\n",
    "if not os.path.exists(base_path):\n",
    "    os.makedirs(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c91eac-a5be-482d-ac2b-1b2411392ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Salvare l'intero dizionario annidato con pickle\n",
    "with open(f'{base_path}new_single_th_all_extracted_spectrograms_2D_task_1_2d_grid_multiband.pkl', 'wb') as f:\n",
    "    pickle.dump(new_single_th_all_extracted_spectrograms_2D_task_1, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1abe8fc-e39f-456b-a6de-757c748af117",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(new_single_th_all_extracted_spectrograms_2D_task_1.keys())\n",
    "print()\n",
    "print(new_single_th_all_extracted_spectrograms_2D_task_1['spectrograms_rest_100'].keys())\n",
    "print()\n",
    "print(len(new_single_th_all_extracted_spectrograms_2D_task_1['spectrograms_rest_100']['labels']))\n",
    "print()\n",
    "#print(new_single_th_all_extracted_spectrograms_2D_task_1['spectrograms_rest_100']['labels'][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defb0561-c5ac-4bc5-ad2f-b27146cee8c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Questa struttura consente di avere i dati degli spettrogrammi correttamente organizzati e concatenati per ogni soggetto,\n",
    "mantenendo la corrispondenza tra dati e etichette per ogni condizione sperimentale\n",
    "\n",
    "Da           \"single_th_all_extracted_reconstructions\"       a           \"subject_level_concatenations_th\"\n",
    "\n",
    "Da           \"new_single_th_all_extracted_reconstructions\"       a       \"new_subject_level_concatenations_th\"\n",
    "\n",
    "Da           \"new_single_th_all_extracted_spectrograms_2D_task_1\"       a       \"new_subject_level_concatenations_spectrograms_th_2D_task_1\"\n",
    "'''\n",
    "\n",
    "\n",
    "# Dizionario per contenere i dati concatenati per ogni soggetto\n",
    "new_subject_level_concatenations_spectrograms_th_2D_task_1 = {}\n",
    "\n",
    "# Variabile per tracciare il soggetto precedente\n",
    "previous_subject_suffix = None\n",
    "\n",
    "print(f\"\\t\\t\\033[1mConcatenazione spettrogrammi 2D per OGNI soggetto di TUTTE le condizioni sperimentali INSIEME\\033[0m\")\n",
    "\n",
    "# Iterazione su tutte le chiavi di new_single_th_all_extracted_spectrograms_2D_task_1\n",
    "for condition, data in new_single_th_all_extracted_spectrograms_2D_task_1.items():\n",
    "    \n",
    "    # Estrazione del suffisso numerico del soggetto\n",
    "    subject_suffix = condition.split('_')[-1]  # Prende solo la parte numerica\n",
    "    \n",
    "    # Creazione del nome della chiave del soggetto specifico\n",
    "    subj_name = f'th_{subject_suffix}'\n",
    "    \n",
    "    # Se stiamo per passare a un nuovo soggetto, concatenare e stampare i risultati del soggetto precedente\n",
    "    if previous_subject_suffix is not None and subject_suffix != previous_subject_suffix:\n",
    "        \n",
    "        print(f\"\\n\\n\\t\\t\\t\\t\\033[1mConcatenazioni per il soggetto corrente ('th_{previous_subject_suffix}'):\\033[0m\\n\")\n",
    "        prev_subject_name = f'th_{previous_subject_suffix}'\n",
    "        levels = new_subject_level_concatenations_spectrograms_th_2D_task_1[prev_subject_name]\n",
    "\n",
    "        # Concatenazione dei dati prima della stampa\n",
    "        spectrograms_concat = np.concatenate(levels['spectrograms'], axis=0)\n",
    "        labels_concat = np.concatenate(levels['labels'], axis=0)\n",
    "\n",
    "        print(f\"Soggetto: \\033[1m{prev_subject_name}\\033[0m, \"\n",
    "              f\"Spettrogrammi shape: \\033[1m{spectrograms_concat.shape}\\033[0m, \"\n",
    "              f\"Labels length: \\033[1m{len(labels_concat)}\\033[0m\")\n",
    "        \n",
    "        # Salvataggio dei dati concatenati nel dizionario\n",
    "        new_subject_level_concatenations_spectrograms_th_2D_task_1[prev_subject_name]['spectrograms'] = spectrograms_concat\n",
    "        new_subject_level_concatenations_spectrograms_th_2D_task_1[prev_subject_name]['labels'] = labels_concat\n",
    "    \n",
    "    # Inizializzare il dizionario per il soggetto specifico se non esiste già\n",
    "    if subj_name not in new_subject_level_concatenations_spectrograms_th_2D_task_1:\n",
    "        new_subject_level_concatenations_spectrograms_th_2D_task_1[subj_name] = {\n",
    "            'spectrograms': [],\n",
    "            'labels': []\n",
    "        }\n",
    "    \n",
    "    # Stampiamo le informazioni per ogni condizione\n",
    "    print(f\"\\n\\n\\nSoggetto: \\033[1m{subj_name}\\033[0m, Condizione: \\033[1m{condition}\\033[0m\")\n",
    "    print(f\"  - Spettrogrammi shape: \\033[1m{data['spectrograms'].shape}\\033[0m\")\n",
    "    print(f\"  - Labels shape: \\033[1m{len(data['labels'])}\\033[0m\")\n",
    "    print(f\"  - Valore unico delle etichette: \\033[1m{np.unique(data['labels'])}\\033[0m\")\n",
    "    \n",
    "    # Concatenazione dei dati\n",
    "    new_subject_level_concatenations_spectrograms_th_2D_task_1[subj_name]['spectrograms'].append(data['spectrograms'])\n",
    "    new_subject_level_concatenations_spectrograms_th_2D_task_1[subj_name]['labels'].append(data['labels'])\n",
    "    \n",
    "    # Aggiorna il soggetto precedente\n",
    "    previous_subject_suffix = subject_suffix\n",
    "\n",
    "# Dopo aver iterato su tutte le condizioni, concatenare e stampare le informazioni dell'ultimo soggetto\n",
    "if previous_subject_suffix is not None:\n",
    "    \n",
    "    last_subject_name = f'th_{previous_subject_suffix}'\n",
    "    levels = new_subject_level_concatenations_spectrograms_th_2D_task_1[last_subject_name]\n",
    "    \n",
    "    print(f\"\\n\\n\\t\\t\\t\\t\\033[1mConcatenazioni per il soggetto corrente ('{last_subject_name}'):\\033[0m\\n\")\n",
    "    \n",
    "    # Concatenazione dei dati dell'ultimo soggetto\n",
    "    spectrograms_concat = np.concatenate(levels['spectrograms'], axis=0)\n",
    "    labels_concat = np.concatenate(levels['labels'], axis=0)\n",
    "    \n",
    "    # Salvataggio dei dati concatenati dell'ultimo soggetto nel dizionario\n",
    "    new_subject_level_concatenations_spectrograms_th_2D_task_1[last_subject_name] = {\n",
    "        'spectrograms': spectrograms_concat,\n",
    "        'labels': labels_concat\n",
    "    }\n",
    "    \n",
    "    print(f\"Soggetto: \\033[1m{last_subject_name}\\033[0m, \"\n",
    "          f\"Spettrogrammi shape: \\033[1m{spectrograms_concat.shape}\\033[0m, \"\n",
    "          f\"Labels length: \\033[1m{len(labels_concat)}\\033[0m\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec151498-e58c-4261-b82a-0b330a561b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''CHIAVI DI TUTTO IL DIZIONARIO '''\n",
    "#subject_level_concatenations_th.keys()\n",
    "\n",
    "\n",
    "new_subject_level_concatenations_spectrograms_th_2D_task_1.keys()\n",
    "\n",
    "\n",
    "#SOGGETTO 1\n",
    "\n",
    "#CHIAVI\n",
    "#subject_level_concatenations_th['th_1'].keys()\n",
    "\n",
    "#DATI\n",
    "#subject_level_concatenations_th['th_1']['theta'].shape\n",
    "\n",
    "#new_subject_level_concatenations_th['th_1']['theta'].shape\n",
    "\n",
    "#subject_level_concatenations_th['th_1']['delta'].shape\n",
    "\n",
    "#LABELS\n",
    "#subject_level_concatenations_th['th_1']['labels'].shape)\n",
    "#type(subject_level_concatenations_th['th_1']['labels'])\n",
    "\n",
    "# Check della concantenazione delle labels TH_1\n",
    "\n",
    "#subject_level_concatenations_th['th_1']['labels'][:42]\n",
    "#subject_level_concatenations_th['th_1']['labels'][41:81]\n",
    "#subject_level_concatenations_th['th_1']['labels'][81:120]\n",
    "#subject_level_concatenations_th['th_1']['labels'][121:164]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea7730b-e80c-4632-a4d1-8fb95e38febd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#subject_level_concatenations_th['th_15']['labels'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff8cf0d-cc3d-4571-b824-e7bf4c034246",
   "metadata": {},
   "outputs": [],
   "source": [
    "#subject_level_concatenations_th['th_1'].keys()\n",
    "\n",
    "new_subject_level_concatenations_spectrograms_th_2D_task_1['th_1'].keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb69bb0e-5d5f-4670-8f5b-478029c33a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#unique_values, counts = np.unique(subject_level_concatenations_th['th_1']['labels'], return_counts=True)\n",
    "\n",
    "#unique_values, counts = np.unique(new_subject_level_concatenations_th['th_1']['labels'], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf50a14-1c61-4c86-a722-ca664734fbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#unique_values\n",
    "#counts\n",
    "#counts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33775d9-7c95-448b-86fb-e045b13be576",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a373cf-a65c-4f9f-9bbb-60f45fa70d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Salvataggio di new_single_th_all_extracted_spectrograms_2D_task_1'''\n",
    "\n",
    "base_path = '/home/stefano/Interrogait/all_datas/Spectrograms_channels_frequencies_motor_tasks/'\n",
    "\n",
    "# Controlla se la cartella esiste, altrimenti la crea\n",
    "if not os.path.exists(base_path):\n",
    "    os.makedirs(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e984d31-b823-4952-9929-cdd205b0a285",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Salvare l'intero dizionario annidato con pickle\n",
    "with open(f'{base_path}new_subject_level_concatenations_spectrograms_th_2D_task_1_2d_grid_multiband.pkl', 'wb') as f:\n",
    "    pickle.dump(new_subject_level_concatenations_spectrograms_th_2D_task_1, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec17f1a-4e37-409d-aaee-ddb9921de60d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### **Concatenazione** All **SINGLE** Subject **Spectrograms (TH)** per **Coppie di Condizioni Sperimentali**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7d1dd1-5078-42f2-bee9-837083062469",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Library Importing \n",
    "    \n",
    "import os\n",
    "import math\n",
    "import copy as cp \n",
    "\n",
    "import tqdm\n",
    "\n",
    "#import mne \n",
    "import scipy\n",
    "\n",
    "import numpy as np  # NumPy per operazioni numeriche\n",
    "import matplotlib.pyplot as plt  # Matplotlib per la isualizzazione dei dati\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a4875a-bb55-4cc7-876d-aa71766dbf5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c453ba4-fc9c-4e03-9f99-05e2bb675d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862067e9-d414-4124-97f2-36386f5259cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cd New_Plots_Sliding_Estimator_MNE_1_45_NF/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ada3e99-5dd9-4ca5-8d79-611491353d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "base_path = '/home/stefano/Interrogait/all_datas/Spectrograms_channels_frequencies_motor_tasks/'\n",
    "    \n",
    "# Caricare l'intero dizionario annidato con pickle\n",
    "with open(f'{base_path}new_single_th_all_extracted_spectrograms_2D_task_1_2d_grid_multiband.pkl', 'rb') as f:\n",
    "    new_single_th_all_extracted_spectrograms_2D_task_1 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0e53e7-0d42-4503-9a6d-4dcf4a75b55f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_single_th_all_extracted_spectrograms_2D_task_1.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99af361d-fd72-4542-9535-08af0b849110",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_single_th_all_extracted_spectrograms_2D_task_1['spectrograms_rest_100'].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58b6e5d-ca01-444a-b247-64b5c7175fa8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### Spiegazione STEP - Concatenazione All Single Subject Spectrograms (TH) across Couples of Experimental Conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8836c72f-4d7c-4c74-94cd-4abdd78e3c3b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "###### **Concatenazione All Single Subject Data (TH) per Coppie di Condizioni Sperimentali**\n",
    "\n",
    "<br>\n",
    "\n",
    "In questo caso, voglio **trasformare le variabili che contengono i miei dati e labels delle 4 condizioni sperimentali assieme**, in modo **da creare sottoinsiemi per ogni possibile coppia di condizioni sperimentali**. \n",
    "\n",
    "Dunque quello che si dovrà fare **per ogni coppia**:\n",
    "\n",
    "1) **Filtrare i dati e le etichette**:\n",
    "\n",
    "- **Estrarre** i dati associati **SOLO alle DUE condizioni in esame** (ad esempio 0 e 1, oppure 1 e 2).\n",
    "- **Creare un nuovo array di etichette** e **un array di dati** ***corrispondenti*** **SOLO a quelle DUE condizioni**.\n",
    "\n",
    "2) **Ripetere questa operazione per OGNI combinazione**:\n",
    "\n",
    "- **Assicurarsi di considerare tutte le coppie** di condizioni sperimentali **SENZA ripetizioni** (ad esempio, non serve processare sia 0 vs 1 che 1 vs 0, perché sono equivalenti!).\n",
    "\n",
    "3) **Creare quindi una struttura organizzata**, che contenga i dati e le etichette separatamente per ogni coppia, per ciascun livello di ricostruzione (theta, delta, theta_strict).\n",
    "\n",
    "<br>\n",
    "\n",
    "Quindi l'obiettivo è di modificare la procedura in modo da **concatenare SOLO le coppie di condizioni sperimentali per OGNI soggetto**. \n",
    "\n",
    "Per fare questo, possiamo utilizzare un **approccio combinatorio** per generare **tutte le possibili coppie di condizioni**.\n",
    "\n",
    "\n",
    "Per quanto riguarda il calcolo combinatorio, possiamo usare il concetto di combinazioni per selezionare le coppie. \n",
    "Se hai 4 condizioni, il numero di combinazioni di coppie di condizioni (senza ripetizioni) si calcola come:\n",
    "\n",
    "$$\n",
    "\\binom{4}{2} = \\frac{4!}{2!(4-2)!} = 6\n",
    "$$\n",
    "\n",
    "\n",
    "Quindi, con 4 condizioni sperimentali, le combinazioni di coppie di condizioni saranno 6, e queste coppie sono:\n",
    "\n",
    "(condizione 1, condizione 2) = 'baseline vs th_resp'\n",
    "(condizione 1, condizione 3) = 'baseline vs pt_resp'\n",
    "(condizione 1, condizione 4) = 'baseline vs shared_resp'\n",
    "(condizione 2, condizione 3) = 'th_resp vs pt_resp'\n",
    "(condizione 2, condizione 4) = 'th_resp vs shared_resp'\n",
    "(condizione 3, condizione 4) = 'pt_resp vs shared_resp' \n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "Piano di modifiche al codice:\n",
    "\n",
    "1) **Creazione delle coppie di condizioni**: Per ogni soggetto, genereremo tutte le coppie possibili di condizioni sperimentali. Utilizzeremo itertools.combinations per ottenere queste coppie.\n",
    "\n",
    "2) **Concatenazione per ciascuna coppia**: Per ogni coppia di condizioni, concatenare i dati e le etichette delle due condizioni selezionate.\n",
    "\n",
    "3) **Salvataggio delle concatenazioni**: Creeremo un dizionario per ciascuna coppia di condizioni per ogni soggetto.\n",
    "\n",
    "\n",
    "**N.B.**\n",
    "\n",
    "Nel codice che sto creando...\n",
    "\n",
    "Ho fatto in modo che ci sia il modo di capire, **per ogni coppia di condizione sperimentale di dati e labels**, a quali condizione sperimentali di dati e labels ci si riferisca, mi spiego:\n",
    "\n",
    "Sviluppo un **modo \"standardizzato\" per il quale per OGNI coppia di condizione sperimentale, la variabile che conterrà i dati e labels associate, sia chiamata in un certo modo**...\n",
    "\n",
    "E nello specifico **con il nome delle DUE condizioni sperimentali che conterranno quei dati e relative labels**...\n",
    "\n",
    "Del tipo: \n",
    "\n",
    "- se è baseline vs th_resp, la variabile sarà \"baseline_vs_th_resp\"\n",
    "- se è baseline vs pt_resp, la variabile sarà \"baseline_vs_pt_resp\"\n",
    "- se è baseline vs shared_resp, la variabile sarà \"baseline_vs_shared_resp\"\n",
    "\n",
    "\n",
    "Senza contare che, questo **processo di standardizzazione del nome delle variabili**, deve esser fatto **per ogni livello di ricostruzione dei dati (sia 4° e 5° livello a partire dai coefficienti di approssimazione, che dal 5 ° livello dei coefficienti di dettaglio)**..\n",
    "\n",
    "Questo significherebbe che, **per ogni soggetto**, dovrei (o potrei insomma) creare **un dizionario**, che \n",
    "\n",
    "- Contenga delle **sotto-chiavi di secondo ordine** (che son theta, delta e theta_strict) e dentro ognuna di queste\n",
    "- Ci siano contenute **le relative 6 sotto-sotto-chiavi di terzo ordine**, relative ai dati e alle labels associate (anch'esse concatenate ovviamente) delle diverse combinazioni di condizioni sperimentali...\n",
    "\n",
    "\n",
    "Ossia, vogliamo creare un dizionario strutturato che rappresenti ogni combinazione di coppie di condizioni sperimentali per ciascun soggetto, separando i dati e le etichette per i vari livelli di ricostruzione (theta, delta, theta_strict). \n",
    "\n",
    "Ogni combinazione di condizioni sperimentali sarà memorizzata in una chiave strutturata, come ad esempio \"baseline_vs_th_resp\", e all'interno di ciascuna chiave avremo le informazioni per i vari livelli di ricostruzione.\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "#### Esempio di Struttura proposta per il dizionario:\n",
    "\n",
    "\n",
    "- Soggetto: ad esempio \"th_1\".\n",
    "- Livelli di ricostruzione: theta, delta, theta_strict.\n",
    "- Combinazioni di condizioni sperimentali: per ciascun livello di ricostruzione, avremo sotto-chiavi per ogni coppia di condizioni.\n",
    "\n",
    "        new_subject_level_concatenations = {\n",
    "            'th_1': {\n",
    "                'theta': {\n",
    "                    'baseline_vs_th_resp': {'data': np.array([...]), 'labels': np.array([...])},\n",
    "                    'baseline_vs_pt_resp': {'data': np.array([...]), 'labels': np.array([...])},\n",
    "                    'baseline_vs_shared_resp': {'data': np.array([...]), 'labels': np.array([...])},\n",
    "                    # Altre combinazioni...\n",
    "                },\n",
    "                'delta': {\n",
    "                    'baseline_vs_th_resp': {'data': np.array([...]), 'labels': np.array([...])},\n",
    "                    'baseline_vs_pt_resp': {'data': np.array([...]), 'labels': np.array([...])},\n",
    "                    'baseline_vs_shared_resp': {'data': np.array([...]), 'labels': np.array([...])},\n",
    "                    # Altre combinazioni...\n",
    "                },\n",
    "                'theta_strict': {\n",
    "                    'baseline_vs_th_resp': {'data': np.array([...]), 'labels': np.array([...])},\n",
    "                    'baseline_vs_pt_resp': {'data': np.array([...]), 'labels': np.array([...])},\n",
    "                    'baseline_vs_shared_resp': {'data': np.array([...]), 'labels': np.array([...])},\n",
    "                    # Altre combinazioni...\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "\n",
    "<br>\n",
    "\n",
    "**SOTTO-STEP 1: IDENTIFICAZIONE DELLE STRINGA NUMERICHE PER LA CREAZIONE DELLE VARIABILI - FUTURE CHIAVI - CHE CONTENGONO LE COPPIE DI DATI E LABELS DELLE RELATIVE COPPIE DI CONDIZIONI SPERIMENTALI CONSIDERATE NEL CICLO CORRENTE DEL LOOP**\n",
    "\n",
    "Aspetta, ci sono altre cose che dovrebbero esser integrate nel codice...\n",
    "\n",
    "cominciamo dalla prima, che è relativa all' \"inferire\" diciamo il nome da fornire alla variabile che conterrà i dati e labels delle due condizioni sperimentali correnti... e deve esser fatto, a partire dal nome delle chiavi di \n",
    "\n",
    "\"new_single_th_all_extracted_reconstructions\"...\n",
    "\n",
    "ora, le sue chiavi son queste\n",
    "\n",
    "dict_keys(['wave_baseline_1', 'wave_th_resp_1', 'wave_pt_resp_1', 'wave_shared_resp_1', 'wave_baseline_2', 'wave_th_resp_2', 'wave_pt_resp_2', 'wave_shared_resp_2', 'wave_baseline_3', 'wave_th_resp_3', 'wave_pt_resp_3', 'wave_shared_resp_3', 'wave_baseline_4', 'wave_th_resp_4', 'wave_pt_resp_4', 'wave_shared_resp_4', 'wave_baseline_5', 'wave_th_resp_5', 'wave_pt_resp_5', 'wave_shared_resp_5', 'wave_baseline_6', 'wave_th_resp_6', 'wave_pt_resp_6', 'wave_shared_resp_6', 'wave_baseline_7', 'wave_th_resp_7', 'wave_pt_resp_7', 'wave_shared_resp_7', 'wave_baseline_8', 'wave_th_resp_8', 'wave_pt_resp_8', 'wave_shared_resp_8', 'wave_baseline_9', 'wave_th_resp_9', 'wave_pt_resp_9', 'wave_shared_resp_9', 'wave_baseline_10', 'wave_th_resp_10', 'wave_pt_resp_10', 'wave_shared_resp_10', 'wave_baseline_11', 'wave_th_resp_11', 'wave_pt_resp_11', 'wave_shared_resp_11', 'wave_baseline_12', 'wave_th_resp_12', 'wave_pt_resp_12', 'wave_shared_resp_12'])\n",
    "\n",
    "\n",
    "ora, il modo in cui si identifica un certo soggetto (ossia la chiavi di \"primo ordine\" che indentificano il soggetto, ossia ad esempio 'th_1'), dipenderebbe dal numero stringa che c'è alla fine di ogni nome stringa di ogni chiave dentro \"new_single_th_all_extracted_reconstructions\", mi spiego:\n",
    "\n",
    "il codice dovrebbe capire che, ad esempio, solo l'ultima carattere stringa di queste prime 4 chiavi:\n",
    "\n",
    "'wave_baseline_1', 'wave_th_resp_1', 'wave_pt_resp_1', 'wave_shared_resp_1', \n",
    "\n",
    "si riferisca al soggetto 1, ossia al futuro \"th_1\"...\n",
    "\n",
    "\n",
    "per il soggetto 2, sarebbero: \n",
    "\n",
    "'wave_th_resp_2', 'wave_pt_resp_2', 'wave_shared_resp_2', e così via per gli altri soggetti..\n",
    "\n",
    "\n",
    "Facendo attenzione al fatto che, dopo il soggetto 9, ovviamente, si passerà alle decine (a livello numerico), per cui saranno gli ultime due caratteri da considerare per l'identificazione delle sue rispettive chiavi, che in quel caso saranno per il soggetto 10, ossia il futuro th_10\n",
    "\n",
    "'wave_baseline_10', 'wave_th_resp_10', 'wave_pt_resp_10', 'wave_shared_resp_10',\n",
    "\n",
    "Inoltre, poi, per creare le variabili associate alle coppie di dati e labels delle relative condizioni sperimentali, dovrà il codice far in modo che il nome di quella variabile dipenda dalle stringhe sempre che si riferiscono al nome delle due chiavi di \"new_single_th_all_extracted_reconstructions\" da cui preleva i dati e le labels... \n",
    "\n",
    "ad esempio, se deve creare la variabile dei dati 'baseline_vs_th_resp\" del primo soggetto, le chiavi rispettive da cui deve andare a prelevare le stringhe saranno appunto \"'wave_baseline_1'\" e \"'wave_th_resp_1'\"....\n",
    "\n",
    "diciamo che si potrebbe creare una lista di stringhe che sarà del tipo:\n",
    "\n",
    "experimental_conditions = ['baseline', 'th_resp', 'pt_resp', 'shared_resp'], per vedere se una di queste sia dentro la rispettiva chiave di  new_single_th_all_extracted_reconstructions su cui sta iterando, che nel nostro caso di esempio sarebbero sempre\n",
    "\n",
    "'wave_baseline_1' (e da cui vede che c'è la stinga 'baseline')\n",
    "'wave_th_resp_1' (e da cui vede che c'è la stinga 'th_resp')\n",
    "\n",
    "è chiaro?\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "In sostanza, desideri un modo per inferire dinamicamente il nome del soggetto e delle variabili che conterranno i dati e le etichette per ogni combinazione di condizioni, a partire dal nome delle chiavi di new_single_th_all_extracted_reconstructions. Ecco un piano per raggiungere questo obiettivo:\n",
    "\n",
    "Passaggi:\n",
    "\n",
    "- Identificare il soggetto:\n",
    "\n",
    "Le chiavi di new_single_th_all_extracted_reconstructions finiscono con un numero che identifica il soggetto (es. wave_baseline_1, wave_th_resp_1, wave_pt_resp_1).\n",
    "Questo numero può essere estratto dalle ultime cifre della chiave (ad esempio, 1 da wave_baseline_1).\n",
    "La variabile associata a ciascun soggetto sarà chiamata th_X, dove X è il numero del soggetto.\n",
    "\n",
    "- Generare dinamicamente il nome delle variabili:\n",
    "\n",
    "A partire dai nomi delle chiavi, possiamo inferire quale combinazione di condizioni sperimentali stiamo trattando (es. baseline_vs_th_resp).\n",
    "Creeremo una lista delle condizioni (experimental_conditions = ['baseline', 'th_resp', 'pt_resp', 'shared_resp']), quindi esamineremo le chiavi per determinare quali condizioni sono presenti.\n",
    "\n",
    "- Creare il dizionario:\n",
    "\n",
    "A ciascun soggetto verrà associato un dizionario, e per ogni combinazione di condizioni sperimentali, assoceremo i dati e le etichette in una chiave che seguirà la convenzione del tipo baseline_vs_th_resp.\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "Spiegazione:\n",
    "\n",
    "1) Estrazione delle condizioni e soggetto:\n",
    "\n",
    "La chiave, ad esempio wave_baseline_1, viene separata in parti. La parte baseline viene estratta per determinare la condizione, mentre 1 indica il numero del soggetto.\n",
    "Queste informazioni vengono utilizzate per creare il nome del soggetto, th_1.\n",
    "\n",
    "2) Combinazioni di condizioni:\n",
    "\n",
    "La lista experimental_conditions contiene le 4 condizioni: baseline, th_resp, pt_resp, shared_resp.\n",
    "Per ogni soggetto, controlliamo quali condizioni sono disponibili nella chiave (ad esempio, se il soggetto 1 ha wave_baseline_1 e wave_th_resp_1, creiamo la combinazione baseline_vs_th_resp).\n",
    "\n",
    "3) Creazione dinamica delle variabili:\n",
    "\n",
    "Utilizziamo la combinazione di condizioni per generare la chiave della variabile (baseline_vs_th_resp).\n",
    "I dati e le etichette per la combinazione di condizioni vengono estratti e concatenati.\n",
    "\n",
    "\n",
    "4) Risultato finale:\n",
    "\n",
    "La struttura finale del dizionario new_subject_level_concatenations avrà una chiave per ciascun soggetto (th_1, th_2, ecc.), e sotto ogni soggetto ci saranno le combinazioni di condizioni per ciascun livello di ricostruzione (theta, delta, theta_strict), con i dati e le etichette corrispondenti.\n",
    "\n",
    "<br>\n",
    "\n",
    "Esempio di output:\n",
    "\n",
    "    {\n",
    "        'th_1': {\n",
    "            'theta': {\n",
    "                'baseline_vs_th_resp': {'data': np.array([...]), 'labels': np.array([...])},\n",
    "                'baseline_vs_pt_resp': {'data': np.array([...]), 'labels': np.array([...])},\n",
    "                'baseline_vs_shared_resp': {'data': np.array([...]), 'labels': np.array([...])},\n",
    "                'th_resp_vs_pt_resp': {'data': np.array([...]), 'labels': np.array([...])},\n",
    "                # Altre combinazioni...\n",
    "            },\n",
    "            'delta': {\n",
    "                # Stessa struttura per 'delta'\n",
    "            },\n",
    "            'theta_strict': {\n",
    "                # Stessa struttura per 'theta_strict'\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    " \n",
    "Questa struttura ti permetterà di avere un'organizzazione chiara e dinamica dei dati per ogni soggetto e combinazione di condizioni sperimentali.\n",
    " \n",
    " \n",
    "<br>\n",
    "\n",
    "**SOTTO-STEP 2: IDENTIFICAZIONE DELLE STRINGA ALFABETICHE PER LA CREAZIONE DELLE VARIABILI - FUTURE CHIAVI - CHE CONTENGONO IL NOME DELLE DUE COPPIE DI CONDIZIONI SPERIMENTALI DI CUI VENGONO PRELEVATI I DATI E LABELS CONCATENATI E CHE VENGONON CONSIDERATE NEL CICLO CORRENTE DEL LOOP**\n",
    "\n",
    "\n",
    "ok, ora c'è una ultima cosa che mi manca da dirti, che è relativa alla ri-assegnazione del codice numerico associato ad ogni coppia di condizioni sperimentali...\n",
    "\n",
    "nel senso che, originariamente...\n",
    "\n",
    "new_single_th_all_extracted_reconstructions ha queste labels, che se io le vedo avrò \n",
    "\n",
    "per baseline una serie di 0, per th_resp una serie di 1, per pt_resp, una serie di 2 e per shared_resp una serie di 3, in questo modo\n",
    "\n",
    "\n",
    "print(f\"Baseline in TH_1:, {np.unique(new_single_th_all_extracted_reconstructions['wave_baseline_1']['labels'], return_counts = True)}\\n\")\n",
    "print(f\"Th_Resp in TH_1:, {np.unique(new_single_th_all_extracted_reconstructions['wave_th_resp_1']['labels'], return_counts = True)}\\n\")\n",
    "print(f\"Pt_Resp in TH_1:, {np.unique(new_single_th_all_extracted_reconstructions['wave_pt_resp_1']['labels'], return_counts = True)}\\n\")\n",
    "print(f\"Shared_Resp in TH_1:, {np.unique(new_single_th_all_extracted_reconstructions['wave_shared_resp_1']['labels'], return_counts = True)}\\n\")\n",
    "\n",
    "\n",
    "Baseline in TH_1:, (array(['0'], dtype='<U1'), array([51]))\n",
    "\n",
    "Th_Resp in TH_1:, (array(['1'], dtype='<U1'), array([40]))\n",
    "\n",
    "Pt_Resp in TH_1:, (array(['2'], dtype='<U1'), array([40]))\n",
    "\n",
    "Shared_Resp in TH_1:, (array(['3'], dtype='<U1'), array([56]))\n",
    "\n",
    "di conseguenza,  nel tuo codice, ho bisogno che \n",
    "\n",
    "le labels associate a 'cond_1' (quando crei la relativa variabile delle due condizioni sperimentali di cui vengono concatenati i dati e le labels) siano riconvertite sempre in '0', mentre \n",
    "\n",
    "le labels associate a 'cond_2' (quando crei la relativa variabile delle due condizioni sperimentali di cui vengono concatenati i dati e le labels) siano riconvertite sempre in '1'\n",
    "\n",
    "questo aspetto è importante, per quando crei le variabili che conterranno le coppie di dati condizioni sperimentali...\n",
    "\n",
    "ora, nel caso in cui tu stia considerando magari baseline vs le altre condizioni sperimentali, è chiaro che in quel caso specifico, ad esempio, baseline sarà sempre la stringa associata a 'cond_1' e quindi in quel caso sarà sempre 0, e quindi sarebbe apposto..\n",
    "\n",
    "ma per gli altri casi di confronto di baseline rispetto alle altre 3 condizioni sperimentali, è chiaro che se sarà th_resp la condizione di confronto, allora in quel caso di quella specifica variabile, le labels non avranno bisogno di esser diciamo 'ri-convertite' perché già naturalmente diciamo baseline avrà le labels '0' e  e th_resp avrà già '1' (come è già originariamente codificato in 'new_subject_level_concatenations'!)\n",
    "\n",
    "ma nel caso delle altre variabili da creare le labels andranno ovviamente riconvertite! Perché?\n",
    "perché ovviamente nel caso sia la th_resp la 'cond_1', ad esempip, in quel caso, le sue labels (che son  originariamente codificate come '1' in 'new_subject_level_concatenations'!) diveteranno '0', mentre le altre condizioni di confronto, una alla volta, diventeranno '1' invece...\n",
    "\n",
    "\n",
    "è chiara diciamo la logica di ri-assegnazione delle relative labels in sostanza?\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "La **logica di ri-assegnazione delle etichette (labels)** è chiara e posso integrarla nel codice. \n",
    "\n",
    "La logica che stai descrivendo consiste essenzialmente nel **garantire che, quando crei una variabile che contiene dati e etichette per due condizioni sperimentali, le etichette siano sempre \"0\" per la prima condizione (cond_1) e \"1\" per la seconda condizione (cond_2)**, \n",
    "\n",
    "                **INDIPENDENTEMENTE** da come sono originariamente codificate in **\"new_single_th_all_extracted_reconstructions\"!\n",
    "                \n",
    "                \n",
    "\n",
    "Ecco come possiamo procedere:\n",
    "\n",
    "- Identificazione delle condizioni: Come hai descritto, determineremo le due condizioni sperimentali da confrontare, ad esempio \"baseline\" contro \"th_resp\", \"baseline\" contro \"pt_resp\", ecc.\n",
    "\n",
    "- Riconversione delle etichette:\n",
    "\n",
    " - Se la condizione di confronto è \"baseline\" (che è associata a 0), non dobbiamo modificare le etichette.\n",
    " - Se la condizione di confronto non è \"baseline\", dovremo riconvertire le etichette di quella condizione a 0 e le etichette della condizione di confronto a 1.\n",
    "\n",
    "- Struttura del codice: Durante la creazione delle variabili, dovremo controllare quale condizione è la prima (cond_1) e quale è la seconda (cond_2), e applicare questa logica per ri-assegnare le etichette di conseguenza.\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "Inoltre\n",
    "\n",
    "\n",
    "dentro \n",
    "\n",
    "\"# Crea tutte le combinazioni uniche di condizioni sperimentali (es. 'baseline vs th_resp')\n",
    "    condition_pairs = list(itertools.combinations(experimental_conditions, 2))\n",
    "\"\n",
    "\n",
    "Effettivamente vengono create delle tuple di coppie di stringhe che corrispondono a quelle con cui dovrebbero esser create le sotto-sotto-chiavi delle coppie di condizioni sperimentali..\n",
    "\n",
    "tuttavia, è giusto che iteri rispetto a 'condition_pairs', ma deve inserire un qualche controllo anche rispetto a questa cosa:\n",
    "\n",
    "originariamente...\n",
    "\n",
    "new_single_th_all_extracted_reconstructions ha queste labels, che se io le vedo avrò\n",
    "\n",
    "per baseline una serie di 0, per th_resp una serie di 1, per pt_resp, una serie di 2 e per shared_resp una serie di 3, in questo modo\n",
    "\n",
    "print(f\"Baseline in TH_1:, {np.unique(new_single_th_all_extracted_reconstructions['wave_baseline_1']['labels'], return_counts = True)}\\n\") print(f\"Th_Resp in TH_1:, {np.unique(new_single_th_all_extracted_reconstructions['wave_th_resp_1']['labels'], return_counts = True)}\\n\") print(f\"Pt_Resp in TH_1:, {np.unique(new_single_th_all_extracted_reconstructions['wave_pt_resp_1']['labels'], return_counts = True)}\\n\") print(f\"Shared_Resp in TH_1:, {np.unique(new_single_th_all_extracted_reconstructions['wave_shared_resp_1']['labels'], return_counts = True)}\\n\")\n",
    "\n",
    "Baseline in TH_1:, (array(['0'], dtype='<U1'), array([51]))\n",
    "\n",
    "Th_Resp in TH_1:, (array(['1'], dtype='<U1'), array([40]))\n",
    "\n",
    "Pt_Resp in TH_1:, (array(['2'], dtype='<U1'), array([40]))\n",
    "\n",
    "Shared_Resp in TH_1:, (array(['3'], dtype='<U1'), array([56]))\n",
    "\n",
    "di conseguenza, nel tuo codice, ho bisogno che\n",
    "\n",
    "le labels associate a 'cond_1' (quando crei la relativa variabile delle due condizioni sperimentali di cui vengono concatenati i dati e le labels) siano riconvertite sempre in '0', mentre\n",
    "\n",
    "le labels associate a 'cond_2' (quando crei la relativa variabile delle due condizioni sperimentali di cui vengono concatenati i dati e le labels) siano riconvertite sempre in '1'\n",
    "\n",
    "questo aspetto è importante, per quando crei le variabili che conterranno le coppie di dati condizioni sperimentali...\n",
    "\n",
    "ora, nel caso in cui tu stia considerando magari baseline vs le altre condizioni sperimentali, che nel caso di \"condition_pairs\" dovrebbe corrispondere ai primi 3 elementi della sua lista no, perché sarebbero \n",
    "\n",
    "[('baseline', 'th_resp'), \n",
    "    ('baseline', 'pt_resp'), \n",
    "    ('baseline', 'shared_resp'), \n",
    "\n",
    "è chiaro che in quel caso specifico, ad esempio, baseline sarà sempre la stringa associata a 'cond_1' e quindi in quel caso sarà sempre 0, e quindi sarebbe apposto..\n",
    "\n",
    "ma per gli altri casi di confronto di baseline rispetto alle altre 3 condizioni sperimentali, è chiaro che se sarà th_resp la condizione di confronto, allora in quel caso di quella specifica variabile, le labels non avranno bisogno di esser diciamo 'ri-convertite' perché già naturalmente diciamo baseline avrà le labels '0' e e th_resp avrà già '1' (come è già originariamente codificato in 'new_subject_level_concatenations'!)\n",
    "\n",
    "ma nel caso delle altre variabili da creare, che fa riferimento a questi altri elementi di \n",
    "\"condition_pairs\" che è creato nel loop ossia\n",
    "\n",
    "('th_resp', 'pt_resp'), \n",
    "('th_resp', 'shared_resp'), \n",
    "('pt_resp', 'shared_resp')]\n",
    "\n",
    "le labels andranno ovviamente riconvertite! Perché? \n",
    "\n",
    "Perché ovviamente nel caso sia la th_resp la 'cond_1', ad esempio, in quel caso, le sue labels (che son originariamente codificate come '1' in 'new_subject_level_concatenations'!) diventeranno '0',\n",
    "\n",
    "mentre le altre condizioni di confronto, una alla volta, diventeranno '1' invece...\n",
    "\n",
    "è chiara diciamo la logica di ri-assegnazione delle relative labels in sostanza?dentro \"# Crea tutte le combinazioni uniche di condizioni sperimentali (es. 'baseline vs th_resp')\n",
    "    condition_pairs = list(itertools.combinations(experimental_conditions, 2))\n",
    "    \"\n",
    "\n",
    "effettivamente vengono create delle tuple di coppie di stringhe che corrispondono a quelle con cui dovrebbero esser create le sotto-sotto-chiavi delle coppie di condizioni sperimentali..\n",
    "\n",
    "tuttavia, è giusto che iteri rispetto a 'condition_pairs', ma deve inserire un qualche controllo anche rispetto a questa cosa:\n",
    "\n",
    "originariamente...\n",
    "\n",
    "new_single_th_all_extracted_reconstructions ha queste labels, che se io le vedo avrò\n",
    "\n",
    "per baseline una serie di 0, per th_resp una serie di 1, per pt_resp, una serie di 2 e per shared_resp una serie di 3, in questo modo\n",
    "\n",
    "print(f\"Baseline in TH_1:, {np.unique(new_single_th_all_extracted_reconstructions['wave_baseline_1']['labels'], return_counts = True)}\\n\") print(f\"Th_Resp in TH_1:, {np.unique(new_single_th_all_extracted_reconstructions['wave_th_resp_1']['labels'], return_counts = True)}\\n\") print(f\"Pt_Resp in TH_1:, {np.unique(new_single_th_all_extracted_reconstructions['wave_pt_resp_1']['labels'], return_counts = True)}\\n\") print(f\"Shared_Resp in TH_1:, {np.unique(new_single_th_all_extracted_reconstructions['wave_shared_resp_1']['labels'], return_counts = True)}\\n\")\n",
    "\n",
    "Baseline in TH_1:, (array(['0'], dtype='<U1'), array([51]))\n",
    "\n",
    "Th_Resp in TH_1:, (array(['1'], dtype='<U1'), array([40]))\n",
    "\n",
    "Pt_Resp in TH_1:, (array(['2'], dtype='<U1'), array([40]))\n",
    "\n",
    "Shared_Resp in TH_1:, (array(['3'], dtype='<U1'), array([56]))\n",
    "\n",
    "di conseguenza, nel tuo codice, ho bisogno che\n",
    "\n",
    "le labels associate a 'cond_1' (quando crei la relativa variabile delle due condizioni sperimentali di cui vengono concatenati i dati e le labels) siano riconvertite sempre in '0', mentre\n",
    "\n",
    "le labels associate a 'cond_2' (quando crei la relativa variabile delle due condizioni sperimentali di cui vengono concatenati i dati e le labels) siano riconvertite sempre in '1'\n",
    "\n",
    "questo aspetto è importante, per quando crei le variabili che conterranno le coppie di dati condizioni sperimentali...\n",
    "\n",
    "ora, nel caso in cui tu stia considerando magari baseline vs le altre condizioni sperimentali, che nel caso di \"condition_pairs\" dovrebbe corrispondere ai primi 3 elementi della sua lista no, perché sarebbero \n",
    "\n",
    "[('baseline', 'th_resp'), \n",
    "    ('baseline', 'pt_resp'), \n",
    "    ('baseline', 'shared_resp'), \n",
    "\n",
    "è chiaro che in quel caso specifico, ad esempio, baseline sarà sempre la stringa associata a 'cond_1' e quindi in quel caso sarà sempre 0, e quindi sarebbe apposto..\n",
    "\n",
    "ma per gli altri casi di confronto di baseline rispetto alle altre 3 condizioni sperimentali, è chiaro che se sarà th_resp la condizione di confronto, allora in quel caso di quella specifica variabile, le labels non avranno bisogno di esser diciamo 'ri-convertite' perché già naturalmente diciamo baseline avrà le labels '0' e e th_resp avrà già '1' (come è già originariamente codificato in 'new_subject_level_concatenations'!)\n",
    "\n",
    "ma nel caso delle altre variabili da creare, che fa riferimento a questi altri elementi di \n",
    "\"condition_pairs\" che è creato nel loop ossia\n",
    "\n",
    "('th_resp', 'pt_resp'), \n",
    "('th_resp', 'shared_resp'), \n",
    "('pt_resp', 'shared_resp')]\n",
    "\n",
    "le labels andranno ovviamente riconvertite! Perché? \n",
    "\n",
    "Perché ovviamente nel caso sia la th_resp la 'cond_1', ad esempio, in quel caso, le sue labels (che son originariamente codificate come '1' in 'new_subject_level_concatenations'!) diventeranno '0',\n",
    "\n",
    "mentre le altre condizioni di confronto, una alla volta, diventeranno '1' invece...\n",
    "\n",
    "è chiara diciamo la logica di ri-assegnazione delle relative labels in sostanza?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416c06aa-eae9-474e-885a-286de23d34c8",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Implementazione STEP - Concatenazione All Single Subject Spectrograms (TH) across Couples of Experimental Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6268314b-b5b5-41cf-9d8b-caa88dfa2dbe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_single_th_all_extracted_spectrograms_2D_task_1.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bd8ee1-2651-43a7-a1c1-0afeb64b8084",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_single_th_all_extracted_spectrograms_2D_task_1['spectrograms_rest_100'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64eed481-ee6d-4b72-81e4-024eb335f076",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(new_single_th_all_extracted_spectrograms_2D_task_1['spectrograms_rest_100'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05dfb0b-cfdf-4c26-b06a-2f877e1f5732",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Rest in TH_1:, {np.unique(new_single_th_all_extracted_spectrograms_2D_task_1['spectrograms_rest_100']['labels'], return_counts = True)}\\n\")\n",
    "print(f\"Left_Fist in TH_1:, {np.unique(new_single_th_all_extracted_spectrograms_2D_task_1['spectrograms_left_fist_100']['labels'], return_counts = True)}\\n\")\n",
    "print(f\"Right_Fist in TH_1:, {np.unique(new_single_th_all_extracted_spectrograms_2D_task_1['spectrograms_right_fist_100']['labels'], return_counts = True)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0637fd0e-a5df-408e-9275-7c050db8fdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_single_th_all_extracted_spectrograms_2D_task_1['spectrograms_rest_100'].keys()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "20a0ce31-faab-4f14-860b-6e91e0800088",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "source": [
    "'''CODE IMPLEMENTATION - DESCRIZIONE'''\n",
    "\n",
    "# Lista delle stringhe alfabetiche delle condizioni sperimentali,\n",
    "# da controllare dentro \"new_single_th_all_extracted_reconstructions\", che ha queste chiavi\n",
    "\n",
    "#dict_keys(['wave_baseline_1', 'wave_th_resp_1', 'wave_pt_resp_1', 'wave_shared_resp_1', \n",
    "#'wave_baseline_2', 'wave_th_resp_2', 'wave_pt_resp_2', 'wave_shared_resp_2', \n",
    "#'wave_baseline_3', 'wave_th_resp_3', 'wave_pt_resp_3', 'wave_shared_resp_3', \n",
    "#'wave_baseline_4', 'wave_th_resp_4', 'wave_pt_resp_4', 'wave_shared_resp_4',\n",
    "#'wave_baseline_5', 'wave_th_resp_5', 'wave_pt_resp_5', 'wave_shared_resp_5',\n",
    "#'wave_baseline_6', 'wave_th_resp_6', 'wave_pt_resp_6', 'wave_shared_resp_6',\n",
    "#'wave_baseline_7', 'wave_th_resp_7', 'wave_pt_resp_7', 'wave_shared_resp_7',\n",
    "#'wave_baseline_8', 'wave_th_resp_8', 'wave_pt_resp_8', 'wave_shared_resp_8',\n",
    "#'wave_baseline_9', 'wave_th_resp_9', 'wave_pt_resp_9', 'wave_shared_resp_9',\n",
    "#'wave_baseline_10', 'wave_th_resp_10', 'wave_pt_resp_10', 'wave_shared_resp_10',\n",
    "#'wave_baseline_11', 'wave_th_resp_11', 'wave_pt_resp_11', 'wave_shared_resp_11',\n",
    "#'wave_baseline_12', 'wave_th_resp_12', 'wave_pt_resp_12', 'wave_shared_resp_12'])\n",
    "#\n",
    "\n",
    "import itertools\n",
    "import numpy as np\n",
    "\n",
    "experimental_conditions = ['baseline', 'th_resp', 'pt_resp', 'shared_resp']\n",
    "\n",
    "# Nuova variabile per memorizzare i risultati di dati e labels concatenati di coppie di condizioni sperimentali\n",
    "new_subject_level_concatenations_coupled_exp_th = {}\n",
    "\n",
    "# Loop su tutte le chiavi del dizionario iniziale\n",
    "for key in new_single_th_all_extracted_reconstructions.keys():\n",
    "    \n",
    "    '''\n",
    "    Identificazione dinamica delle stringhe numeriche per creare \n",
    "    le chiavi e i nomi delle variabili delle coppie di condizioni sperimentali\n",
    "       \n",
    "    Gestione della stringa numerica che rappresenta un soggetto identificato con ANCHE decine (due cifre):\n",
    "    Aggiunta di una logica che riconosca identificatori numerici di ANCHE due cifre e li gestisca correttamente\n",
    "    '''\n",
    "    \n",
    "    # Identifica il numero del soggetto, considerando sia una cifra che due cifre\n",
    "    \n",
    "    '''\n",
    "    Spiegazione \n",
    "    \n",
    "    1) Gestione delle stringhe numeriche: La logica per estrarre il numero del soggetto usa key.split('_') \n",
    "    per individuare l'ultima parte della chiave\n",
    "    \n",
    "    2) Si verifica se questa parte è composta esclusivamente da cifre con .isdigit()\n",
    "    Questo gestisce sia numeri a una cifra (es. '1') che a due cifre (es. '12')\n",
    "    \n",
    "    '''\n",
    "    key_parts = key.split('_')\n",
    "    subject_number = key_parts[-1] if key_parts[-1].isdigit() else None  # Verifica se è numerico\n",
    "    \n",
    "    # Verifica che il numero del soggetto sia valido\n",
    "    if subject_number is None:\n",
    "        continue  # Salta chiavi non valide\n",
    "    \n",
    "    subject_key = f\"th_{subject_number}\"  # Es. 'th_1' o 'th_12'\n",
    "    \n",
    "    # Inizializza il dizionario per il soggetto se non esiste\n",
    "    \n",
    "    #'''Nuova variabile per appendere i dati e labels concatenati di coppie di condizioni sperimentali:\n",
    "\n",
    "    #I risultati vengono salvati in una nuova variabile denominata \"new_subject_level_concatenations_coupled_exp_th\",\n",
    "    #dove la struttura è analoga a quella precedente, ma separata per scopi distinti.\n",
    "    #'''\n",
    "    \n",
    "    if subject_key not in new_subject_level_concatenations_coupled_exp_th:\n",
    "        new_subject_level_concatenations_coupled_exp_th[subject_key] = {'theta': {}, 'delta': {}, 'theta_strict': {}}\n",
    "    \n",
    "    '''\n",
    "    Qui, creo tutte le combinazioni possibili di coppie di condizioni sperimentali \n",
    "    \n",
    "    In questo caso, applico le regole del calcolo combinatorio, per il quale se hai 4 condizioni,\n",
    "    il numero di combinazioni di coppie di condizioni (senza ripetizioni) si calcola come:\n",
    "    \n",
    "    $$\n",
    "    \\binom{4}{2} = \\frac{4!}{2!(4-2)!} = 6\n",
    "    $$\n",
    "\n",
    "    Quindi, con 4 condizioni sperimentali, le combinazioni di coppie di condizioni saranno 6, e queste coppie sono:\n",
    "\n",
    "    (condizione 1, condizione 2) = 'baseline vs th_resp'\n",
    "    (condizione 1, condizione 3) = 'baseline vs pt_resp'\n",
    "    (condizione 1, condizione 4) = 'baseline vs shared_resp'\n",
    "    (condizione 2, condizione 3) = 'th_resp vs pt_resp'\n",
    "    (condizione 2, condizione 4) = 'th_resp vs shared_resp'\n",
    "    (condizione 3, condizione 4) = 'pt_resp vs shared_resp' \n",
    "\n",
    "    '''\n",
    "    \n",
    "     # Crea tutte le combinazioni uniche di condizioni sperimentali (es. 'baseline vs th_resp')\n",
    "    condition_pairs = list(itertools.combinations(experimental_conditions, 2))\n",
    "    \n",
    "    #print(f\"Condition Pairs are: {condition_pairs}\")\n",
    "    #Condition Pairs are: [('baseline', 'th_resp'), \n",
    "    #('baseline', 'pt_resp'), \n",
    "    #('baseline', 'shared_resp'), \n",
    "    #('th_resp', 'pt_resp'), \n",
    "    #('th_resp', 'shared_resp'), \n",
    "    #('pt_resp', 'shared_resp')]\n",
    "\n",
    "    \n",
    "    # Loop sulle combinazioni\n",
    "    for cond_1, cond_2 in condition_pairs:\n",
    "        \n",
    "            # Crea il nome della variabile per la combinazione\n",
    "            condition_pair_key = f\"{cond_1}_vs_{cond_2}\"\n",
    "            \n",
    "            # Ottieni i dati e le etichette delle due condizioni per ogni livello\n",
    "            for level in ['theta', 'delta', 'theta_strict']:\n",
    "                \n",
    "                # Ottieni i dati e le etichette delle due condizioni\n",
    "                data_cond_1 = new_single_th_all_extracted_reconstructions.get(f\"wave_{cond_1}_{subject_number}\", {}).get(level)\n",
    "                print(f\"data_cond_1 is {cond_1}\\n\")\n",
    "                labels_cond_1 = new_single_th_all_extracted_reconstructions.get(f\"wave_{cond_1}_{subject_number}\", {}).get('labels')\n",
    "                #print(f\"data_cond_1 is {current_condition}\\n\"\n",
    "\n",
    "                data_cond_2 = new_single_th_all_extracted_reconstructions.get(f\"wave_{cond_2}_{subject_number}\", {}).get(level)\n",
    "                print(f\"data_cond_2 is {cond_2}\\n\")\n",
    "                labels_cond_2 = new_single_th_all_extracted_reconstructions.get(f\"wave_{cond_2}_{subject_number}\", {}).get('labels')\n",
    "\n",
    "                # Verifica che i dati siano validi\n",
    "                if data_cond_1 is None or labels_cond_1 is None or data_cond_2 is None or labels_cond_2 is None:\n",
    "                    continue  # Salta combinazioni incomplete\n",
    "\n",
    "                # Riassegna le etichette per garantire che \"cond_1\" = 0 e \"cond_2\" = 1\n",
    "                labels_cond_1 = np.zeros_like(labels_cond_1)  # Tutte 0\n",
    "                labels_cond_2 = np.ones_like(labels_cond_2)   # Tutte 1\n",
    "\n",
    "                # Concatenazione dei dati e delle etichette\n",
    "                concatenated_data = np.vstack((data_cond_1, data_cond_2))\n",
    "                concatenated_labels = np.hstack((labels_cond_1, labels_cond_2))\n",
    "\n",
    "                # Salva i risultati nella struttura\n",
    "                new_subject_level_concatenations_coupled_exp_th[subject_key][level][condition_pair_key] = {\n",
    "                   'data': concatenated_data,\n",
    "                   'labels': concatenated_labels}\n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "id": "87a4a68a-12ea-4ecd-99b7-3a30e9c44edd",
   "metadata": {
    "tags": []
   },
   "source": [
    "'''CODE IMPLEMENTATION - PRACTICAL CODE VERSION 1 - SENZA CONSIDERAZIONE DI CHIAVE 'COEFF_FIFTH_DETAIL_THETA'''\n",
    "\n",
    "# Lista delle stringhe alfabetiche delle condizioni sperimentali,\n",
    "# da controllare dentro \"new_single_th_all_extracted_reconstructions\", che ha queste chiavi\n",
    "\n",
    "#dict_keys(['wave_baseline_1', 'wave_th_resp_1', 'wave_pt_resp_1', 'wave_shared_resp_1', \n",
    "#'wave_baseline_2', 'wave_th_resp_2', 'wave_pt_resp_2', 'wave_shared_resp_2', \n",
    "#'wave_baseline_3', 'wave_th_resp_3', 'wave_pt_resp_3', 'wave_shared_resp_3', \n",
    "#'wave_baseline_4', 'wave_th_resp_4', 'wave_pt_resp_4', 'wave_shared_resp_4',\n",
    "#'wave_baseline_5', 'wave_th_resp_5', 'wave_pt_resp_5', 'wave_shared_resp_5',\n",
    "#'wave_baseline_6', 'wave_th_resp_6', 'wave_pt_resp_6', 'wave_shared_resp_6',\n",
    "#'wave_baseline_7', 'wave_th_resp_7', 'wave_pt_resp_7', 'wave_shared_resp_7',\n",
    "#'wave_baseline_8', 'wave_th_resp_8', 'wave_pt_resp_8', 'wave_shared_resp_8',\n",
    "#'wave_baseline_9', 'wave_th_resp_9', 'wave_pt_resp_9', 'wave_shared_resp_9',\n",
    "#'wave_baseline_10', 'wave_th_resp_10', 'wave_pt_resp_10', 'wave_shared_resp_10',\n",
    "#'wave_baseline_11', 'wave_th_resp_11', 'wave_pt_resp_11', 'wave_shared_resp_11',\n",
    "#'wave_baseline_12', 'wave_th_resp_12', 'wave_pt_resp_12', 'wave_shared_resp_12'])\n",
    "#\n",
    "\n",
    "import itertools\n",
    "import numpy as np\n",
    "\n",
    "experimental_conditions = ['baseline', 'th_resp', 'pt_resp', 'shared_resp']\n",
    "\n",
    "# Nuova variabile per memorizzare i risultati di dati e labels concatenati di coppie di condizioni sperimentali\n",
    "new_subject_level_concatenations_coupled_exp_th = {}\n",
    "\n",
    "# Loop su tutte le chiavi del dizionario iniziale\n",
    "for key in new_single_th_all_extracted_reconstructions.keys():\n",
    "    \n",
    "    '''\n",
    "    Identificazione dinamica delle stringhe numeriche per creare \n",
    "    le chiavi e i nomi delle variabili delle coppie di condizioni sperimentali\n",
    "       \n",
    "    Gestione della stringa numerica che rappresenta un soggetto identificato con ANCHE decine (due cifre):\n",
    "    Aggiunta di una logica che riconosca identificatori numerici di ANCHE due cifre e li gestisca correttamente\n",
    "    '''\n",
    "    \n",
    "    # Identifica il numero del soggetto, considerando sia una cifra che due cifre\n",
    "    \n",
    "    '''\n",
    "    Spiegazione \n",
    "    \n",
    "    1) Gestione delle stringhe numeriche: La logica per estrarre il numero del soggetto usa key.split('_') \n",
    "    per individuare l'ultima parte della chiave\n",
    "    \n",
    "    2) Si verifica se questa parte è composta esclusivamente da cifre con .isdigit()\n",
    "    Questo gestisce sia numeri a una cifra (es. '1') che a due cifre (es. '12')\n",
    "    \n",
    "    '''\n",
    "    key_parts = key.split('_')\n",
    "    subject_number = key_parts[-1] if key_parts[-1].isdigit() else None  # Verifica se è numerico\n",
    "    \n",
    "    # Verifica che il numero del soggetto sia valido\n",
    "    if subject_number is None:\n",
    "        continue  # Salta chiavi non valide\n",
    "    \n",
    "    subject_key = f\"th_{subject_number}\"  # Es. 'th_1' o 'th_12'\n",
    "    \n",
    "    # Inizializza il dizionario per il soggetto se non esiste\n",
    "    \n",
    "    #'''Nuova variabile per appendere i dati e labels concatenati di coppie di condizioni sperimentali:\n",
    "\n",
    "    #I risultati vengono salvati in una nuova variabile denominata \"new_subject_level_concatenations_coupled_exp_th\",\n",
    "    #dove la struttura è analoga a quella precedente, ma separata per scopi distinti.\n",
    "    #'''\n",
    "    \n",
    "    if subject_key not in new_subject_level_concatenations_coupled_exp_th:\n",
    "        new_subject_level_concatenations_coupled_exp_th[subject_key] = {'theta': {}, 'delta': {}, 'coeff_fifth_detail_theta': {}}\n",
    "    \n",
    "    '''\n",
    "    Qui, creo tutte le combinazioni possibili di coppie di condizioni sperimentali \n",
    "    \n",
    "    In questo caso, applico le regole del calcolo combinatorio, per il quale se hai 4 condizioni,\n",
    "    il numero di combinazioni di coppie di condizioni (senza ripetizioni) si calcola come:\n",
    "    \n",
    "    $$\n",
    "    \\binom{4}{2} = \\frac{4!}{2!(4-2)!} = 6\n",
    "    $$\n",
    "\n",
    "    Quindi, con 4 condizioni sperimentali, le combinazioni di coppie di condizioni saranno 6, e queste coppie sono:\n",
    "\n",
    "    (condizione 1, condizione 2) = 'baseline vs th_resp'\n",
    "    (condizione 1, condizione 3) = 'baseline vs pt_resp'\n",
    "    (condizione 1, condizione 4) = 'baseline vs shared_resp'\n",
    "    (condizione 2, condizione 3) = 'th_resp vs pt_resp'\n",
    "    (condizione 2, condizione 4) = 'th_resp vs shared_resp'\n",
    "    (condizione 3, condizione 4) = 'pt_resp vs shared_resp' \n",
    "\n",
    "    '''\n",
    "    \n",
    "    # Crea tutte le combinazioni uniche di condizioni sperimentali (es. 'baseline vs th_resp')\n",
    "    condition_pairs = list(itertools.combinations(experimental_conditions, 2))\n",
    "    \n",
    "    #print(f\"Condition Pairs are: {condition_pairs}\")\n",
    "    #Condition Pairs are: [('baseline', 'th_resp'), \n",
    "    #('baseline', 'pt_resp'), \n",
    "    #('baseline', 'shared_resp'), \n",
    "    #('th_resp', 'pt_resp'), \n",
    "    #('th_resp', 'shared_resp'), \n",
    "    #('pt_resp', 'shared_resp')]\n",
    "\n",
    "    \n",
    "    # Loop sulle combinazioni\n",
    "    for cond_1, cond_2 in condition_pairs:\n",
    "        \n",
    "            # Crea il nome della variabile per la combinazione\n",
    "            condition_pair_key = f\"{cond_1}_vs_{cond_2}\"\n",
    "            \n",
    "            # Ottieni i dati e le etichette delle due condizioni per ogni livello\n",
    "            for level in ['theta', 'delta', 'coeff_fifth_detail_theta']:\n",
    "                \n",
    "                # Ottieni i dati e le etichette delle due condizioni\n",
    "                data_cond_1 = new_single_th_all_extracted_reconstructions.get(f\"wave_{cond_1}_{subject_number}\", {}).get(level)\n",
    "                print(f\"data_cond_1 is {cond_1}\\n\")\n",
    "                labels_cond_1 = new_single_th_all_extracted_reconstructions.get(f\"wave_{cond_1}_{subject_number}\", {}).get('labels')\n",
    "                #print(f\"data_cond_1 is {current_condition}\\n\"\n",
    "\n",
    "                data_cond_2 = new_single_th_all_extracted_reconstructions.get(f\"wave_{cond_2}_{subject_number}\", {}).get(level)\n",
    "                print(f\"data_cond_2 is {cond_2}\\n\")\n",
    "                labels_cond_2 = new_single_th_all_extracted_reconstructions.get(f\"wave_{cond_2}_{subject_number}\", {}).get('labels')\n",
    "\n",
    "                # Verifica che i dati siano validi\n",
    "                if data_cond_1 is None or labels_cond_1 is None or data_cond_2 is None or labels_cond_2 is None:\n",
    "                    continue  # Salta combinazioni incomplete\n",
    "\n",
    "                # Riassegna le etichette per garantire che \"cond_1\" = 0 e \"cond_2\" = 1\n",
    "                labels_cond_1 = np.zeros_like(labels_cond_1, dtype=int)  # Tutte 0\n",
    "                labels_cond_2 = np.ones_like(labels_cond_2, dtype=int)   # Tutte 1\n",
    "\n",
    "                # Concatenazione dei dati e delle etichette\n",
    "                concatenated_data = np.vstack((data_cond_1, data_cond_2))\n",
    "                concatenated_labels = np.hstack((labels_cond_1, labels_cond_2))\n",
    "\n",
    "                # Salva i risultati nella struttura\n",
    "                new_subject_level_concatenations_coupled_exp_th[subject_key][level][condition_pair_key] = {\n",
    "                   'data': concatenated_data,\n",
    "                   'labels': concatenated_labels}\n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "id": "41218921-9ce3-480f-b50b-7bd96cec9930",
   "metadata": {
    "tags": []
   },
   "source": [
    "'''CLEARER VERSION WITHOUT COMPLICATED PRINTS'''\n",
    "\n",
    "import itertools\n",
    "import numpy as np\n",
    "\n",
    "experimental_conditions = ['baseline', 'th_resp', 'pt_resp', 'shared_resp']\n",
    "\n",
    "# Nuova variabile per memorizzare i risultati di dati e labels concatenati di coppie di condizioni sperimentali\n",
    "new_subject_level_concatenations_coupled_exp_th = {}\n",
    "\n",
    "# Loop su tutte le chiavi del dizionario iniziale\n",
    "for key in new_single_th_all_extracted_reconstructions.keys():\n",
    "\n",
    "    key_parts = key.split('_')\n",
    "    subject_number = key_parts[-1] if key_parts[-1].isdigit() else None  # Verifica se è numerico\n",
    "    \n",
    "    # Verifica che il numero del soggetto sia valido\n",
    "    if subject_number is None:\n",
    "        continue  # Salta chiavi non valide\n",
    "    \n",
    "    subject_key = f\"th_{subject_number}\"  # Es. 'th_1' o 'th_12'\n",
    "\n",
    "    # Inizializza la struttura se non esiste ancora\n",
    "    if subject_key not in new_subject_level_concatenations_coupled_exp_th:\n",
    "        new_subject_level_concatenations_coupled_exp_th[subject_key] = {'theta': {}, 'delta': {}, 'theta_strict': {}}\n",
    "    \n",
    "    # Crea tutte le combinazioni uniche di condizioni sperimentali (es. 'baseline vs th_resp')\n",
    "    condition_pairs = list(itertools.combinations(experimental_conditions, 2))\n",
    "\n",
    "    # Loop sulle combinazioni\n",
    "    for cond_1, cond_2 in condition_pairs:\n",
    "        \n",
    "        # Crea il nome della variabile per la combinazione\n",
    "        condition_pair_key = f\"{cond_1}_vs_{cond_2}\"\n",
    "        \n",
    "        # Ottieni i dati e le etichette delle due condizioni per ogni livello\n",
    "        for level in ['theta', 'delta', 'coeff_fifth_detail_theta']:\n",
    "            \n",
    "            # Gestisci il caso per 'coeff_fifth_detail_theta'\n",
    "            if level == 'coeff_fifth_detail_theta':\n",
    "                # Ottieni i dati e le etichette per il livello coeff_fifth_detail_theta\n",
    "                data_cond_1 = new_single_th_all_extracted_reconstructions.get(f\"wave_{cond_1}_{subject_number}\", {}).get(level)\n",
    "                #print(f\"data_cond_1 is {cond_1} (coeff_fifth_detail_theta)\\n\")\n",
    "                labels_cond_1 = new_single_th_all_extracted_reconstructions.get(f\"wave_{cond_1}_{subject_number}\", {}).get('labels')\n",
    "                \n",
    "                data_cond_2 = new_single_th_all_extracted_reconstructions.get(f\"wave_{cond_2}_{subject_number}\", {}).get(level)\n",
    "                #print(f\"data_cond_2 is {cond_2} (coeff_fifth_detail_theta)\\n\")\n",
    "                labels_cond_2 = new_single_th_all_extracted_reconstructions.get(f\"wave_{cond_2}_{subject_number}\", {}).get('labels')\n",
    "            else:\n",
    "                # Ottieni i dati e le etichette per gli altri livelli (theta, delta)\n",
    "                data_cond_1 = new_single_th_all_extracted_reconstructions.get(f\"wave_{cond_1}_{subject_number}\", {}).get(level)\n",
    "                #rint(f\"data_cond_1 is {cond_1}\\n\")\n",
    "                labels_cond_1 = new_single_th_all_extracted_reconstructions.get(f\"wave_{cond_1}_{subject_number}\", {}).get('labels')\n",
    "                \n",
    "                data_cond_2 = new_single_th_all_extracted_reconstructions.get(f\"wave_{cond_2}_{subject_number}\", {}).get(level)\n",
    "                #print(f\"data_cond_2 is {cond_2}\\n\")\n",
    "                labels_cond_2 = new_single_th_all_extracted_reconstructions.get(f\"wave_{cond_2}_{subject_number}\", {}).get('labels')\n",
    "\n",
    "            # Verifica che i dati siano validi\n",
    "            if data_cond_1 is None or labels_cond_1 is None or data_cond_2 is None or labels_cond_2 is None:\n",
    "                continue  # Salta combinazioni incomplete\n",
    "\n",
    "            # Riassegna le etichette per garantire che \"cond_1\" = 0 e \"cond_2\" = 1\n",
    "            labels_cond_1 = np.zeros_like(labels_cond_1, dtype=int)  # Tutte 0\n",
    "            labels_cond_2 = np.ones_like(labels_cond_2, dtype=int)   # Tutte 1\n",
    "\n",
    "            # Concatenazione dei dati e delle etichette\n",
    "            concatenated_data = np.vstack((data_cond_1, data_cond_2))\n",
    "            concatenated_labels = np.hstack((labels_cond_1, labels_cond_2))\n",
    "\n",
    "            # Salva i risultati nella struttura\n",
    "            if level == 'coeff_fifth_detail_theta':\n",
    "                # Salva i dati sotto 'theta_strict' per 'coeff_fifth_detail_theta'\n",
    "                new_subject_level_concatenations_coupled_exp_th[subject_key]['theta_strict'][condition_pair_key] = {\n",
    "                    'data': concatenated_data,\n",
    "                    'labels': concatenated_labels}\n",
    "            else:\n",
    "                # Salva i dati sotto i livelli 'theta' o 'delta'\n",
    "                new_subject_level_concatenations_coupled_exp_th[subject_key][level][condition_pair_key] = {\n",
    "                    'data': concatenated_data,\n",
    "                    'labels': concatenated_labels}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62253bf1-e078-4d22-9a8e-01ccbc1815d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''DETAILED VERSION WITH COMPLICATED PRINTS\n",
    "\n",
    "    CORREZIONE UFFICIALE PER SPETTROGRAMS\n",
    "'''\n",
    "\n",
    "\n",
    "import itertools\n",
    "import numpy as np\n",
    "\n",
    "# Definizione delle condizioni sperimentali\n",
    "#experimental_conditions = ['baseline', 'th_resp', 'pt_resp', 'shared_resp']\n",
    "\n",
    "'''UNICA MODIFICA PER DATASET MOTOR TASK'''\n",
    "experimental_conditions = ['rest', 'left_fist', 'right_fist']\n",
    "\n",
    "# Variabile per tenere traccia del soggetto corrente (per output facoltativo)\n",
    "last_subject_key = None\n",
    "\n",
    "# Dizionario per tenere traccia delle combinazioni già elaborate per ogni soggetto (evitare duplicati)\n",
    "printed_combinations = {}\n",
    "\n",
    "# Nuovo dizionario per memorizzare i risultati concatenati per coppia di condizioni per ogni soggetto\n",
    "new_subject_level_concatenations_spectrograms_coupled_exp_th_task_1 = {}\n",
    "\n",
    "# Itera su tutte le chiavi del dizionario di partenza\n",
    "for key in new_single_th_all_extracted_spectrograms_2D_task_1.keys():\n",
    "    # Esempio di key: \"spectrograms_baseline_1\", \"spectrograms_th_resp_1\", etc.\n",
    "    key_parts = key.split('_')\n",
    "    subject_number = key_parts[-1] if key_parts[-1].isdigit() else None\n",
    "    if subject_number is None:\n",
    "        continue  # Salta eventuali chiavi non valide\n",
    "    \n",
    "    # Crea il nome del soggetto (es. \"th_1\")\n",
    "    subject_key = f\"th_{subject_number}\"\n",
    "    \n",
    "    # Se cambiamo soggetto, stampiamo (facoltativo)\n",
    "    if subject_key != last_subject_key:\n",
    "        if last_subject_key is not None:\n",
    "            print(\"\\n\" + \"-\" * 50 + f\" END OF {last_subject_key.upper()} \" + \"-\" * 50 + \"\\n\")\n",
    "        print(f\"\\nProcessing Subject: {subject_key}\\n\" + \"=\" * 80)\n",
    "        printed_combinations[subject_key] = set()  # Inizializza il set per il soggetto corrente\n",
    "    last_subject_key = subject_key\n",
    "\n",
    "    # Inizializza la struttura per il soggetto se non esiste già\n",
    "    if subject_key not in new_subject_level_concatenations_spectrograms_coupled_exp_th_task_1:\n",
    "        new_subject_level_concatenations_spectrograms_coupled_exp_th_task_1[subject_key] = {}\n",
    "\n",
    "    # Crea tutte le combinazioni uniche di condizioni sperimentali (es. \"baseline_vs_th_resp\")\n",
    "    condition_pairs = list(itertools.combinations(experimental_conditions, 2))\n",
    "    \n",
    "    # Loop sulle coppie di condizioni\n",
    "    for cond_1, cond_2 in condition_pairs:\n",
    "        condition_pair_key = f\"{cond_1}_vs_{cond_2}\"\n",
    "        if condition_pair_key in printed_combinations[subject_key]:\n",
    "            continue  # Salta se già elaborata per questo soggetto\n",
    "        \n",
    "        print(f\"\\n\\tCreation of Coupled Condition: \\033[1m{condition_pair_key}\\033[0m\")\n",
    "        printed_combinations[subject_key].add(condition_pair_key)\n",
    "        \n",
    "        # Estrai i dati e le etichette per la prima condizione\n",
    "        data_cond_1 = new_single_th_all_extracted_spectrograms_2D_task_1.get(f\"spectrograms_{cond_1}_{subject_number}\", {}).get('spectrograms')\n",
    "        labels_cond_1 = new_single_th_all_extracted_spectrograms_2D_task_1.get(f\"spectrograms_{cond_1}_{subject_number}\", {}).get('labels')\n",
    "        \n",
    "        # Estrai i dati e le etichette per la seconda condizione\n",
    "        data_cond_2 = new_single_th_all_extracted_spectrograms_2D_task_1.get(f\"spectrograms_{cond_2}_{subject_number}\", {}).get('spectrograms')\n",
    "        labels_cond_2 = new_single_th_all_extracted_spectrograms_2D_task_1.get(f\"spectrograms_{cond_2}_{subject_number}\", {}).get('labels')\n",
    "        \n",
    "        # Salta la coppia se uno dei dati non è presente\n",
    "        if data_cond_1 is None or labels_cond_1 is None or data_cond_2 is None or labels_cond_2 is None:\n",
    "            continue\n",
    "        \n",
    "        # Riassegna le etichette: tutti 0 per cond_1, tutti 1 per cond_2\n",
    "        labels_cond_1 = np.zeros_like(labels_cond_1, dtype=int)\n",
    "        labels_cond_2 = np.ones_like(labels_cond_2, dtype=int)\n",
    "        \n",
    "        # Concatenazione dei dati (verticale) e delle etichette (orizzontale)\n",
    "        concatenated_data = np.concatenate((data_cond_1, data_cond_2), axis=0)\n",
    "        concatenated_labels = np.concatenate((labels_cond_1, labels_cond_2), axis=0)\n",
    "        \n",
    "        # Salva il risultato per questa coppia nel dizionario del soggetto\n",
    "        new_subject_level_concatenations_spectrograms_coupled_exp_th_task_1[subject_key][condition_pair_key] = {\n",
    "            'data': concatenated_data,\n",
    "            'labels': concatenated_labels\n",
    "        }\n",
    "        \n",
    "        print(f\"Condition pair '{condition_pair_key}' for subject {subject_key} => Data shape: {concatenated_data.shape}, Labels length: {len(concatenated_labels)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b368691b-4f84-4a9a-9979-434190fa9fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('finito')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca96089-503e-440e-8765-ee1d84617fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\t\\t\\t\\t\\033[1mStructure of new_subject_level_concatenations_spectrograms_coupled_exp_th_task_1\\033[0m: \\n\")\n",
    "print(f\"\\033[1mFirst Order Keys\\033[0m: {new_subject_level_concatenations_spectrograms_coupled_exp_th_task_1.keys()}\\n\")\n",
    "print(f\"\\033[1mSecond Order Keys\\033[0m: {new_subject_level_concatenations_spectrograms_coupled_exp_th_task_1['th_100'].keys()}\\n\")\n",
    "print(f\"\\033[1mThird Order Keys\\033[0m: \\n{new_subject_level_concatenations_spectrograms_coupled_exp_th_task_1['th_100']['rest_vs_left_fist'].keys()}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751ed3a3-8f21-4e53-8ae8-870134f877eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''VERIFICO CHE LA CONCATENAZIONE SIA AVVENUTA CORRETTAMENTE!\n",
    "\n",
    "    CORREZIONE UFFICIALE PER SPETTROGRAMS\n",
    "'''\n",
    "\n",
    "print(\"\\tNOW, LET US SEE IF THE CONCATENATIONS RESPECT THE ORIGINAL SHAPES FOR EVERY COUPLED EXPERIMENTAL CONDITION!\")\n",
    "print(\"\\tFOR THE 1°ST SUBJECT: CHECK IF THE SUM OF INDIVIDUAL EXP COND SHAPE MATCHES THE COUPLED COND CONCATENATION SHAPE:\\n\\n\")\n",
    "\n",
    "print(\"\\033[1mINDIVIDUAL EXP COND SHAPE OF FIRST SUBJECT\\033[0m:\")\n",
    "\n",
    "# Verifica delle dimensioni originali per le singole condizioni sperimentali\n",
    "\n",
    "#for cond in ['baseline', 'th_resp', 'pt_resp', 'shared_resp']:\n",
    "for cond in ['rest', 'left_fist', 'right_fist']:    \n",
    "    \n",
    "    key = f'spectrograms_{cond}_100'\n",
    "    if key in new_single_th_all_extracted_spectrograms_2D_task_1:\n",
    "        unique_labels, counts = np.unique(new_single_th_all_extracted_spectrograms_2D_task_1[key]['labels'], return_counts=True)\n",
    "        print(f\"{cond.capitalize()} in TH_100: {unique_labels}, Counts: {counts}\\n\")\n",
    "    else:\n",
    "        print(f\"Warning: {key} not found in new_single_th_all_extracted_spectrograms_2D_task_1\\n\")\n",
    "\n",
    "# Seleziona il primo soggetto (ad esempio, 'th_1')\n",
    "subject_key = 'th_100'\n",
    "\n",
    "# Itera per ogni coppia di condizioni sperimentali direttamente (senza livelli)\n",
    "for condition_pair_key, data_labels in new_subject_level_concatenations_spectrograms_coupled_exp_th_task_1.get(subject_key, {}).items():\n",
    "    \n",
    "    # Estrarre dati e labels dalla struttura corretta\n",
    "    data = data_labels['data']\n",
    "    labels = data_labels['labels']\n",
    "\n",
    "    # Stampare il nome della coppia di condizioni e le loro dimensioni\n",
    "    print(f\"Condition Pair: \\033[1m{condition_pair_key}\\033[0m\")\n",
    "    \n",
    "    if data is not None and labels is not None:\n",
    "        print(f\"  Data Shape: {data.shape}\")\n",
    "        print(f\"  Labels Shape: {labels.shape}\")\n",
    "    else:\n",
    "        print(\"  Missing data or labels!\")\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a216f62-7abe-4264-815b-109ec3e4d9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.unique(new_subject_level_concatenations_spectrograms_coupled_exp_th_task_1['th_100']['rest_vs_left_fist']['labels'], return_counts = True))\n",
    "print(np.unique(new_subject_level_concatenations_spectrograms_coupled_exp_th_task_1['th_100']['rest_vs_right_fist']['labels'], return_counts = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09686403-6ebd-420c-9909-95cf78454ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\t\\t\\t\\033[1mBASELINE_VS_TH_RESP\\033[0m\\n\")\n",
    "print(new_subject_level_concatenations_spectrograms_coupled_exp_th_task_1['th_100']['rest_vs_left_fist']['labels'][:40])\n",
    "print(new_subject_level_concatenations_spectrograms_coupled_exp_th_task_1['th_100']['rest_vs_left_fist']['labels'][40:])\n",
    "print()\n",
    "print()\n",
    "print(f\"\\t\\t\\t\\033[1mTH_RESP_VS_SHARED_RESP\\033[0m\\n\")\n",
    "print(new_subject_level_concatenations_spectrograms_coupled_exp_th_task_1['th_100']['rest_vs_right_fist']['labels'][:40])\n",
    "print(new_subject_level_concatenations_spectrograms_coupled_exp_th_task_1['th_100']['rest_vs_right_fist']['labels'][40:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18b85ed-6d27-4857-8f2d-f9aea6e5034b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### STEP - Salvataggio Dataset di All Single Therapists EEG Data Spectrograms across Couples of Experimental Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992bab17-ea09-4dc6-aac9-37231fb87a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8ffadb-aa0f-4286-b15c-6325b8c83341",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '/home/stefano/Interrogait/all_datas/Spectrograms_channels_frequencies_motor_tasks/'\n",
    "\n",
    "# Controlla se la cartella esiste, altrimenti la crea\n",
    "if not os.path.exists(base_path):\n",
    "    os.makedirs(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddef07d3-ca0c-4187-848f-bbe2da0406ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Salvare l'intero dizionario annidato con pickle\n",
    "with open(f'{base_path}new_subject_level_concatenations_spectrograms_coupled_exp_th_task_1_2d_grid_multiband.pkl', 'wb') as f:\n",
    "    pickle.dump(new_subject_level_concatenations_spectrograms_coupled_exp_th_task_1, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894d649b-297d-41d7-97b2-c81a361048b4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### **Concatenazione** **ALL** Single Subject **Spectrograms (TH)** per **Coppie di Condizioni Sperimentali INSIEME**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334ff614-a499-4160-8fb1-e4489940597c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Library Importing \n",
    "    \n",
    "import os\n",
    "import math\n",
    "import copy as cp \n",
    "\n",
    "import tqdm\n",
    "\n",
    "#import mne \n",
    "import scipy\n",
    "\n",
    "import numpy as np  # NumPy per operazioni numeriche\n",
    "import matplotlib.pyplot as plt  # Matplotlib per la isualizzazione dei dati\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import pickle\n",
    "\n",
    "import os \n",
    "\n",
    "base_path = '/home/stefano/Interrogait/all_datas/Spectrograms_channels_frequencies_motor_tasks/'\n",
    "\n",
    "# Controlla se la cartella esiste, altrimenti la crea\n",
    "if not os.path.exists(base_path):\n",
    "    os.makedirs(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276d0542-641e-49be-8044-be880aadf13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caricare l'intero dizionario annidato con pickle\n",
    "with open(f'{base_path}/new_subject_level_concatenations_spectrograms_coupled_exp_th_task_1_2d_grid_multiband.pkl', 'rb') as f:\n",
    "    new_subject_level_concatenations_spectrograms_coupled_exp_th_task_1 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9be05c-9636-4bc3-b3ec-ee952b7764de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_subject_level_concatenations_spectrograms_coupled_exp_th.keys()\n",
    "#new_subject_level_concatenations_spectrograms_coupled_exp_th['th_1'].keys()\n",
    "#new_subject_level_concatenations_spectrograms_coupled_exp_th['th_1']['theta'].keys()\n",
    "#new_subject_level_concatenations_spectrograms_coupled_exp_th['th_1']['theta']['baseline_vs_th_resp'].keys()\n",
    "#np.unique(new_subject_level_concatenations_spectrograms_coupled_exp_th['th_1']['theta']['baseline_vs_th_resp']['labels'], return_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd7d623-353e-47cf-abb1-d4f408e34de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(new_subject_level_concatenations_spectrograms_coupled_exp_th_task_1['th_100']['rest_vs_left_fist']['labels'], return_counts = True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6df2fe29-6b87-4612-80e9-fb7a3c16edbc",
   "metadata": {
    "tags": []
   },
   "source": [
    "##NEW OFFICIAL VERSION!\n",
    "\n",
    "#SENZA DICT_NAME!\n",
    "\n",
    "\n",
    "'''CODICE DI PARTENZA PER MODIFICHE A SPETTROGRAMMI'''\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def concatenate_all_single_subj_wavelets_coupled_experimental_conditions_th(data_structure, wavelet_levels, conditions):\n",
    "    \n",
    "    \"\"\"\n",
    "    Concatena i dati e le etichette per ogni condizione sperimentale da una struttura dati con un livello in più,\n",
    "    dove questo livello rappresenta le diverse coppie di condizioni sperimentali iterate nel ciclo ossia\n",
    "    \n",
    "    'baseline_vs_th_resp', 'baseline_vs_pt_resp', 'baseline_vs_shared_resp', \n",
    "    'th_resp_vs_pt_resp', 'th_resp_vs_shared_resp', 'pt_resp_vs_shared_resp'\n",
    "    \n",
    "    ordinandoli anche per etichetta.\n",
    "    \n",
    "    Questo perché ogni array di labels avrà sempre o 0 od 1 come etichette,\n",
    "    dato che son coppie di condizioni sperimentali\n",
    "\n",
    "    Parameters:\n",
    "        data_structure (dict): La struttura dati di input che contiene i dati per soggetti e condizioni.\n",
    "        conditions (list): Le condizioni sperimentali (chiavi del secondo livello) da processare.\n",
    "        \n",
    "\n",
    "    Returns:\n",
    "        dict: Un dizionario contenente i nuovi dizionari con \n",
    "        i dati concatenati e le etichette per ogni coppia di condizioni sperimentali\n",
    "    \n",
    "    \"\"\"\n",
    "        \n",
    "        \n",
    "    # Dizionario per contenere i dati concatenati di tutti i soggetti\n",
    "    all_subj_data_by_coupled_cond = {}\n",
    "    \n",
    "    # Itera su ogni livello di ricostruzione wavelet ('theta', 'delta', 'theta_strict')\n",
    "    \n",
    "    for reconstruction_level in wavelet_levels:\n",
    "        \n",
    "        all_subj_data_by_coupled_cond[reconstruction_level] = {}  # Struttura annidata per livello\n",
    "\n",
    "        # Itera su ogni coppia di condizioni sperimentali\n",
    "        for condition_pair in conditions:\n",
    "            \n",
    "            #Dizionari per raccogliere dati e labels ordinati per ogni coppia di condizioni sperimentali\n",
    "            # che è dinamico, per ogni coppia di condizioni sperimentali \n",
    "            #(quindi si ricreeranno passando alla condizione sperimentale successiva!)\n",
    "            \n",
    "            data_by_label = {}\n",
    "            labels_by_label = {}\n",
    "            shape_labels_per_subject = {0: [], 1: []}  # Inizializza il dizionario per 0 e 1\n",
    "\n",
    "            # Itera su tutti i soggetti\n",
    "            # In questo caso, itera sulle chiavi di ogni soggetto\n",
    "\n",
    "            # Quindi prenderà, per la relativa coppia di condizioni sperimentali di ogni soggetto,\n",
    "            # i dati e le labels di quel soggetto, per quella relativa coppia di condizioni sperimentali\n",
    "            \n",
    "            for subject_key in data_structure.keys():\n",
    "                \n",
    "                # Controlla se il livello di ricostruzione esiste per il soggetto\n",
    "                if reconstruction_level not in data_structure[subject_key]:\n",
    "                    continue\n",
    "                    \n",
    "                # Controlla se il livello di ricostruzione esiste per il soggetto\n",
    "                if condition_pair not in data_structure[subject_key][reconstruction_level]:\n",
    "                    continue\n",
    "                \n",
    "                # Qui estrae i dati e le labels per questa condizione sperimentale di quel soggettio lì\n",
    "                subject_data = data_structure[subject_key][reconstruction_level][condition_pair]['data']\n",
    "                subject_labels = data_structure[subject_key][reconstruction_level][condition_pair]['labels']\n",
    "                \n",
    "                # Trova le etichette uniche e gli indici corrispondenti per quella coppia di condizioni sperimentali lì,\n",
    "                # Ossia, potrà trovare gli 0 e gli 1 \n",
    "                \n",
    "                unique_labels = np.unique(subject_labels)\n",
    "                \n",
    "                #A quel punto, per ognuna delle due labels trovate per quella coppia di condizioni sperimentali lì\n",
    "                #Che saranno sempre o 0 o 1\n",
    "                \n",
    "                for label in unique_labels:\n",
    "                    \n",
    "                    # Trova gli indici dei dati corrispondenti a questa etichetta\n",
    "                    # Una volta per lo 0 ed una volta per l' 1\n",
    "                    \n",
    "                    label_indices = np.where(subject_labels == label)[0]\n",
    "                    \n",
    "                    # A quel punto, estrae i dati e le labels per questi indici\n",
    "                    # Una volta per lo 0 ed una volta per l' 1\n",
    "                    \n",
    "                    data_for_label = subject_data[label_indices]\n",
    "                    labels_for_label = subject_labels[label_indices]\n",
    "                    \n",
    "                    # A quel punto, per ogni soggetto, per ogni condzione sperimentale, \n",
    "                    # per quelle due labels là (sempre presenti, per ogni coppia di condizioni sperimentali)\n",
    "                    # Una volta per lo 0 ed una volta per l' 1\n",
    "\n",
    "                    #Andrà a creare per ogni etichetta, una chiave che si chiamerà \n",
    "                    #o 0 od 1 (inizialmente, vuoto -> perché deve esser inizializzato)\n",
    "                    #E poi, dopo, ci appenderà le labels \n",
    "                     # Una volta per lo 0 ed una volta per l' 1\n",
    "                    #  Di quel soggetto per quella coppia di condizioni sperimentali iterate a quel momento\n",
    "                    \n",
    "                    #Aggiunge ai dizionari globali, creando la chiave se non esiste\n",
    "                    if label not in data_by_label:\n",
    "                        data_by_label[label] = []\n",
    "                        labels_by_label[label] = []\n",
    "\n",
    "                    data_by_label[label].append(data_for_label)\n",
    "                    labels_by_label[label].append(labels_for_label)\n",
    "                    \n",
    "                    # **Salva la shape delle etichette per il soggetto corrente**\n",
    "                    shape_labels_per_subject[label].append(labels_for_label.shape[0]) # Aggiungi solo la dimensione (numero di etichette)\n",
    "                    \n",
    "                    '''PRINT PER CHECK LABELS DI OGNI SOGGETTO PER OGNI COPPIA DI CONDIZIONE CONDIZIONI SPERIMENTALI''' \n",
    "                    #print(f\"Soggetto: \\033[1m{subject_key}\\033[0m, Livello: \\033[1m{reconstruction_level}\\033[0m, Condizione: \\033[1m{condition_pair}\\033[0m, \"\n",
    "                    #      f\"Etichetta: \\033[1m{label}\\033[0m, Shape: \\033[1m{labels_for_label.shape[0]}\\033[0m\")\n",
    "                    \n",
    "                    # **Aggiungi un print di controllo per ogni soggetto**\n",
    "                    #print(f\"Soggetto: \\033[1m{subject_key}\\033[1m, Livello: {reconstruction_level}, Condizione: {condition_pair}, Etichetta: {label}, Shape: {labels_for_label.shape[0]}\")\n",
    "            \n",
    "            \n",
    "            #*** *** *** *** *** *** *** *** *** *** *** *** *** *** ***\n",
    "            \n",
    "            # Dopodiché, vado a creare invece i dizionari che conterranno\n",
    "            # Le concatenazioni, di dati e labels corrispondenti, di tutti i soggetti per cui l'etichetta era \n",
    "            # o 0 od 1 \n",
    "\n",
    "            # Di conseguenza, qui dentro dovrei avere, per ogni coppia di condizioni sperimentali\n",
    "            # Tutti gli 0 ed 1 (ed i relativi dati corrispondenti)\n",
    "            # di tutti i soggetti, ma concatenati\n",
    "\n",
    "            concatenated_data_by_label = {}\n",
    "            concatenated_labels_by_label = {}\n",
    "\n",
    "            #for label in data_by_label.keys():\n",
    "            #    if len(data_by_label[label]) > 0:  # Evita errori di concatenazione\n",
    "            #        concatenated_data_by_label[label] = np.vstack(data_by_label[label])\n",
    "            #        concatenated_labels_by_label[label] = np.hstack(labels_by_label[label])\n",
    "            \n",
    "            for label in data_by_label.keys():\n",
    "                concatenated_data_by_label[label] = np.vstack(data_by_label[label])\n",
    "                concatenated_labels_by_label[label] = np.hstack(labels_by_label[label])\n",
    "\n",
    "                # **Calcolare la shape totale delle etichette**\n",
    "                #total_labels_0 = np.sum(1 for subject_labels in labels_by_label[label] if 0 in subject_labels)\n",
    "                #total_labels_1 = np.sum(1 for subject_labels in labels_by_label[label] if 1 in subject_labels)\n",
    "                #total_labels = total_labels_0 + total_labels_1\n",
    "\n",
    "                # **Determinare gli indici delle etichette 0 e 1 nell'array finale**\n",
    "\n",
    "                # Gli indici delle etichette 0\n",
    "                indices_labels_0 = np.where(concatenated_labels_by_label[label] == 0)[0]\n",
    "\n",
    "                # Gli indici delle etichette 1\n",
    "                indices_labels_1 = np.where(concatenated_labels_by_label[label] == 1)[0]\n",
    "                \n",
    "                # Indici iniziale e finale per le etichette 0 e 1\n",
    "                start_idx_0 = indices_labels_0[0] if len(indices_labels_0) > 0 else None\n",
    "                end_idx_0 = indices_labels_0[-1] if len(indices_labels_0) > 0 else None\n",
    "                start_idx_1 = indices_labels_1[0] if len(indices_labels_1) > 0 else None\n",
    "                end_idx_1 = indices_labels_1[-1] if len(indices_labels_1) > 0 else None\n",
    "\n",
    "\n",
    "                # **Print finale per verificare la concatenazione per ogni label**\n",
    "                #print(f\"\\nCondizione: \\033[1m{condition_pair}\\033[0m, Etichetta: {label}\")\n",
    "                #print(f\"  - Shape dei dati concatenati per \\033[1m{label}\\033[0m: {concatenated_data_by_label[label].shape}\")\n",
    "                #print(f\"  - Shape delle etichette concatenate per \\033[1m{label}\\033[0m: {concatenated_labels_by_label[label].shape}\")\n",
    "\n",
    "                # **Stampa la lista delle shapes delle etichette per ogni soggetto per questa etichetta**\n",
    "                #print(f\"\\n  - Shape delle etichette per soggetto (per etichetta {label}): {shape_labels_per_subject[label]}\\n\")\n",
    "\n",
    "\n",
    "                # **Stampa il conteggio totale delle etichette**\n",
    "                #print(f\"\\n  - Totale delle etichette 0: {total_labels_0}\")\n",
    "                #print(f\"  - Totale delle etichette 1: {total_labels_1}\")\n",
    "                #print(f\"  - Totale delle etichette per la condizione: {total_labels}\\n\")\n",
    "\n",
    "                # **Stampa gli indici per le etichette 0 e 1**\n",
    "                # **OSSIA --> Stampa gli indici per l'etichetta corrente**\n",
    "\n",
    "                #if label == 0:\n",
    "                #    print(f\"\\n  - Indici per etichetta 0: Inizio = {start_idx_0}, Fine = {end_idx_0}\")\n",
    "                #else:\n",
    "                #    print(f\"  - Indici per etichetta 1: Inizio = {start_idx_1}, Fine = {end_idx_1}\\n\")\n",
    "\n",
    "\n",
    "                #print(f\"\\n  - Indici per etichetta 0: Inizio = {start_idx_0}, Fine = {end_idx_0}\")\n",
    "                #print(f\"  - Indici per etichetta 1: Inizio = {start_idx_1}, Fine = {end_idx_1}\")\n",
    "\n",
    "\n",
    "            #ARRIVATI FINO A QUI, abbiamo che siccome stiamo iterando prima per tutti gli 0 e poi per tutti gli 1\n",
    "            #Significa che, assumendo che siamo dentro 'baseline_vs_th_resp' e che \n",
    "\n",
    "            #'baseline' sia rappresentato dalle etichette 0\n",
    "            #'th_resp' sia rappresentato dalle etichette 1\n",
    "\n",
    "            #Al PRIMO ciclo avrò che:\n",
    "\n",
    "            #con concatenated_data_by_label[label] ho solo concatenato tutti i dati (di 'baseline' per 'baseline_vs_th_resp' di tutti i soggetti)\n",
    "            #con concatenated_labels_by_label[label] ho solo concatenato tutti gli 0 (di 'baseline' per 'baseline_vs_th_resp'di tutti i soggetti)\n",
    "\n",
    "            #Al SECONDO ciclo avrò che:\n",
    "\n",
    "            #con concatenated_data_by_label[label] ho solo concatenato tutti i dati (di 'th_resp' per 'baseline_vs_th_resp'  di tutti i soggetti)\n",
    "            #con concatenated_labels_by_label[label] ho solo concatenato tutti gli 0 (di 'th_resp' per 'baseline_vs_th_resp' di tutti i soggetti)\n",
    "\n",
    "            #Quindi mi manca ancora \n",
    "\n",
    "            #A) CONCATENARE I DATI:\n",
    "\n",
    "            #1)prima tutti i dati (di 'baseline' per 'baseline_vs_th_resp' di tutti i soggetti) \n",
    "\n",
    "            #CON\n",
    "\n",
    "            #2)tutti i dati (di 'th_resp' per 'baseline_vs_th_resp'  di tutti i soggetti)\n",
    "\n",
    "            #che verrà fatto dentro all_data (che è anch'esso una variabile dinamica!)\n",
    "\n",
    "            #B) CONCATENARE LE LABELS:\n",
    "\n",
    "            #1)prima tutti le labels (di 'baseline' per 'baseline_vs_th_resp' di tutti i soggetti) \n",
    "\n",
    "            #CON\n",
    "\n",
    "            #2)tutti le labels (di 'th_resp' per 'baseline_vs_th_resp' di tutti i soggetti)\n",
    "\n",
    "            #che verrà fatto dentro all_labels (che è anch'esso una variabile dinamica!)\n",
    "\n",
    "            # Liste per raccogliere dati e labels di tutte le etichette\n",
    "\n",
    "            # Qui dentro, invece, dov con\n",
    "            \n",
    "            all_data = []\n",
    "            all_labels = []\n",
    "\n",
    "            for label in concatenated_data_by_label.keys():\n",
    "                all_data.append(concatenated_data_by_label[label])\n",
    "                all_labels.append(concatenated_labels_by_label[label])\n",
    "            \n",
    "            #Alla fine, qui dentro avrò che, PER OGNI COPPIA DI CONDIZIONI SPERIMENTALI\n",
    "\n",
    "\n",
    "            #'final_data' dovrebbe avere \n",
    "                #- prima tutti i dati di tutti i soggetti associati all'etichetta 0 \n",
    "                #- e poi tutti i dati di tutti i soggetti associati all'etichetta 1\n",
    "\n",
    "            #'final_labels' dovrebbe avere \n",
    "                #- prima tutte le labels di tutti i soggetti associati all'etichetta 0\n",
    "                #- e poi tutte tutte le labels di tutti soggetti associati all'etichetta 1...\n",
    "                \n",
    "            if all_data:  # Evita errori di concatenazione se non ci sono dati\n",
    "                final_data = np.vstack(all_data)\n",
    "                final_labels = np.hstack(all_labels)\n",
    "                \n",
    "                all_subj_data_by_coupled_cond[reconstruction_level][condition_pair] = {\n",
    "                    'data': final_data,\n",
    "                    'labels': final_labels\n",
    "                }\n",
    "                \n",
    "\n",
    "    #print(\"\\n\\033[1mIntervalli di indici per ciascuna etichetta nei sotto-dizionari:\\033[0m\\n\")\n",
    "\n",
    "    #for reconstruction_level, conditions_dict in all_subj_data_by_coupled_cond.items():\n",
    "    #    for condition_pair, value in conditions_dict.items():\n",
    "    #        labels = value['labels']\n",
    "    #        unique_labels = np.unique(labels)\n",
    "    #        total_labels = 0\n",
    "\n",
    "    #        print(f\"\\nLivello Wavelet: {reconstruction_level}, Condizione: {condition_pair}\")\n",
    "    #        for label in unique_labels:\n",
    "    #            label_indices = np.where(labels == label)[0]\n",
    "    #            start_idx = label_indices[0] if len(label_indices) > 0 else None\n",
    "    #            end_idx = label_indices[-1] if len(label_indices) > 0 else None\n",
    "    #            total_labels += len(label_indices)\n",
    "\n",
    "    #            print(f\"  Etichetta \\033[1m{label}\\033[0m: Indici \\033[1m{start_idx}-{end_idx}\\033[0m \"\n",
    "    #                  f\"(Totale Etichette: \\033[1m{len(label_indices)}\\033[0m)\")\n",
    "\n",
    "    #        print(f\"Totale etichette (0 e 1): \\033[1m{total_labels}\\033[0m\\n\")\n",
    "\n",
    "    return all_subj_data_by_coupled_cond\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26e56a0-fad4-4463-90bb-438f5cd6a481",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''CODICE UFFICIALE CON MODIFICHE A SPETTROGRAMMI'''\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def concatenate_all_subjects_coupled_spectrogram_conditions_th(data_structure, conditions):\n",
    "    \n",
    "    \"\"\"\n",
    "    Concatena globalmente i dati e le etichette per ogni coppia di condizioni sperimentali\n",
    "    a partire dalla struttura 'new_subject_level_concatenations_spectrograms_coupled_exp_th'.\n",
    "    I dati di ogni soggetto (già raggruppati per coppia di condizioni) vengono ulteriormente \n",
    "    concatenati per ottenere un unico array globale per ogni coppia.\n",
    "    \n",
    "    Parameters:\n",
    "        data_structure (dict): Struttura dati con chiavi per soggetto (es. 'th_1', 'th_2', ...)\n",
    "                               e, per ciascun soggetto, chiavi per ciascuna coppia di condizioni sperimentali.\n",
    "        condition_pairs (list): Lista di coppie di condizioni sperimentali (es. 'baseline_vs_th_resp', ...)\n",
    "        \n",
    "    Returns:\n",
    "        dict: Un dizionario globale in cui ogni chiave è una coppia di condizioni e il valore\n",
    "              è un dizionario con 'data' e 'labels' concatenati globalmente (da tutti i soggetti).\n",
    "    \"\"\"\n",
    "        \n",
    "    # Dizionario per contenere i dati concatenati di tutti i soggetti\n",
    "    all_subj_data_by_coupled_cond = {}\n",
    "\n",
    "    # Itera su ogni coppia di condizioni sperimentali\n",
    "    for condition_pair in conditions:\n",
    "\n",
    "        #Dizionari per raccogliere dati e labels ordinati per ogni coppia di condizioni sperimentali\n",
    "        # che è dinamico, per ogni coppia di condizioni sperimentali \n",
    "        #(quindi si ricreeranno passando alla condizione sperimentale successiva!)\n",
    "\n",
    "        data_by_label = {}\n",
    "        labels_by_label = {}\n",
    "        shape_labels_per_subject = {0: [], 1: []}  # Inizializza il dizionario per 0 e 1\n",
    "\n",
    "        # Itera su tutti i soggetti\n",
    "        # In questo caso, itera sulle chiavi di ogni soggetto\n",
    "\n",
    "        # Quindi prenderà, per la relativa coppia di condizioni sperimentali di ogni soggetto,\n",
    "        # i dati e le labels di quel soggetto, per quella relativa coppia di condizioni sperimentali\n",
    "\n",
    "        for subject_key in data_structure.keys():\n",
    "\n",
    "            # Controlla se il livello di ricostruzione esiste per il soggetto\n",
    "            if condition_pair not in data_structure[subject_key]:\n",
    "                continue\n",
    "\n",
    "            # Qui estrae i dati e le labels per questa condizione sperimentale di quel soggettio lì\n",
    "            subject_data = data_structure[subject_key][condition_pair]['data']\n",
    "            subject_labels = data_structure[subject_key][condition_pair]['labels']\n",
    "\n",
    "            # Trova le etichette uniche e gli indici corrispondenti per quella coppia di condizioni sperimentali lì,\n",
    "            # Ossia, potrà trovare gli 0 e gli 1 \n",
    "\n",
    "            unique_labels = np.unique(subject_labels)\n",
    "\n",
    "            #A quel punto, per ognuna delle due labels trovate per quella coppia di condizioni sperimentali lì\n",
    "            #Che saranno sempre o 0 o 1\n",
    "\n",
    "            for label in unique_labels:\n",
    "\n",
    "                # Trova gli indici dei dati corrispondenti a questa etichetta\n",
    "                # Una volta per lo 0 ed una volta per l' 1\n",
    "\n",
    "                label_indices = np.where(subject_labels == label)[0]\n",
    "\n",
    "                # A quel punto, estrae i dati e le labels per questi indici\n",
    "                # Una volta per lo 0 ed una volta per l' 1\n",
    "\n",
    "                data_for_label = subject_data[label_indices]\n",
    "                labels_for_label = subject_labels[label_indices]\n",
    "\n",
    "                # A quel punto, per ogni soggetto, per ogni condzione sperimentale, \n",
    "                # per quelle due labels là (sempre presenti, per ogni coppia di condizioni sperimentali)\n",
    "                # Una volta per lo 0 ed una volta per l' 1\n",
    "\n",
    "                #Andrà a creare per ogni etichetta, una chiave che si chiamerà \n",
    "                #o 0 od 1 (inizialmente, vuoto -> perché deve esser inizializzato)\n",
    "                #E poi, dopo, ci appenderà le labels \n",
    "                 # Una volta per lo 0 ed una volta per l' 1\n",
    "                #  Di quel soggetto per quella coppia di condizioni sperimentali iterate a quel momento\n",
    "\n",
    "                #Aggiunge ai dizionari globali, creando la chiave se non esiste\n",
    "                if label not in data_by_label:\n",
    "                    data_by_label[label] = []\n",
    "                    labels_by_label[label] = []\n",
    "\n",
    "                data_by_label[label].append(data_for_label)\n",
    "                labels_by_label[label].append(labels_for_label)\n",
    "\n",
    "                # **Salva la shape delle etichette per il soggetto corrente**\n",
    "                shape_labels_per_subject[label].append(labels_for_label.shape[0]) # Aggiungi solo la dimensione (numero di etichette)\n",
    "\n",
    "                '''PRINT PER CHECK LABELS DI OGNI SOGGETTO PER OGNI COPPIA DI CONDIZIONE CONDIZIONI SPERIMENTALI''' \n",
    "                #print(f\"Soggetto: \\033[1m{subject_key}\\033[0m, Livello: \\033[1m{reconstruction_level}\\033[0m, Condizione: \\033[1m{condition_pair}\\033[0m, \"\n",
    "                #      f\"Etichetta: \\033[1m{label}\\033[0m, Shape: \\033[1m{labels_for_label.shape[0]}\\033[0m\")\n",
    "\n",
    "                # **Aggiungi un print di controllo per ogni soggetto**\n",
    "                #print(f\"Soggetto: \\033[1m{subject_key}\\033[1m, Livello: {reconstruction_level}, Condizione: {condition_pair}, Etichetta: {label}, Shape: {labels_for_label.shape[0]}\")\n",
    "\n",
    "            \n",
    "        #*** *** *** *** *** *** *** *** *** *** *** *** *** *** ***\n",
    "\n",
    "        # Dopodiché, vado a creare invece i dizionari che conterranno\n",
    "        # Le concatenazioni, di dati e labels corrispondenti, di tutti i soggetti per cui l'etichetta era \n",
    "        # o 0 od 1 \n",
    "\n",
    "        # Di conseguenza, qui dentro dovrei avere, per ogni coppia di condizioni sperimentali\n",
    "        # Tutti gli 0 ed 1 (ed i relativi dati corrispondenti)\n",
    "        # di tutti i soggetti, ma concatenati\n",
    "\n",
    "        concatenated_data_by_label = {}\n",
    "        concatenated_labels_by_label = {}\n",
    "\n",
    "        #for label in data_by_label.keys():\n",
    "        #    if len(data_by_label[label]) > 0:  # Evita errori di concatenazione\n",
    "        #        concatenated_data_by_label[label] = np.vstack(data_by_label[label])\n",
    "        #        concatenated_labels_by_label[label] = np.hstack(labels_by_label[label])\n",
    "            \n",
    "        for label in data_by_label.keys():\n",
    "            concatenated_data_by_label[label] = np.vstack(data_by_label[label])\n",
    "            concatenated_labels_by_label[label] = np.hstack(labels_by_label[label])\n",
    "\n",
    "            # **Calcolare la shape totale delle etichette**\n",
    "            #total_labels_0 = np.sum(1 for subject_labels in labels_by_label[label] if 0 in subject_labels)\n",
    "            #total_labels_1 = np.sum(1 for subject_labels in labels_by_label[label] if 1 in subject_labels)\n",
    "            #total_labels = total_labels_0 + total_labels_1\n",
    "\n",
    "            # **Determinare gli indici delle etichette 0 e 1 nell'array finale**\n",
    "\n",
    "            # Gli indici delle etichette 0\n",
    "            indices_labels_0 = np.where(concatenated_labels_by_label[label] == 0)[0]\n",
    "\n",
    "            # Gli indici delle etichette 1\n",
    "            indices_labels_1 = np.where(concatenated_labels_by_label[label] == 1)[0]\n",
    "\n",
    "            # Indici iniziale e finale per le etichette 0 e 1\n",
    "            start_idx_0 = indices_labels_0[0] if len(indices_labels_0) > 0 else None\n",
    "            end_idx_0 = indices_labels_0[-1] if len(indices_labels_0) > 0 else None\n",
    "            start_idx_1 = indices_labels_1[0] if len(indices_labels_1) > 0 else None\n",
    "            end_idx_1 = indices_labels_1[-1] if len(indices_labels_1) > 0 else None\n",
    "\n",
    "\n",
    "            # **Print finale per verificare la concatenazione per ogni label**\n",
    "            #print(f\"\\nCondizione: \\033[1m{condition_pair}\\033[0m, Etichetta: {label}\")\n",
    "            #print(f\"  - Shape dei dati concatenati per \\033[1m{label}\\033[0m: {concatenated_data_by_label[label].shape}\")\n",
    "            #print(f\"  - Shape delle etichette concatenate per \\033[1m{label}\\033[0m: {concatenated_labels_by_label[label].shape}\")\n",
    "\n",
    "            # **Stampa la lista delle shapes delle etichette per ogni soggetto per questa etichetta**\n",
    "            #print(f\"\\n  - Shape delle etichette per soggetto (per etichetta {label}): {shape_labels_per_subject[label]}\\n\")\n",
    "\n",
    "\n",
    "            # **Stampa il conteggio totale delle etichette**\n",
    "            #print(f\"\\n  - Totale delle etichette 0: {total_labels_0}\")\n",
    "            #print(f\"  - Totale delle etichette 1: {total_labels_1}\")\n",
    "            #print(f\"  - Totale delle etichette per la condizione: {total_labels}\\n\")\n",
    "\n",
    "            # **Stampa gli indici per le etichette 0 e 1**\n",
    "            # **OSSIA --> Stampa gli indici per l'etichetta corrente**\n",
    "\n",
    "            #if label == 0:\n",
    "            #    print(f\"\\n  - Indici per etichetta 0: Inizio = {start_idx_0}, Fine = {end_idx_0}\")\n",
    "            #else:\n",
    "            #    print(f\"  - Indici per etichetta 1: Inizio = {start_idx_1}, Fine = {end_idx_1}\\n\")\n",
    "\n",
    "\n",
    "            #print(f\"\\n  - Indici per etichetta 0: Inizio = {start_idx_0}, Fine = {end_idx_0}\")\n",
    "            #print(f\"  - Indici per etichetta 1: Inizio = {start_idx_1}, Fine = {end_idx_1}\")\n",
    "\n",
    "\n",
    "        #ARRIVATI FINO A QUI, abbiamo che siccome stiamo iterando prima per tutti gli 0 e poi per tutti gli 1\n",
    "        #Significa che, assumendo che siamo dentro 'baseline_vs_th_resp' e che \n",
    "\n",
    "        #'baseline' sia rappresentato dalle etichette 0\n",
    "        #'th_resp' sia rappresentato dalle etichette 1\n",
    "\n",
    "        #Al PRIMO ciclo avrò che:\n",
    "\n",
    "        #con concatenated_data_by_label[label] ho solo concatenato tutti i dati (di 'baseline' per 'baseline_vs_th_resp' di tutti i soggetti)\n",
    "        #con concatenated_labels_by_label[label] ho solo concatenato tutti gli 0 (di 'baseline' per 'baseline_vs_th_resp'di tutti i soggetti)\n",
    "\n",
    "        #Al SECONDO ciclo avrò che:\n",
    "\n",
    "        #con concatenated_data_by_label[label] ho solo concatenato tutti i dati (di 'th_resp' per 'baseline_vs_th_resp'  di tutti i soggetti)\n",
    "        #con concatenated_labels_by_label[label] ho solo concatenato tutti gli 0 (di 'th_resp' per 'baseline_vs_th_resp' di tutti i soggetti)\n",
    "\n",
    "        #Quindi mi manca ancora \n",
    "\n",
    "        #A) CONCATENARE I DATI:\n",
    "\n",
    "        #1)prima tutti i dati (di 'baseline' per 'baseline_vs_th_resp' di tutti i soggetti) \n",
    "\n",
    "        #CON\n",
    "\n",
    "        #2)tutti i dati (di 'th_resp' per 'baseline_vs_th_resp'  di tutti i soggetti)\n",
    "\n",
    "        #che verrà fatto dentro all_data (che è anch'esso una variabile dinamica!)\n",
    "\n",
    "        #B) CONCATENARE LE LABELS:\n",
    "\n",
    "        #1)prima tutti le labels (di 'baseline' per 'baseline_vs_th_resp' di tutti i soggetti) \n",
    "\n",
    "        #CON\n",
    "\n",
    "        #2)tutti le labels (di 'th_resp' per 'baseline_vs_th_resp' di tutti i soggetti)\n",
    "\n",
    "        #che verrà fatto dentro all_labels (che è anch'esso una variabile dinamica!)\n",
    "\n",
    "        # Liste per raccogliere dati e labels di tutte le etichette\n",
    "\n",
    "        # Qui dentro, invece, dov con\n",
    "\n",
    "        all_data = []\n",
    "        all_labels = []\n",
    "\n",
    "        for label in concatenated_data_by_label.keys():\n",
    "            all_data.append(concatenated_data_by_label[label])\n",
    "            all_labels.append(concatenated_labels_by_label[label])\n",
    "\n",
    "        #Alla fine, qui dentro avrò che, PER OGNI COPPIA DI CONDIZIONI SPERIMENTALI\n",
    "\n",
    "\n",
    "        #'final_data' dovrebbe avere \n",
    "            #- prima tutti i dati di tutti i soggetti associati all'etichetta 0 \n",
    "            #- e poi tutti i dati di tutti i soggetti associati all'etichetta 1\n",
    "\n",
    "        #'final_labels' dovrebbe avere \n",
    "            #- prima tutte le labels di tutti i soggetti associati all'etichetta 0\n",
    "            #- e poi tutte tutte le labels di tutti soggetti associati all'etichetta 1...\n",
    "\n",
    "        if all_data:  # Evita errori di concatenazione se non ci sono dati\n",
    "            final_data = np.vstack(all_data)\n",
    "            final_labels = np.hstack(all_labels)\n",
    "\n",
    "            all_subj_data_by_coupled_cond[condition_pair] = {\n",
    "                'data': final_data,\n",
    "                'labels': final_labels\n",
    "            }\n",
    "            \n",
    "    return all_subj_data_by_coupled_cond\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cda8bf-e4d0-42a2-845e-6fcb47924502",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Parametri\n",
    "\n",
    "\n",
    "#conditions = ['baseline_vs_th_resp', 'baseline_vs_pt_resp', 'baseline_vs_shared_resp',\n",
    "#              'th_resp_vs_pt_resp', 'th_resp_vs_shared_resp', 'pt_resp_vs_shared_resp']\n",
    "\n",
    "    \n",
    "conditions = ['rest_vs_left_fist', 'rest_vs_right_fist', 'left_fist_vs_right_fist']\n",
    "\n",
    "\n",
    "# Chiamata alla funzione, qui definisco a mano il nome della variabile (i.e., \n",
    "new_all_th_concat_spectrograms_coupled_exp_task_1 = concatenate_all_subjects_coupled_spectrogram_conditions_th(\n",
    "    data_structure=new_subject_level_concatenations_spectrograms_coupled_exp_th_task_1,\n",
    "    conditions=conditions\n",
    ")\n",
    "\n",
    "#print(\"\\n\\033[1mIntervalli di indici per ciascuna etichetta nei sotto-dizionari:\\033[0m\\n\")\n",
    "\n",
    "\n",
    "for condition_pair, value in new_all_th_concat_spectrograms_coupled_exp_task_1.items():\n",
    "    labels = value['labels']\n",
    "    unique_labels = np.unique(labels)\n",
    "    total_labels = 0\n",
    "\n",
    "    #print(f\"\\nCondizione: \\033[1m{condition_pair}\\033[0m\")\n",
    "    for label in unique_labels:\n",
    "        label_indices = np.where(labels == label)[0]\n",
    "        start_idx = label_indices[0] if len(label_indices) > 0 else None\n",
    "        end_idx = label_indices[-1] if len(label_indices) > 0 else None\n",
    "        total_labels += len(label_indices)\n",
    "\n",
    "        #print(f\"  Etichetta \\033[1m{label}\\033[0m: Indici \\033[1m{start_idx}-{end_idx}\\033[0m \"\n",
    "        #      f\"(Totale Etichette: \\033[1m{len(label_indices)}\\033[0m)\")\n",
    "\n",
    "    #print(f\"Totale etichette (0 e 1): \\033[1m{total_labels}\\033[0m\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf57fc8-f279-443f-add5-775d38239e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('finito')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51890b2a-7912-4b5e-9d1a-96cb86d01104",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_all_th_concat_spectrograms_coupled_exp_task_1['rest_vs_left_fist'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23e48ec-b91a-4527-9724-bcc7a2a8aab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.unique(new_all_th_concat_spectrograms_coupled_exp_task_1['rest_vs_left_fist']['labels'], return_counts = True))\n",
    "print()\n",
    "print(np.unique(new_all_th_concat_spectrograms_coupled_exp_task_1['rest_vs_right_fist']['labels'], return_counts = True))\n",
    "print()\n",
    "print(np.unique(new_all_th_concat_spectrograms_coupled_exp_task_1['left_fist_vs_right_fist']['labels'], return_counts = True))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d4fc9108-7fe3-4398-8742-f73062d23a2f",
   "metadata": {
    "tags": []
   },
   "source": [
    "#new_concatenated_dictionaries.keys()\n",
    "#new_concatenated_dictionaries['theta'].keys()\n",
    "#new_concatenated_dictionaries['theta']['baseline_vs_th_resp'].keys()\n",
    "#np.unique(new_concatenated_dictionaries['theta']['baseline_vs_th_resp']['labels'], return_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d7f930-1241-45a3-9a3b-79f26b35a14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Ecco un piccolo snippet che, per ciascuna coppia di condizioni in new_all_th_concat_spectrograms_coupled_exp_task_1, \n",
    "stampa per ogni valore di label (0 e 1) l’indice di partenza e quello di fine nel vettore labels:\n",
    "\n",
    "Come funziona\n",
    "\n",
    "np.unique(labels) restituisce i valori distinti (ad es. [0, 1]).\n",
    "\n",
    "Per ciascun valore val, np.where(labels == val)[0] trova tutti gli indici in cui labels è uguale a val.\n",
    "\n",
    "Con .min() e .max() ricavi il primo e l’ultimo indice di ciascun blocco.\n",
    "\n",
    "Se vuoi anche vedere tutte le sott‐sequenze (ad es. se le label non sono concatenate in un unico blocco), \n",
    "puoi invece usare [itertools.groupby] o scorrere i idxs alla ricerca di “buchi”. \n",
    "\n",
    "Ma nel tuo caso — visto che hai prima aggiunto tutti gli zero e poi tutti gli uno — vedrai sempre un singolo intervallo per ciascuna label.\n",
    "\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "for cond_pair, cond_data in new_all_th_concat_spectrograms_coupled_exp_task_1.items():\n",
    "    labels = np.array(cond_data['labels'])\n",
    "    print(f\"\\n=== {cond_pair} ===\")\n",
    "    for val in np.unique(labels):\n",
    "        idxs = np.where(labels == val)[0]\n",
    "        start, end = idxs.min(), idxs.max()\n",
    "        print(f\"  label {val}: indices {start} → {end} (count = {len(idxs)})\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb3a904-890f-43f0-8317-74efcf077ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cond_pair, cond_data in new_all_th_concat_spectrograms_coupled_exp_task_1.items():\n",
    "    data = cond_data['data']      # shape: (n_trials, ...)\n",
    "    labels = cond_data['labels']  # shape: (n_trials,)\n",
    "    print(f\"{cond_pair}:\")\n",
    "    print(f\"  data shape  = {data.shape}\")\n",
    "    print(f\"  labels len  = {len(labels)}\\n\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4340c9b7-9f31-4de8-b0ad-8ab3bda8c8e6",
   "metadata": {
    "tags": []
   },
   "source": [
    "##NEW OFFICIAL VERSION!\n",
    "\n",
    "#CON DICT_NAME!\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def concatenate_all_single_subj_wavelets_coupled_experimental_conditions_th(data_structure, wavelet_levels, conditions, prefix):\n",
    "    \n",
    "    \"\"\"\n",
    "    Concatena i dati e le etichette per ogni condizione sperimentale da una struttura dati con un livello in più,\n",
    "    dove questo livello rappresenta le diverse coppie di condizioni sperimentali iterate nel ciclo ossia\n",
    "    \n",
    "    'baseline_vs_th_resp', 'baseline_vs_pt_resp', 'baseline_vs_shared_resp', \n",
    "    'th_resp_vs_pt_resp', 'th_resp_vs_shared_resp', 'pt_resp_vs_shared_resp'\n",
    "    \n",
    "    ordinandoli anche per etichetta.\n",
    "    \n",
    "    Questo perché ogni array di labels avrà sempre o 0 od 1 come etichette,\n",
    "    dato che son coppie di condizioni sperimentali\n",
    "\n",
    "    Parameters:\n",
    "        data_structure (dict): La struttura dati di input che contiene i dati per soggetti e condizioni.\n",
    "        conditions (list): Le condizioni sperimentali (chiavi del secondo livello) da processare.\n",
    "        prefix (str): Il prefisso del nome dinamico del dizionario.\n",
    "        \n",
    "\n",
    "    Returns:\n",
    "        dict: Un dizionario contenente i nuovi dizionari con \n",
    "        i dati concatenati e le etichette per ogni coppia di condizioni sperimentali\n",
    "    \n",
    "    \"\"\"\n",
    "        \n",
    "        \n",
    "    # Dizionario per contenere i dati concatenati di tutti i soggetti\n",
    "    all_subj_data_by_coupled_cond = {}\n",
    "    \n",
    "    # Itera su ogni livello di ricostruzione wavelet ('theta', 'delta', 'theta_strict')\n",
    "    \n",
    "    for reconstruction_level in wavelet_levels:\n",
    "        \n",
    "        all_subj_data_by_coupled_cond[reconstruction_level] = {}  # Struttura annidata per livello\n",
    "\n",
    "        # Itera su ogni coppia di condizioni sperimentali\n",
    "        for condition_pair in conditions:\n",
    "            \n",
    "            #Dizionari per raccogliere dati e labels ordinati per ogni coppia di condizioni sperimentali\n",
    "            # che è dinamico, per ogni coppia di condizioni sperimentali \n",
    "            #(quindi si ricreeranno passando alla condizione sperimentale successiva!)\n",
    "            \n",
    "            data_by_label = {}\n",
    "            labels_by_label = {}\n",
    "            shape_labels_per_subject = {0: [], 1: []}  # Inizializza il dizionario per 0 e 1\n",
    "\n",
    "            # Itera su tutti i soggetti\n",
    "            # In questo caso, itera sulle chiavi di ogni soggetto\n",
    "\n",
    "            # Quindi prenderà, per la relativa coppia di condizioni sperimentali di ogni soggetto,\n",
    "            # i dati e le labels di quel soggetto, per quella relativa coppia di condizioni sperimentali\n",
    "            \n",
    "            for subject_key in data_structure.keys():\n",
    "                \n",
    "                # Controlla se il livello di ricostruzione esiste per il soggetto\n",
    "                if reconstruction_level not in data_structure[subject_key]:\n",
    "                    continue\n",
    "                    \n",
    "                # Controlla se il livello di ricostruzione esiste per il soggetto\n",
    "                if condition_pair not in data_structure[subject_key][reconstruction_level]:\n",
    "                    continue\n",
    "                \n",
    "                # Qui estrae i dati e le labels per questa condizione sperimentale di quel soggettio lì\n",
    "                subject_data = data_structure[subject_key][reconstruction_level][condition_pair]['data']\n",
    "                subject_labels = data_structure[subject_key][reconstruction_level][condition_pair]['labels']\n",
    "                \n",
    "                # Trova le etichette uniche e gli indici corrispondenti per quella coppia di condizioni sperimentali lì,\n",
    "                # Ossia, potrà trovare gli 0 e gli 1 \n",
    "                \n",
    "                unique_labels = np.unique(subject_labels)\n",
    "                \n",
    "                #A quel punto, per ognuna delle due labels trovate per quella coppia di condizioni sperimentali lì\n",
    "                #Che saranno sempre o 0 o 1\n",
    "                \n",
    "                for label in unique_labels:\n",
    "                    \n",
    "                    # Trova gli indici dei dati corrispondenti a questa etichetta\n",
    "                    # Una volta per lo 0 ed una volta per l' 1\n",
    "                    \n",
    "                    label_indices = np.where(subject_labels == label)[0]\n",
    "                    \n",
    "                    # A quel punto, estrae i dati e le labels per questi indici\n",
    "                    # Una volta per lo 0 ed una volta per l' 1\n",
    "                    \n",
    "                    data_for_label = subject_data[label_indices]\n",
    "                    labels_for_label = subject_labels[label_indices]\n",
    "                    \n",
    "                    # A quel punto, per ogni soggetto, per ogni condzione sperimentale, \n",
    "                    # per quelle due labels là (sempre presenti, per ogni coppia di condizioni sperimentali)\n",
    "                    # Una volta per lo 0 ed una volta per l' 1\n",
    "\n",
    "                    #Andrà a creare per ogni etichetta, una chiave che si chiamerà \n",
    "                    #o 0 od 1 (inizialmente, vuoto -> perché deve esser inizializzato)\n",
    "                    #E poi, dopo, ci appenderà le labels \n",
    "                     # Una volta per lo 0 ed una volta per l' 1\n",
    "                    #  Di quel soggetto per quella coppia di condizioni sperimentali iterate a quel momento\n",
    "                    \n",
    "                    #Aggiunge ai dizionari globali, creando la chiave se non esiste\n",
    "                    if label not in data_by_label:\n",
    "                        data_by_label[label] = []\n",
    "                        labels_by_label[label] = []\n",
    "\n",
    "                    data_by_label[label].append(data_for_label)\n",
    "                    labels_by_label[label].append(labels_for_label)\n",
    "                    \n",
    "                    # **Salva la shape delle etichette per il soggetto corrente**\n",
    "                    shape_labels_per_subject[label].append(labels_for_label.shape[0]) # Aggiungi solo la dimensione (numero di etichette)\n",
    "\n",
    "                    #print(f\"Soggetto: {subject_key}, Livello: {reconstruction_level}, Condizione: {condition_pair}, \"\n",
    "                    #      f\"Etichetta: {label}, Shape: {labels_for_label.shape[0]}\")\n",
    "                    \n",
    "                    # **Aggiungi un print di controllo per ogni soggetto**\n",
    "                    print(f\"Soggetto: {subject_key}, Livello: {reconstruction_level}, Condizione: {condition_pair}, Etichetta: {label}, Shape: {labels_for_label.shape[0]}\")\n",
    "            \n",
    "            \n",
    "            #*** *** *** *** *** *** *** *** *** *** *** *** *** *** ***\n",
    "            \n",
    "            # Dopodiché, vado a creare invece i dizionari che conterranno\n",
    "            # Le concatenazioni, di dati e labels corrispondenti, di tutti i soggetti per cui l'etichetta era \n",
    "            # o 0 od 1 \n",
    "\n",
    "            # Di conseguenza, qui dentro dovrei avere, per ogni coppia di condizioni sperimentali\n",
    "            # Tutti gli 0 ed 1 (ed i relativi dati corrispondenti)\n",
    "            # di tutti i soggetti, ma concatenati\n",
    "\n",
    "            concatenated_data_by_label = {}\n",
    "            concatenated_labels_by_label = {}\n",
    "\n",
    "            #for label in data_by_label.keys():\n",
    "            #    if len(data_by_label[label]) > 0:  # Evita errori di concatenazione\n",
    "            #        concatenated_data_by_label[label] = np.vstack(data_by_label[label])\n",
    "            #        concatenated_labels_by_label[label] = np.hstack(labels_by_label[label])\n",
    "            \n",
    "            for label in data_by_label.keys():\n",
    "                concatenated_data_by_label[label] = np.vstack(data_by_label[label])\n",
    "                concatenated_labels_by_label[label] = np.hstack(labels_by_label[label])\n",
    "\n",
    "                # **Calcolare la shape totale delle etichette**\n",
    "                #total_labels_0 = np.sum(1 for subject_labels in labels_by_label[label] if 0 in subject_labels)\n",
    "                #total_labels_1 = np.sum(1 for subject_labels in labels_by_label[label] if 1 in subject_labels)\n",
    "                #total_labels = total_labels_0 + total_labels_1\n",
    "\n",
    "                # **Determinare gli indici delle etichette 0 e 1 nell'array finale**\n",
    "\n",
    "                # Gli indici delle etichette 0\n",
    "                indices_labels_0 = np.where(concatenated_labels_by_label[label] == 0)[0]\n",
    "\n",
    "                # Gli indici delle etichette 1\n",
    "                indices_labels_1 = np.where(concatenated_labels_by_label[label] == 1)[0]\n",
    "                \n",
    "                # Indici iniziale e finale per le etichette 0 e 1\n",
    "                start_idx_0 = indices_labels_0[0] if len(indices_labels_0) > 0 else None\n",
    "                end_idx_0 = indices_labels_0[-1] if len(indices_labels_0) > 0 else None\n",
    "                start_idx_1 = indices_labels_1[0] if len(indices_labels_1) > 0 else None\n",
    "                end_idx_1 = indices_labels_1[-1] if len(indices_labels_1) > 0 else None\n",
    "\n",
    "\n",
    "                # **Print finale per verificare la concatenazione per ogni label**\n",
    "                #print(f\"\\nCondizione: \\033[1m{condition_pair}\\033[0m, Etichetta: {label}\")\n",
    "                #print(f\"  - Shape dei dati concatenati per \\033[1m{label}\\033[0m: {concatenated_data_by_label[label].shape}\")\n",
    "                #print(f\"  - Shape delle etichette concatenate per \\033[1m{label}\\033[0m: {concatenated_labels_by_label[label].shape}\")\n",
    "\n",
    "                # **Stampa la lista delle shapes delle etichette per ogni soggetto per questa etichetta**\n",
    "                #print(f\"\\n  - Shape delle etichette per soggetto (per etichetta {label}): {shape_labels_per_subject[label]}\\n\")\n",
    "\n",
    "\n",
    "                # **Stampa il conteggio totale delle etichette**\n",
    "                #print(f\"\\n  - Totale delle etichette 0: {total_labels_0}\")\n",
    "                #print(f\"  - Totale delle etichette 1: {total_labels_1}\")\n",
    "                #print(f\"  - Totale delle etichette per la condizione: {total_labels}\\n\")\n",
    "\n",
    "                # **Stampa gli indici per le etichette 0 e 1**\n",
    "                # **OSSIA --> Stampa gli indici per l'etichetta corrente**\n",
    "\n",
    "                #if label == 0:\n",
    "                #    print(f\"\\n  - Indici per etichetta 0: Inizio = {start_idx_0}, Fine = {end_idx_0}\")\n",
    "                #else:\n",
    "                #    print(f\"  - Indici per etichetta 1: Inizio = {start_idx_1}, Fine = {end_idx_1}\\n\")\n",
    "\n",
    "\n",
    "                #print(f\"\\n  - Indici per etichetta 0: Inizio = {start_idx_0}, Fine = {end_idx_0}\")\n",
    "                #print(f\"  - Indici per etichetta 1: Inizio = {start_idx_1}, Fine = {end_idx_1}\")\n",
    "\n",
    "\n",
    "            #ARRIVATI FINO A QUI, abbiamo che siccome stiamo iterando prima per tutti gli 0 e poi per tutti gli 1\n",
    "            #Significa che, assumendo che siamo dentro 'baseline_vs_th_resp' e che \n",
    "\n",
    "            #'baseline' sia rappresentato dalle etichette 0\n",
    "            #'th_resp' sia rappresentato dalle etichette 1\n",
    "\n",
    "            #Al PRIMO ciclo avrò che:\n",
    "\n",
    "            #con concatenated_data_by_label[label] ho solo concatenato tutti i dati (di 'baseline' per 'baseline_vs_th_resp' di tutti i soggetti)\n",
    "            #con concatenated_labels_by_label[label] ho solo concatenato tutti gli 0 (di 'baseline' per 'baseline_vs_th_resp'di tutti i soggetti)\n",
    "\n",
    "            #Al SECONDO ciclo avrò che:\n",
    "\n",
    "            #con concatenated_data_by_label[label] ho solo concatenato tutti i dati (di 'th_resp' per 'baseline_vs_th_resp'  di tutti i soggetti)\n",
    "            #con concatenated_labels_by_label[label] ho solo concatenato tutti gli 0 (di 'th_resp' per 'baseline_vs_th_resp' di tutti i soggetti)\n",
    "\n",
    "            #Quindi mi manca ancora \n",
    "\n",
    "            #A) CONCATENARE I DATI:\n",
    "\n",
    "            #1)prima tutti i dati (di 'baseline' per 'baseline_vs_th_resp' di tutti i soggetti) \n",
    "\n",
    "            #CON\n",
    "\n",
    "            #2)tutti i dati (di 'th_resp' per 'baseline_vs_th_resp'  di tutti i soggetti)\n",
    "\n",
    "            #che verrà fatto dentro all_data (che è anch'esso una variabile dinamica!)\n",
    "\n",
    "            #B) CONCATENARE LE LABELS:\n",
    "\n",
    "            #1)prima tutti le labels (di 'baseline' per 'baseline_vs_th_resp' di tutti i soggetti) \n",
    "\n",
    "            #CON\n",
    "\n",
    "            #2)tutti le labels (di 'th_resp' per 'baseline_vs_th_resp' di tutti i soggetti)\n",
    "\n",
    "            #che verrà fatto dentro all_labels (che è anch'esso una variabile dinamica!)\n",
    "\n",
    "            # Liste per raccogliere dati e labels di tutte le etichette\n",
    "\n",
    "            # Qui dentro, invece, dov con\n",
    "            \n",
    "            all_data = []\n",
    "            all_labels = []\n",
    "\n",
    "            for label in concatenated_data_by_label.keys():\n",
    "                all_data.append(concatenated_data_by_label[label])\n",
    "                all_labels.append(concatenated_labels_by_label[label])\n",
    "            \n",
    "            #Alla fine, qui dentro avrò che, PER OGNI COPPIA DI CONDIZIONI SPERIMENTALI\n",
    "\n",
    "\n",
    "            #'final_data' dovrebbe avere \n",
    "                #- prima tutti i dati di tutti i soggetti associati all'etichetta 0 \n",
    "                #- e poi tutti i dati di tutti i soggetti associati all'etichetta 1\n",
    "\n",
    "            #'final_labels' dovrebbe avere \n",
    "                #- prima tutte le labels di tutti i soggetti associati all'etichetta 0\n",
    "                #- e poi tutte tutte le labels di tutti soggetti associati all'etichetta 1...\n",
    "                \n",
    "            if all_data:  # Evita errori di concatenazione se non ci sono dati\n",
    "                final_data = np.vstack(all_data)\n",
    "                final_labels = np.hstack(all_labels)\n",
    "                \n",
    "                # Nome dinamico del dizionario\n",
    "                dict_name = f\"{prefix}{reconstruction_level}_{condition_pair}\"\n",
    "                \n",
    "                #all_subj_data_by_coupled_cond[reconstruction_level][condition_pair] = {\n",
    "                #    'data': final_data,\n",
    "                #    'labels': final_labels\n",
    "                #}\n",
    "                \n",
    "                all_subj_data_by_coupled_cond[dict_name]= {\n",
    "                    'data': final_data,\n",
    "                    'labels': final_labels\n",
    "                }\n",
    "                \n",
    "\n",
    "    print(\"\\n\\033[1mIntervalli di indici per ciascuna etichetta nei sotto-dizionari:\\033[0m\\n\")\n",
    "\n",
    "    for reconstruction_level, conditions_dict in all_subj_data_by_coupled_cond.items():\n",
    "        for condition_pair, value in conditions_dict.items():\n",
    "            labels = value['labels']\n",
    "            unique_labels = np.unique(labels)\n",
    "            total_labels = 0\n",
    "\n",
    "            print(f\"\\nLivello Wavelet: {reconstruction_level}, Condizione: {condition_pair}\")\n",
    "            for label in unique_labels:\n",
    "                label_indices = np.where(labels == label)[0]\n",
    "                start_idx = label_indices[0] if len(label_indices) > 0 else None\n",
    "                end_idx = label_indices[-1] if len(label_indices) > 0 else None\n",
    "                total_labels += len(label_indices)\n",
    "\n",
    "                print(f\"  Etichetta \\033[1m{label}\\033[0m: Indici \\033[1m{start_idx}-{end_idx}\\033[0m \"\n",
    "                      f\"(Totale Etichette: \\033[1m{len(label_indices)}\\033[0m)\")\n",
    "\n",
    "            print(f\"Totale etichette (0 e 1): \\033[1m{total_labels}\\033[0m\\n\")\n",
    "\n",
    "    return all_subj_data_by_coupled_cond\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "176a134e-52a7-4b29-9289-80e526918078",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Parametri\n",
    "conditions = ['baseline_vs_th_resp', 'baseline_vs_pt_resp', 'baseline_vs_shared_resp',\n",
    "              'th_resp_vs_pt_resp', 'th_resp_vs_shared_resp', 'pt_resp_vs_shared_resp']\n",
    "\n",
    "\n",
    "wavelet_levels = ['theta', 'delta', 'theta_strict']\n",
    "\n",
    "prefix = \"new_all_th_concat_reconstructions_\"\n",
    "\n",
    "# Chiamata alla funzione\n",
    "new_concatenated_dictionaries = concatenate_all_single_subj_wavelets_coupled_experimental_conditions_th(\n",
    "    data_structure=new_subject_level_concatenations_coupled_exp_th,\n",
    "    wavelet_levels = wavelet_levels,\n",
    "    conditions=conditions,\n",
    "    prefix=prefix\n",
    ")\n",
    "\n",
    "# Stampa i risultati per verifica\n",
    "#print('\\n\\033[1mRISULTATO FINALE TUTTI I SOGGETTI TH\\033[0m') \n",
    "#for key, value in new_concatenated_dictionaries.items():\n",
    "#    print(f\"{key}:\")\n",
    "#    print(f\"  Dati: {value['data'].shape}\")\n",
    "#    print(f\"  Labels: {value['labels'].shape}\")\n",
    "\n",
    "\n",
    "print(\"\\n\\033[1mIntervalli di indici per ciascuna etichetta nei sotto-dizionari:\\033[0m\\n\")\n",
    "\n",
    "for dict_name, value in new_concatenated_dictionaries.items():\n",
    "    labels = value['labels']\n",
    "    unique_labels = np.unique(labels)\n",
    "    total_labels = 0\n",
    "\n",
    "    print(f\"\\nDizionario: {dict_name}\")  # Stampa il nome dinamico del dizionario\n",
    "    for label in unique_labels:\n",
    "        label_indices = np.where(labels == label)[0]\n",
    "        start_idx = label_indices[0] if len(label_indices) > 0 else None\n",
    "        end_idx = label_indices[-1] if len(label_indices) > 0 else None\n",
    "        total_labels += len(label_indices)\n",
    "\n",
    "        print(f\"  Etichetta \\033[1m{label}\\033[0m: Indici \\033[1m{start_idx}-{end_idx}\\033[0m \"\n",
    "              f\"(Totale Etichette: \\033[1m{len(label_indices)}\\033[0m)\")\n",
    "\n",
    "    print(f\"Totale etichette (0 e 1): \\033[1m{total_labels}\\033[0m\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e530b627-16ea-4ae9-bd23-e4ba33327d9e",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### STEP - Salvataggio Dataset di **All Single Therapists** EEG Data Spectrograms across **Couples of Experimental Conditions** INSIEME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad952a3c-40cc-42e1-8c9b-cd93c10130e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9483533a-62e0-4075-bd37-fdff617d4dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e687b2b-b400-4fa1-a2e9-7c3870173b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '/home/stefano/Interrogait/all_datas/Spectrograms_channels_frequencies_motor_tasks/'\n",
    "\n",
    "# Controlla se la cartella esiste, altrimenti la crea\n",
    "if not os.path.exists(base_path):\n",
    "    os.makedirs(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628d29db-c881-440f-80ae-366ff2bea5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Salvare l'intero dizionario annidato con pickle\n",
    "with open(f'{base_path}new_all_th_concat_spectrograms_coupled_exp_task_1_2d_grid_multiband.pkl', 'wb') as f:\n",
    "    pickle.dump(new_all_th_concat_spectrograms_coupled_exp_task_1, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9ba683-a1f2-44ce-8828-0521278a65dc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Impostazione **Weight & Biases DL Training** con **Rappresentazione Tempo-Frequenza dei miei dati EEG** a seconda del Dataset del Task scelto\n",
    "\n",
    "\n",
    "Notebook **\"Optimization Weight and Biases Time Domain EEG Signal\"**\n",
    "\n",
    "- Task 1: Motor Execution (Open and close right or left fist) - Unilateral - Runs 3, 7, 11 \n",
    "- Task 2: Motor Imagery (Imagine opening and closing right and left fists) - Unilateral - Runs 4, 8, 12 \n",
    "- Task 3: Motor Execution (Open and close both fists and feet) - Bilateral - Runs 5, 9, 13 \n",
    "- Task 4: Motor Imagery (Imagine opening and closing both fists and feet) - Bilateral - Runs 6, 10, 14 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf99c3e4-b58d-4693-96b7-2bb4d6ea9abc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### **Weight & Biases Login & REMOTE CHECKS - EEG Spectrograms - Time x Frequencies**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7417df88-6461-42ec-8993-f2f0a7d87763",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### **Weight & Biases Login PRECEDURA CORRETTA ✅ (CANCELLAZIONE RUNS e NON SWEEPS!) - EEG Spectrograms - Time x Frequencies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e969919d-7025-48c0-ae24-70b22b4be691",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Puoi usare l’API Python di W&B per elencare da remoto tutti i progetti di una certa entity (tuo utente o organizzazione).\n",
    "\n",
    "Ad esempio:\n",
    "\n",
    "'''\n",
    "\n",
    "import wandb\n",
    "\n",
    "# 1) autenticati (se non l’hai già fatto con wandb.login())\n",
    "# wandb.login()\n",
    "\n",
    "# 2) crea un’istanza dell’API\n",
    "api = wandb.Api()\n",
    "\n",
    "# 3) scegli la tua entity (nome utente o org). \n",
    "#    Se omesso, prende la tua entity di default.\n",
    "\n",
    "entity = 'stefano-bargione-universit-di-roma-tor-vergata'\n",
    "\n",
    "# 4) prendi la lista dei progetti\n",
    "projects = api.projects(entity=entity)\n",
    "\n",
    "# 5) stampa i nomi\n",
    "for proj in projects:\n",
    "    print(proj.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13123a3-bd02-4006-8ef0-bc0d42a93517",
   "metadata": {},
   "outputs": [],
   "source": [
    "###TUTTE ASSIEME\n",
    "\n",
    "\n",
    "import wandb\n",
    "\n",
    "# Nomi dei progetti\n",
    "project_names = [\n",
    "    'left_fist_vs_right_fist_spectrograms_new',\n",
    "    'rest_vs_right_fist_spectrograms_new',\n",
    "    'rest_vs_left_fist_spectrograms_new'\n",
    "]\n",
    "\n",
    "user_name = 'stefano-bargione-universit-di-roma-tor-vergata'\n",
    "\n",
    "# Connessione all'API di W&B\n",
    "api = wandb.Api()\n",
    "\n",
    "# Itera su tutti i progetti\n",
    "for project_name in project_names:\n",
    "    print(f\"\\nSelezione delle run per il progetto: \\033[1m{project_name}\\033[0m\")\n",
    "    \n",
    "    # Recupera tutte le run del progetto\n",
    "    runs = api.runs(f\"{user_name}/{project_name}\")\n",
    "    \n",
    "    # Salva gli ID delle run da eliminare\n",
    "    run_ids_to_delete = []\n",
    "    \n",
    "    for run in runs:\n",
    "        #print(f\"Estrazione run ID: {run.id} - Run Name: {run.name}\")\n",
    "        run_ids_to_delete.append(run.id)  # Aggiungi l'ID della run alla lista\n",
    "    \n",
    "    print(f\"\\nTotale runs da eliminare: \\033[1m{len(run_ids_to_delete)}\\033[0m\")\n",
    "    \n",
    "    # Elimina le run\n",
    "    for run_id in run_ids_to_delete:\n",
    "        run = api.run(f\"{user_name}/{project_name}/{run_id}\")\n",
    "        run.delete()  # Elimina la run\n",
    "        #print(f\"Eliminata la run con ID: {run_id}\")\n",
    "    print(f\"Eliminazione runs completata\")\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7536a90f-3c86-4b58-9065-5552372d76a4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### **IO**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d47769-3a7d-44af-8e23-1ad252f56af0",
   "metadata": {},
   "source": [
    "Prima avevo avviata una ricerca di iper-parametri con API da jupyter e avevo impostato la creazione di cartelle per ogni combinazione di dati...\n",
    "\n",
    "tuttavia, ora quando andava ho notato che le cartelle non so state create alle fine.. come mai? è dovuto ad un overload di sovraccarica o è semplicemente un ritardo dovuto all'esecuzione di grande mole di dati da remoto tra l'altro con l'api che ritarda la sincronizzazione delle operazioni del codice su quello che dovrei vedere su jupyter? \n",
    "\n",
    "è fondamentale che le cartelle ed i vari files .pkl del mio codice si salvino, perché poi io le richiamo successivamente per estrarmi gli iper-parametri migliori di ogni ottimizzazione fatta.. devo gestire le risorse di calcolo in modo più equilibrato, affinché le operazioni di salvataggio vengano eseguite correttamente?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4b1979-abc6-468f-ab80-e4728b205bed",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### **CHATGPT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99379ce0-2a4e-41eb-a4f7-7b01069490b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "È molto più probabile che la cartella ci sia già, ma:\n",
    "\n",
    "Non si trovi sotto la radice che Jupyter ti mostra (di solito /mnt/data), bensì in /home/stefano/..., per cui il file‑browser non la “vede” fino a quando non navighi esplicitamente lì.\n",
    "\n",
    "O che tu abbia settato WANDB_DIR dopo l’import wandb, quindi wandb abbia già inizializzato il suo percorso di default.\n",
    "\n",
    "In ogni caso non è un problema di “troppa mole di dati che rallenta” o di W&B che perde file, bensì di:\n",
    "\n",
    "percorso sbagliato in cui guardi\n",
    "\n",
    "sincronizzazione asincrona di wandb (che salva localmente in run.dir e lo invia al cloud in background)\n",
    "\n",
    "Controlla davvero se la cartella esiste\n",
    "Nella cella del notebook, esegui:\n",
    "\n",
    "bash\n",
    "Copia\n",
    "Modifica\n",
    "!ls -l /home/stefano/Interrogait/WB_spectrograms_analyses_motor_task_1\n",
    "o più genericamente\n",
    "\n",
    "bash\n",
    "Copia\n",
    "Modifica\n",
    "!find /home/stefano/Interrogait -maxdepth 2 -type d\n",
    "Se la cartella esiste veramente, basta che la navighi nel file‑browser (“…” in alto a sinistra → “Change directory” → incolli quel path) o che tu salvi direttamente in /mnt/data/... così la vedi subito.\n",
    "\n",
    "Come forzare wandb a usare la cartella che vuoi\n",
    "Metti prima di ogni import wandb queste due righe:\n",
    "\n",
    "python\n",
    "Copia\n",
    "Modifica\n",
    "import os\n",
    "WB_dir = \"/mnt/data/WB_spectrograms_analyses_motor_task_1\"\n",
    "os.makedirs(WB_dir, exist_ok=True)\n",
    "os.environ[\"WANDB_DIR\"] = WB_dir\n",
    "Poi:\n",
    "\n",
    "python\n",
    "Copia\n",
    "Modifica\n",
    "import wandb\n",
    "wandb.login()\n",
    "run = wandb.init(\n",
    "    project=\"spectrograms-analyses-motor-task-1\",\n",
    "    dir=WB_dir,         # <–– anche qui puoi sovrascrivere il path\n",
    "    resume=\"allow\"      # <–– se fai sweep/runs multipli\n",
    ")\n",
    "In questo modo:\n",
    "\n",
    "Wandb salverà localmente tutti i log e i file di run in WB_dir.\n",
    "\n",
    "Il file‑browser di Jupyter (che punta su /mnt/data) li vedrà immediatamente.\n",
    "\n",
    "Wandb poi sincronizzerà tutto in cloud, ma tu puoi lavorare “in locale” senza perdere nulla.\n",
    "\n",
    "Salvare i .pkl\n",
    "Quando salvi i tuoi .pkl all’interno della loop di hyperopt fai:\n",
    "\n",
    "python\n",
    "Copia\n",
    "Modifica\n",
    "out_path = os.path.join(WB_dir, f\"{run.id}__{combo_name}.pkl\")\n",
    "with open(out_path, \"wb\") as f:\n",
    "    pickle.dump(my_results, f)\n",
    "wandb.save(out_path)   # <–– forza wandb ad aggiungere questo file allo snapshot del run\n",
    "In questo modo:\n",
    "\n",
    "Il file viene scritto subito in WB_dir\n",
    "\n",
    "Viene collegato al run W&B (utile se poi fai wandb.restore)\n",
    "\n",
    "Verifica “a freddo”\n",
    "Dopo aver fatto partire i tuoi esperimenti, in un’altra cella puoi lanciare:\n",
    "\n",
    "bash\n",
    "Copia\n",
    "Modifica\n",
    "!ls -R /mnt/data/WB_spectrograms_analyses_motor_task_1\n",
    "oppure – da CLI –\n",
    "\n",
    "bash\n",
    "Copia\n",
    "Modifica\n",
    "wandb files <ENTITY>/<PROJECT>/<RUN_ID>\n",
    "per vedere l’elenco dei file che sono stati salvati/sincronizzati.\n",
    "\n",
    "Se invece proprio non trovi nulla, controlla:\n",
    "\n",
    "che non ci siano errori silenziosi (un try/except: pass che assorbe i problemi di I/O)\n",
    "\n",
    "che tu stia eseguendo la cella di creazione delle cartelle prima di qualunque wandb.init\n",
    "\n",
    "che non stia scrivendo in un container o in un filesystem ephemeral diverso da quello mostrato dal file‑browser\n",
    "\n",
    "Con questa configurazione dovresti avere:\n",
    "\n",
    "Cartelle create sotto /mnt/data/WB_spectrograms_analyses_motor_task_1\n",
    "\n",
    "I tuoi .pkl visibili subito in Jupyter\n",
    "\n",
    "Wandb che continua a fare upload in background senza perderli\n",
    "\n",
    "Fammi sapere se così riesci a trovarli ed evitare di perdere i risultati dei tuoi sweep!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7649d5f0-6605-49ea-9f5e-5e799a045106",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Optimization Weight and Biases - EEG Spectrograms - Frequency x Time  - Con CNN2D_LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850dc7e0-3903-4f53-943f-9e1eb82cfcaa",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### **Weight & Biases Procedure FINAL SEQUENCE OF STEPS - EEG Spectrograms - Time x Frequencies ONLY HYPER-PARAMS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ec911a-7a8a-4989-afe4-7b96ab67c20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Library Importing \n",
    "    \n",
    "import os\n",
    "import math\n",
    "import copy as cp \n",
    "\n",
    "import tqdm\n",
    "from tqdm import tqdm\n",
    "\n",
    "import random \n",
    "\n",
    "#import mne \n",
    "import scipy\n",
    "\n",
    "import numpy as np  # NumPy per operazioni numeriche\n",
    "import matplotlib.pyplot as plt  # Matplotlib per la visualizzazione dei dati\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import random\n",
    "\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8dd209b-0cbb-4297-bde7-e59df15f02d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '/home/stefano/Interrogait/all_datas/Spectrograms_motor_tasks/'\n",
    "\n",
    "# Controlla se la cartella esiste, altrimenti la crea\n",
    "if not os.path.exists(base_path):\n",
    "    os.makedirs(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4277d3a8-e182-414d-8f52-197a426670d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "base_path = '/home/stefano/Interrogait/all_datas/Spectrograms_motor_tasks/'\n",
    "    \n",
    "# Caricare l'intero dizionario annidato con pickle\n",
    "with open(f'{base_path}new_all_th_concat_spectrograms_coupled_exp_task_1.pkl', 'rb') as f:\n",
    "    new_all_th_concat_spectrograms_coupled_exp_task_1 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f42f70-c798-4f77-ab11-8dd180d79507",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_all_th_concat_spectrograms_coupled_exp_task_1.keys() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff466de-a96d-4394-9663-243981322086",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_all_th_concat_spectrograms_coupled_exp_task_1['rest_vs_right_fist'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4294ac6e-9f6d-4809-9468-8dd9fcb9c969",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new_all_th_concat_spectrograms_coupled_exp_task_1['rest_vs_left_fist']['data'].shape)\n",
    "print()\n",
    "print(new_all_th_concat_spectrograms_coupled_exp_task_1['rest_vs_right_fist']['data'].shape)\n",
    "print()\n",
    "print(new_all_th_concat_spectrograms_coupled_exp_task_1['left_fist_vs_right_fist']['data'].shape)\n",
    "print()\n",
    "print(np.unique(new_all_th_concat_spectrograms_coupled_exp_task_1['rest_vs_left_fist']['labels'], return_counts = True))\n",
    "print()\n",
    "print(np.unique(new_all_th_concat_spectrograms_coupled_exp_task_1['rest_vs_right_fist']['labels'], return_counts = True))\n",
    "print()\n",
    "print(np.unique(new_all_th_concat_spectrograms_coupled_exp_task_1['left_fist_vs_right_fist']['labels'], return_counts = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5039f7-48e4-48f1-8d46-78ed4072a607",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### **Utils Functions - EEG Spectrograms - Time x Frequencies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48437c5-f3cd-4806-b692-3b2b115c27ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "QUI DENTRO HO CONFIGURATO \n",
    "LE FUNZIONI DI CONTROLLO DELLE STRINGHE \n",
    "PER IL SALVATAGGIO DELLE PERFORMANCE DEL MODELLO\n",
    "NELLE RELATIVE SUBFOLDERS\n",
    "\n",
    "(I.E., get_subfolder_from_key, get_subfolder_from_key_hyper)\n",
    "\n",
    "IN MODO CHE SI LEGHINO ALLA CHIAVE 'STANDARDIZATION' DELL'OGGETTO SWEEP_CONFIG\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "def load_data(data_type, category, subject_type, condition = \"th_resp_vs_pt_resp\"):\n",
    "    \"\"\"\n",
    "    Carica i dati EEG dalla directory appropriata, già salvati con la finestra temporale (0°-640° punto)\n",
    "\n",
    "    Parameters:\n",
    "    - data_type: str, \"spectrograms\",\n",
    "    - category: str, \"task_1\"\n",
    "    - subject_type: str, \"th\" (terapisti)\n",
    "    - condition: str, condizione sperimentale da selezionare\n",
    "    \n",
    "\n",
    "    Returns:\n",
    "    - X: Dati EEG sotto-selezionati (50°-300° punto e canali selezionati se applicabile)\n",
    "    - y: Etichette corrispondenti\n",
    "    \"\"\"\n",
    "\n",
    "    # Definizione dei percorsi base\n",
    "    base_paths = {\n",
    "        \"spectrograms\": {\n",
    "            \"familiar\": \"/home/stefano/Interrogait/all_datas/Spectrograms_motor_tasks/\"\n",
    "            #\"unfamiliar\": \"/home/stefano/Interrogait/all_datas/Unfamiliar_Spectrograms/\"\n",
    "        },\n",
    "    }\n",
    "\n",
    "    # Seleziona il path corretto\n",
    "    base_path = base_paths[data_type][category]\n",
    "\n",
    "    # Determina il nome del file corretto\n",
    "    if data_type in [\"spectrograms\"]:\n",
    "        filename = f\"new_all_{subject_type}_concat_spectrograms_coupled_exp_task_1.pkl\"\n",
    "    else:\n",
    "        raise ValueError(\"data_type non valido!\")\n",
    "        \n",
    "    # Caricamento del file\n",
    "    filepath = base_path + filename\n",
    "    \n",
    "    with open(filepath, \"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "    \n",
    "    '''\n",
    "    Per i dati spectrogram, la funzione seleziona la condizione desiderata (i.e., condition = \"th_resp_vs_pt_resp\") \n",
    "    e preleva i dati e le etichette associati a quella condizione.\n",
    "    '''\n",
    "    \n",
    "    # Selezione della finestra temporale e delle etichette\n",
    "    X = data[condition][\"data\"]\n",
    "    y = data[condition][\"labels\"]\n",
    "\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "\n",
    "def select_channels(data, channels=[12, 30, 48]):\n",
    "    \"\"\"\n",
    "    Seleziona i canali EEG specificati SOLO per i dati 1-20 e 1-45.\n",
    "\n",
    "    Parameters:\n",
    "    - data: array NumPy, dati EEG con shape (n_trials, n_channels, n_timepoints)\n",
    "    - channels: list, indici dei canali da selezionare\n",
    "\n",
    "    Returns:\n",
    "    - data filtrato sui canali specificati\n",
    "    \"\"\"\n",
    "    return data[:, channels, :]\n",
    "\n",
    "\n",
    "# Funzione per train-test split\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "\n",
    "def split_data(X, y, test_size=0.2, val_size=0.2):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=val_size, random_state=42)\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test\n",
    "\n",
    "'''ATTENZIONE CAMBIATA'''\n",
    "# Funzione per standardizzare i dati\n",
    "def standardize_data(X_train, X_val, X_test, eps = 1e-8):\n",
    "    \n",
    "    mean = X_train.mean(axis=0, keepdims=True)\n",
    "    std = X_train.std(axis=0, keepdims=True)\n",
    "    \n",
    "    X_train = (X_train - mean) / (std + eps)\n",
    "    X_val = (X_val - mean) / (std + eps)\n",
    "    X_test = (X_test - mean) / (std + eps)\n",
    "    \n",
    "    return X_train, X_val, X_test\n",
    "\n",
    "\n",
    "\n",
    "# Import modelli (definisci le classi CNN1D, ReadMEndYou, ReadMYMind)\n",
    "#from models import CNN1D, ReadMEndYou, ReadMYMind  # Assicurati di avere i modelli definiti in 'models.py'\n",
    "\n",
    "# Funzione per inizializzare i modelli\n",
    "def initialize_models():\n",
    "    #model = CNN1D(input_channels=3, num_classes=2)\n",
    "    #model_CNN = CNN2D(input_channels=3, num_classes=2)\n",
    "    \n",
    "    model_CNN = CNN2D(input_channels=64, num_classes=2)\n",
    "    \n",
    "    #model_LSTM = ReadMEndYou(input_size=3, hidden_sizes=[24, 48, 62], output_size=2, bidirectional=True)\n",
    "    #model_LSTM = ReadMEndYou(input_size=3 * 26, hidden_sizes=[24, 48, 62], output_size=2, bidirectional=True)\n",
    "    \n",
    "    model_LSTM = ReadMEndYou(input_size=64 * 81, hidden_sizes=[24, 48, 62], output_size=2, bidirectional=True)\n",
    "    \n",
    "    #model_Transformer = ReadMYMind(num_channels=3, seq_length=250, d_model=16, num_heads=4, num_layers=2, num_classes=2)\n",
    "    #model_Transformer = ReadMYMind(d_model=16, num_heads=4, num_layers=2, num_classes=2, channels=3, freqs=26)\n",
    "    \n",
    "    model_Transformer = ReadMYMind(d_model=16, num_heads=4, num_layers=2, num_classes=2, channels=64, freqs=81)\n",
    "    \n",
    "    \n",
    "    return model_CNN, model_LSTM, model_Transformer\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "\n",
    "'''\n",
    "Questa funzione prende in input i dati di training, validation e test, \n",
    "il tipo di modello scelto e la dimensione del batch. Si occupa di:\n",
    "\n",
    "Calcolare i pesi delle classi.\n",
    "Convertire i dati in tensori PyTorch, con le opportune trasformazioni per CNN, LSTM o Transformer.\n",
    "Creare i dataset e i dataloader per il training.\n",
    "'''\n",
    "\n",
    "\n",
    "def prepare_data_for_model(X_train, X_val, X_test, y_train, y_val, y_test, model_type, batch_size=48):\n",
    "    \n",
    "    # Calcolo dei pesi delle classi\n",
    "    class_weights = compute_class_weight(class_weight='balanced', \n",
    "                                         classes=np.unique(y_train), \n",
    "                                         y=y_train)\n",
    "    \n",
    "    class_weights_tensor = torch.tensor(class_weights, dtype=torch.float32)\n",
    "    class_weights_tensor = class_weights_tensor.to(dtype=torch.float32, device=device)\n",
    "    \n",
    "    # Conversione delle etichette in interi\n",
    "    y_train = y_train.astype(int)\n",
    "    y_val = y_val.astype(int)\n",
    "    y_test = y_test.astype(int)\n",
    "    \n",
    "    # Conversione dei dati in tensori PyTorch con permutazione se necessario\n",
    "    \n",
    "    '''OCCHIO QUI CAMBIATO'''\n",
    "    #if model_type == \"CNN2D\":\n",
    "    \n",
    "    if model_type == \"CNN2D_LSTM_TF\":\n",
    "        X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "        X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "        X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "    \n",
    "    #BiLSTM (ReadMEndYou):\n",
    "    #Ora il modello si aspetta l’input con shape (batch, canali, frequenze, tempo) \n",
    "    #e, al suo interno, \n",
    "    #esegue la permutazione per avere il tempo come dimensione sequenziale. \n",
    "    #Non serve quindi applicare una permutazione anche qui.\n",
    "    \n",
    "    elif model_type == \"BiLSTM\":\n",
    "            \n",
    "        X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "        X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "        X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "    \n",
    "    #Transformer (ReadMYMind):\n",
    "    #Analogamente, il modello gestisce internamente la riorganizzazione dell’input, quindi lasciamo i dati nella loro forma originale.\n",
    "    elif model_type == \"Transformer\":\n",
    "        X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "        X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "        X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(\"Modello non riconosciuto. Scegli tra 'CNN', 'LSTM' o 'Transformer'.\")\n",
    "    \n",
    "    # Conversione delle etichette in tensori\n",
    "    y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "    y_val_tensor = torch.tensor(y_val, dtype=torch.long)\n",
    "    y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "    \n",
    "    # Creazione dei dataset\n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "    test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "    \n",
    "    # Creazione dei dataloader\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    return train_loader, val_loader, test_loader, class_weights_tensor\n",
    "\n",
    "\n",
    "\n",
    "# Funzione per determinare a quale subfolder appartiene la chiave\n",
    "def get_subfolder_from_key(key, model_standardization):\n",
    "    \n",
    "    #DEFINIZIONE DELLA PATH DOVE VIENE SALVATO IL FILE\n",
    "    if '_familiar_th' in key:\n",
    "        return 'th_fam'\n",
    "    elif '_unfamiliar_th' in key:\n",
    "        return 'th_unfam'\n",
    "    elif '_familiar_pt' in key:\n",
    "        return 'pt_fam'\n",
    "    elif '_unfamiliar_pt' in key:\n",
    "        return 'pt_unfam'\n",
    "    else:\n",
    "        return None\n",
    "     \n",
    "   \n",
    "    \n",
    "# Funzione per salvare i risultati\n",
    "def save_performance_results(model_name, my_train_results, my_test_results, key, data_type, sweep_config, condition = \"th_resp_vs_pt_resp\"):\n",
    "    \"\"\"\n",
    "    Funzione che salva i risultati del modello in base alla combinazione di 'key' e 'model_name'.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Identificazione del subfolder in base alla chiave\n",
    "    subfolder = get_subfolder_from_key(key, sweep_config)\n",
    "    \n",
    "    # Debug: controllo sulla subfolder\n",
    "    print(f\"\\nDEBUG - Chiave: \\033[1m{key}\\033[0m, Subfolder ottenuto: \\033[1m{subfolder}\\033[0m\")\n",
    "    \n",
    "    if subfolder is None:\n",
    "        print(f\"Errore: La chiave \\033[1m{key}\\033[0m non corrisponde a nessun subfolder valido.\\n\")\n",
    "        return\n",
    "    \n",
    "     # Determinazione del tipo di dato direttamente dalla chiave\n",
    "    if \"spectrograms\" in key:\n",
    "        data_type_str = \"spectrograms\"\n",
    "    else:\n",
    "        print(f\"Errore: Tipo di dato non riconosciuto nella chiave '{key}'.\")\n",
    "        return\n",
    "\n",
    "    # Creazione del nome del file con l'inclusione della combinazione key + model_name\n",
    "    file_name = f\"{model_name}_performances_{condition}_{subfolder}_{data_type_str}.pkl\"\n",
    "    folder_path = os.path.join(base_folder, subfolder)\n",
    "    \n",
    "    # Verifica se la cartella di destinazione esiste, altrimenti creala\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "    \n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "    # Creazione del dizionario con i risultati\n",
    "    results_dict = {\n",
    "        'my_train_results': my_train_results,\n",
    "        'my_test_results': my_test_results\n",
    "    }\n",
    "\n",
    "    # Salvataggio del dizionario con i risultati\n",
    "    try:\n",
    "        with open(file_path, 'wb') as f:\n",
    "            pickle.dump(results_dict, f)\n",
    "        print(f\"\\nRisultati salvati con successo ✅ in: \\n\\033[1m{file_path}\\033[0m\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"Errore durante il salvataggio dei risultati: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe3ce3a-6857-4973-b213-11f041bc1997",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### **DL Models - EEG Spectrograms - Time x Frequencies**"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5ad83eb4-9e1a-4c70-8d77-ac088cc381ed",
   "metadata": {
    "tags": []
   },
   "source": [
    "'''\n",
    "DEFINIZIONE DEI MODELLI OLD VERSIONS\n",
    "'''\n",
    "\n",
    "class CNN1D(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_channels, num_classes):\n",
    "        \n",
    "        super(CNN1D, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(input_channels, 16, kernel_size=8, stride=1)\n",
    "        self.bn1 = nn.BatchNorm1d(16)  # Batch Normalization\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=2)\n",
    "\n",
    "        self.conv2 = nn.Conv1d(16, 32, kernel_size=6, stride=1)\n",
    "        self.bn2 = nn.BatchNorm1d(32)  # Batch Normalization\n",
    "        self.pool2 = nn.AvgPool1d(kernel_size=2)      \n",
    "        \n",
    "        self.conv3 = nn.Conv1d(32, 48, kernel_size=4, stride=1)\n",
    "        self.bn3 = nn.BatchNorm1d(48)  # Batch Normalization\n",
    "        self.pool3 = nn.AvgPool1d(kernel_size=2)      \n",
    "\n",
    "        self.fc1 = nn.LazyLinear(8)\n",
    "        self.dropout = nn.Dropout(0.5)  # 50% di dropout\n",
    "        self.fc2 = nn.LazyLinear(num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Passaggio attraverso il primo strato convoluzionale, BatchNorm e pooling\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)  # Batch Normalization\n",
    "        x = F.elu(x)\n",
    "        #x = torch.tanh(x)  # Sostituito ELU con tanh\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        # Passaggio attraverso il secondo strato convoluzionale, BatchNorm e pooling\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)  # Batch Normalization\n",
    "        x = F.elu(x)\n",
    "        #x = torch.tanh(x)  # Sostituito ELU con tanh\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        # Passaggio attraverso il secondo strato convoluzionale, BatchNorm e pooling\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)  # Batch Normalization\n",
    "        x = F.elu(x)\n",
    "        x = torch.tanh(x)  # Sostituito ELU con tanh\n",
    "        x = self.pool3(x)\n",
    "\n",
    "        # Flatten per preparare i dati per gli strati fully connected\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "\n",
    "        # Passaggio attraverso il primo strato fully connected\n",
    "        x = self.fc1(x)\n",
    "        x = F.elu(x)\n",
    "        #x = torch.tanh(x)  # Sostituito ELU con tanh\n",
    "\n",
    "        # Dropout per evitare overfitting\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # Passaggio attraverso il secondo strato fully connected\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    \n",
    "# Iperparametri CNN\n",
    "#num_classes = 2\n",
    "\n",
    "# Creazione del modello CNN\n",
    "#model = CNN1D(input_channels = 3, num_classes = num_classes)\n",
    "\n",
    "\n",
    "class ReadMEndYou(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, output_size, num_layers=3, dropout=0.5, bidirectional=False):\n",
    "        super(ReadMEndYou, self).__init__()\n",
    "        \n",
    "        self.bidirectional = bidirectional  # Impostazione della bidirezionalità\n",
    "        \n",
    "        # Adattiamo hidden_size in base alla bidirezionalità\n",
    "        \n",
    "        self.hidden_sizes = [\n",
    "            hidden_sizes[0] * 2 if bidirectional else hidden_sizes[0],\n",
    "            hidden_sizes[1] * 2 if bidirectional else hidden_sizes[1],\n",
    "            hidden_sizes[2] * 2 if bidirectional else hidden_sizes[2]\n",
    "        ]\n",
    "        \n",
    "        # Definizione dei layer LSTM\n",
    "        self.lstm1 = nn.LSTM(input_size=input_size, \n",
    "                             hidden_size=self.hidden_sizes[0], \n",
    "                             num_layers=1, \n",
    "                             batch_first=True, \n",
    "                             dropout=0, \n",
    "                             bidirectional=bidirectional)\n",
    "\n",
    "        self.lstm2 = nn.LSTM(input_size=self.hidden_sizes[0] * 2 if bidirectional else self.hidden_sizes[0],\n",
    "                             hidden_size=self.hidden_sizes[1], \n",
    "                             num_layers=1, \n",
    "                             batch_first=True, \n",
    "                             dropout=0,\n",
    "                             bidirectional=bidirectional)\n",
    "        \n",
    "        \n",
    "        self.lstm3 = nn.LSTM(input_size=self.hidden_sizes[1] * 2 if bidirectional else self.hidden_sizes[1],\n",
    "                             hidden_size=self.hidden_sizes[2], \n",
    "                             num_layers=1, \n",
    "                             batch_first=True, \n",
    "                             dropout=0,\n",
    "                             bidirectional=bidirectional)\n",
    "        \n",
    "        \n",
    "        # Dropout layer tra gli LSTM e prima del fully connected\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # Layer finale per la classificazione\n",
    "        self.fc = nn.Linear(self.hidden_sizes[2] * 2 if bidirectional else self.hidden_sizes[2], output_size)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # LSTM 1\n",
    "        out, _ = self.lstm1(x)\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        # LSTM 2\n",
    "        out, _ = self.lstm2(out)\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        # LSTM 3\n",
    "        out, _ = self.lstm3(out)\n",
    "        out = self.dropout(out)\n",
    "       \n",
    "        # Estrazione dell'ultimo time-step\n",
    "        out = out[:, -1, :]\n",
    "        \n",
    "        # Dropout prima del layer fully connected\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        # Passaggio attraverso il layer finale per la previsione\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "        \n",
    "# Parametri\n",
    "#I 3 canali EEG\n",
    "#input_sizes = 3 \n",
    "\n",
    "#hidden_sizes = [24, 48, 62]\n",
    "\n",
    "#output_sizes = 2  # Ad esempio, classificazione binaria\n",
    "\n",
    "# Creazione del modello\n",
    "#model = ReadMEndYou(input_size=input_sizes, hidden_sizes=hidden_sizes, output_size=output_sizes, bidirectional= True)\n",
    "\n",
    "# Visualizzare il modello\n",
    "#print(model)\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class ReadMYMind(nn.Module):\n",
    "    def __init__(self, num_channels, seq_length, d_model, num_heads, num_layers, num_classes):\n",
    "        super(ReadMYMind, self).__init__()\n",
    "        \n",
    "        # Embedding per portare i dati EEG in uno spazio latente\n",
    "        \n",
    "        # da # (batch_size, 3, 300) -> (batch_size, 3, 16)\n",
    "        self.embedding = nn.Linear(seq_length, d_model)  \n",
    "        \n",
    "        #Il modulo nn.TransformerEncoder si aspetta un input di forma:\n",
    "        #(seq_length, batch_size, embedding_dim)\n",
    "        \n",
    "        # Attenzione Spaziale\n",
    "        self.spatial_transformer = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(d_model=d_model, nhead=num_heads),\n",
    "            num_layers=num_layers\n",
    "        )\n",
    "\n",
    "        # Attenzione Temporale\n",
    "        self.temporal_transformer = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(d_model=d_model, nhead=num_heads),\n",
    "            num_layers=num_layers\n",
    "        )\n",
    "\n",
    "        # Cross-attention per combinare spaziale e temporale iterativamente\n",
    "        self.cross_attention = nn.MultiheadAttention(embed_dim=d_model, num_heads=num_heads)\n",
    "\n",
    "        # Layer finale di fusione e classificazione\n",
    "        self.fc_fusion = nn.Linear(d_model, d_model)\n",
    "        self.fc_classify = nn.Linear(d_model, num_classes)\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        #SHAPE DATI PRIMA DELLA TRASFORMAZIONE SPAZIALE\n",
    "        #print(f\"x shape before embedding: {x.shape}\") \n",
    "        #(batch_size, 3, 300)  # già nella forma corretta\n",
    "        \n",
    "        x = self.embedding(x)   # da # (batch_size, 3, 300) -> (batch_size, 3, 16)\n",
    "        \n",
    "        #print(f\"x shape after embedding: {x.shape}\")\n",
    "        \n",
    "        #Permuta per il TransformerEncoder, che vuole\n",
    "        #(seq_length, batch_size, embedding_dim)\n",
    "        \n",
    "        # da (batch_size, 3, 16) -> (16, batch_size, 3) \n",
    "        # quindi da (batch_size, 3, 16) sposta l'ultima dimensione (16) alla prima posizione, \n",
    "        # perché ho rimappato i 300 punti temporali in uno spazio latente 16 dimensionale.\n",
    "        # Dopodiché, il batch size lo mantengo alla dimensione 2 \n",
    "        # E alla dimensione 3 metto invece 3 (che erano i miei canali e che diventano invece l'embedding_dim)\n",
    "        \n",
    "        #x = x.permute(2, 0, 1)  \n",
    "        \n",
    "        #print(f\"X shape before spatial_transformer: {x.shape}\") # (seq_length = 16, batch_size, embedding_dim = 3)\n",
    "        \n",
    "        x_spatial = self.spatial_transformer(x)  # (seq_length = 16, batch_size, embedding_dim = 3)\n",
    "            \n",
    "        #print(f\"X shape after spatial_transformer: {x_spatial.shape}\") # (seq_length = 16, batch_size, embedding_dim = 3)\n",
    "    \n",
    "        # Prima iterazione: attenzione temporale per ogni canale\n",
    "        \n",
    "        #print(f\"X_spatial shape before temporal attention: {x_spatial.shape}\") # (seq_length = 16, batch_size, embedding_dim = 3)\n",
    "    \n",
    "        x_temporal = self.temporal_transformer(x_spatial) #batch_size, d_model, num_channels\n",
    "        \n",
    "        #print(f\"X shape after temporal_transformer: {x_temporal.shape}\") # (seq_length = 16, batch_size, embedding_dim = 3)\n",
    "        \n",
    "        #Nel caso della nn.MultiheadAttention, la shape corretta dell'input è:\n",
    "        \n",
    "        #Query (Q): (seq_length, batch_size, embedding_dim)\n",
    "        #Key (K) e Value (V): (seq_length, batch_size, embedding_dim)\n",
    "        \n",
    "        # Cross-attention: combinazione spaziale-temporale\n",
    "        x_cross, _ = self.cross_attention(x_spatial, x_temporal, x_temporal)\n",
    "        \n",
    "        # Seconda iterazione: raffinamento con attenzione spaziale\n",
    "        #x_spatial_refined = self.spatial_transformer(x_cross)\n",
    "       \n",
    "        # Seconda iterazione: raffinamento con attenzione temporale\n",
    "        #x_temporal_refined = self.temporal_transformer(x_cross)\n",
    "       \n",
    "        # Fusione finale delle informazioni\n",
    "        #x_fused = self.fc_fusion((x_spatial_refined + x_temporal_refined).mean(dim=1))  # (batch_size, d_model)\n",
    "        \n",
    "        x_fused = self.fc_fusion((x_spatial + x_temporal).mean(dim=1))  # (batch_size, d_model)\n",
    "        \n",
    "        # Classificazione finale\n",
    "        output = self.fc_classify(x_fused)  # (batch_size, num_classes)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea640cf-3673-4603-9f76-f9d0a9a88e87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Per far sì che la SOMMA ELEMENT-WISE DEL PERCORSO RESIDUO sia valida, il numero di canali di res deve coincidere con quello dell’output convoluzionale (64).\n",
    "Nel nostro blocco 2, però:\n",
    "\n",
    "- Il path principale prende in ingresso 32 canali (x dopo il primo pool) e, attraverso due convoluzioni, esce con 64 canali.\n",
    "- Il path residuo (res = x) resta a 32 canali: non possiamo sommarlo al main path a 64 canali.\n",
    "\n",
    "La soluzione “standard” in ResNet è applicare sullo skip una 1×1 convolution che porta i 32 canali di res a 64, esattamente come il main path.\n",
    "\n",
    "In PyTorch:\n",
    "\n",
    "1.  Aggiungi un layer di “proiezione” 1×1 nel blocco 2\n",
    "    \n",
    "    Nel costruttore (__init__), subito prima di definire il blocco 2, dichiari:\n",
    "\n",
    "    # in __init__(), subito dopo self.pool o prima di bn2a\n",
    "    self.res_conv = nn.Conv2d(32, 64, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "    self.res_bn   = nn.BatchNorm2d(64)   # (opzionale, migliora la stabilità)\n",
    "\n",
    "2. Applica la proiezione nel forward\n",
    "   \n",
    "   Nel forward, nel blocco 2 sostituisci:\n",
    "\n",
    "    # prima:\n",
    "    res = x\n",
    "    \n",
    "    # ... convoluzioni ...\n",
    "    x = x + res\n",
    "    \n",
    "    \n",
    "    con invece questa altra cosa 👇\n",
    "\n",
    "\n",
    "    # prendi il “residuo” su cui fare la somma\n",
    "    res = x  \n",
    "\n",
    "    # proietta res da 32→64 canali\n",
    "    res = self.res_conv(res)  # (B,32,40,4) -> (B,64,40,4)\n",
    "    res = self.res_bn(res)    # (B,64,40,4)\n",
    "\n",
    "    # main path\n",
    "    x = self.bn2a(x)\n",
    "    x = F.relu(self.conv2a(x))\n",
    "    x = self.bn2b(x)\n",
    "    x = self.conv2b(x)        # (B,64,40,4)\n",
    "\n",
    "    # ora i due tensori hanno entrambi 64 canali\n",
    "    x = x + res               # (B,64,40,4)\n",
    "    x = F.relu(x)\n",
    "    x = self.pool(x)          # (B,64,20,2)\n",
    "\n",
    "\n",
    "3. Il blocco 2 diventa così\n",
    "\n",
    "    # --- Block 2 (residual with projection) ---\n",
    "    # in __init__:\n",
    "    self.res_conv = nn.Conv2d(32, 64, kernel_size=1, bias=False)\n",
    "    self.res_bn   = nn.BatchNorm2d(64)\n",
    "    self.bn2a  = nn.BatchNorm2d(32)\n",
    "    self.conv2a= nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "    self.bn2b  = nn.BatchNorm2d(64)\n",
    "    self.conv2b= nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "\n",
    "    # in forward:\n",
    "    res = x\n",
    "    res = self.res_conv(res)\n",
    "    res = self.res_bn(res)\n",
    "\n",
    "    x = self.bn2a(x)\n",
    "    x = F.relu(self.conv2a(x))\n",
    "    x = self.bn2b(x)\n",
    "    x = self.conv2b(x)\n",
    "\n",
    "    x = x + res\n",
    "    x = F.relu(x)\n",
    "    x = self.pool(x)\n",
    "    \n",
    "\n",
    "\n",
    "Perché funziona\n",
    "\n",
    "- res_conv con kernel 1×1 ricalcola solo i canali, lasciando inalterata la risoluzione spaziale (40 × 4).\n",
    "- Ora res ha 64 canali e può essere sommato all’output del main path, che ha a sua volta 64 mappe feature.\n",
    "- La BatchNorm aggiunta dopo la proiezione aiuta a mantenere la stessa distribuzione statistica di ciò che accade nel main path.\n",
    "\n",
    "Con questo piccolo accorgimento rendi il tuo blocco 2 conforme alla ResNet originaria e senza errori di shape nella somma residua.\n",
    "\n",
    "******************* ******************* ******************* ******************* ******************* ******************* ******************* *******************\n",
    "\n",
    "[...]\n",
    "\n",
    "IO: Ok, ma che cosa cambia? oppure, rimane uguale all'implementazione descritta nel paper con questa ulteriore modifica?\n",
    "\n",
    "\n",
    "******************* ******************* ******************* ******************* ******************* ******************* ******************* *******************\n",
    "[...]\n",
    "\n",
    "Non cambia nulla in termini di capacità espressiva o di “architettura astratta” rispetto al paper, perché quella 1×1 “di proiezione” \n",
    "è semplicemente un dettaglio d’implementazione che serve a far combaciare i canali quando costruisci il blocco residuo in PyTorch.\n",
    "\n",
    "\n",
    "    Cosa scrive il paper\n",
    "    Block 1: 1×1 input→32 canali → pool\n",
    "    Block 2: due convoluzioni 3×3 con 64 filtri ciascuna, somma con l’input del blocco → pool\n",
    "    Block 3: conv 3×3 con 128 filtri → pool\n",
    "\n",
    "Nel testo non viene esplicitato, ma implicitamente per fare\n",
    "\n",
    "\n",
    "    input_block2  (B,32,H,W)\n",
    "→ conv2a & conv2b (B,64,H,W)\n",
    "→ add(input_block2, output)  # somma residua\n",
    "devi “allineare” i 32 canali dell’input ai 64 del main path.\n",
    "\n",
    "\n",
    "\n",
    "Perché serve la 1×1 conv\n",
    "In PyTorch, se fai\n",
    "\n",
    "    res = x              # (B,32,H,W)\n",
    "    x   = conv2a(x)      # → (B,64,H,W)\n",
    "    x   = conv2b(x)      # → (B,64,H,W)\n",
    "    x   = x + res        # ❌ ERROR: 64 vs 32 canali\n",
    "    \n",
    "\n",
    "devi prima trasformare res da 32→64 canali, e il modo “canonicamente” corretto è una convoluzione 1×1:\n",
    "\n",
    "\n",
    "    res = self.res_conv(res)  # Conv2d(32→64, kernel_size=1)\n",
    "    res = self.res_bn(res)z\n",
    "    # ora res e x hanno entrambi 64 canali\n",
    "    x   = x + res             # ✅ OK\n",
    "\n",
    "\n",
    "In che modo resta fedele al paper:\n",
    "\n",
    "    Numero di filtri nei tre blocchi (32 → 64 → 128)\n",
    "    Kernel 3×3 e padding=“same”,\n",
    "    MaxPool2d(2,2) dopo ogni blocco,\n",
    "    Dropout 0.2,\n",
    "    LSTM unidirezionale 64,\n",
    "    Head finale 3-class softmax,\n",
    "\n",
    "    Tutto rimane identico-->  La 1×1 conv è solo un’aggiunta necessaria per realizzare “meccanicamente” la somma residua quando l’input\n",
    "    e l’output del blocco hanno numero diverso di canali.\n",
    "\n",
    "Quindi:\n",
    "\n",
    "Architettura logica = quella del paper (3 blocchi, residual sul secondo, LSTM, …)\n",
    "Dettaglio d’implementazione = aggiunta della 1×1 conv per far combaciare le shape interne in PyTorch\n",
    "Senza quella 1×1 conv, il tuo codice andrebbe in errore di dimensione, ma dal punto di vista del paper non stai in alcun modo “cambiando” \n",
    "le scelte di filtro, pooling o flusso dei dati.\n",
    "\n",
    "******************* ******************* ******************* ******************* ******************* ******************* ******************* *******************\n",
    "\n",
    "\n",
    "Ok vorrei che mi facessi 3 cose:\n",
    "\n",
    "1) mi rispiegassi questo passaggio \"somma element-wise del percorso residuo sia valida\"\n",
    "2) nel mio caso, parto da una matrice di dati EEG a 64 canali, e nella tua implementazione manca questa info o mi sbaglio?\n",
    "3) mi ridai tutta la classe della rete modificata in base a questo discorso che mi facevi rispetto al \" Aggiungi un layer di “proiezione” 1×1 nel blocco 2\"?\n",
    "\n",
    "\n",
    "******************* ******************* ******************* ******************* ******************* ******************* ******************* *******************\n",
    "\n",
    "\n",
    "\n",
    "1) “SOMMA ELEMENT-WISE DEL PERCORSO RESIDUO SIA VALIDA”\n",
    "\n",
    "Quando fai un blocco residuale (come in ResNet), hai due “rami”:\n",
    "\n",
    "Main path: applica due (o più) convoluzioni al tensore di input\n",
    "\n",
    "Skip path: trasporta l’input in parallelo, per sommarlo all’output del main path\n",
    "\n",
    "Per poter sommare due tensori element‐wise, devono avere esattamente la stessa shape in tutte le dimensioni: batch, canali, altezza, larghezza.\n",
    "\n",
    "Nel nostro caso:\n",
    "\n",
    "Input al blocco ha shape (B, C_in, H, W).\n",
    "\n",
    "Main path lo trasforma in (B, C_out, H, W) tramite due conv 3×3 (qui C_out=64).\n",
    "\n",
    "Skip path inizialmente era semplicemente res = input, dunque res.shape == (B, C_in, H, W) con C_in=32.\n",
    "\n",
    "Non puoi quindi fare\n",
    "\n",
    "    # ❌ non funziona, 32 ≠ 64 canali\n",
    "    out = main_path(input)      # shape (B,64,H,W)\n",
    "    res = input                 # shape (B,32,H,W)\n",
    "    sum = out + res             # ERRORE di broadcast sui canali\n",
    "\n",
    "Per “allineare” i canali del skip a quelli del main path, inserisci una convoluzione 1×1 che mappa C_in→C_out:\n",
    "\n",
    "\n",
    "    res = conv1x1(res)  # ora res.shape == (B,64,H,W)\n",
    "    out = main_path(input)  # (B,64,H,W)\n",
    "    sum = out + res         # ✅ canali e spatial matchata → somma valida\n",
    "    \n",
    "Questa 1×1 conv non cambia altezza/larghezza, ma riallinea il numero di feature‐map (canali).\n",
    "\n",
    "\n",
    "\n",
    "2) Numero di canali di input nel tuo caso\n",
    "Dati EEG originali: 61 elettrodi, poi ridotti a 15 per soggetto, quindi 30 canali totali per il dataset paired.\n",
    "\n",
    "Se tu invece parti da un dataset a 64 canali (magari stai usando tutti i 61 electrodes + derivazioni), \n",
    "devi semplicemente passare quel numero di canali al modello:\n",
    "\n",
    "\n",
    "model = CNNLSTM_TF(n_channels=64, n_classes=2, dropout=0.2)\n",
    "\n",
    "In questo modo BatchNorm2d e Conv2d del primo blocco sapranno che devono aspettarsi input con 64 canali.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec34781-e9ab-4a56-b0b5-34cc1f8a783f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "DEFINIZIONE DEI MODELLI NEW VERSION PER SPETTROGRAMMI\n",
    "'''\n",
    "\n",
    "\n",
    "'''CNN2D_LSTM_TF\n",
    "\n",
    "Spiegazione dettagliata dei passaggi\n",
    "\n",
    "1) Input\n",
    "\n",
    "Shape Iniziale: (batch_size, 64, 81, 9)\n",
    "64 canali EEG, 81 bin di frequenza, 9 finestre temporali\n",
    "\n",
    "2) Block 1\n",
    "\n",
    "BatchNorm2d(64) normalizza ciascun canale\n",
    "Conv2d(64→32, 3×3, padding=1) produce 32 mappe (B,32,81,9)\n",
    "ReLU mantiene la stessa shape\n",
    "MaxPool2d(2,2) dimezza: frequenza 81→40, time 9→4 → (B,32,40,4)\n",
    "\n",
    "3) Block 2 “residuo”\n",
    "\n",
    "res = x salva skip (B,32,40,4)\n",
    "res_conv 1×1: Conv2d(32→64,k=1) riallinea i canali → (B,64,40,4)\n",
    "res_bn normalizza → (B,64,40,4)\n",
    "\n",
    "    Main path:\n",
    "\n",
    "        BatchNorm2d(32) → (B,32,40,4)\n",
    "        Conv2d(32→64,3×3,pad=1) + ReLU → (B,64,40,4)\n",
    "        BatchNorm2d(64) → (B,64,40,4)\n",
    "        Conv2d(64→64,3×3,pad=1) → (B,64,40,4)\n",
    "\n",
    "    Somma residua: (B,64,40,4) + (B,64,40,4) → (B,64,40,4)\n",
    "    ReLU + Pool: dimezza → (B,64,20,2)\n",
    "\n",
    "4) Block 3\n",
    "\n",
    "    Conv2d(64→128,3×3,pad=1) + BatchNorm + ReLU → (B,128,20,2)\n",
    "    MaxPool2d → frequenza 20→10, time 2→1 → (B,128,10,1)\n",
    "\n",
    "5) Preparazione per LSTM\n",
    "\n",
    "    permute(0,2,1,3): porta freq come sequenza → (B,10,128,1)\n",
    "    reshape(b,10,128*1): collapse canali×time → (B,10,128)\n",
    "\n",
    "6) LSTM + testata finale\n",
    "\n",
    "    Dropout 0.2 su (B,10,128)\n",
    "    LSTM unidirezionale 128→64: produce out = (B,10,64)\n",
    "    Estrai ultimo timestep out[:, -1, :] → (B,64)\n",
    "    Linear(64→2) → logits (B,2)\n",
    "\n",
    "Così hai un modello che parte da 64 canali EEG, mantiene l’architettura a 3 blocchi residui + LSTM del paper, e termina con una classificazione binaria.\n",
    "\n",
    "'''\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN2D_LSTM_TF(nn.Module):\n",
    "\n",
    "    def __init__(self, input_channels=64, num_classes=2, dropout=0.2):\n",
    "        super().__init__()\n",
    "        # --- Block 1 ---\n",
    "        self.bn1   = nn.BatchNorm2d(input_channels)    # normalizza 64 canali\n",
    "        self.conv1 = nn.Conv2d(input_channels, 32, kernel_size=3, padding=1)\n",
    "        self.pool  = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # --- Block 2 (residual) ---\n",
    "        # Proiezione 1×1 per riallineare i canali di skip (32→64)\n",
    "        self.res_conv = nn.Conv2d(32, 64, kernel_size=1, bias=False)\n",
    "        self.res_bn   = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.bn2a   = nn.BatchNorm2d(32)\n",
    "        self.conv2a = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn2b   = nn.BatchNorm2d(64)\n",
    "        self.conv2b = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "\n",
    "        # --- Block 3 ---\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.bn3   = nn.BatchNorm2d(128)\n",
    "\n",
    "        # --- Head: Dropout + LSTM + FC finale ---\n",
    "        self.dropout     = nn.Dropout(dropout)\n",
    "        self.hidden_size = 64\n",
    "        \n",
    "        # dopo 3 pool: freq da 81→10, time da 9→1 → feature per timestep = 128×1\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=128,\n",
    "            hidden_size=self.hidden_size,\n",
    "            num_layers=1,\n",
    "            batch_first=True,\n",
    "            bidirectional=False\n",
    "        )\n",
    "        self.classifier = nn.Linear(self.hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B,64,81,9)\n",
    "\n",
    "        # --- Block 1 ---\n",
    "        x = self.bn1(x)                   # → (B,64,81,9)\n",
    "        x = F.relu(self.conv1(x))         # → (B,32,81,9)\n",
    "        x = self.pool(x)                  # → (B,32,40,4)\n",
    "\n",
    "        # --- Block 2 (residuo) ---\n",
    "        res = x                           # skip: (B,32,40,4)\n",
    "        res = self.res_conv(res)          # progetto: → (B,64,40,4)\n",
    "        res = self.res_bn(res)            # → (B,64,40,4)\n",
    "\n",
    "        # main path\n",
    "        x = self.bn2a(x)                  # → (B,32,40,4)\n",
    "        x = F.relu(self.conv2a(x))        # → (B,64,40,4)\n",
    "        x = self.bn2b(x)                  # → (B,64,40,4)\n",
    "        x = self.conv2b(x)                # → (B,64,40,4)\n",
    "\n",
    "        x = x + res                       # somma residua valida → (B,64,40,4)\n",
    "        x = F.relu(x)                     \n",
    "        x = self.pool(x)                  # → (B,64,20,2)\n",
    "\n",
    "        # --- Block 3 ---\n",
    "        x = F.relu(self.bn3(self.conv3(x)))  # → (B,128,20,2)\n",
    "        x = self.pool(x)                     # → (B,128,10,1)\n",
    "\n",
    "        # --- Prepara per LSTM ---\n",
    "        x = x.permute(0, 2, 1, 3)         # → (B,10,128,1)\n",
    "        b, seq, ch, tw = x.size()        \n",
    "        x = x.reshape(b, seq, ch * tw)    # → (B,10,128)\n",
    "\n",
    "        # --- LSTM + classificazione ---\n",
    "        out, _ = self.lstm(self.dropout(x))  # → out: (B,10,64)\n",
    "        last = out[:, -1, :]                 # prendo l’ultima uscita → (B,64)\n",
    "        logits = self.classifier(last)       # → (B,2)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b33f039-08dc-4e9c-aeb4-cd91dad0a4f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "DEFINIZIONE DEI MODELLI NEW VERSION PER SPETTROGRAMMI\n",
    "'''    \n",
    "    \n",
    "\n",
    "'''CNN2D\n",
    "\n",
    "Una CNN2D si aspetta input in forma (batch, canali, altezza, larghezza). \n",
    "Nel tuo caso, puoi interpretare l’\"altezza\" come i bin di frequenza (38)\n",
    "e la \"larghezza\" come le finestre temporali (6).\n",
    "\n",
    "Quindi, la tua CNN2D lavorerebbe direttamente con:\n",
    "Shape: (batch, canali, frequenze, tempo)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class CNN2D(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_channels, num_classes):\n",
    "        \n",
    "        super(CNN2D, self).__init__()\n",
    "        \n",
    "        # Ipotizziamo kernel 3x3 con padding per mantenere le dimensioni (puoi adattare a tuo piacimento)\n",
    "        self.conv1 = nn.Conv2d(input_channels, 16, kernel_size=(2, 2), stride=(1, 1), padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=(2, 2))\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=(2, 2), stride=(1, 1), padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.pool2 = nn.AvgPool2d(kernel_size=(2, 2))\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(32, 48, kernel_size=(2, 2), stride=(1, 1), padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(48)\n",
    "        self.pool3 = nn.AvgPool2d(kernel_size=(2, 2))\n",
    "        \n",
    "        # Utilizzo LazyLinear per evitare di calcolare manualmente la dimensione piatta finale\n",
    "        self.fc1 = nn.LazyLinear(8)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.LazyLinear(num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # x: (batch, canali, frequenze, tempo)\n",
    "        \n",
    "        # Passaggio attraverso il primo strato convoluzionale, BatchNorm e pooling\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)  # Batch Normalization\n",
    "        x = F.elu(x)\n",
    "        #x = torch.tanh(x)  # Sostituito ELU con tanh\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        # Passaggio attraverso il secondo strato convoluzionale, BatchNorm e pooling\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)  # Batch Normalization\n",
    "        x = F.elu(x)\n",
    "        #x = torch.tanh(x)  # Sostituito ELU con tanh\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        # Passaggio attraverso il secondo strato convoluzionale, BatchNorm e pooling\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)  # Batch Normalization\n",
    "        x = F.elu(x)\n",
    "        x = torch.tanh(x)  # Sostituito ELU con tanh\n",
    "        x = self.pool3(x)\n",
    "\n",
    "        # Flatten per preparare i dati per gli strati fully connected\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "\n",
    "        # Passaggio attraverso il primo strato fully connected\n",
    "        x = self.fc1(x)\n",
    "        x = F.elu(x)\n",
    "        #x = torch.tanh(x)  # Sostituito ELU con tanh\n",
    "\n",
    "        # Dropout per evitare overfitting\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # Passaggio attraverso il secondo strato fully connected\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "'''\n",
    "Gli LSTM si aspettano un input in forma (batch, lunghezza_sequenza, dimensione_feature). \n",
    "Dovrai quindi decidere qual è la dimensione sequenziale.\n",
    "\n",
    "Opzione comune: usare il tempo come sequenza\n",
    "Step 1: Trasponi i dati in modo da avere il tempo come dimensione sequenziale.\n",
    "\n",
    "Dalla forma (batch, canali, frequenze, tempo) puoi fare:\n",
    "\n",
    "\n",
    "x = x.permute(0, 3, 1, 2)  # Diventa (batch, tempo, canali, frequenze)\n",
    "\n",
    "Step 2: Unisci le dimensioni dei canali e dei bin di frequenza in un’unica dimensione di feature:\n",
    "\n",
    "\n",
    "batch, tempo, canali, frequenze = x.shape\n",
    "x = x.reshape(batch, tempo, canali * frequenze)  # Ora: (batch, tempo, canali*frequenze)\n",
    "\n",
    "Nel tuo caso, per 3 canali e 38 bin di frequenza: input_size = 3 * 38 = 114 e lunghezza sequenza = 6.\n",
    "\n",
    "Nota: Se invece preferisci usare i bin di frequenza come sequenza, potresti fare:\n",
    "\n",
    "x = x.permute(0, 2, 1, 3)  # (batch, frequenze, canali, tempo)\n",
    "x = x.reshape(batch, frequenze, canali * tempo)  # Sequence length = 38, feature size = 3*6 = 18\n",
    "La scelta dipende dal tipo di informazione temporale o spettrale che vuoi evidenziare.\n",
    "\n",
    "'''\n",
    "\n",
    "class ReadMEndYou(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_sizes, output_size, dropout=0.5, bidirectional=False):\n",
    "        \"\"\"\n",
    "        input_size: dimensione delle feature per time-step (dovrà essere canali * frequenze)\n",
    "        hidden_sizes: lista con le dimensioni degli hidden state, es. [24, 48, 62]\n",
    "        output_size: numero di classi\n",
    "        \n",
    "        \"\"\"\n",
    "    \n",
    "        super(ReadMEndYou, self).__init__()\n",
    "        \n",
    "        self.bidirectional = bidirectional # Impostazione della bidirezionalità    \n",
    "        \n",
    "        # Adattiamo hidden_size in base alla bidirezionalità\n",
    "        self.hidden_sizes = [\n",
    "            hidden_sizes[0] * 2 if bidirectional else hidden_sizes[0],\n",
    "            hidden_sizes[1] * 2 if bidirectional else hidden_sizes[1],\n",
    "            hidden_sizes[2] * 2 if bidirectional else hidden_sizes[2]\n",
    "        ]\n",
    "        \n",
    "        self.lstm1 = nn.LSTM(input_size=input_size, \n",
    "                             hidden_size=self.hidden_sizes[0], \n",
    "                             num_layers=1, \n",
    "                             batch_first=True, \n",
    "                             dropout=0, \n",
    "                             bidirectional=bidirectional)\n",
    "        self.lstm2 = nn.LSTM(input_size=self.hidden_sizes[0] * 2 if bidirectional else self.hidden_sizes[0],\n",
    "                             hidden_size=self.hidden_sizes[1], \n",
    "                             num_layers=1, \n",
    "                             batch_first=True, \n",
    "                             dropout=0,\n",
    "                             bidirectional=bidirectional)\n",
    "        self.lstm3 = nn.LSTM(input_size=self.hidden_sizes[1] * 2 if bidirectional else self.hidden_sizes[1],\n",
    "                             hidden_size=self.hidden_sizes[2],\n",
    "                             num_layers=1, \n",
    "                             batch_first=True, \n",
    "                             dropout=0,\n",
    "                             bidirectional=bidirectional)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(self.hidden_sizes[2] * 2 if bidirectional else self.hidden_sizes[2], output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # x: (batch, canali, frequenze, tempo)\n",
    "        \n",
    "        # Trasponi per avere il tempo come dimensione sequenziale:\n",
    "        x = x.permute(0, 3, 1, 2)  # -> (batch, tempo, canali, frequenze)\n",
    "        \n",
    "        batch, time, channels, freqs = x.shape\n",
    "        \n",
    "        x = x.reshape(batch, time, channels * freqs)  # -> (batch, tempo, channels*frequencies)\n",
    "        # Ora input_size deve essere channels * freqs (es. 64 * 81 = 7471)\n",
    "        \n",
    "        # LSTM 1\n",
    "        out, _ = self.lstm1(x)\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        # LSTM 2\n",
    "        out, _ = self.lstm2(out)\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        # LSTM 3\n",
    "        out, _ = self.lstm3(out)\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        # Estraiamo l'output dell'ultimo time-step\n",
    "        out = out[:, -1, :]\n",
    "        \n",
    "        # Dropout prima del layer fully connected    \n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        # Passaggio attraverso il layer finale per la previsione\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "        \n",
    "\n",
    "\n",
    "'''\n",
    "Il modulo Transformer in PyTorch lavora tipicamente su input di forma (seq_length, batch, embedding_dim).\n",
    "\n",
    "Nel codice attuale, si parte da una forma simile a (batch, canali, seq_length), ma dovrai adattarla alla nuova struttura.\n",
    "\n",
    "Possibili approcci:\n",
    "\n",
    "1) Approccio A: usare il tempo come sequenza\n",
    "\n",
    "Se consideri il tempo (6 time windows) come la sequenza, puoi procedere come segue:\n",
    "\n",
    "A) Unisci canali e frequenze in un’unica dimensione di feature:\n",
    "\n",
    "# Dati originali: (batch, canali, frequenze, tempo)\n",
    "x = x.permute(0, 3, 1, 2)  # (batch, tempo, canali, frequenze)\n",
    "batch, tempo, canali, frequenze = x.shape\n",
    "x = x.reshape(batch, tempo, canali * frequenze)  # (batch, tempo, 3*38 = 114)\n",
    "\n",
    "B) Modifica il layer di embedding:\n",
    "\n",
    "Nel codice attuale, l'embedding è definito come:\n",
    "\n",
    "self.embedding = nn.Linear(seq_length, d_model)\n",
    "Dovrai cambiarlo in modo che mappi le dimensioni delle feature (in questo caso 114) a uno spazio latente:\n",
    "\n",
    "self.embedding = nn.Linear(canali * frequenze, d_model)\n",
    "\n",
    "C) Permuta per il Transformer:\n",
    "\n",
    "Dopo l'embedding, passa l'input alla forma (seq_length, batch, d_model):\n",
    "\n",
    "x = x.permute(1, 0, 2)  # Ora: (tempo, batch, d_model)\n",
    "\n",
    "\n",
    "2) Approccio B: usare i bin di frequenza come sequenza\n",
    "In alternativa, se reputi più rilevante la risoluzione spettrale, puoi considerare i 38 bin come sequenza e combinare canali e tempo:\n",
    "\n",
    "\n",
    "x = x.permute(0, 2, 1, 3)  # (batch, frequenze, canali, tempo)\n",
    "batch, frequenze, canali, tempo = x.shape\n",
    "x = x.reshape(batch, frequenze, canali * tempo)  # (batch, frequenze, 3*6 = 18)\n",
    "\n",
    "E poi procedere con un embedding layer che mappa da 18 a d_model e permutare in (frequenze, batch, d_model).\n",
    "\n",
    "Scelta dell'approccio:\n",
    "Se l'aspetto temporale è più critico, probabilmente è meglio usare l’Approccio A (sequenza di lunghezza 6).\n",
    "Se invece vuoi dare maggior rilievo alla struttura spettrale, l’Approccio B potrebbe essere più indicato.\n",
    "\n",
    "Ricorda che la scelta dipende dalla natura del tuo problema e dalla rilevanza delle informazioni temporali rispetto a quelle spettrali.\n",
    "'''\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "#Scelta: In questa implementazione abbiamo deciso di usare il tempo come sequenza.\n",
    "#In alternativa, potresti scegliere i bin di frequenza come sequenza, ma ciò richiederebbe una diversa riorganizzazione delle dimensioni \n",
    "#(ad esempio, un permute diverso).\n",
    "\n",
    "\n",
    "\n",
    "class ReadMYMind(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, num_heads, num_layers, num_classes, channels=64, freqs=81):\n",
    "        \n",
    "        super(ReadMYMind, self).__init__()\n",
    "\n",
    "        # Il layer di embedding mapperà la feature dimension (channels * freqs) a d_model\n",
    "        self.embedding = nn.Linear(channels * freqs, d_model)\n",
    "        \n",
    "        # Transformer per l'attenzione spaziale (qui si applica direttamente alla sequenza temporale)\n",
    "        self.spatial_transformer = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(d_model=d_model, nhead=num_heads),\n",
    "            num_layers=num_layers\n",
    "        )\n",
    "        # Transformer per l'attenzione temporale (si potrebbe considerare un'iterazione successiva)\n",
    "        self.temporal_transformer = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(d_model=d_model, nhead=num_heads),\n",
    "            num_layers=num_layers\n",
    "        )\n",
    "        # Cross-attention per combinare le rappresentazioni\n",
    "        self.cross_attention = nn.MultiheadAttention(embed_dim=d_model, num_heads=num_heads)\n",
    "        \n",
    "        # Fusione e classificazione finale\n",
    "        self.fc_fusion = nn.Linear(d_model, d_model)\n",
    "        self.fc_classify = nn.Linear(d_model, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x: (batch, canali, frequenze, tempo)\n",
    "        \n",
    "        # Utilizziamo il tempo come sequenza\n",
    "        x = x.permute(0, 3, 1, 2)  # -> (batch, tempo, canali, frequenze)\n",
    "        \n",
    "        batch, time, channels, freqs = x.shape\n",
    "        x = x.reshape(batch, time, channels * freqs)  # -> (batch, tempo, channels*frequencies)\n",
    "        \n",
    "        # Embedding: (batch, tempo, d_model)\n",
    "        x = self.embedding(x)\n",
    "        \n",
    "        # Transformer richiede input di forma (seq_length, batch, embedding_dim)\n",
    "        x = x.permute(1, 0, 2)  # -> (tempo, batch, d_model)\n",
    "        \n",
    "        # Applichiamo il Transformer per l'attenzione spaziale\n",
    "        x_spatial = self.spatial_transformer(x)\n",
    "        # Applichiamo il Transformer per l'attenzione temporale\n",
    "        x_temporal = self.temporal_transformer(x_spatial)\n",
    "        \n",
    "        # Cross-attention: (tempo, batch, d_model)\n",
    "        x_cross, _ = self.cross_attention(x_spatial, x_temporal, x_temporal)\n",
    "        \n",
    "        # Fusione: per esempio, facciamo una media sul tempo (dimensione 0)\n",
    "        x_fused = self.fc_fusion((x_spatial + x_temporal).mean(dim=0))  # -> (batch, d_model)\n",
    "        \n",
    "        # Classificazione finale\n",
    "        output = self.fc_classify(x_fused)  # -> (batch, num_classes)\n",
    "        \n",
    "        return output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c36133-9160-47bc-a94e-4a264da6c862",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new_all_th_concat_spectrograms_coupled_exp_task_1['rest_vs_left_fist']['data'].shape)\n",
    "print()\n",
    "print(new_all_th_concat_spectrograms_coupled_exp_task_1['rest_vs_right_fist']['data'].shape)\n",
    "print()\n",
    "print(new_all_th_concat_spectrograms_coupled_exp_task_1['left_fist_vs_right_fist']['data'].shape)\n",
    "print()\n",
    "print(np.unique(new_all_th_concat_spectrograms_coupled_exp_task_1['rest_vs_left_fist']['labels'], return_counts = True))\n",
    "print()\n",
    "print(np.unique(new_all_th_concat_spectrograms_coupled_exp_task_1['rest_vs_right_fist']['labels'], return_counts = True))\n",
    "print()\n",
    "print(np.unique(new_all_th_concat_spectrograms_coupled_exp_task_1['left_fist_vs_right_fist']['labels'], return_counts = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa7fd3e-f612-408e-894a-1fadb15e6087",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Ecco un codice che fornisce dati di input fittizi a ciascuna rete neurale, \n",
    "stampa le dimensioni a ogni passaggio e verifica che gli output abbiano le forme attese.\n",
    "\n",
    "Ho mantenuto le forme coerenti con i tuoi parametri:\n",
    "\n",
    "\n",
    "Batch size: 8\n",
    "Numero di canali EEG: 3\n",
    "Numero di frequenze: 38\n",
    "Numero di timepoints (campioni temporali): 100\n",
    "Numero di classi: 2\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Parametri\n",
    "batch_size = 45\n",
    "input_channels = 64   # Canali EEG\n",
    "num_freqs = 81       # Numero di frequenze\n",
    "num_timepoints = 9  # Numero di campioni temporali\n",
    "\n",
    "num_classes = 2       # Numero di classi\n",
    "\n",
    "dropout = 0.2\n",
    "\n",
    "# Creazione di dati fittizi per il test\n",
    "x = torch.randn(batch_size, input_channels, num_freqs, num_timepoints)  # (batch, canali, frequenze, tempo)\n",
    "print(f\"Input iniziale: {x.shape}\\n\")\n",
    "\n",
    "# ---- CNN2D ----\n",
    "#cnn_model = CNN2D(input_channels=input_channels, num_classes=num_classes)\n",
    "\n",
    "cnn_model = CNN2D_LSTM_TF(input_channels = input_channels, num_classes =num_classes, dropout = dropout)\n",
    "cnn_output = cnn_model(x)\n",
    "print(f\"Output CNN2D_LSTM_TF: {cnn_output.shape}\\n\")  # Atteso: (batch_size, num_classes)\n",
    "\n",
    "\n",
    "# ---- ReadMEndYou (LSTM) ----\n",
    "hidden_sizes = [24, 48, 62]\n",
    "lstm_model = ReadMEndYou(input_size=input_channels * num_freqs, hidden_sizes=hidden_sizes, output_size=num_classes)\n",
    "lstm_output = lstm_model(x)\n",
    "print(f\"Output ReadMEndYou (LSTM): {lstm_output.shape}\\n\")  # Atteso: (batch_size, num_classes)\n",
    "\n",
    "# ---- ReadMYMind (Transformer) ----\n",
    "d_model = 64   # Dimensione embedding\n",
    "num_heads = 8   # Numero di teste di attenzione\n",
    "num_layers = 3  # Numero di strati Transformer\n",
    "\n",
    "transformer_model = ReadMYMind(d_model=d_model, num_heads=num_heads, num_layers=num_layers, num_classes=num_classes)\n",
    "transformer_output = transformer_model(x)\n",
    "print(f\"Output ReadMYMind (Transformer): {transformer_output.shape}\\n\")  # Atteso: (batch_size, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7faddbf-acc3-49a5-bea4-9fd05d08f3f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "DEFINIZIONE EARLY STOPPING\n",
    "'''\n",
    "\n",
    "import io\n",
    "from PIL import Image\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience = 10, min_delta = 0.001, mode = 'max'):\n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "        :param patience: Numero di epoche da attendere prima di interrompere il training se non c'è miglioramento\n",
    "        \n",
    "        Esempio: il training si interromperà se non si osserva un miglioramento per (N = 5) epoche consecutive.\n",
    "        \n",
    "        :param min_delta: Variazione minima richiesta per considerare un miglioramento\n",
    "        \n",
    "        definisce il miglioramento minimo richiesto per essere considerato significativo. \n",
    "        Se il miglioramento è inferiore a min_delta, non viene considerato un vero miglioramento.\n",
    "        \n",
    "        Il parametro min_delta in una configurazione di early stopping indica \n",
    "        la minima variazione del valore di una metrica \n",
    "        (ad esempio, la perdita o l'accuratezza) \n",
    "        che deve verificarsi tra un'epoca e la successiva \n",
    "        per continuare l'allenamento. \n",
    "        \n",
    "        In genere, il valore di min_delta dipende dal tipo di modello e dai dati specifici, \n",
    "        ma di solito si trova in un intervallo tra 0.001 e 0.01.\n",
    "    \n",
    "            - Se stai cercando di evitare che l'allenamento si fermi troppo presto,\n",
    "            puoi impostare un valore più basso per min_delta (come 0.001), \n",
    "            - Se vuoi essere più conservativo e permettere fluttuazioni nei valori della metrica,\n",
    "            un valore più alto (come 0.01) potrebbe essere appropriato.\n",
    "\n",
    "        Un buon punto di partenza potrebbe essere 0.001, e poi fare dei test per capire quale valore funziona meglio\n",
    "        nel tuo caso specifico!\n",
    "        \n",
    "        :param mode: 'min' per monitorare la loss (minimizzazione), 'max' per l'accuracy (massimizzazione)\n",
    "        \n",
    "        'max' → ottimizza metriche da massimizzare (es. accuracy, F1-score, AUC).\n",
    "        'min' → ottimizza metriche da minimizzare (es. loss).\n",
    "        \n",
    "        \"\"\"\n",
    "            \n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.mode = mode\n",
    "        self.best_score = None # Tiene traccia del miglior punteggio osservato\n",
    "        self.counter = 0 # Conta quante epoche consecutive non migliorano\n",
    "        self.early_stop = False # Flag che indica se attivare l'early stopping\n",
    "        \n",
    "        #Ogni volta che si chiama la classe con early_stopping(current_score), controlla se il modello sta migliorando o meno.\n",
    "\n",
    "    def __call__(self, current_score):\n",
    "        \n",
    "        #Caso 1: Prima iterazione (best_score ancora None)\n",
    "        #→ Se non esiste ancora un miglior punteggio, lo inizializza con il primo valore ricevuto.\n",
    "        \n",
    "        if self.best_score is None:\n",
    "            self.best_score = current_score\n",
    "            \n",
    "        #Caso 2: Il modello migliora\n",
    "        #→ Se il valore migliora di almeno min_delta, aggiorna best_score e resetta il contatore.\n",
    "\n",
    "        elif (self.mode == 'min' and current_score < self.best_score - self.min_delta) or \\\n",
    "             (self.mode == 'max' and current_score > self.best_score + self.min_delta):\n",
    "            self.best_score = current_score\n",
    "            self.counter = 0  # Reset contatore se migliora\n",
    "            \n",
    "        #Caso 3: Il modello NON migliora\n",
    "        \n",
    "        #→ Se il valore non migliora, incrementa il contatore.\n",
    "        #→ Se il contatore raggiunge patience, imposta early_stop = True, segnalando che il training deve essere interrotto.\n",
    "        \n",
    "        else:\n",
    "            self.counter += 1  # Incrementa se non migliora\n",
    "            if self.counter >= self.patience:\n",
    "                print(f\"🛑 Early stopping attivato! Nessun miglioramento per {self.patience} epoche consecutive.\")\n",
    "                self.early_stop = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7be7255-190c-4f3e-ad00-239862879723",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### **Weight & Biases Login & REMOTE CHECKS - EEG Spectrograms - Time x Frequencies**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f116f3-1cb8-4a80-933a-7de522bd8b86",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### **Weight & Biases Login PRECEDURA CORRETTA ✅ (CANCELLAZIONE RUNS e NON SWEEPS!) - EEG Spectrograms - Time x Frequencies V1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88397cbb-d0bb-48f0-b5e0-369187cf83b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Puoi usare l’API Python di W&B per elencare da remoto tutti i progetti di una certa entity (tuo utente o organizzazione).\n",
    "\n",
    "Ad esempio:\n",
    "\n",
    "'''\n",
    "\n",
    "import wandb\n",
    "\n",
    "# 1) autenticati (se non l’hai già fatto con wandb.login())\n",
    "# wandb.login()\n",
    "\n",
    "# 2) crea un’istanza dell’API\n",
    "api = wandb.Api()\n",
    "\n",
    "# 3) scegli la tua entity (nome utente o org). \n",
    "#    Se omesso, prende la tua entity di default.\n",
    "\n",
    "entity = 'stefano-bargione-universit-di-roma-tor-vergata'\n",
    "\n",
    "# 4) prendi la lista dei progetti\n",
    "projects = api.projects(entity=entity)\n",
    "\n",
    "# 5) stampa i nomi\n",
    "for proj in projects:\n",
    "    print(proj.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22940494-7c33-49ee-811d-2513e498e762",
   "metadata": {},
   "outputs": [],
   "source": [
    "###TUTTE ASSIEME\n",
    "\n",
    "\n",
    "import wandb\n",
    "\n",
    "# Nomi dei progetti\n",
    "project_names = [\n",
    "    #'left_fist_vs_right_fist_spectrograms_channels_freqs_params_hyperparams',\n",
    "    #'rest_vs_right_fist_spectrograms_channels_freqs_params_hyperparams',\n",
    "    #'rest_vs_left_fist_spectrograms_channels_freqs_params_hyperparams'\n",
    "    #'left_fist_vs_right_fist_spectrograms',\n",
    "    #'rest_vs_right_fist_spectrograms',\n",
    "    #'rest_vs_left_fist_spectrograms',\n",
    "    'left_fist_vs_right_fist_spectrograms_new',\n",
    "    'rest_vs_right_fist_spectrograms_new',\n",
    "    'rest_vs_left_fist_spectrograms_new'\n",
    "    \n",
    "]\n",
    "\n",
    "user_name = 'stefano-bargione-universit-di-roma-tor-vergata'\n",
    "\n",
    "# Connessione all'API di W&B\n",
    "api = wandb.Api()\n",
    "\n",
    "# Itera su tutti i progetti\n",
    "for project_name in project_names:\n",
    "    print(f\"\\nSelezione delle run per il progetto: \\033[1m{project_name}\\033[0m\")\n",
    "    \n",
    "    # Recupera tutte le run del progetto\n",
    "    runs = api.runs(f\"{user_name}/{project_name}\")\n",
    "    \n",
    "    # Salva gli ID delle run da eliminare\n",
    "    run_ids_to_delete = []\n",
    "    \n",
    "    for run in runs:\n",
    "        #print(f\"Estrazione run ID: {run.id} - Run Name: {run.name}\")\n",
    "        run_ids_to_delete.append(run.id)  # Aggiungi l'ID della run alla lista\n",
    "    \n",
    "    print(f\"\\nTotale runs da eliminare: \\033[1m{len(run_ids_to_delete)}\\033[0m\")\n",
    "    \n",
    "    # Elimina le run\n",
    "    for run_id in run_ids_to_delete:\n",
    "        run = api.run(f\"{user_name}/{project_name}/{run_id}\")\n",
    "        run.delete()  # Elimina la run\n",
    "        #print(f\"Eliminata la run con ID: {run_id}\")\n",
    "    print(f\"Eliminazione runs completata\")\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c972fe-00b6-445f-858e-7a11d56ef39a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### **Weight & Biases Login PRECEDURA CORRETTA ✅ (CANCELLAZIONE RUNS e SWEEPS!) - EEG Spectrograms - Time x Frequencies V2** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e72b82b-1c95-42de-8069-d31392f21e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''UFFICIALE 19 LUGLIO\n",
    "\n",
    "Spiegazione delle modifiche:\n",
    "Comando per ottenere la lista degli sweep:\n",
    "\n",
    "\n",
    "cmd_list = [\n",
    "    sys.executable, \"-m\", \"wandb\", \"sweep\",\n",
    "    \"--project\", path, \"--list\"\n",
    "]\n",
    "Qui usiamo --list per ottenere la lista di tutti gli sweep per il progetto.\n",
    "\n",
    "Comando per cancellare uno sweep:\n",
    "\n",
    "\n",
    "cmd_delete = [\n",
    "    sys.executable, \"-m\", \"wandb\", \"sweep\",\n",
    "    \"--delete\", f\"{path}/{sweep_id}\"\n",
    "]\n",
    "Qui usiamo --delete per eliminare ogni sweep individuato.\n",
    "\n",
    "Verifica degli sweep dopo la cancellazione:\n",
    "\n",
    "Una volta che abbiamo cancellato gli sweep, facciamo una seconda chiamata proj.sweeps() \n",
    "per verificare se ci sono ancora sweep attivi.\n",
    "\n",
    "Come funziona:\n",
    "Il codice esegue una lista di tutti i progetti che corrispondono ai pattern.\n",
    "\n",
    "Per ogni progetto, le run vengono cancellate prima.\n",
    "\n",
    "Poi, per ogni sweep associato al progetto, il comando wandb sweep --delete viene eseguito per eliminarlo.\n",
    "\n",
    "Infine, viene effettuata una verifica se gli sweep sono stati effettivamente cancellati.\n",
    "\n",
    "Con queste modifiche, dovresti essere in grado di eliminare completamente gli sweep oltre a fermarli.\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "import sys\n",
    "import subprocess\n",
    "import wandb\n",
    "\n",
    "# Configurazione API e entity\n",
    "entity = \"stefano-bargione-universit-di-roma-tor-vergata\"\n",
    "api = wandb.Api()\n",
    "\n",
    "# 1) Pattern da cercare nel nome dei progetti\n",
    "patterns = [\n",
    "    \"_spectrograms_time_freqs_new_3d_grid_multiband\",\n",
    "    #\"_spectrograms_channels_freqs_new_imagery_3d_grid_multiband\",\n",
    "]\n",
    "\n",
    "# 2) Prendi tutti i progetti e filtra\n",
    "print(\"Recupero tutti i progetti dell'entity…\")\n",
    "all_projects = api.projects(entity=entity)\n",
    "target_projects = [p for p in all_projects if any(pat in p.name for pat in patterns)]\n",
    "\n",
    "if not target_projects:\n",
    "    print(\"Nessun progetto corrispondente ai pattern trovati.\")\n",
    "    sys.exit(0)\n",
    "\n",
    "# 3) Cicla sui progetti selezionati\n",
    "for proj in target_projects:\n",
    "    name = proj.name\n",
    "    path = f\"{entity}/{name}\"\n",
    "    print(f\"\\n→ Progetto: {path}\")\n",
    "\n",
    "    # 3.1) Elimina tutte le run (per_page=None fa paging automatico)\n",
    "    try:\n",
    "        runs = api.runs(path, per_page=None)\n",
    "        runs = list(runs)  # forza il fetch di tutte le pagine\n",
    "        if runs:\n",
    "            print(f\"   • Eliminando {len(runs)} run…\")\n",
    "            for run in runs:\n",
    "                try:\n",
    "                    run.delete()\n",
    "                    print(f\"     – Run {run.id} eliminata\")\n",
    "                except Exception as e:\n",
    "                    print(f\"     – Errore eliminando run {run.id}: {e}\")\n",
    "        else:\n",
    "            print(\"   (nessuna run trovata)\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ⚠️ Impossibile caricare le run: {e}\")\n",
    "\n",
    "    # 3.2) Cancella tutti gli sweep via CLI Python module\n",
    "    # Evitiamo di chiamare un eseguibile esterno, usiamo `python -m wandb`\n",
    "    # Lo stesso interprete che esegue questo script è in sys.executable\n",
    "    \n",
    "    cmd_list = [\n",
    "        sys.executable, \"-m\", \"wandb\", \"sweep\",\n",
    "        \"--project\", path, \"--list\"\n",
    "    ]\n",
    "    res = subprocess.run(cmd_list, capture_output=True, text=True)\n",
    "\n",
    "    if res.returncode != 0 or not res.stdout.strip():\n",
    "        print(\"   • Nessuno sweep trovato o progetto inesistente\")\n",
    "        continue\n",
    "\n",
    "    # Ogni riga di res.stdout ha uno sweep_id come primo token\n",
    "    for line in res.stdout.splitlines():\n",
    "        sweep_id = line.split()[0]\n",
    "        print(f\"   • Cancello sweep {sweep_id}\")\n",
    "        cmd_delete = [\n",
    "            sys.executable, \"-m\", \"wandb\", \"sweep\",\n",
    "            \"--delete\", f\"{path}/{sweep_id}\"\n",
    "        ]\n",
    "        subprocess.run(cmd_delete, check=False)\n",
    "\n",
    "    # Verifica che gli sweep siano stati cancellati\n",
    "    print(\"Verifica sweep attivi dopo cancellazione...\")\n",
    "    sweeps = proj.sweeps()  # Riprova a ottenere gli sweep\n",
    "    if not sweeps:\n",
    "        print(\"   ✅ Nessuno sweep attivo trovato.\")\n",
    "    else:\n",
    "        print(f\"   ⚠️ Sweep ancora attivo: {sweeps}\")\n",
    "\n",
    "    print(f\"  ✅ Run e sweep eliminati per {path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33ed947-1486-438f-bc84-8563c3f5efe7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### **Weight & Biases Login - EEG Spectrograms - Time x Frequencies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad84821c-fa05-4dcf-a0eb-5b9ebaa967f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "WEIGHT AND BIASES LOGIN\n",
    "\n",
    "Il messaggio che stai ricevendo indica \n",
    "che sei già connesso al tuo account Weights & Biases (wandb).\n",
    "\n",
    "Se vuoi forzare il login, puoi usare il comando suggerito:\n",
    "\n",
    "wandb login --relogin\n",
    "\n",
    "Questo comando ti permetterà di reinserire le credenziali e riconnetterti al tuo account.\n",
    "Se non hai bisogno di disconnetterti o di cambiare l'account,\n",
    "puoi semplicemente continuare a usare wandb senza ulteriori passaggi. \n",
    "Hai bisogno di ulteriore assistenza con wandb o con il tuo progetto?\n",
    "'''\n",
    "\n",
    "\n",
    "import wandb\n",
    "wandb.login()\n",
    "print(\"✅ Weights & Biases login effettuato con successo!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54df1467-5a1e-4071-bf65-8842ac409ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Per modificare il percorso in cui W&B salva i dati localmente,\n",
    "puoi configurare la variabile di ambiente WANDB_DIR.\n",
    "\n",
    "Questo ti permette di specificare una directory personalizzata in cui W&B salva tutti i file associati al tuo run, inclusi i dati e i log.\n",
    "'''\n",
    "\n",
    "import os\n",
    "\n",
    "# Imposta la directory per i dati W&B:\n",
    "# Questo cambierà la cartella in cui W&B salva i dati per quella sessione di esecuzione\n",
    "\n",
    "# Definisci la cartella principale\n",
    "WB_dir = \"/home/stefano/Interrogait/WB_spectrograms_analyses_motor_task_1_new\"\n",
    "os.makedirs(WB_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "os.environ[\"WANDB_DIR\"] = WB_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a554dc13-c2f8-463a-a453-062b6012d3ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Apri il file in modalità lettura binaria ('rb')\n",
    "\n",
    "#path = '/home/stefano/Interrogait/all_datas/Unfamiliar_Spectrograms/'\n",
    "path = '/home/stefano/Interrogait/all_datas/Spectrograms_motor_tasks/'\n",
    "\n",
    "with open(f\"{path}new_all_th_concat_spectrograms_coupled_exp_task_1.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c332ad-a46e-45ff-a3ec-46a4aad4ecf8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Itera sulle chiavi del dizionario principale\n",
    "for condition, values in data.items():\n",
    "    if isinstance(values, dict) and \"data\" in values and \"labels\" in values:\n",
    "        X_shape = values[\"data\"].shape\n",
    "        y_length = len(values[\"labels\"])\n",
    "        print(f\"🔹 Condizione: {condition}\")\n",
    "        print(f\"   ➡ Shape dati: {X_shape}\")\n",
    "        print(f\"   ➡ Lunghezza labels: {y_length}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421b5547-bc02-467a-bb1c-803f764c2f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_all_th_concat_spectrograms_coupled_exp_task_1.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796a4bd4-fead-478a-a343-9533a875585f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##################### CODICE UFFICIALE DEL 04/03/2025 ORE 9:30 #####################\n",
    "                                 ##################### SENZA DETTAGLI SCRITTI V°3 #####################\n",
    "        \n",
    "'''ATTENZIONE: \n",
    "\n",
    "HO SOSTITUITO LE VARIABILI DI \n",
    "\n",
    "    1) DATASET_TRAIN_LOADER -->  TRAIN_LOADER\n",
    "    2) DATASET_VAL_LOADER -->  VAL_LOADER\n",
    "\n",
    "    VEDI FUNZIONE 'PREPARE_DATA_FOR_MODEL --> NOMI DELLE VARIABILI DEI TORCH TENSOR DATASET LOADER SON  'TRAIN_LOADER' E VAL_LOADER!!!  \n",
    "\n",
    "'''\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import wandb\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "import copy as cp\n",
    "import numpy as np\n",
    "\n",
    "import wandb\n",
    "import random\n",
    "import copy as cp\n",
    "\n",
    "\n",
    "# Definisci le lista delle coppie di condizioni sperimentali\n",
    "#experimental_conditions = [\"th_resp_vs_pt_resp\", \"th_resp_vs_shared_resp\", \"pt_resp_vs_shared_resp\"]\n",
    "\n",
    "experimental_conditions = [\"rest_vs_left_fist\", \"rest_vs_right_fist\", \"left_fist_vs_right_fist\"]\n",
    "\n",
    "# Inizializza il dizionario per caricare i dati\n",
    "data_dict = {}\n",
    "\n",
    "# Definisci la cartella principale\n",
    "#base_dir = \"/home/stefano/Interrogait/WB_spectrograms_best_results\"\n",
    "\n",
    "'''HO AGGIUNTO NEW QUI PER CREARE CARTELLA CON SWEEP NUOVI, CONFRONTANDO BILSTM & TRANSFORMER CON CNN2D_LSTM!'''\n",
    "\n",
    "base_dir = \"/home/stefano/Interrogait/WB_spectrograms_best_results_motor_task_1_new\"\n",
    "os.makedirs(base_dir, exist_ok=True)\n",
    "\n",
    "'''LOOP DI CARICAMENTO DATI'''\n",
    "\n",
    "for condition in experimental_conditions:\n",
    "    # Crea la cartella per la condizione sperimentale\n",
    "    condition_dir = os.path.join(base_dir, condition)\n",
    "    os.makedirs(condition_dir, exist_ok=True)\n",
    "    \n",
    "    # Aggiungi un livello di annidamento per ogni condizione\n",
    "    data_dict[condition] = {}\n",
    "    \n",
    "    for data_type in [\"spectrograms\"]:\n",
    "        \n",
    "        # Crea la cartella per il tipo di dato\n",
    "        data_dir = os.path.join(condition_dir, data_type)\n",
    "        os.makedirs(data_dir, exist_ok=True)\n",
    "        \n",
    "        #for category in [\"familiar\", \"unfamiliar\"]:\n",
    "        \n",
    "        for category in [\"familiar\"]:\n",
    "            \n",
    "            # Crea la cartella per la categoria\n",
    "            #category_dir = os.path.join(data_dir, category)\n",
    "            #os.makedirs(category_dir, exist_ok=True)\n",
    "            \n",
    "            #for subject_type in [\"th\", \"pt\"]:\n",
    "            \n",
    "            for subject_type in [\"th\"]:\n",
    "                # Caricamento e suddivisione dei dati\n",
    "                \n",
    "                #if data_type == \"spectrograms\":\n",
    "                    \n",
    "                print(f\"Caricamento dati per: {condition} - {data_type} - {category}_{subject_type}\")\n",
    "                X, y = load_data(data_type, category, subject_type, condition=condition)\n",
    "                \n",
    "                \n",
    "                # Creazione della chiave per il dizionario annidato\n",
    "                data_dict[condition][data_type] = data_dict[condition].get(data_type, {})\n",
    "                data_dict[condition][data_type][f\"{category}_{subject_type}\"] = (X, y)\n",
    "                \n",
    "                # Stampa di conferma\n",
    "                print(f\"Dataset caricato: \\033[1m{condition}\\033[0m_\\033[1m{data_type}\\033[0m_\\033[1m{category}_{subject_type}\\033[0m - Shape X: \\033[1m{X.shape}\\033[0m, Shape y: \\033[1m{len(y)}\\033[0m\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1c5cdc-a15c-4f57-8d25-44a5970a3035",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict['rest_vs_left_fist'].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daff8e19-8139-45d2-97cc-54941f8d0ccf",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### **Sweep Configuration - EEG Spectrograms - Time x Frequencies ONLY HYPER-PARAMS**\n",
    "\n",
    "#### **Sweep separati per ciascuno dei modelli CNN2D_LSTM_TF, BiLSTM e Transformer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea054fe-af1a-48fd-849b-534a33096336",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "N.B. \n",
    "\n",
    "PER SAPERE A QUALE COMBINAZIONE DI FATTORI CORRISPONDONO I DATI (i.e, X_train, X_val, X_test, y_train, y_val, y_test)\n",
    "\n",
    "MI CREO UN DIZIONARIO ULTERIORE, 'DATA_DICT_PREPROCESSED' CHE CONTIENE PER OGNI COMBINAZIONE DI FATTORI I DATI SPLITTATI\n",
    "\n",
    "IN QUESTO MODO, QUANDO FORNISCO ALLA FUNZIONE 'TRAINING_SWEEP' LA TUPLA CON I VARI DATI ((TRAIN, VAL E TEST))\n",
    "IO POSSO CAPIRE A QUALE COMBINAZIONI DI FATTORI CORRISPONDE QUELLA TUPLA DI DATI (TRAIN, VAL E TEST)\n",
    "\n",
    "\n",
    "INOLTRE,\n",
    "MI CREO ANCHE UNA LISTA DI TUPLE DI STRINGHE, DOVE OGNI TUPLA CONTIENE LE STRINGHE DELLE CHIAVI USATE \n",
    "PER LA GENERAZIONE DI DATA_DICT_PREPROCESSED.\n",
    "\n",
    "IN QUESTO MODO, MI ASSICURO CHE SIA UNA COERENZA TRA LA CREAZIONE DEI 'NAME' E 'TAG' DELLA RUN\n",
    "E\n",
    "LA CORRETTA ESTRAZIONE DEI DATI (OSSIA I DATI DI QUALE CONDIZIONE SPERIMENTALE, QUALI EEG INPUT, E DA CHI PROVENGONO!)  \n",
    "\n",
    "\n",
    "Questo approccio permette di garantire la corrispondenza tra \n",
    "\n",
    "1) le chiavi dei dati pre‐processati e \n",
    "2) la configurazione delle runs su W&B\n",
    "\n",
    "andando a creare due strutture in parallelo:\n",
    "\n",
    "- data_dict_preprocessed – che contiene, per ogni combinazione (condition, data_type, category_subject), \n",
    "                            la tupla dei dati già suddivisi (X_train, X_val, X_test, y_train, y_val, y_test);\n",
    "                            \n",
    "- sweeps_id – che contiene, per ogni combinazione (condition, data_type, category_subject), \n",
    "              sia la stringa univoca dello sweep ID, che l'insieme delle stringhe che formano la combinazione (condition, data_type, category_subject)\n",
    "\n",
    "\n",
    "\n",
    "LOOP DI PREPARAZIONE DATI (FINO A DATASET SPLITTING)\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#A QUESTO PUNTO PER OGNI DATASET, FACCIO STEP PRIMA DELLO SWEEP\n",
    "\n",
    "# Set per tenere traccia dei dataset già elaborati\n",
    "processed_datasets = set()\n",
    "\n",
    "# Seleziona il dispositivo (GPU o CPU)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "# Modelli che useremo nei sweep\n",
    "MODEL_LIST = [\"CNN2D_LSTM_TF\", \"BiLSTM\", \"Transformer\"] #ReadMEndYou and #ReadMYMind\n",
    "\n",
    "\n",
    "\n",
    "# Dizionario per salvare gli sweep ID associati a ogni condizione sperimentale\n",
    "\n",
    "'''sweep_ids_for_models contiene la struttura che mi serve da copiare per best_models''' \n",
    "sweep_ids_for_models = {}\n",
    "\n",
    "'''sweep_ids contiene la struttura che mi serve da copiare per iterare sui singoli swweps di ogni combinazione di fattori'''\n",
    "sweep_ids = {}  \n",
    "\n",
    "'''DIZIONARIO CHE VIENE FORNITO IN INGRESSO A TRAINING_SWEEP'''\n",
    "# Dizionario per salvare la tupla di dati già preprocessati\n",
    "data_dict_preprocessed = {}\n",
    "\n",
    "\n",
    "# Loop di addestramento e test per ogni condizione sperimentale\n",
    "for condition, data_types in data_dict.items():  # Itera sulle condizioni sperimentali\n",
    "    \n",
    "    data_dict_preprocessed[condition] = {}\n",
    "    \n",
    "    # Aggiungi al dizionario sweep_ids\n",
    "    if condition not in sweep_ids:\n",
    "        sweep_ids[condition] = {}\n",
    "        \n",
    "        '''sweep_ids_for_models'''\n",
    "        sweep_ids_for_models[condition] = {}\n",
    "        \n",
    "    for data_type, categories in data_types.items():  # Itera sui tipi di dati (1_20, 1_45, wavelet)\n",
    "        \n",
    "        data_dict_preprocessed[condition][data_type] = {}\n",
    "        \n",
    "        if data_type not in sweep_ids[condition]:\n",
    "            sweep_ids[condition][data_type] = {}\n",
    "            \n",
    "            '''sweep_ids_for_models'''\n",
    "            sweep_ids_for_models[condition][data_type] = {}\n",
    "            \n",
    "        for category_subject, (X_data, y_data) in categories.items():  # Itera sulle coppie category_subject\n",
    "            \n",
    "            # 1. Prepara spazio nei dizionari: sotto category_subject, un dict per ogni modello\n",
    "            \n",
    "            data_dict_preprocessed[condition][data_type][category_subject] = None\n",
    "            \n",
    "            if category_subject not in sweep_ids[condition][data_type]:\n",
    "                \n",
    "                sweep_ids[condition][data_type][category_subject] = {}\n",
    "                \n",
    "                '''NUOVA MODIFICA'''\n",
    "                sweep_ids[condition][data_type][category_subject] = {\n",
    "                model: [] for model in MODEL_LIST\n",
    "                }\n",
    "\n",
    "                '''sweep_ids_for_models'''\n",
    "                sweep_ids_for_models[condition][data_type][category_subject] = {}\n",
    "                \n",
    "                '''NUOVA MODIFICA'''\n",
    "                sweep_ids_for_models[condition][data_type][category_subject] = {\n",
    "                model: [] for model in MODEL_LIST\n",
    "                }\n",
    "                \n",
    "            print(f\"\\n\\n\\033[1mEstrazione Dati\\033[0m della Chiave \\033[1m{condition}_{data_type}_{category_subject}\\033[0m\")\n",
    "            \n",
    "            # Controlla se il dataset è già stato elaborato (se la chiave è già nel set)\n",
    "            if (condition, data_type, category_subject) in processed_datasets:\n",
    "                print(f\"⚠️ ATTENZIONE: Il dataset {condition} - {data_type} - {category_subject} è già stato elaborato! Salto iterazione...\")\n",
    "                continue  # Salta se il dataset è già stato processato\n",
    "\n",
    "            # Aggiungi il dataset al set\n",
    "            processed_datasets.add((condition, data_type, category_subject))\n",
    "\n",
    "            X_train, X_val, X_test, y_train, y_val, y_test = split_data(X_data, y_data)\n",
    "            \n",
    "            data_dict_preprocessed[condition][data_type][category_subject] = (X_train, X_val, X_test, y_train, y_val, y_test)\n",
    "            \n",
    "            # Puoi anche aggiungere altri print per verificare la dimensione dei set\n",
    "            print(f\"\\033[1mDataset Splitting\\033[0m: Train Set Shape: {X_train.shape}, Validation Set Shape: {X_val.shape}, Test Set Shape: {X_test.shape}\")\n",
    "\n",
    "            \n",
    "print(f\"\\nCreato \\033[1mdata_dict_preprocessed\\033[0m\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a08ca3-10c8-4632-af5c-c53d088191c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict['rest_vs_left_fist'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf116f23-8ba2-4406-b398-cd3d47ccbbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_dict_preprocessed.keys())\n",
    "print(data_dict_preprocessed['rest_vs_left_fist'].keys())\n",
    "print(data_dict_preprocessed['rest_vs_left_fist']['spectrograms'].keys())\n",
    "print(type(data_dict_preprocessed['rest_vs_left_fist']['spectrograms'].keys()))\n",
    "\n",
    "#All'interno, c'è una tupla, di 6 elementi!\n",
    "print(type(data_dict_preprocessed['rest_vs_left_fist']['spectrograms']['familiar_th']))\n",
    "\n",
    "#I 6 elementi della tupla sono X_train, X_val, X_test, y_train, y_val, y_test !\n",
    "print(len(data_dict_preprocessed['rest_vs_left_fist']['spectrograms']['familiar_th']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff50819c-a351-4a6c-89a3-15e2de12de5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sweep_ids_for_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7506ac2-a33e-4e02-9152-906033b915a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sweep_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4edc613-0a27-4c95-91c7-999fd85ce350",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sweep_ids_for_models)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "196520be-1826-4f81-bc46-dbb192533c88",
   "metadata": {
    "tags": []
   },
   "source": [
    "#Tutti gli sweep saranno organizzati sotto lo stesso progetto,\n",
    "#che corrisponde alla coppia di condizioni sperimentali corrente (i.e., exp_cond).\n",
    "\n",
    "#Questo significa che tutte le runs che verranno lanciate con quello sweep, \n",
    "#saranno associate a quella specifica coppia di condizioni sperimentali corrente.\n",
    "\n",
    "#Dato che sto iterando su ogni coppia di condizioni sperimentali, \n",
    "#ogni sweep verrà automaticamente salvato all'interno del progetto corrispondente \n",
    "#della specifica condizione sperimentale (exp_cond).\n",
    "\n",
    "#In pratica, se hai più condizioni sperimentali \n",
    "#(ad esempio, \"Condizione_A\", \"Condizione_B\", ecc.),\n",
    "#WandB creerà automaticamente sweep separati all'interno dei rispettivi progetti\n",
    "\n",
    "\n",
    "#Creo la configurazione dello sweep e la eseguo\n",
    "sweep_config = {\n",
    "    \"method\": \"random\",\n",
    "    \"metric\": {\"name\": \"val_accuracy\", \"goal\": \"maximize\"},\n",
    "    \"parameters\": {\n",
    "        \n",
    "        #\"lr\": {\"values\": [0.01, 0.001, 0.0005, 0.0001]},\n",
    "        \n",
    "        \"lr\": {\"values\": [1e-3]}, # fissato al valore di default del paper\n",
    "        \n",
    "        #\"weight_decay\": {\"values\": [0, 0.01, 0.001, 0.0001]},\n",
    "        \n",
    "        \"n_epochs\": {\"value\": 100},\n",
    "        \"patience\": {\"value\": 12},\n",
    "        \n",
    "        #\"model_name\":{\"values\": ['CNN2D', 'BiLSTM', 'Transformer']},\n",
    "        \n",
    "        #\"model_name\":{\"values\": ['CNN2D_LSTM_FC', 'BiLSTM', 'Transformer']},\n",
    "        \"model_name\":{\"values\": ['CNN2D_LSTM_FC']},\n",
    "        \n",
    "        #\"batch_size\": {\"values\": [32, 48, 64, 96]},\n",
    "        #\"batch_size\": {\"values\": [32, 48, 64, 72, 84, 96]},\n",
    "        #\"batch_size\": {\"values\": [32, 48, 64, 72, 84]},\n",
    "        \n",
    "        \"batch_size\": {\"values\": [32, 48, 64, 72, 84, 96]},\n",
    "        #\"batch_size\": {\"values\": [16, 24, 32, 48, 64]},\n",
    "        \"standardization\":{\"values\": [True, False]},\n",
    "        \n",
    "        \"beta1\": {\"value\": 0.9},\n",
    "        \"beta2\": {\"value\": 0.999},\n",
    "        \"eps\": {\"value\": 1e-8},\n",
    "        \n",
    "    }\n",
    "}\n",
    "    \n",
    "'''SWEEP_IDS_FOR_MODELS'''\n",
    "\n",
    "#Preparazione del dizionario sweep_ids_for_models (lo aggiorno inserendo il livello delle chiavi dei modelli, per copiare poi la struttura per creare best_models)\n",
    "\n",
    "for condition in sweep_ids_for_models:\n",
    "    for data_type in sweep_ids_for_models[condition]:\n",
    "        for category_subject in sweep_ids_for_models[condition][data_type]:\n",
    "            for model_name in sweep_config[\"parameters\"][\"model_name\"][\"values\"]:\n",
    "                \n",
    "                # Aggiungi il modello al dizionario, se non esiste già\n",
    "                if model_name not in sweep_ids_for_models[condition][data_type][category_subject]:\n",
    "                    sweep_ids_for_models[condition][data_type][category_subject][model_name] = []\n",
    "\n",
    "                    \n",
    "print(f\"\\nAggiornato \\033[1msweep_ids_for_models\\033[0m\")\n",
    "\n",
    "\n",
    "#Preparazione del dizionario best_models (facendo una copia della struttura di 'sweep_ids_for_models')\n",
    "\n",
    "#In questo modo potrò, per ogni condizione sperimentale, tipo di dato EEG e combinazione di ruolo/gruppo,\n",
    "#accedere facilmente al miglior modello (cioè ai suoi pesi e bias) e gestirlo in maniera separata!\n",
    "\n",
    "import copy\n",
    "best_models = copy.deepcopy(sweep_ids_for_models)\n",
    "\n",
    "# Inizializzo il dizionario che contiene il migliori modello tra quelli degli sweep testati, \n",
    "# relativi ad una certa combinazione di fattori,\n",
    "#per ogni condizione sperimentale\n",
    "#tipo di dato EEG \n",
    "#combinazione di ruolo/gruppo\n",
    "\n",
    "for condition in best_models:\n",
    "    for data_type in best_models[condition]:\n",
    "        for category_subject in best_models[condition][data_type]:\n",
    "            for model_name in best_models[condition][data_type][category_subject]:\n",
    "                best_models[condition][data_type][category_subject][model_name] = {\n",
    "                    \"model\": None,\n",
    "                    \"max_val_acc\": -float('inf'),\n",
    "                    \"best_epoch\": None,\n",
    "                    \n",
    "                    #ATTENZIONE! CREATA ALTRA CHIAVE PER SALVARE \n",
    "                    #LA MIGLIORE CONFIGURAZIONE DI IPER-PARAMETRI DI OGNI MODELLO!\n",
    "                    \"config\": None}\n",
    "                \n",
    "print(f\"\\nCreato \\033[1mbest_models\\033[0m\")\n",
    "\n",
    "\n",
    "'''SWEEP_IDS'''\n",
    "\n",
    "#Preparazione del dizionario sweep_ids (lo aggiorno inserendo solo una lista all'ultimo livello)\n",
    "\n",
    "# Itera su sweep_ids e crea le chiavi per category_subject con liste vuote\n",
    "for condition in sweep_ids:\n",
    "    for data_type in sweep_ids[condition]:\n",
    "        for category_subject in sweep_ids[condition][data_type]:\n",
    "            # Inizializza una lista vuota se non esiste già\n",
    "            if not isinstance(sweep_ids[condition][data_type][category_subject], list):\n",
    "                sweep_ids[condition][data_type][category_subject] = []\n",
    "                    \n",
    "print(f\"\\nAggiornato \\033[1msweep_ids\\033[0m\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c49b01-f5cb-461d-ba8b-345a10b9be75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "''' \n",
    "\n",
    "                                                                    AGGIORNATA AL 19 LUGLIO\n",
    "                                                                    \n",
    "                                                                    \n",
    "#\"learning rate : {\"value\"[1e-5, 5e-5, 1e-4, 5e-4, 1e-3, 5e-3, 1e-2]\"}\n",
    "#\"n_epochs\": {\"value\": 100},\n",
    "# \"patience\": {\"value\": 12},\n",
    "#\"batch_size\": {\"values\": [16, 24, 32, 48, 64, 72, 84, 96]}\n",
    "#\"standardization\": {\"values\": [True, False]}, \n",
    "# \"beta1\": {\"values\": [0.8, 0.85, 0.9, 0.95]},\n",
    "#  \"beta2\": {\"values\": [0.98, 0.99, 0.995, 0.999]},\n",
    "#  \"eps\": {\"value\": [1e-8, 1e-7, 1e-6, 1e-5]}                                                                                                                            \n",
    "\n",
    "\n",
    "\n",
    "sweep_config = {\n",
    "    \"method\": \"random\",\n",
    "    \"metric\": {\"name\": \"val_accuracy\", \"goal\": \"maximize\"},\n",
    "    \"parameters\": {\n",
    "        \n",
    "        \"lr\": {\"values\": [1e-5, 5e-5, 1e-4, 5e-4, 1e-3, 5e-3, 1e-2]}, # fissato al valore di default del paper\n",
    "\n",
    "        \"weight_decay\":  {\"values\": [0, 1e-4, 1e-3, 1e-2, 1e-1]},\n",
    "        \n",
    "        \"n_epochs\": {\"value\": 100},\n",
    "        \"patience\": {\"value\": 12},\n",
    "        \n",
    "        \n",
    "        \"model_name\":{\"values\": ['CNN3D_LSTM_FC']},\n",
    "\n",
    "        \"batch_size\": {\"values\": [32, 48, 64, 96]},\n",
    "\n",
    "        \"standardization\":{\"values\": [True, False]},\n",
    "\n",
    "        \"beta1\": {\"values\": [0.9, 0.95]},\n",
    "\n",
    "        \"beta2\": {\"values\": [0.99, 0.995]},\n",
    "        \n",
    "        \"eps\": {\"values\": [1e-8, 1e-7]},\n",
    "        \n",
    "        #In questo modo:\n",
    "        \n",
    "        \"use_lstm\":      {\"values\":[True, False]},\n",
    "        \"lstm_hidden\":   {\"values\":[32]},\n",
    "        \"dropout\":       {\"values\":[0.5]},\n",
    "        \n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "#Tutti gli sweep saranno organizzati sotto lo stesso progetto,\n",
    "#che corrisponde alla coppia di condizioni sperimentali corrente (i.e., exp_cond).\n",
    "\n",
    "#Questo significa che tutte le runs che verranno lanciate con quello sweep, \n",
    "#saranno associate a quella specifica coppia di condizioni sperimentali corrente.\n",
    "\n",
    "#Dato che sto iterando su ogni coppia di condizioni sperimentali, \n",
    "#ogni sweep verrà automaticamente salvato all'interno del progetto corrispondente \n",
    "#della specifica condizione sperimentale (exp_cond).\n",
    "\n",
    "#In pratica, se hai più condizioni sperimentali \n",
    "#(ad esempio, \"Condizione_A\", \"Condizione_B\", ecc.),\n",
    "#WandB creerà automaticamente sweep separati all'interno dei rispettivi progetti\n",
    "\n",
    "\n",
    "#Creo la configurazione dello sweep e la eseguo:\n",
    "\n",
    "#uno per il modello CNN3D_LSTM_FC, originariamente era così\n",
    "\n",
    "\n",
    "#sweep_config_cnn3d= {\n",
    "#    \"method\": \"random\",\n",
    "#    \"metric\": {\"name\": \"val_accuracy\", \"goal\": \"maximize\"},\n",
    "#    \"parameters\": {\n",
    "#        \"lr\": {\"values\": [1e-5, 5e-5, 1e-4, 5e-4, 1e-3, 5e-3, 1e-2]},\n",
    "#        \"weight_decay\": {\"values\": [0, 1e-4, 1e-3, 1e-2, 1e-1]},\n",
    "#        \"n_epochs\": {\"value\": 100},\n",
    "#       \"patience\": {\"value\": 12},\n",
    "#        \"model_name\": {\"values\": [\"CNN2D_LSTM_TF\"]},\n",
    "#        \"batch_size\": {\"values\": [32, 48, 64, 96]},\n",
    "        \n",
    "#        \"standardization\": {\"values\": [True,False]}, #        '''ATTENZIONE QUI IMPOSTIAMO SEMPRE A TRUE'''\n",
    "#        \"beta1\": {\"values\": [0.9, 0.95]},\n",
    "#        \"beta2\": {\"values\": [0.99, 0.995]},\n",
    "#        \"eps\": {\"values\": [1e-8, 1e-7]},\n",
    "#        \"use_lstm\": {\"values\": [True, False]},\n",
    "#        \"lstm_hidden\": {\"values\": [32]},\n",
    "#        \"dropout\": {\"values\": [0.5]},\n",
    "#    }\n",
    "#}\n",
    "\n",
    "\n",
    "#sweep_config_cnn_sep = {\n",
    "#    \"method\": \"random\",\n",
    "#    \"metric\": {\"name\": \"val_accuracy\", \"goal\": \"maximize\"},\n",
    "#    \"parameters\": {\n",
    "#        \"lr\": {\"values\": [1e-5, 5e-5, 1e-4, 5e-4, 1e-3, 5e-3, 1e-2]},\n",
    "#        \"weight_decay\": {\"values\": [0, 1e-4, 1e-3, 1e-2, 1e-1]},\n",
    "#        \"n_epochs\": {\"value\": 100},\n",
    "#        \"patience\": {\"value\": 12},\n",
    "#        \"model_name\": {\"values\": [\"SeparableCNN2D_LSTM_FC\"]},\n",
    "#        \"batch_size\": {\"values\": [32, 48, 64, 96]},\n",
    "#        \"standardization\": {\"values\": [True,False]}, #        '''ATTENZIONE QUI IMPOSTIAMO SEMPRE A TRUE'''\n",
    "#        \"beta1\": {\"values\": [0.9, 0.95]},\n",
    "#        \"beta2\": {\"values\": [0.99, 0.995]},\n",
    "#        \"eps\": {\"values\": [1e-8, 1e-7]},\n",
    "#        \"use_lstm\": {\"values\": [True, False]},\n",
    "#        \"lstm_hidden\": {\"values\": [32]},\n",
    "#        \"dropout\": {\"values\": [0.5]},\n",
    "#    }\n",
    "#}\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "# Comodo mapper per il tuo loop\n",
    "sweep_config_dict_stft = {\n",
    "    \"CNN2D_LSTM_TF\": sweep_config_cnn2d_lstm_tf,\n",
    "    \"ReadMEndYou\": sweep_config_bilstm,\n",
    "    \"ReadMYMind\": sweep_config_transformer,\n",
    "}\n",
    "Nota pratica (per l’integrazione nel training)\n",
    "CNN2D_LSTM_TF: passa dropout=config.dropout.\n",
    "\n",
    "ReadMEndYou: costruisci con\n",
    "ReadMEndYou(input_size=channels*freqs, hidden_sizes=[config.hidden1, config.hidden2, config.hidden3],\n",
    "output_size=2, dropout=config.dropout, bidirectional=config.bidirectional).\n",
    "\n",
    "ReadMYMind: costruisci con\n",
    "ReadMYMind(d_model=config.d_model, num_heads=config.num_heads, num_layers=config.num_layers, num_classes=2, channels=config.channels, freqs=config.freqs).\n",
    "\n",
    "'''\n",
    "# 2.1 – Sweep config per ciascun modello\n",
    "\n",
    "#CNN2D_LSTM_TF\n",
    "sweep_config_cnn2d_lstm_tf = {\n",
    "    \"method\": \"random\",\n",
    "    \"metric\": {\"name\": \"val_accuracy\", \"goal\": \"maximize\"},\n",
    "    \"parameters\": {\n",
    "        \"lr\": {\"values\": [1e-5, 5e-5, 1e-4, 5e-4, 1e-3, 5e-3, 1e-2]},\n",
    "        \"weight_decay\": {\"values\": [0, 1e-4, 1e-3, 1e-2, 1e-1]},\n",
    "        \"n_epochs\": {\"value\": 100},\n",
    "        \"patience\": {\"value\": 12},\n",
    "        \"model_name\": {\"values\": [\"CNN2D_LSTM_TF\"]},\n",
    "        \"batch_size\": {\"values\": [32, 48, 64, 96]},\n",
    "        \n",
    "        \"standardization\": {\"values\": [True]}, #        '''ATTENZIONE QUI IMPOSTIAMO SEMPRE A TRUE'''\n",
    "        \n",
    "        \"beta1\": {\"values\": [0.9, 0.95]},\n",
    "        \"beta2\": {\"values\": [0.99, 0.995]},\n",
    "        \"eps\": {\"values\": [1e-8, 1e-7]},\n",
    "        \n",
    "        # --- specifici del modello ---\n",
    "    \n",
    "        \"dropout\": {\"values\": [0.5]},\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "sweep_config_bilstm = {\n",
    "    \"method\": \"random\",\n",
    "    \"metric\": {\"name\": \"val_accuracy\", \"goal\": \"maximize\"},\n",
    "    \"parameters\": {\n",
    "        \"lr\": {\"values\": [1e-5, 5e-5, 1e-4, 5e-4, 1e-3, 5e-3, 1e-2]},\n",
    "        \"weight_decay\": {\"values\": [0, 1e-4, 1e-3, 1e-2, 1e-1]},\n",
    "        \"n_epochs\": {\"value\": 100},\n",
    "        \"patience\": {\"value\": 12},\n",
    "        \"model_name\": {\"values\": [\"BiLSTM\"]},\n",
    "        \"batch_size\": {\"values\": [32, 48, 64, 96]},\n",
    "        \n",
    "        \"standardization\": {\"values\": [True]}, #        '''ATTENZIONE QUI IMPOSTIAMO SEMPRE A TRUE'''\n",
    "        \n",
    "        \"beta1\": {\"values\": [0.9, 0.95]},\n",
    "        \"beta2\": {\"values\": [0.99, 0.995]},\n",
    "        \"eps\": {\"values\": [1e-8, 1e-7]},\n",
    "        \n",
    "        # --- specifici del modello ---\n",
    "        \"dropout\": {\"values\": [0.5]},\n",
    "        \"bidirectional\": {\"values\": [False, True]},\n",
    "        \n",
    "        #Soluzione 1 per mettere valori agli hidden sizes\n",
    "        #\"hidden1\": {\"values\": [24, 32, 48, 64]},\n",
    "        #\"hidden2\": {\"values\": [48, 64, 96, 128]},\n",
    "        #\"hidden3\": {\"values\": [62, 96, 128, 160]}\n",
    "        # in build del modello: hidden_sizes=[hidden1, hidden2, hidden3]\n",
    "        \n",
    "        #Soluzione 2 per mettere valori agli hidden sizes\n",
    "        \n",
    "        #hidden_sizes = [24, 48, 62]\n",
    "        #lstm_model = ReadMEndYou(input_size=input_channels * num_freqs, hidden_sizes=hidden_sizes, output_size=num_classes)\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "sweep_config_transformer = {\n",
    "    \"method\": \"random\",\n",
    "    \"metric\": {\"name\": \"val_accuracy\", \"goal\": \"maximize\"},\n",
    "    \"parameters\": {\n",
    "        \"lr\": {\"values\": [1e-5, 5e-5, 1e-4, 5e-4, 1e-3, 5e-3, 1e-2]},\n",
    "        \"weight_decay\": {\"values\": [0, 1e-4, 1e-3, 1e-2, 1e-1]},\n",
    "        \"n_epochs\": {\"value\": 100},\n",
    "        \"patience\": {\"value\": 12},\n",
    "        \"model_name\": {\"values\": [\"Transformer\"]},\n",
    "        \"batch_size\": {\"values\": [32, 48, 64, 96]},\n",
    "        \n",
    "        \"standardization\": {\"values\": [True]}, #        '''ATTENZIONE QUI IMPOSTIAMO SEMPRE A TRUE'''\n",
    "        \n",
    "        \"beta1\": {\"values\": [0.9, 0.95]},\n",
    "        \"beta2\": {\"values\": [0.99, 0.995]},\n",
    "        \"eps\": {\"values\": [1e-8, 1e-7]},\n",
    "        \n",
    "        # --- specifici del modello ---\n",
    "        \"d_model\": {\"values\": [32]},\n",
    "        \"num_heads\": {\"values\": [2]},\n",
    "        \"num_layers\": {\"values\": [2]},\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "'''SWEEP_IDS_FOR_MODELS\n",
    "\n",
    "# 2) Popolo sweep_ids_for_models in base a MODEL_LIST (già inizializzato nella prima cella)\n",
    "'''\n",
    "\n",
    "#Preparazione del dizionario sweep_ids_for_models (lo aggiorno inserendo il livello delle chiavi dei modelli, per copiare poi la struttura per creare best_models)\n",
    "\n",
    "#for condition in sweep_ids_for_models:\n",
    "    #for data_type in sweep_ids_for_models[condition]:\n",
    "        #for category_subject in sweep_ids_for_models[condition][data_type]:\n",
    "            #for model_name in sweep_config[\"parameters\"][\"model_name\"][\"values\"]:\n",
    "                \n",
    "                # Aggiungi il modello al dizionario, se non esiste già\n",
    "                #if model_name not in sweep_ids_for_models[condition][data_type][category_subject]:\n",
    "                    #sweep_ids_for_models[condition][data_type][category_subject][model_name] = []\n",
    "\n",
    "                    \n",
    "print(f\"\\nAggiornato \\033[1msweep_ids_for_models\\033[0m\")\n",
    "\n",
    "\n",
    "'''BEST_MODELS\n",
    "\n",
    "# 3) Creo best_models da sweep_ids_for_models\n",
    "'''\n",
    "\n",
    "#Preparazione del dizionario best_models (facendo una copia della struttura di 'sweep_ids_for_models')\n",
    "\n",
    "#In questo modo potrò, per ogni condizione sperimentale, tipo di dato EEG e combinazione di ruolo/gruppo,\n",
    "#accedere facilmente al miglior modello (cioè ai suoi pesi e bias) e gestirlo in maniera separata!\n",
    "\n",
    "import copy\n",
    "best_models = copy.deepcopy(sweep_ids_for_models)\n",
    "\n",
    "# Inizializzo il dizionario che contiene il migliori modello tra quelli degli sweep testati, \n",
    "# relativi ad una certa combinazione di fattori,\n",
    "#per ogni condizione sperimentale\n",
    "#tipo di dato EEG \n",
    "#combinazione di ruolo/gruppo\n",
    "\n",
    "for condition in best_models:\n",
    "    for data_type in best_models[condition]:\n",
    "        for category_subject in best_models[condition][data_type]:\n",
    "            for model_name in best_models[condition][data_type][category_subject]:\n",
    "                best_models[condition][data_type][category_subject][model_name] = {\n",
    "                    \"model\": None,\n",
    "                    \"max_val_acc\": -float('inf'),\n",
    "                    \"best_epoch\": None,\n",
    "                    \n",
    "                    #ATTENZIONE! CREATA ALTRA CHIAVE PER SALVARE \n",
    "                    #LA MIGLIORE CONFIGURAZIONE DI IPER-PARAMETRI DI OGNI MODELLO!\n",
    "                    \"config\": None}\n",
    "                \n",
    "print(f\"\\nCreato \\033[1mbest_models\\033[0m\")\n",
    "\n",
    "\n",
    "#'''SWEEP_IDS'''\n",
    "\n",
    "#Preparazione del dizionario sweep_ids (lo aggiorno inserendo solo una lista all'ultimo livello)\n",
    "\n",
    "# Itera su sweep_ids e crea le chiavi per category_subject con liste vuote\n",
    "#for condition in sweep_ids:\n",
    "    #for data_type in sweep_ids[condition]:\n",
    "        #for category_subject in sweep_ids[condition][data_type]:\n",
    "            # Inizializza una lista vuota se non esiste già\n",
    "            #if not isinstance(sweep_ids[condition][data_type][category_subject], list):\n",
    "                #sweep_ids[condition][data_type][category_subject] = []\n",
    "                    \n",
    "#print(f\"\\nAggiornato \\033[1msweep_ids\\033[0m\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac943546-dad8-4e06-b930-3e5a57e29599",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#print(best_models)\n",
    "#print(sweep_ids_for_models)\n",
    "#print(sweep_ids)\n",
    "#print(data_dict_preprocessed['th_resp_vs_pt_resp']['1_20']['familiar_th'][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10dd6a05-9e7a-4a81-a531-e60e556a4611",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f63022-8593-4d8a-b530-45ae594617d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sweep_ids_for_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e4ee29-740c-4b7d-881b-2fd5462f5840",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sweep_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e59c2a-5262-46a2-92dd-e848b40c80af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_dict_preprocessed['th_resp_vs_pt_resp']['1_20']['familiar_th'][5].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed93509d-1f02-4b49-8142-54eaa5b3d924",
   "metadata": {
    "tags": []
   },
   "source": [
    "**NOTA BENE**\n",
    "\n",
    "Come output, io otterrò **quando crei gli sweeps** una cosa come questa, ad esempio:\n",
    "\n",
    "        Create sweep with ID: y73iajvw\n",
    "        Sweep URL: https://wandb.ai/stefano-bargione-universit-di-roma-tor-vergata/th_resp_vs_pt_resp/sweeps/y73iajvw\n",
    "        Sweep ID creato per th_resp_vs_pt_resp - 1_20 - familiar_th - CNN1D: n° sweep y73iajvw\n",
    "        Create sweep with ID: 3b6o28jt\n",
    "        Sweep URL: https://wandb.ai/stefano-bargione-universit-di-roma-tor-vergata/th_resp_vs_pt_resp/sweeps/3b6o28jt\n",
    "        Sweep ID creato per th_resp_vs_pt_resp - 1_20 - familiar_th - BiLSTM: n° sweep 3b6o28jt\n",
    "        Create sweep with ID: q6yp4fas\n",
    "\n",
    "        .....\n",
    "\n",
    "Vedendole bene, per **ogni condizione sperimentale (3)**, **per ogni dato EEG (3)** e **per ogni provenienza del dato EEG (4)**, \n",
    "Io **DOVREI OTTENERE** in totale = **3x3x4 = 36 sweeps** per **OGNI CONDIZIONE SPERIMENTALE**\n",
    "\n",
    "\n",
    "Per **ognuna di queste sweeps**, io se ho capito bene creerò **15 esperimenti** (le mie runs), che corrispondo alle **diverse configurazioni di iper-parametri testati per lo stesso specifico sweep**!\n",
    "\n",
    "(ad esempio, solo questo \n",
    "\n",
    "<br> \n",
    "\n",
    "        Create sweep with ID: y73iajvw\n",
    "        Sweep URL: https://wandb.ai/stefano-bargione-universit-di-roma-tor-vergata/th_resp_vs_pt_resp/sweeps/y73iajvw\n",
    "        Sweep ID creato per th_resp_vs_pt_resp - 1_20 - familiar_th - CNN1D: n° sweep y73iajvw)\n",
    "\n",
    "Dove, le diverse configurazioni, son determinate randomicamente a partire dai valori dentro la variabile \"**sweep_config**\"  che è questa \n",
    "\n",
    "\n",
    "    #Creo la configurazione dello sweep e la eseguo\n",
    "    sweep_config = {\n",
    "        \"method\": \"random\",\n",
    "        \"metric\": {\"name\": \"val_accuracy\", \"goal\": \"maximize\"},\n",
    "        \"parameters\": {\n",
    "            \"lr\": {\"values\": [0.01, 0.001, 0.0005, 0.0001]},\n",
    "            \"weight_decay\": {\"values\": [0, 0.01, 0.001, 0.0001]},\n",
    "            \"n_epochs\": {\"value\": 100},\n",
    "            \"patience\": {\"value\": 10},\n",
    "            \"model_name\":{\"values\": ['CNN1D', 'BiLSTM', 'Transformer']},\n",
    "            \"batch_size\": {\"values\": [32, 48, 64, 96]},\n",
    "            \"standardization\":{\"values\": [True, False]},\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6dc50b6-44da-4401-80f8-5a40ad40d848",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "ATTENZIONE CHE A QUESTO PUNTO\n",
    "\n",
    "\n",
    "1) sweep_ids[cond][dtype][cat][model_name] contiene le tuple (sweep_id, combo_key) per ciascun modello, che ancora non esistono perché devo esser create durante la creazione degli sweeps, ma ho solo una lista\n",
    "\n",
    "{'rest_vs_left_fist': {'spectrograms': {'familiar_th': []}}, \n",
    "'rest_vs_right_fist': {'spectrograms': {'familiar_th': []}}, \n",
    "'left_fist_vs_right_fist': {'spectrograms': {'familiar_th': []}}}\n",
    "\n",
    "\n",
    "2) sweep_ids_for_models e best_models sono paralleli a sweep_ids con lo stesso livello model_name\n",
    "\n",
    "ossia \n",
    "\n",
    "sweep_ids_for_models come\n",
    "\n",
    "{'rest_vs_left_fist': {'spectrograms': {'familiar_th': {'CNN2D_LSTM_FC': [], 'ReadMEndYou': [], 'ReadMYMind': []}}},\n",
    "'rest_vs_right_fist': {'spectrograms': {'familiar_th': {'CNN2D_LSTM_FC': [], 'ReadMEndYou': [], 'ReadMYMind': []}}},\n",
    "'left_fist_vs_right_fist': {'spectrograms': {'familiar_th': {'CNN2D_LSTM_FC': [], 'ReadMEndYou': [], 'ReadMYMind': []}}}}\n",
    "\n",
    "best_models come\n",
    "\n",
    "{'rest_vs_left_fist': {'spectrograms': {'familiar_th': \n",
    "{'CNN2D_LSTM_FC': {'model': None, 'max_val_acc': -inf, 'best_epoch': None, 'config': None}, \n",
    "'ReadMEndYou': {'model': None, 'max_val_acc': -inf, 'best_epoch': None, 'config': None},\n",
    "'ReadMYMind': {'model': None, 'max_val_acc': -inf, 'best_epoch': None, 'config': None}}}},\n",
    "\n",
    "'rest_vs_right_fist': {'spectrograms': {'familiar_th': \n",
    "{'CNN2D_LSTM_FC': {'model': None, 'max_val_acc': -inf, 'best_epoch': None, 'config': None}, \n",
    "'ReadMEndYou': {'model': None, 'max_val_acc': -inf, 'best_epoch': None, 'config': None},\n",
    "'ReadMYMind': {'model': None, 'max_val_acc': -inf, 'best_epoch': None, 'config': None}}}},\n",
    "\n",
    "'left_fist_vs_right_fist': {'spectrograms': {'familiar_th': \n",
    "{'CNN2D_LSTM_FC': {'model': None, 'max_val_acc': -inf, 'best_epoch': None, 'config': None}, \n",
    "'ReadMEndYou': {'model': None, 'max_val_acc': -inf, 'best_epoch': None, 'config': None},\n",
    "'ReadMYMind': {'model': None, 'max_val_acc': -inf, 'best_epoch': None, 'config': None}}}},\n",
    "\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8ea618-45ec-47e8-831a-6b8139394446",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Popolamento di sweep_ids e lancio degli agenti:\n",
    "\n",
    "Obiettivo: \n",
    "\n",
    "Per ogni combinazione (condition, data_type, category_subject, model_name), \n",
    "Se la lista è vuota, crei uno sweep usando wandb.sweep(sweep_config, project=condition) e lo inserisci nella lista. \n",
    "In seguito, iteri su quella lista (che ora contiene IL TUO SPECIFICO sweep_id) e lanci wandb.agent() per eseguire il training.\n",
    "\n",
    "\n",
    "\n",
    "Nota importante:\n",
    "L'ID restituito da wandb.sweep() è una STRINGA UNIVOCA generata automaticamente da WandB.\n",
    "Non puoi assegnargli direttamente una stringa personalizzata, ma puoi comunque usarlo per mappare nel tuo dizionario la combinazione di fattori! \n",
    "\n",
    "In questo ciclo, il fatto che la lista parta vuota è normale: il codice la popola se necessario e poi lancia l'agente per ogni sweep_id presente.\n",
    "\n",
    "\n",
    "****** ****** ******  ****** ****** ******  ****** ****** ******  ****** ****** ******  ****** ****** ******\n",
    "INOLTRE, BISOGNA CONTROLLARE CHE SI STIA ITERANDO CORRETTAMENTE SOLO SULLA COMBINAZIONE CORRENTE DI \n",
    "\n",
    "                CONDITION, DATA_TYPE, CATEGORY_SUBJECT E MODEL_NAME\n",
    "                \n",
    "QUESTO PERCHÉ SE UN CICLO SI RIPETE PER UNA CONDIZIONE IN PIÙ UNA COMBINAZIONE, POTREBBE GENERARE PIÙ  SWEEP IDS DI QUELLI CHE TI ASPETTI!\n",
    "****** ****** ******  ****** ****** ******  ****** ****** ******  ****** ****** ******  ****** ****** ******\n",
    "\n",
    "\n",
    "\n",
    "SOLUZIONE:\n",
    "\n",
    "Un buon approccio per evitare la creazione ripetuta di Sweep ID \n",
    "per la stessa combinazione di condition, data_type, category_subject e model_name \n",
    "è quello di utilizzare un SET per tenere traccia delle combinazioni già processate.\n",
    "Se una combinazione è già presente nel set, non dovresti creare un nuovo Sweep ID, ma semplicemente saltare quella parte del codice\n",
    "\n",
    "\n",
    "Inoltre, ho avuto una idea ad un certo punto! \n",
    "\n",
    "\n",
    "****************************** ******************************\n",
    "ILLUMINAZIONE DEL POMERIGGIO DEL 04/03/2025: \n",
    "****************************** ******************************\n",
    "\n",
    "\n",
    "Quando creo ogni sweep singolarmente, si genera una stringa univoca di quello sweep, che si riferisce ad un dataset che è il prodotto di diversi fattori:\n",
    "\n",
    "- una certa condizione sperimentale,  \n",
    "- una certo preprocessing sui dati EEG (1_20, 1_45, wavelet)\n",
    "- una certa provenienza del dato proprio (in termini di ruolo e gruppo --> th o pt, familiar o unfamiliar)\n",
    "\n",
    "\n",
    "Di conseguenza, iterando su ogni sweep_ids (che ho fatto in modo avesse la STESSA struttura dei miei dati già splittati i.e, data_dict_preprocessed\n",
    "io posso, \n",
    "\n",
    "1) da un lato eseguire la creazione della stringa univoca associata a quello sweep,\n",
    "2) crearmi una 'combination_key', che sarebbe l'insieme delle stringhe che descrivono quel dataset specifico di data_dict_preprocessed\n",
    "\n",
    "che sarà costituito da\n",
    "\n",
    "- una certa condizione sperimentale,  \n",
    "- una certo preprocessing sui dati EEG (1_20, 1_45, wavelet)\n",
    "- una certa provenienza del dato proprio (in termini di ruolo e gruppo --> th o pt, familiar o unfamiliar)\n",
    "\n",
    "\n",
    "Poiché quindi so già la corrispondenza tra ogni Sweep ID e la sua combinazione di fattori (condition, data_type, category_subject), \n",
    "posso creare un MAPPING, che associ, ad certo Sweep ID e la stringa che descrive i suoi fattori associati!\n",
    "\n",
    "\n",
    "In questo modo, forse, si riesce a risolvere il PROBLEMA 2 NELLA CELLA DI CREAZIONE DELLA FUNZIONE DI TRAINING (VEDI SOTTO!)\n",
    "\n",
    "\n",
    "\n",
    "                                                        ******IMPORTANTE MODIFICA*****\n",
    "                                                        \n",
    "Ora lo sweep_ids non si deve sdoppiare ora, perché sostanzialmente, \n",
    "per ogni modello si creano gli sweeps ids corrispondenti e salvati come valore\n",
    "dentro la chiave del modello corrispondente, sotto forma di tupla...\n",
    "\n",
    "cioè non più così\n",
    "\n",
    "\"sweep_ids[condition][data_type][category_subject].append((new_sweep_id, combination_key))\"\n",
    "\n",
    "ma una cosa del genere\n",
    "\n",
    "\"sweep_ids[condition][data_type][category_subject][model_name].append((new_sweep_id, combination_key))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "COME ERA PRIMA\n",
    "\n",
    "#Inizializza un set per tenere traccia delle combinazioni già elaborate\n",
    "\n",
    "created_combinations = set()\n",
    "\n",
    "for condition in sweep_ids:\n",
    "    for data_type in sweep_ids[condition]:\n",
    "        for category_subject in sweep_ids[condition][data_type]:\n",
    "            \n",
    "            combination_key = f\"{condition}_{data_type}_{category_subject}\"\n",
    "\n",
    "            # Controlla se la combinazione è già stata elaborata\n",
    "            if combination_key not in created_combinations:\n",
    "\n",
    "                if not sweep_ids[condition][data_type][category_subject]:\n",
    "                    #new_sweep_id = wandb.sweep(sweep_config, project=f\"{condition}_spectrograms\")\n",
    "                    new_sweep_id = wandb.sweep(sweep_config, project=f\"{condition}_spectrograms_channels_freqs_new_3d_grid_multiband\")\n",
    "\n",
    "                    #QUI, viene creata la mappatura tra Sweep ID e la descrizione della combinazione (in formato di stringhe)\n",
    "                    #CON LA CREAZIONE DI UNA TUPLA, DENTRO LA LISTA \n",
    "                \n",
    "                    sweep_ids[condition][data_type][category_subject].append((new_sweep_id, combination_key))\n",
    "                    \n",
    "                    print(f\"Sweep ID creato per \\033[1m{combination_key}\\033[0m: n° sweep \\033[1m{new_sweep_id}\\033[0m\")\n",
    "\n",
    "                # Aggiungi la combinazione al set per evitare duplicazioni\n",
    "                created_combinations.add(combination_key)\n",
    "            else:\n",
    "                # Se la combinazione è già stata creata, salta\n",
    "                print(f\"Sweep ID per {combination_key} già esistente.\")\n",
    "                \n",
    "'''\n",
    "\n",
    "\n",
    "'''\n",
    "ADESSO\n",
    "\n",
    "\n",
    "Cosa fa questo snippet\n",
    "\n",
    "Cicla su ogni (condition, data_type, category_subject) una volta sola grazie a created_combinations.\n",
    "\n",
    "All’interno, fa un sottoloop su MODEL_LIST (i tuoi due modelli).\n",
    "\n",
    "In base a model_name, sceglie sweep_config_cnn3d o sweep_config_cnn_sep.\n",
    "\n",
    "Chiama wandb.sweep(...) con il config giusto e salva il risultato in\n",
    "\n",
    "\n",
    "sweep_ids[condition][data_type][category_subject][model_name]\n",
    "anziché nella lista “piatta” che avevi prima.\n",
    "\n",
    "\n",
    "In questo modo:\n",
    "\n",
    "sweep_ids[cond][dtype][cat] resta un dict con due chiavi (\"CNN3D_LSTM_FC\" e \"SeparableCNN2D_LSTM_FC\")\n",
    "\n",
    "Ognuna di quelle chiavi punta a una propria lista di tuple (sweep_id, combo_key)\n",
    "\n",
    "Non serve sdoppiare l’intero sweep_ids, perché tiene già separati gli sweep di ciascun modello\n",
    "\n",
    "Più tardi, quando lancerai gli agent, ti basterà:\n",
    "\n",
    "\n",
    "for model_name, sweeps in sweep_ids[cond][dtype][cat].items():\n",
    "    for sweep_id, combo_key in sweeps:\n",
    "        # qui scegli il train_fn in base a model_name\n",
    "        wandb.agent(sweep_id, function=train_fn_map[model_name], count=200)\n",
    "e ogni modello girerà solo i suoi sweep.\n",
    "\n",
    "\n",
    "\n",
    "Alla fine, sweep_ids avrà la forma:\n",
    "\n",
    "{\n",
    "  'rest_vs_left_fist': {\n",
    "    'spectrograms': {\n",
    "      'familiar_th': {\n",
    "         'CNN3D_LSTM_FC':       [(sweep_id_1, 'rest_vs_left_fist_spectrograms_familiar_th')],\n",
    "         'SeparableCNN2D_LSTM_FC': [(sweep_id_2, 'rest_vs_left_fist_spectrograms_familiar_th')]\n",
    "      }\n",
    "    }\n",
    "  },\n",
    "  …\n",
    "}\n",
    "'''\n",
    "\n",
    "\n",
    "#Ecco come puoi riscrivere solo la TERZA CELLA (quella in cui crei effettivamente gli sweep) \n",
    "#mantenendo la tua struttura “a celle” e usando per ognuno il sweep_config giusto in base al model_name.\n",
    "\n",
    "#Creazione degli sweep (Terza cella)\n",
    "#Ecco il solo snippet che devi usare per creare gli sweep ripartiti per modello, usando i due sweep_config_*:\n",
    "\n",
    "\n",
    "'''\n",
    "Per mantenere la stessa logica di prima ma tenendo conto che ora stai lavorando con modelli separati, \n",
    "dovresti modificare il controllo in modo che verifichi se una combinazione di condition, data_type, category_subject\n",
    "è già stata processata per ciascun modello.\n",
    "\n",
    "Quindi, il controllo dovrebbe essere fatto separatamente per ogni modello dentro il loop che itera sui modelli (MODEL_LIST).\n",
    "Di seguito ti mostro la versione modificata che tiene conto di questo:\n",
    "\n",
    "\n",
    "\n",
    "#Inizializza un set per tenere traccia delle combinazioni già elaborate\n",
    "\n",
    "created_combinations = set()\n",
    "\n",
    "for condition in sweep_ids:\n",
    "    for data_type in sweep_ids[condition]:\n",
    "        for category_subject in sweep_ids[condition][data_type]:\n",
    "            \n",
    "            combination_key = f\"{condition}_{data_type}_{category_subject}\"\n",
    "\n",
    "            # Controlla se la combinazione è già stata elaborata\n",
    "            if combination_key not in created_combinations:\n",
    "\n",
    "                if not sweep_ids[condition][data_type][category_subject]:\n",
    "                    #new_sweep_id = wandb.sweep(sweep_config, project=f\"{condition}_spectrograms\")\n",
    "                    new_sweep_id = wandb.sweep(sweep_config, project=f\"{condition}_spectrograms_channels_freqs_new_3d_grid_multiband\")\n",
    "\n",
    "                    #QUI, viene creata la mappatura tra Sweep ID e la descrizione della combinazione (in formato di stringhe)\n",
    "                    #CON LA CREAZIONE DI UNA TUPLA, DENTRO LA LISTA \n",
    "                \n",
    "                    sweep_ids[condition][data_type][category_subject].append((new_sweep_id, combination_key))\n",
    "                    \n",
    "                    print(f\"Sweep ID creato per \\033[1m{combination_key}\\033[0m: n° sweep \\033[1m{new_sweep_id}\\033[0m\")\n",
    "\n",
    "                # Aggiungi la combinazione al set per evitare duplicazioni\n",
    "                created_combinations.add(combination_key)\n",
    "            else:\n",
    "                # Se la combinazione è già stata creata, salta\n",
    "                print(f\"Sweep ID per {combination_key} già esistente.\")\n",
    "                \n",
    "                \n",
    "                \n",
    "'''\n",
    "\n",
    "                    \n",
    "'''\n",
    "\n",
    "Cosa è stato cambiato rispetto alla versione precedente?\n",
    "Controllo della combinazione di modello:\n",
    "La logica del controllo della combinazione (combination_key, model_name) nel set created_combinations è corretta, \n",
    "perché vogliamo evitare di creare più volte lo stesso sweep per una combinazione di condition, data_type, category_subject, e model_name.\n",
    "\n",
    "Controllo e creazione dello sweep:\n",
    "Il codice controlla prima se la combinazione con il modello non è stata già processata \n",
    "con il controllo if (combination_key, model_name) not in created_combinations. \n",
    "\n",
    "Se non è stata processata, procede a creare lo sweep corrispondente. \n",
    "Se la combinazione esiste già, salta la creazione dello sweep per quel modello.\n",
    "\n",
    "Aggiunta del nuovo sweep ID:\n",
    "Una volta creato il nuovo sweep per il modello, viene aggiunto correttamente \n",
    "alla lista del modello specifico sotto sweep_ids[condition][data_type][category_subject][model_name].\n",
    "\n",
    "Aggiunta al set delle combinazioni:\n",
    "Dopo aver creato lo sweep, aggiungiamo (combination_key, model_name) al set created_combinations\n",
    "per tenere traccia delle combinazioni già elaborate.\n",
    "\n",
    "Verifica della logica:\n",
    "La combinazione (combination_key, model_name) deve essere unica per ciascun modello, \n",
    "e quindi il controllo che evita duplicazioni nel set è corretto.\n",
    "\n",
    "La creazione dello sweep per ciascun modello separato è mantenuta, \n",
    "e viene applicata solo quando la combinazione specifica non è già stata elaborata per quel modello.\n",
    "\n",
    "In questo modo, la logica funziona come nel codice precedente, ma ora si tiene conto anche dei modelli separati, \n",
    "creando un sweep per ciascuno di essi e mantenendo la traccia delle combinazioni in modo appropriato.\n",
    "\n",
    "'''\n",
    "created_combinations = set()\n",
    "\n",
    "\n",
    "\n",
    "#CNN2D_LSTM_TF\n",
    "#sweep_config_cnn2d_lstm_tf\n",
    "\n",
    "#sweep_config_bilstm\n",
    "#sweep_config_transformer\n",
    "# Per semplicità, tieni MODEL_LIST a portata di mano\n",
    "MODEL_LIST = [\"CNN2D_LSTM_TF\", \"BiLSTM\", \"Transformer\"]\n",
    "\n",
    "for condition in sweep_ids:\n",
    "    for data_type in sweep_ids[condition]:\n",
    "        for category_subject in sweep_ids[condition][data_type]:\n",
    "            \n",
    "            combination_key = f\"{condition}_{data_type}_{category_subject}\"\n",
    "            \n",
    "            # per ciascun modello, creo uno sweep separato\n",
    "            for model_name in MODEL_LIST:\n",
    "\n",
    "                # Controlla se la combinazione di condition, data_type, category_subject + modello è già stata elaborata\n",
    "                if (combination_key, model_name) not in created_combinations:\n",
    "\n",
    "                    # Scegli il config in base al model_name\n",
    "                    if model_name == \"CNN2D_LSTM_TF\":\n",
    "                        sweep_conf = sweep_config_cnn2d_lstm_tf\n",
    "                        \n",
    "                    elif model_name == \"BiLSTM\":  # ReadMEndYou\n",
    "                        sweep_conf = sweep_config_bilstm\n",
    "                        \n",
    "                    elif model_name == \"Transformer\":  # ReadMYMind\n",
    "                        sweep_conf = sweep_config_transformer\n",
    "                    else:\n",
    "                        raise ValueError(f\"Modello non riconosciuto: {model_name}\")\n",
    "                    \n",
    "                    # Controllo se la lista per il modello specifico è vuota\n",
    "                    if not sweep_ids[condition][data_type][category_subject][model_name]:\n",
    "\n",
    "                        # Crea lo sweep e lo appendo nella lista dedicata a quel modello\n",
    "                        \n",
    "                        '''\n",
    "                        QUESTO COME ERA IMPOSTATO PRIMA NELLA VERSIONE SENZA SWEEP CONFIG MODEL-SPECIFIC\n",
    "                        \n",
    "                        #new_sweep_id = wandb.sweep(sweep_config, project=f\"{condition}_spectrograms_new\")\n",
    "                        '''\n",
    "                        \n",
    "                        #new_sweep_id = wandb.sweep(sweep_conf, project=f\"{condition}_spectrograms_channels_freqs_new_3d_grid_multiband\")\n",
    "                        \n",
    "                        '''\n",
    "                        QUESTO SAREBBE COME ORA LO IMPOSTO PER LA VERSIONE CON SWEEP CONFIG MODEL-SPECIFIC\n",
    "                        \n",
    "                        '''\n",
    "                        \n",
    "                        new_sweep_id = wandb.sweep(sweep_conf, project=f\"{condition}_spectrograms_time_freqs_new_3d_grid_multiband\")\n",
    "                        \n",
    "                        #QUI, viene creata la mappatura tra Sweep ID e la descrizione della combinazione (in formato di stringhe)\n",
    "                        #CON LA CREAZIONE DI UNA TUPLA, DENTRO LA LISTA \n",
    "                        \n",
    "                        sweep_ids[condition][data_type][category_subject][model_name].append((new_sweep_id, combination_key))\n",
    "\n",
    "                    print(f\"▶ Sweep \\033[1m{new_sweep_id}\\033[0m creato per \\033[1m{combination_key}\\033[0m, modello \\033[1m{model_name}\\033[0m\")\n",
    "                    \n",
    "                    # Aggiungi la combinazione al set per evitare duplicazioni\n",
    "                    created_combinations.add((combination_key, model_name))  # Aggiungi la combinazione con il modello\n",
    "                else:\n",
    "                    # Se la combinazione è già stata creata, salta\n",
    "                    print(f\"⚠️ {combination_key} già processato per il modello {model_name}, skip.\")\n",
    "                    continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252578bd-70f3-44f0-841b-4eb630d1b7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcola e stampa il numero totale di combinazioni uniche (e quindi di sweep creati)\n",
    "\n",
    "total_sweeps = len(created_combinations)\n",
    "total_runs = total_sweeps * 200\n",
    "\n",
    "print(f\"Numero totale di sweep creati: {total_sweeps}\")\n",
    "print(f\"Numero totale di runs da eseguire: {total_runs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04502bfa-2971-4e7e-a669-89aa3bdc279f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''ESEGUI QUI QUESTA CELLA PER VEDERE COME SI STRUTTURA SWEEP_IDS'''\n",
    "\n",
    "#sweep_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c276b84f-ae96-42a9-bcdb-824ed0da90f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sweep_ids.keys()\n",
    "#sweep_ids['th_resp_vs_pt_resp'].keys()\n",
    "#sweep_ids['th_resp_vs_pt_resp'].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c812a0-5880-4625-8aee-0757b59bb413",
   "metadata": {},
   "source": [
    "**NOTA BENE**\n",
    "\n",
    "\n",
    "I **numeri degli sweeps** tornano e son corretti! \n",
    "Tuttavia, avendo solo preparato l'inizializzazione degli sweeps dentro 'sweep_ids', \n",
    "Sul sito di weight and biases, io vedo le tre condizioni sperimentali, create ciascuna come un progetto separato, che è corretto, ma ancora le runs di ciascuna le vedo a 0\n",
    "\n",
    "Deduco che questo comportamento, dovrebbe esser normale, dato che ancora non ho avviato l'agente appunto wandb.agent(), con cui gli fornisco lo sweep_id generato adesso in questo loop precedente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e260dee4-ee39-40b7-ad94-b1b62282f605",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_dict_preprocessed.keys())\n",
    "print(sweep_ids.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a06c575-f9af-42f5-a772-4f6f293b8734",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict_preprocessed.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09939de-1da0-4084-b53d-cf9785867368",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict_preprocessed['rest_vs_left_fist'].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61e9817-bab3-4fb9-ab75-1f199d0ad8a7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### **VERSIONE DEL 6 MARZO (RISOLUZIONE DEFINITIVA)**\n",
    "\n",
    "##### **Training Function Edits - EEG Spectrograms - Time x Frequencies ONLY HYPER-PARAMS**\n",
    "\n",
    "#### **Sweep separati per ciascuno dei modelli CNN2D_LSTM_TF, BiLSTM e Transformer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14a54b4-0587-4ed2-aa17-33e2781c8ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''CELLA DI ESEMPIO PER VERIFICARE SE QUESTA FUNZIONE FACESSE IL PARSING DELLE STRINGHE DELLE COMBINAZIONI DI FATTORI CORRETTAMENTE'''\n",
    "\n",
    "import re\n",
    "\n",
    "def parse_combination_key(combination_key):\n",
    "    \"\"\"\n",
    "    Estrae condition_experiment e subject_key da combination_key\n",
    "    dove il data_type è fisso a \"spectrograms\".\n",
    "    \n",
    "    Esempio di chiave: \n",
    "    \"pt_resp_vs_shared_resp_spectrograms_familiar_th\"\n",
    "    \"\"\"\n",
    "    match = re.match(\n",
    "        r\"^(rest_vs_left_fist|rest_vs_right_fist|left_fist_vs_right_fist)_spectrograms_(familiar_th|familiar_pt|unfamiliar_th|unfamiliar_pt)$\",\n",
    "        combination_key\n",
    "    )\n",
    "    if match:\n",
    "        condition_experiment = match.group(1)\n",
    "        subject_key = match.group(2)\n",
    "        return condition_experiment, subject_key\n",
    "    else:\n",
    "        raise ValueError(f\"Formato non valido: {combination_key}\")\n",
    "\n",
    "# Test\n",
    "combination_key = \"rest_vs_left_fist_spectrograms_familiar_th\"\n",
    "condition_experiment, subject_key = parse_combination_key(combination_key)\n",
    "\n",
    "print(\"Condizione:\", condition_experiment)\n",
    "print(\"Soggetto:\", subject_key)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dac9de8c-d6f6-4ed6-a075-e0eb35446d5b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "'''\n",
    "                                                                ***** FUNZIONE DI TRAINING *****\n",
    "                                                                ***** VERSIONE DEL 5 MARZO *****\n",
    "                                                                \n",
    "                                                    **** SALVATAGGIO SOLO PESI E BIAS DI UN CERTO MODELLO ****      \n",
    "                                                                \n",
    "Il punto critico è garantire che ogni configurazione di iperparametri estratta randomicamente da W&B per OGNI SWEEP sia coerente con:\n",
    "\n",
    "Il dataset giusto (ossia la coppia di condizioni sperimentali corrispondente).\n",
    "Il tipo di dato EEG usato (1_20, 1_45, wavelet ecc.).\n",
    "L'origine dei dati tra le quattro tipologie di soggetti.\n",
    "\n",
    "\n",
    "che io andrei a prelevare ogni volta da 'data_dict_preprocessed'!\n",
    "\n",
    "Quindi, ad ogni iterazione del loop sui dati (i.e., data_dict_preprocessed?)\n",
    "il codice dovrebbe assicurarsi/verificare che, \n",
    "\n",
    "\n",
    "1) la configurazione selezionata da W&B presa da uno SPECIFICO SWEEP,  \n",
    "sia quella che effettivamente corrisponde ad un certo dataset in termini di combinazione di fattori \n",
    "\n",
    "- una specifica condizione sperimentale\n",
    "- una specifico tipo di dato EEG \n",
    "- una specifica combinazione di ruolo/gruppo\n",
    "\n",
    "\n",
    "2) che le run di quella sweep siano inserita nel progetto del dataset di quella specifica condizione sperimentale,\n",
    "\n",
    "\n",
    "(3 PLUS OPZIONALE\n",
    "\n",
    "e che il \"name\" e i \"tag\" (eventualmente, delle runs associate a quello sweep)\n",
    "siano costruiti in maniera coerente con la combinazione di fattori associata allo sweep (e quindi alla condizione sperimentale corrente)\n",
    "\n",
    "\n",
    "\n",
    "****************************** ******************************\n",
    "CONCLUSIONE A CUI SON ARRIVATO LA MATTINA DEL 04/03/2025: \n",
    "****************************** ******************************\n",
    "\n",
    "Dato che ogni sweep si applica per verificare, tra le 15 diversi set di iper-parametri diversi, \n",
    "quale sia la configurazione migliore, per uno specifico set di dati in termini di combinazione di fattori, che sono\n",
    "\n",
    "- relativi ad una certa condizione sperimentale,  \n",
    "- con un certo preprocessing\n",
    "- con un certa provenienza del dato\n",
    "\n",
    "\n",
    "Son arrivato ad un punto in cui credo che sia davvero molto complesso controllare la corrispondenza esatta tra \n",
    "\n",
    "1) di chi esegue lo sweep\n",
    "2) la definizione del nome della sue 15 runs (cioè di quale dato si riferisca etc. in termini di combinazione di fattori) ...\n",
    "\n",
    "Quindi l'unica cosa che ha senso è forse solo creare le runs in modo da inserirle tutte assieme in base al solo nome del progetto,\n",
    "che però è prelevabile dalla prima chiave di 'data_dict_preprocessed'.. \n",
    "\n",
    "in questo modo, pur non avendo il controllo sul nome della run e del suo tag,\n",
    "almeno dovrei esser sicuro che comunque le runs associate all'uso dei dati di ALMENO \n",
    "una certa condizione sperimentale vengano inserite nel relativo progetto su weight and biases...\n",
    "\n",
    "\n",
    "\n",
    "TUTTAVIA, \n",
    "\n",
    "****************************** ******************************\n",
    "ILLUMINAZIONE DEL POMERIGGIO DEL 04/03/2025: \n",
    "****************************** ******************************\n",
    "\n",
    "MI HA PORTATO A PENSARE A PROVARE A CAPIRE ANCORA SE RIESCO A RISOLVERE IL PROBLEMA ...\n",
    "'''\n",
    "\n",
    "\n",
    "#VERSIONE NUOVA!\n",
    "\n",
    "#Fase 2: Creazione della funzione di 'training_sweep' \n",
    "    \n",
    "'''Questa funzione parse_combination_key serve per estrarre \n",
    "le varie stringhe che compongono la combinazioni di fattori (condizione sperimentale, tipo di dato EEG e provenienza del dato EEG) \n",
    "che si riferiscono allo sweep ID corrente.\n",
    "\n",
    "Esempio:\n",
    "\n",
    "Lo tupla sweep (sweep ID, combinazioni di fattori in stringa) è la seguente:\n",
    "\n",
    "Inizio l'agent per sweep_id: ('4u94ovth', 'pt_resp_vs_shared_resp_wavelet_unfamiliar_pt') dove\n",
    "- sweep ID: 4u94ovth\n",
    "- combinazioni di fattori in stringa: pt_resp_vs_shared_resp_wavelet_unfamiliar_pt\n",
    "\n",
    "Di conseguenza, quando avvio l'agent per quella condizione sperimentale nel loop, \n",
    "dentro la funzione di 'training_sweep' io prenderò in input la tupla\n",
    "\n",
    "\n",
    "\"\"\" Esegue il training per uno specifico sweep \"\"\"\n",
    "\n",
    "def training_sweep(data_dict_preprocessed, sweep_config, sweep_ids, sweep_id, sweep_tuple, best_models): \n",
    "\n",
    "sweep_id, combination_key = sweep_tuple\n",
    "exp_cond, data_type, category_subject = parse_combination_key(combination_key)\n",
    "\n",
    "\n",
    "E lui estrarrà la combinazione di fattori che la compongono, in questo caso è \n",
    "\n",
    "1) Condizione Sperimentale = pt_resp_vs_shared_resp\n",
    "2) Tipo di Dato EEG = wavelet\n",
    "3) Provenienza del Tipo di Dato EEG unfamiliar_pt\n",
    "\n",
    "Successivamente, confronta se questa combinazione di stringhe si trova dentro la mia struttura dati e, se la trova\n",
    "\n",
    "1) creerà il progetto con il nome della condizione sperimentale combaciante tra \n",
    " \n",
    " - la combination_key associata allo Sweep ID corrente e\n",
    " - il sottodizionario di data_dict_preprocessed \n",
    " \n",
    "2) le relative run di quello specifico Sweep, verranno nominate con la combinazioni di fattori combaciante su W&B\n",
    "\n",
    "3) Esegue e gestisce il salvataggio della migliore configurazione di iper-parametri del relativo modello preso in esame (CNN1D, BiLSTM e Transformer)\n",
    "   tra le 15 runs di OGNI SWEEP\n",
    "   \n",
    "\n",
    "'''\n",
    "\n",
    "import re\n",
    "\n",
    "def parse_combination_key(combination_key):\n",
    "    \"\"\"\n",
    "    Estrae condition_experiment e subject_key da combination_key\n",
    "    dove il data_type è fisso a \"spectrograms\".\n",
    "    \n",
    "    Esempio di chiave: \n",
    "    \"pt_resp_vs_shared_resp_spectrograms_familiar_th\"\n",
    "    \"\"\"\n",
    "    match = re.match(\n",
    "        r\"^(pt_resp_vs_shared_resp|th_resp_vs_pt_resp|th_resp_vs_shared_resp)_spectrograms_(familiar_th|familiar_pt|unfamiliar_th|unfamiliar_pt)$\",\n",
    "        combination_key\n",
    "    )\n",
    "    if match:\n",
    "        condition_experiment = match.group(1)\n",
    "        subject_key = match.group(2)\n",
    "        return condition_experiment, subject_key\n",
    "    else:\n",
    "        raise ValueError(f\"Formato non valido: {combination_key}\")\n",
    "        \n",
    "        \n",
    "def training_sweep(data_dict_preprocessed, sweep_config, sweep_ids, sweep_id, sweep_tuple, best_models): \n",
    "    \n",
    "    # Per ogni sweep, che viene iterato nel loop, io prendo \n",
    "    #1) la stringa univoca dello Sweep ID\n",
    "    #2) la sua combinazione di fattori stringa (che mi serviranno per prelevare il dato corrispondente da 'data_dict_preprocessed'\n",
    "    \n",
    "    sweep_id, combination_key = sweep_tuple\n",
    "    \n",
    "    # Ora la funzione restituisce solo (exp_condition, subject_key)\n",
    "    exp_cond, category_subject = parse_combination_key(combination_key)\n",
    "    \n",
    "    # Poiché ora i dati sono solo di tipo \"spectrograms\", li impostiamo in modo fisso:\n",
    "    data_type = \"spectrograms\"\n",
    "\n",
    "    if not (exp_cond in data_dict_preprocessed and category_subject in data_dict_preprocessed[exp_cond][data_type]):\n",
    "        raise ValueError(f\"❌ ERRORE - Combinazione \\033[1mNON TROVATA\\033[0m in data_dict_preprocessed: \\033[1m{exp_cond}\\033[0m, \\033[1m{category_subject}\\033[0m\")\n",
    "\n",
    "    run_name = f\"{exp_cond}_{data_type}_{category_subject}\"\n",
    "    tags = [exp_cond, data_type, category_subject]\n",
    "\n",
    "    #Inizializza la run dello specifico Sweep dentro Weights & Biases (W&B) con\n",
    "\n",
    "    #1) un nome del progetto pari alla condizione sperimentale corrente\n",
    "    #2) il nome e tag della run in base alla combinazione di fattori corrispondente\n",
    "    #3) la congiurazione di iper-parametri è pari a quella passata in input a 'training_sweep'\n",
    "\n",
    "    #Vedi questo link su wandb.init() per vedere i suoi parametri --> #https://docs.wandb.ai/ref/python/init/\n",
    "    \n",
    "    # Inizializza la run in W&B nel progetto che termina con \"_spectrograms\"\n",
    "    wandb.init(project=f\"{exp_cond}_spectrograms\", name=run_name, tags=tags)\n",
    "\n",
    "    print(f\"\\nCreo wandb project per: \\033[1m{exp_cond}_spectrograms\\033[0m\")\n",
    "    print(f\"Lo sweep corrente è \\033[1m{sweep_tuple}\\033[0m\")\n",
    "    print(f\"\\nInizio addestramento sul dataset \\033[1m{exp_cond}\\033[0m con dati EEG \\033[1m{data_type}\\033[0m di \\033[1m{category_subject}\\033[0m\")\n",
    "\n",
    "    # Parametri dell'esperimento presi da wandb\n",
    "    config = wandb.config\n",
    "\n",
    "    # Recupera i dati pre-processati per la combinazione corrente una volta verificata l'esatta corrispondenza tra:\n",
    "    #1)il combination_key dello sweep\n",
    "    #2)l'esistenza di specifico dataset con le stesse 'combination_key' dentro data_dict_preprocessed\n",
    "\n",
    "    try:\n",
    "        X_train, X_val, X_test, y_train, y_val, y_test = data_dict_preprocessed[exp_cond][data_type][category_subject]\n",
    "        print(f\"\\nCarico i dati di \\033[1m{exp_cond}\\033[0m, \\033[1m{data_type}\\033[0m, \\033[1m{category_subject}\\033[0m\")\n",
    "        print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "        print(f\"X_val shape: {X_val.shape}, y_val shape: {y_val.shape}\")\n",
    "        print(f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\\n\")\n",
    "    except KeyError:\n",
    "        raise ValueError(f\"❌ ERRORE - Combinazione \\033[1mNON TROVATA\\033[0m in data_dict_preprocessed: \\033[1m{exp_cond}\\033[0m, \\033[1m{data_type}\\033[0m, \\033[1m{category_subject}\\033[0m\")\n",
    "\n",
    "\n",
    "    if config.standardization:\n",
    "        # Standardizzazione\n",
    "        X_train, X_val, X_test = standardize_data(X_train, X_val, X_test)\n",
    "        print(f\"\\nUso DATI \\033[1mSTANDARDIZZATI\\033[0m!\")\n",
    "    else:\n",
    "        print(f\"\\nUso DATI \\033[1mNON STANDARDIZZATI\\033[0m!\")\n",
    "\n",
    "    # Preparazione dei dataloaders (N.B. prendo uno dei modelli considerati dentro config.model_name)\n",
    "    train_loader, val_loader, test_loader, class_weights_tensor = prepare_data_for_model(\n",
    "        X_train, X_val, X_test, y_train, y_val, y_test, model_type=config.model_name, batch_size = config.batch_size\n",
    "    )\n",
    "\n",
    "    #Qui estraggo il relativo modello su cui sto iterando al momento corrente e lo inizializzo\n",
    "\n",
    "    # Inizializza il modello in base al valore scelto in config.model_name\n",
    "    #if config.model_name == \"CNN2D\":\n",
    "    #    model = CNN1D(input_channels=3, num_classes=2)\n",
    "    #    print(f\"\\nInizializzazione Modello \\033[1m{config.model_name}\\033[0m\")\n",
    "    #elif config.model_name == \"BiLSTM\":\n",
    "    #    model = ReadMEndYou(input_size=3, hidden_sizes=[24, 48, 62], output_size=2, bidirectional=True)\n",
    "    #    print(f\"\\nInizializzazione Modello \\033[1m{config.model_name}\\033[0m\")\n",
    "    #elif config.model_name == \"Transformer\":\n",
    "    #    model = ReadMYMind(num_channels=3, seq_length=250, d_model=16, num_heads=4, num_layers=2, num_classes=2)\n",
    "    #    print(f\"\\nInizializzazione Modello \\033[1m{config.model_name}\\033[0m\")\n",
    "        \n",
    "    # Inizializza il modello in base al valore scelto in config.model_name\n",
    "    if config.model_name == \"CNN2D\":\n",
    "        model = CNN2D(input_channels=3, num_classes=2)\n",
    "        print(f\"\\nInizializzazione Modello \\033[1mCNN2D\\033[0m\")\n",
    "        \n",
    "    elif config.model_name == \"BiLSTM\":\n",
    "        # Qui, input_size = canali * frequenze = 3 * 38 = 114\n",
    "        model = ReadMEndYou(input_size= 3 * 38, hidden_sizes=[24, 48, 62], output_size=2, bidirectional=True)\n",
    "        print(f\"\\nInizializzazione Modello \\033[1mBiLSTM\\033[0m\")\n",
    "        \n",
    "    elif config.model_name == \"Transformer\":\n",
    "        # Per il Transformer, passiamo anche i parametri channels e freqs per adattare l'embedding\n",
    "        model = ReadMYMind(d_model=16, num_heads=4, num_layers=2, num_classes=2, channels=3, freqs=38)\n",
    "        print(f\"\\nInizializzazione Modello \\033[1mTransformer\\033[0m\")\n",
    "\n",
    "        \n",
    "    #ORIGINAL VERSION OF TIME SERIES EEG DATA REPRESENTATION  \n",
    "    #def initialize_models():\n",
    "        #model_CNN = CNN1D(input_channels=3, num_classes=2)\n",
    "        #model_LSTM = ReadMEndYou(input_size=3, hidden_sizes=[24, 48, 62], output_size=2, bidirectional=True)\n",
    "        #model_Transformer = ReadMYMind(num_channels=3, seq_length=250, d_model=16, num_heads=4, num_layers=2, num_classes=2)\n",
    "        \n",
    "        #return model_CNN, model_LSTM, model_Transformer\n",
    "\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config.lr, weight_decay=config.weight_decay)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "\n",
    "    # Parametri di training\n",
    "    n_epochs = config.n_epochs\n",
    "    patience = config.patience\n",
    "    early_stopping = EarlyStopping(patience=patience, mode='max')\n",
    "\n",
    "    best_model = None\n",
    "    max_val_acc = 0\n",
    "    best_epoch = 0\n",
    "\n",
    "    pbar = tqdm(range(n_epochs))\n",
    "\n",
    "    for epoch in pbar:\n",
    "        train_loss_tmp = []\n",
    "        correct_train = 0\n",
    "        y_true_train_list, y_pred_train_list = [], []\n",
    "\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            y_pred = model(x)\n",
    "            loss = criterion(y_pred, y.view(-1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss_tmp.append(loss.item())\n",
    "            _, predicted_train = torch.max(y_pred, 1)\n",
    "            correct_train += (predicted_train == y).sum().item()\n",
    "            y_true_train_list.extend(y.cpu().numpy())\n",
    "            y_pred_train_list.extend(predicted_train.cpu().numpy())\n",
    "\n",
    "        accuracy_train = correct_train / len(train_loader.dataset)\n",
    "        loss_train = np.mean(train_loss_tmp)\n",
    "\n",
    "        precision_train = precision_score(y_true_train_list, y_pred_train_list, average='weighted')\n",
    "        recall_train = recall_score(y_true_train_list, y_pred_train_list, average='weighted')\n",
    "        f1_train = f1_score(y_true_train_list, y_pred_train_list, average='weighted')\n",
    "        auc_train = roc_auc_score(y_true_train_list, y_pred_train_list, average='weighted')\n",
    "\n",
    "        loss_val_tmp = []\n",
    "        correct_val = 0\n",
    "        y_true_val_list, y_pred_val_list = [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for x, y in val_loader:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                y_pred = model(x)\n",
    "\n",
    "                loss = criterion(y_pred, y.view(-1))\n",
    "                loss_val_tmp.append(loss.item())\n",
    "                _, predicted_val = torch.max(y_pred, 1)\n",
    "\n",
    "                correct_val += (predicted_val == y).sum().item()\n",
    "                y_true_val_list.extend(y.cpu().numpy())\n",
    "                y_pred_val_list.extend(predicted_val.cpu().numpy())\n",
    "\n",
    "        accuracy_val = correct_val / len(val_loader.dataset)\n",
    "        loss_val = np.mean(loss_val_tmp)\n",
    "\n",
    "        wandb.log({\n",
    "            \"epoch\": epoch,\n",
    "            \"train_loss\": loss_train,\n",
    "            \"train_accuracy\": accuracy_train,\n",
    "            \"train_precision\": precision_train,\n",
    "            \"train_recall\": recall_train,\n",
    "            \"train_f1\": f1_train,\n",
    "            \"train_auc\": auc_train,\n",
    "            \"val_loss\": loss_val,\n",
    "            \"val_accuracy\": accuracy_val\n",
    "        })\n",
    "\n",
    "        if accuracy_val > max_val_acc:\n",
    "            max_val_acc = accuracy_val\n",
    "            best_epoch = epoch\n",
    "            best_model = cp.deepcopy(model)\n",
    "\n",
    "        early_stopping(accuracy_val)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"🛑 Early stopping attivato!\")\n",
    "            break\n",
    "\n",
    "\n",
    "        '''\n",
    "        Qui, si usa config.model_name tra le chiavi di best_models, \n",
    "        così che gestisca automaticamente il salvataggio del best model estratto dalla configurazione randomica di iper-parametri\n",
    "        della specifica run di un determinato sweep, che è relativa allo specifico modello correntemente estratto randomicamente dalla sweep_config!\n",
    "        '''\n",
    "\n",
    "        if best_models[exp_cond][data_type][category_subject][config.model_name][\"max_val_acc\"] == -float('inf'):\n",
    "\n",
    "            # Salvo il primo best_model per quella combinazione\n",
    "            best_models[exp_cond][data_type][category_subject][config.model_name] = {\n",
    "                \"model\": cp.deepcopy(model),\n",
    "                \"max_val_acc\": accuracy_val,\n",
    "                \"best_epoch\": epoch,\n",
    "            }\n",
    "\n",
    "            best_model_name = f\"{config.model_name}_{exp_cond}_{data_type}_{category_subject}\"\n",
    "\n",
    "            model_path = os.path.join(base_dir, exp_cond, data_type, category_subject)\n",
    "\n",
    "            os.makedirs(model_path, exist_ok=True)\n",
    "\n",
    "            model_file = f\"{model_path}/{best_model_name}.pth\"\n",
    "\n",
    "            torch.save(best_model.state_dict(), model_file)\n",
    "            print(f\"Il modello \\n\\033[1m{best_model_name}\\033[0m verrà salvato in questa folder directory: \\n\\033[1m{model_file}\\033[0m\")\n",
    "\n",
    "            #Condizione di aggiornamento:\n",
    "            #Se l'accuracy corrente (accuracy_val) di quel modello di quello sweep supera il valore già salvato in best_models[...], \n",
    "            #allora aggiorniamo il dizionario e sovrascriviamo il file del best model, di quel modello, di quella combinazione di fattori.\n",
    "\n",
    "\n",
    "            # Puoi confrontare e salvare il modello solo se il nuovo è migliore\n",
    "\n",
    "\n",
    "            #Questo assicura che il salvataggio del modello avvenga solo se\n",
    "            #il nuovo modello ha un'accuratezza di validazione (max_val_acc) migliore \n",
    "            #rispetto a quella già memorizzata per la condizione specifica (exp_cond).\n",
    "\n",
    "            #In questo modo, si evita di sovrascrivere il modello salvato con uno peggiore\n",
    "\n",
    "\n",
    "            # Nuovo modello migliore per questa combinazione: aggiorna e sovrascrivi il file\n",
    "\n",
    "\n",
    "        elif accuracy_val > best_models[exp_cond][data_type][category_subject][config.model_name][\"max_val_acc\"]:\n",
    "                best_models[exp_cond][data_type][category_subject][config.model_name] = {\n",
    "                    \"model\": best_model,\n",
    "                    \"max_val_acc\": accuracy_val,\n",
    "                    \"best_epoch\": best_epoch,\n",
    "                }\n",
    "                best_model_name = f\"{config.model_name}_{exp_cond}_{data_type}_{category_subject}\"\n",
    "                model_path = os.path.join(base_dir, exp_cond, data_type, category_subject)\n",
    "                os.makedirs(model_path, exist_ok=True)\n",
    "\n",
    "                print(f\"Il modello di questa folder directory:\\n\\033[1m{model_path}\\033[0m\")\n",
    "                print(f\"\\nHa un MIGLIORAMENTO!\")\n",
    "\n",
    "                model_file = f\"{model_path}/{best_model_name}.pth\"\n",
    "\n",
    "                if os.path.exists(model_file):\n",
    "\n",
    "                    # Se il file esiste, stampiamo un messaggio di aggiornamento\n",
    "                    print(f\"\\n⚠️ ATTENZIONE: \\nIl modello \\033[1m{best_model_name}\\033[0m verrà AGGIORNATO in \\n\\033[1m{model_path}\\033[0m\")\n",
    "\n",
    "                    # Salva il miglior modello solo se è stato aggiornato\n",
    "                    torch.save(best_model.state_dict(), model_file)\n",
    "                    print(f\"\\nIl nome del modello AGGIORNATO è:\\n\\033[1m{best_model_name}\\033[0m\")\n",
    "\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "                #Condizione \"nessun miglioramento\":\n",
    "                #Se il modello corrente non migliora il best già salvato, viene semplicemente stampato un messaggio.\n",
    "\n",
    "                #Questa logica garantisce che per ogni combinazione il file .pth contenga \n",
    "                #sempre i pesi del miglior modello (secondo la validation accuracy) fino a quel momento.\n",
    "                #Adatta eventualmente i nomi delle variabili (es. accuracy_val vs max_val_acc) per essere coerente con il resto del tuo codice.\n",
    "        else:\n",
    "            ''''QUI VA RIDEFINITO LA MODEL_PATH (e anche se vuoi MODE_FILE) ALTRIMENTI IN QUESTO ELSE NON ESISTONO!'''\n",
    "\n",
    "            best_model_name = f\"{config.model_name}_{exp_cond}_{data_type}_{category_subject}\"\n",
    "            model_path = os.path.join(base_dir, exp_cond, data_type, category_subject)\n",
    "            model_file = f\"{model_path}/{best_model_name}.pth\"\n",
    "            print(f\"Nessun miglioramento per il modello \\033[1m{config.model_name}\\033[0m in \\n\\033[1m{model_path}\\033[0m, ossia \\n\\033[1m{model_file}\\033[0m\")\n",
    "\n",
    "    wandb.finish()\n",
    "        \n",
    "    return best_models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76676513-de54-4d44-a2f6-ec0ac2057370",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "                                                                ***** FUNZIONE DI TRAINING *****\n",
    "                                                                ***** VERSIONE DEL 5 MARZO *****\n",
    "                                                                \n",
    "                                                                    **** SALVATAGGIO DI **** \n",
    "                                                        \n",
    "                                                        1) PESI E BIAS DI UN CERTO MODELLO \n",
    "                                                        2) CONFIGURAZIONE IPER-PARAMETRI DI UN CERTO MODELLO\n",
    "                                                                \n",
    "Il punto critico è garantire che ogni configurazione di iperparametri estratta randomicamente da W&B per OGNI SWEEP sia coerente con:\n",
    "\n",
    "Il dataset giusto (ossia la coppia di condizioni sperimentali corrispondente).\n",
    "Il tipo di dato EEG usato (1_20, 1_45, wavelet ecc.).\n",
    "L'origine dei dati tra le quattro tipologie di soggetti.\n",
    "\n",
    "\n",
    "che io andrei a prelevare ogni volta da 'data_dict_preprocessed'!\n",
    "\n",
    "Quindi, ad ogni iterazione del loop sui dati (i.e., data_dict_preprocessed?)\n",
    "il codice dovrebbe assicurarsi/verificare che, \n",
    "\n",
    "\n",
    "1) la configurazione selezionata da W&B presa da uno SPECIFICO SWEEP,  \n",
    "sia quella che effettivamente corrisponde ad un certo dataset in termini di combinazione di fattori \n",
    "\n",
    "- una specifica condizione sperimentale\n",
    "- una specifico tipo di dato EEG \n",
    "- una specifica combinazione di ruolo/gruppo\n",
    "\n",
    "\n",
    "2) che le run di quella sweep siano inserita nel progetto del dataset di quella specifica condizione sperimentale,\n",
    "\n",
    "\n",
    "(3 PLUS OPZIONALE\n",
    "\n",
    "e che il \"name\" e i \"tag\" (eventualmente, delle runs associate a quello sweep)\n",
    "siano costruiti in maniera coerente con la combinazione di fattori associata allo sweep (e quindi alla condizione sperimentale corrente)\n",
    "\n",
    "\n",
    "\n",
    "****************************** ******************************\n",
    "CONCLUSIONE A CUI SON ARRIVATO LA MATTINA DEL 04/03/2025: \n",
    "****************************** ******************************\n",
    "\n",
    "Dato che ogni sweep si applica per verificare, tra le 15 diversi set di iper-parametri diversi, \n",
    "quale sia la configurazione migliore, per uno specifico set di dati in termini di combinazione di fattori, che sono\n",
    "\n",
    "- relativi ad una certa condizione sperimentale,  \n",
    "- con un certo preprocessing\n",
    "- con un certa provenienza del dato\n",
    "\n",
    "\n",
    "Son arrivato ad un punto in cui credo che sia davvero molto complesso controllare la corrispondenza esatta tra \n",
    "\n",
    "1) di chi esegue lo sweep\n",
    "2) la definizione del nome della sue 15 runs (cioè di quale dato si riferisca etc. in termini di combinazione di fattori) ...\n",
    "\n",
    "Quindi l'unica cosa che ha senso è forse solo creare le runs in modo da inserirle tutte assieme in base al solo nome del progetto,\n",
    "che però è prelevabile dalla prima chiave di 'data_dict_preprocessed'.. \n",
    "\n",
    "in questo modo, pur non avendo il controllo sul nome della run e del suo tag,\n",
    "almeno dovrei esser sicuro che comunque le runs associate all'uso dei dati di ALMENO \n",
    "una certa condizione sperimentale vengano inserite nel relativo progetto su weight and biases...\n",
    "\n",
    "\n",
    "\n",
    "TUTTAVIA, \n",
    "\n",
    "****************************** ******************************\n",
    "ILLUMINAZIONE DEL POMERIGGIO DEL 04/03/2025: \n",
    "****************************** ******************************\n",
    "\n",
    "MI HA PORTATO A PENSARE A PROVARE A CAPIRE ANCORA SE RIESCO A RISOLVERE IL PROBLEMA ...\n",
    "'''\n",
    "\n",
    "\n",
    "#VERSIONE NUOVA!\n",
    "\n",
    "#Fase 2: Creazione della funzione di 'training_sweep' \n",
    "    \n",
    "'''Questa funzione parse_combination_key serve per estrarre \n",
    "le varie stringhe che compongono la combinazioni di fattori (condizione sperimentale, tipo di dato EEG e provenienza del dato EEG) \n",
    "che si riferiscono allo sweep ID corrente.\n",
    "\n",
    "Esempio:\n",
    "\n",
    "Lo tupla sweep (sweep ID, combinazioni di fattori in stringa) è la seguente:\n",
    "\n",
    "Inizio l'agent per sweep_id: ('4u94ovth', 'pt_resp_vs_shared_resp_wavelet_unfamiliar_pt') dove\n",
    "- sweep ID: 4u94ovth\n",
    "- combinazioni di fattori in stringa: pt_resp_vs_shared_resp_wavelet_unfamiliar_pt\n",
    "\n",
    "Di conseguenza, quando avvio l'agent per quella condizione sperimentale nel loop, \n",
    "dentro la funzione di 'training_sweep' io prenderò in input la tupla\n",
    "\n",
    "\n",
    "\"\"\" Esegue il training per uno specifico sweep \"\"\"\n",
    "\n",
    "def training_sweep(data_dict_preprocessed, sweep_config, sweep_ids, sweep_id, sweep_tuple, best_models): \n",
    "\n",
    "sweep_id, combination_key = sweep_tuple\n",
    "exp_cond, data_type, category_subject = parse_combination_key(combination_key)\n",
    "\n",
    "\n",
    "E lui estrarrà la combinazione di fattori che la compongono, in questo caso è \n",
    "\n",
    "1) Condizione Sperimentale = pt_resp_vs_shared_resp\n",
    "2) Tipo di Dato EEG = wavelet\n",
    "3) Provenienza del Tipo di Dato EEG unfamiliar_pt\n",
    "\n",
    "Successivamente, confronta se questa combinazione di stringhe si trova dentro la mia struttura dati e, se la trova\n",
    "\n",
    "1) creerà il progetto con il nome della condizione sperimentale combaciante tra \n",
    " \n",
    " - la combination_key associata allo Sweep ID corrente e\n",
    " - il sottodizionario di data_dict_preprocessed \n",
    " \n",
    "2) le relative run di quello specifico Sweep, verranno nominate con la combinazioni di fattori combaciante su W&B\n",
    "\n",
    "3) Esegue e gestisce il salvataggio della migliore configurazione di iper-parametri del relativo modello preso in esame (CNN1D, BiLSTM e Transformer)\n",
    "   tra le 15 runs di OGNI SWEEP\n",
    "   \n",
    "\n",
    "'''\n",
    "\n",
    "import re\n",
    "\n",
    "def parse_combination_key(combination_key):\n",
    "    \"\"\"\n",
    "    Estrae condition_experiment e subject_key da combination_key\n",
    "    dove il data_type è fisso a \"spectrograms\".\n",
    "    \n",
    "    Esempio di chiave: \n",
    "    \"pt_resp_vs_shared_resp_spectrograms_familiar_th\"\n",
    "    \"\"\"\n",
    "    match = re.match(\n",
    "        r\"^(rest_vs_left_fist|rest_vs_right_fist|left_fist_vs_right_fist)_spectrograms_(familiar_th|familiar_pt|unfamiliar_th|unfamiliar_pt)$\",\n",
    "        combination_key\n",
    "    )\n",
    "    if match:\n",
    "        condition_experiment = match.group(1)\n",
    "        subject_key = match.group(2)\n",
    "        return condition_experiment, subject_key\n",
    "    else:\n",
    "        raise ValueError(f\"Formato non valido: {combination_key}\")\n",
    "        \n",
    "        \n",
    "def training_sweep(data_dict_preprocessed, sweep_config, sweep_ids, sweep_id, sweep_tuple, best_models): \n",
    "    \n",
    "    # Per ogni sweep, che viene iterato nel loop, io prendo \n",
    "    #1) la stringa univoca dello Sweep ID\n",
    "    #2) la sua combinazione di fattori stringa (che mi serviranno per prelevare il dato corrispondente da 'data_dict_preprocessed'\n",
    "    \n",
    "    sweep_id, combination_key = sweep_tuple\n",
    "    \n",
    "    # Ora la funzione restituisce solo (exp_condition, subject_key)\n",
    "    exp_cond, category_subject = parse_combination_key(combination_key)\n",
    "    \n",
    "    # Poiché ora i dati sono solo di tipo \"spectrograms\", li impostiamo in modo fisso:\n",
    "    data_type = \"spectrograms\"\n",
    "\n",
    "    if not (exp_cond in data_dict_preprocessed and category_subject in data_dict_preprocessed[exp_cond][data_type]):\n",
    "        raise ValueError(f\"❌ ERRORE - Combinazione \\033[1mNON TROVATA\\033[0m in data_dict_preprocessed: \\033[1m{exp_cond}\\033[0m, \\033[1m{category_subject}\\033[0m\")\n",
    "    \n",
    "\n",
    "    run_name = f\"{exp_cond}_{data_type}_{category_subject}\"\n",
    "    \n",
    "    tags = [exp_cond, data_type, category_subject]\n",
    "\n",
    "    #Inizializza la run dello specifico Sweep dentro Weights & Biases (W&B) con\n",
    "\n",
    "    #1) un nome del progetto pari alla condizione sperimentale corrente\n",
    "    #2) il nome e tag della run in base alla combinazione di fattori corrispondente\n",
    "    #3) la congiurazione di iper-parametri è pari a quella passata in input a 'training_sweep'\n",
    "\n",
    "    #Vedi questo link su wandb.init() per vedere i suoi parametri --> #https://docs.wandb.ai/ref/python/init/\n",
    "    \n",
    "    # Inizializza la run in W&B nel progetto che termina con \"_spectrograms\"\n",
    "    \n",
    "    '''OCCHIO DA CAMBIARE CAMBIATO'''\n",
    "        \n",
    "    #wandb.init(project=f\"{exp_cond}_spectrograms_channels_freqs_new_3d_grid_multiband\", name=run_name, tags=tags)\n",
    "    \n",
    "    #PER TASK 1/3\n",
    "    wandb.init(project=f\"{exp_cond}_spectrograms_time_freqs_new_3d_grid_multiband\", name=run_name, tags=tags)\n",
    "    \n",
    "    #PER TASK 2/4\n",
    "    #wandb.init(project=f\"{exp_cond}_spectrograms_time_freqs_new_imagery_3d_grid_multiband\", name=run_name, tags=tags)\n",
    "\n",
    "    print(f\"\\nCreo wandb project per: \\033[1m{exp_cond}_spectrograms\\033[0m\")\n",
    "    print(f\"Lo sweep corrente è \\033[1m{sweep_tuple}\\033[0m\")\n",
    "    print(f\"\\nInizio addestramento sul dataset \\033[1m{exp_cond}\\033[0m con dati EEG \\033[1m{data_type}\\033[0m di \\033[1m{category_subject}\\033[0m\")\n",
    "\n",
    "    # Parametri dell'esperimento presi da wandb\n",
    "    config = wandb.config\n",
    "\n",
    "    # Recupera i dati pre-processati per la combinazione corrente una volta verificata l'esatta corrispondenza tra:\n",
    "    #1)il combination_key dello sweep\n",
    "    #2)l'esistenza di specifico dataset con le stesse 'combination_key' dentro data_dict_preprocessed\n",
    "\n",
    "    try:\n",
    "        X_train, X_val, X_test, y_train, y_val, y_test = data_dict_preprocessed[exp_cond][data_type][category_subject]\n",
    "        print(f\"\\nCarico i dati di \\033[1m{exp_cond}\\033[0m, \\033[1m{data_type}\\033[0m, \\033[1m{category_subject}\\033[0m\")\n",
    "        print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "        print(f\"X_val shape: {X_val.shape}, y_val shape: {y_val.shape}\")\n",
    "        print(f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\\n\")\n",
    "    except KeyError:\n",
    "        raise ValueError(f\"❌ ERRORE - Combinazione \\033[1mNON TROVATA\\033[0m in data_dict_preprocessed: \\033[1m{exp_cond}\\033[0m, \\033[1m{data_type}\\033[0m, \\033[1m{category_subject}\\033[0m\")\n",
    "\n",
    "\n",
    "    if config.standardization:\n",
    "        # Standardizzazione\n",
    "        X_train, X_val, X_test = standardize_data(X_train, X_val, X_test)\n",
    "        print(f\"\\nUso DATI \\033[1mSTANDARDIZZATI\\033[0m!\")\n",
    "    else:\n",
    "        print(f\"\\nUso DATI \\033[1mNON STANDARDIZZATI\\033[0m!\")\n",
    "\n",
    "    # Preparazione dei dataloaders (N.B. prendo uno dei modelli considerati dentro config.model_name)\n",
    "    train_loader, val_loader, test_loader, class_weights_tensor = prepare_data_for_model(\n",
    "        X_train, X_val, X_test, y_train, y_val, y_test, model_type=config.model_name, batch_size = config.batch_size\n",
    "    )\n",
    "\n",
    "    #Qui estraggo il relativo modello su cui sto iterando al momento corrente e lo inizializzo\n",
    "\n",
    "        \n",
    "    # Inizializza il modello in base al valore scelto in config.model_name\n",
    "    #if config.model_name == \"CNN2D\":\n",
    "    #    model = CNN2D(input_channels=64, num_classes=2)\n",
    "    #    print(f\"\\nInizializzazione Modello \\033[1mCNN2D\\033[0m\")\n",
    "    \n",
    "    '''# ====== MODELLI TIME×FREQ ======\n",
    "    \n",
    "    cnn_model = CNN2D_LSTM_TF(input_channels = input_channels, num_classes =num_classes, dropout = dropout)\n",
    "    hidden_sizes = [24, 48, 62]\n",
    "    lstm_model = ReadMEndYou(input_size=input_channels * num_freqs, hidden_sizes=hidden_sizes, output_size=num_classes)\n",
    "    transformer_model = ReadMYMind(d_model=d_model, num_heads=num_heads, num_layers=num_layers, num_classes=num_classes)\n",
    "    \n",
    "    # Creazione di dati fittizi per il test\n",
    "    x = torch.randn(batch_size, input_channels, num_freqs, num_timepoints)  # (batch, canali, frequenze, tempo)\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # ricavo channels e freqs dai dati (shape attesa: N, C, F, T)\n",
    "    channels, freqs = int(X_train.shape[1]), int(X_train.shape[2])\n",
    "    \n",
    "    if config.model_name == \"CNN2D_LSTM_TF\":\n",
    "        \n",
    "        '''OCCHIO QUI ADESSO SAREBBE TEMPO x FREQUENZA'''\n",
    "    \n",
    "        model = CNN2D_LSTM_TF(\n",
    "            input_channels = channels, # qui 64\n",
    "            num_classes = 2,\n",
    "            dropout=config.dropout,\n",
    "        )\n",
    "\n",
    "        print(f\"\\nInizializzazione Modello \\033[1mCNN2D_LSTM_TF\\033[0m\")\n",
    "    \n",
    "    \n",
    "    elif config.model_name == \"BiLSTM\":\n",
    "        hidden_sizes = [24, 48, 62]\n",
    "        model = ReadMEndYou(\n",
    "            input_size = channels * freqs, #  qui 64*81\n",
    "            hidden_sizes = hidden_sizes,\n",
    "            output_size = 2,\n",
    "            dropout = config.dropout,\n",
    "            bidirectional = config.bidirectional\n",
    "        )\n",
    "        print(f\"\\nInizializzazione Modello \\033[1mReadMEndYou (BiLSTM)\\033[0m\")\n",
    "    \n",
    "    \n",
    "    elif config.model_name == \"Transformer\":\n",
    "        model = ReadMYMind(\n",
    "            d_model=config.d_model,\n",
    "            num_heads=config.num_heads,\n",
    "            num_layers=config.num_layers,\n",
    "            num_classes=2,\n",
    "            channels = channels,\n",
    "            freqs = freqs \n",
    "            \n",
    "        )\n",
    "        \n",
    "        print(f\"\\nInizializzazione Modello \\033[1mReadMYMind (Transformer)\\033[0m\")\n",
    "    else:\n",
    "        raise ValueError(f\"Modello sconosciuto: {config.model_name}\")\n",
    "        \n",
    "    #elif config.model_name == \"BiLSTM\":\n",
    "        # Qui, input_size = canali * frequenze = 3 * 38 = 78\n",
    "        #model = ReadMEndYou(input_size= 64 * 45, hidden_sizes=[24, 48, 62], output_size=2, bidirectional=True)\n",
    "        #print(f\"\\nInizializzazione Modello \\033[1mBiLSTM\\033[0m\")\n",
    "        \n",
    "    #elif config.model_name == \"Transformer\":\n",
    "        # Per il Transformer, passiamo anche i parametri channels e freqs per adattare l'embedding\n",
    "        #model = ReadMYMind(d_model=16, num_heads=4, num_layers=2, num_classes=2, channels=64, freqs=45)\n",
    "        #print(f\"\\nInizializzazione Modello \\033[1mTransformer\\033[0m\")\n",
    "\n",
    "        \n",
    "    #ORIGINAL VERSION OF TIME SERIES EEG DATA REPRESENTATION  \n",
    "    #def initialize_models():\n",
    "        #model_CNN = CNN1D(input_channels=3, num_classes=2)\n",
    "        #model_LSTM = ReadMEndYou(input_size=3, hidden_sizes=[24, 48, 62], output_size=2, bidirectional=True)\n",
    "        #model_Transformer = ReadMYMind(num_channels=3, seq_length=250, d_model=16, num_heads=4, num_layers=2, num_classes=2)\n",
    "        \n",
    "        #return model_CNN, model_LSTM, model_Transformer\n",
    "\n",
    "    '''\n",
    "    Cosa è cambiato rispetto alla tua versione\n",
    "    Optimizer Adam ora prende betas=(0.9,0.999) e eps=1e-8.\n",
    "\n",
    "    ReduceLROnPlateau posizionato subito dopo l’optimizer, chiamato su val_loss ogni epoca.\n",
    "\n",
    "    EarlyStopping con patience=12, mode='min' su val_loss.\n",
    "\n",
    "    Loop sulle epoche fino a config.n_epochs (100), senza limitare a 60.\n",
    "\n",
    "    Tutti i parametri di sweep_config (lr, weight_decay, n_epochs, patience, batch_size, standardization…) rimangono esposti e loggati.\n",
    "\n",
    "    In questo modo riproduci fedelmente il training descritto nel paper, senza stravolgere la tua pipeline di sweep.\n",
    "    '''\n",
    "    \n",
    "    '''OLD VERSION'''\n",
    "    #optimizer = optim.Adam(model.parameters(), lr=config.lr, weight_decay=config.weight_decay)\n",
    "    \n",
    "    '''NEW VERSION'''\n",
    "    optimizer = optim.Adam(\n",
    "        model.parameters(),\n",
    "        lr = config.lr,               # da sweep: es. [0.01,0.001,...]\n",
    "        betas = (config.beta1, config.beta2),          # paper\n",
    "        eps = config.eps,                    # paper\n",
    "        weight_decay=config.weight_decay\n",
    "    )\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss(weight = class_weights_tensor)\n",
    "    \n",
    "    '''NEW VERSION'''\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer,\n",
    "        mode ='min',      # monitoriamo val_loss\n",
    "        factor = 0.1,      # dimezza lr\n",
    "        patience = 8,      # 4 epoche di plateau\n",
    "        verbose = True\n",
    "    )\n",
    "    \n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "\n",
    "    # Parametri di training\n",
    "    n_epochs = config.n_epochs\n",
    "    patience = config.patience\n",
    "    \n",
    "    #early_stopping = EarlyStopping(patience=patience, mode='max')\n",
    "    \n",
    "    '''NEW VERSION'''\n",
    "    early_stopping = EarlyStopping(patience=patience, mode='min')\n",
    "    \n",
    "    best_model = None\n",
    "    max_val_acc = 0\n",
    "    best_epoch = 0\n",
    "        \n",
    "    #'''AGGIORNAMENTI FINALI'''\n",
    "    #from sklearn.metrics import roc_auc_score\n",
    "\n",
    "    pbar = tqdm(range(n_epochs))\n",
    "\n",
    "    for epoch in pbar:\n",
    "        \n",
    "        # ---------------------- TRAIN ----------------------\n",
    "        #'''AGGIORNAMENTI FINALI'''\n",
    "        #model.train()  \n",
    "        \n",
    "        train_loss_tmp = []\n",
    "        correct_train = 0\n",
    "        y_true_train_list, y_pred_train_list = [], []\n",
    "\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            y_pred = model(x)\n",
    "            loss = criterion(y_pred, y.view(-1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss_tmp.append(loss.item())\n",
    "            _, predicted_train = torch.max(y_pred, 1)\n",
    "            correct_train += (predicted_train == y).sum().item()\n",
    "            y_true_train_list.extend(y.cpu().numpy())\n",
    "            y_pred_train_list.extend(predicted_train.cpu().numpy())\n",
    "            \n",
    "            #'''AGGIORNAMENTI FINALI'''\n",
    "            \n",
    "            # 👇 NOVITÀ: SCORE CONTINUO PER AUC TRAIN (usa la Softmax):\n",
    "            # OPZIONE A: puoi usare la Softmax per avere le probabilità,\n",
    "            # OPZIONE B: oppure direttamente CrossEntropy y_pred[:,1] (logit della classe 1).\n",
    "            \n",
    "            # Opzione A: usare le probabilità (softmax) \n",
    "            \n",
    "            #DECOMMENTA QUESTE 2 RIGHE PER USARE SOFTMAX\n",
    "            \n",
    "            #probs_train = torch.softmax(y_pred, dim=1)\n",
    "            #y_score_train_list.extend(probs_train[:, 1].detach().cpu().numpy())\n",
    "            \n",
    "            # Opzione B: usare direttamente i logits della classe 1 (consigliata, compatibile con CrossEntropy)\n",
    "            \n",
    "            #DECOMMENTA QUESTA RIGA PER USARE CROSSENTROPY\n",
    "            \n",
    "            # y_score_train_list.extend(y_pred[:, 1].detach().cpu().numpy())\n",
    "\n",
    "        accuracy_train = correct_train / len(train_loader.dataset)\n",
    "        loss_train = np.mean(train_loss_tmp)\n",
    "\n",
    "        precision_train = precision_score(y_true_train_list, y_pred_train_list, average='weighted')\n",
    "        recall_train = recall_score(y_true_train_list, y_pred_train_list, average='weighted')\n",
    "        f1_train = f1_score(y_true_train_list, y_pred_train_list, average='weighted')\n",
    "        \n",
    "        '''come dovrebbe essere calcolato se non si dovesse passare al load_best_run_results'''\n",
    "        #auc_train = roc_auc_score(y_true_train_list, y_pred_train_list)\n",
    "        \n",
    "        '''come è stato calcolato se si dovesse passare al load_best_run_results'''\n",
    "        auc_train = roc_auc_score(y_true_train_list, y_pred_train_list, average='weighted')\n",
    "        \n",
    "        \n",
    "        \n",
    "        #'''AGGIORNAMENTI FINALI'''\n",
    "        #try:\n",
    "            #auc_train = roc_auc_score(y_true_train_list, y_pred_train_list, average='weighted')\n",
    "        #except ValueError:\n",
    "            #print(\"⚠️ AUC non calcolabile: nel train set c'è una sola classe.\")\n",
    "            #auc_val = np.nan\n",
    "        \n",
    "        # ---------------------- VALIDATION ----------------------\n",
    "        #'''AGGIORNAMENTI FINALI'''\n",
    "        #model.eval()\n",
    "        \n",
    "        loss_val_tmp = []\n",
    "        correct_val = 0\n",
    "        y_true_val_list, y_pred_val_list = [], []\n",
    "        \n",
    "                \n",
    "        #'''AGGIORNAMENTI FINALI'''\n",
    "        #y_score_val_list = []  # per AUC valida\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for x, y in val_loader:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                y_pred = model(x)\n",
    "\n",
    "                loss = criterion(y_pred, y.view(-1))\n",
    "                loss_val_tmp.append(loss.item())\n",
    "                _, predicted_val = torch.max(y_pred, 1)\n",
    "\n",
    "                correct_val += (predicted_val == y).sum().item()\n",
    "                y_true_val_list.extend(y.cpu().numpy())\n",
    "                y_pred_val_list.extend(predicted_val.cpu().numpy())\n",
    "                \n",
    "                #'''AGGIORNAMENTI FINALI'''\n",
    "                \n",
    "                # 👇 NOVITÀ: SCORE CONTINUO PER AUC TRAIN (usa la Softmax):\n",
    "                \n",
    "                # OPZIONE A: puoi usare la Softmax per avere le probabilità,\n",
    "                # OPZIONE B: oppure direttamente CrossEntropy y_pred[:,1] (logit della classe 1).\n",
    "                \n",
    "                # Opzione A: usare le probabilità (softmax) \n",
    "                \n",
    "                #DECOMMENTA QUESTE 2 RIGHE PER USARE SOFTMAX\n",
    "                \n",
    "                #probs_val = torch.softmax(y_pred, dim=1)\n",
    "                #y_score_val_list.extend(probs_val[:, 1].detach().cpu().numpy())\n",
    "                \n",
    "                # Opzione B: usare direttamente i logits della classe 1 (consigliata, compatibile con CrossEntropy)\n",
    "                \n",
    "                #DECOMMENTA QUESTA RIGA PER USARE CROSSENTROPY\n",
    "                # y_score_val_list.extend(y_pred[:, 1].detach().cpu().numpy())\n",
    "                \n",
    "\n",
    "        accuracy_val = correct_val / len(val_loader.dataset)\n",
    "        loss_val = np.mean(loss_val_tmp)\n",
    "        \n",
    "        #'''AGGIORNAMENTI FINALI'''\n",
    "        #precision_val = precision_score(y_true_val_list, y_pred_val_list, average='weighted')\n",
    "        #recall_val    = recall_score(y_true_val_list, y_pred_val_list, average='weighted')\n",
    "        #f1_val        = f1_score(y_true_val_list, y_pred_val_list, average='weighted')\n",
    "        \n",
    "        #try:\n",
    "            # ATTENZIONE: qui usiamo gli score continui, NON le etichette\n",
    "            #auc_val = roc_auc_score(y_true_val_list, y_score_val_list, average='weighted')\n",
    "        #except ValueError:\n",
    "            #print(\"⚠️ AUC non calcolabile: nel validation set c'è una sola classe.\")\n",
    "            #auc_val = np.nan\n",
    "\n",
    "        wandb.log({\n",
    "            \"epoch\": epoch,\n",
    "            \n",
    "            # TRAIN\n",
    "            \"train_loss\": loss_train,\n",
    "            \"train_accuracy\": accuracy_train,\n",
    "            \"train_precision\": precision_train,\n",
    "            \"train_recall\": recall_train,\n",
    "            \"train_f1\": f1_train,\n",
    "            \"train_auc\": auc_train,\n",
    "            \n",
    "            # VALIDATION\n",
    "            \n",
    "            \"val_loss\": loss_val,\n",
    "            \"val_accuracy\": accuracy_val,\n",
    "            \n",
    "            # se vuoi loggare anche queste (consigliato):\n",
    "            \n",
    "            #\"val_precision\": precision_val,\n",
    "            #\"val_recall\": recall_val,\n",
    "            #\"val_f1\": f1_val,\n",
    "            #\"val_auc\": auc_val,\n",
    "        })\n",
    "        \n",
    "        #Nota: questa patch qua sopra (correzione su train e validation) rende corretto anche train_auc per le run future, \n",
    "        #quindi non avrai più bisogno della “correzione a posteriori” in load_best_run_results \n",
    "        #per i nuovi esperimenti (ma la puoi lasciare per compatibilità coi vecchi run).\n",
    "\n",
    "        if accuracy_val > max_val_acc:\n",
    "            max_val_acc = accuracy_val\n",
    "            best_epoch = epoch\n",
    "            best_model = cp.deepcopy(model)\n",
    "            \n",
    "        '''OLD VERSION'''\n",
    "        #early_stopping(accuracy_val)\n",
    "        #if early_stopping.early_stop:\n",
    "            #print(\"🛑 Early stopping attivato!\")\n",
    "            #break\n",
    "\n",
    "        '''NEW VERSION'''\n",
    "        scheduler.step(loss_val)\n",
    "        early_stopping(loss_val)\n",
    "        if early_stopping.early_stop:\n",
    "            print(f\"🛑 Early stopping attivato!\")\n",
    "            break\n",
    "\n",
    "        '''\n",
    "        Qui, si usa config.model_name tra le chiavi di best_models, \n",
    "        così che gestisca automaticamente il salvataggio del best model estratto dalla configurazione randomica di iper-parametri\n",
    "        della specifica run di un determinato sweep, che è relativa allo specifico modello correntemente estratto randomicamente dalla sweep_config!\n",
    "        \n",
    "        ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** *****\n",
    "        IMPORTANTISSIMO: COME SALVARSI LA MIGLIORE CONFIGURAZIONE DI IPER-PARAMETRI DI UN CERTO MODELLO, DI UN DATO DI UNA CERTA COMBINAZIONE DI FATTORI\n",
    "        (CONDIZIONE SPERIMENTALE, TIPO DI DATO, PROVENIENZA DEL DATO!)\n",
    "        ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** *****\n",
    "        \n",
    "        CHATGPT:\n",
    "        \n",
    "        Nei run eseguiti con W&B ogni esecuzione registra automaticamente la configurazione degli iper-parametri (tramite wandb.config) \n",
    "        insieme alle metriche e ai log. \n",
    "        Quindi, a meno che tu non abbia modificato il comportamento predefinito, \n",
    "        ogni run con il tuo sweep ha già la configurazione associata registrata nei run logs di W&B.\n",
    "\n",
    "        Tuttavia, per associare in modo “automatico” e diretto la migliore configurazione agli specifici modelli salvati in .pth, \n",
    "        potresti considerare di fare uno o più di questi aggiustamenti:\n",
    "\n",
    "        Salvare la configurazione nel dizionario dei best_models:\n",
    "        Quando aggiorni il dizionario best_models (cioè quando salvi il miglior modello per una determinata combinazione), \n",
    "        puoi salvare anche una copia della configurazione corrente. \n",
    "        \n",
    "        Ad esempio, potresti modificare il blocco in cui aggiorni best_models in questo modo:\n",
    "        \n",
    "        best_models[exp_cond][data_type][category_subject][config.model_name] = {\n",
    "            \"model\": cp.deepcopy(model),\n",
    "            \"max_val_acc\": accuracy_val,\n",
    "            \"best_epoch\": best_epoch,\n",
    "            \"config\": dict(config)  # Salva la configurazione degli iper-parametri\n",
    "        }\n",
    "        \n",
    "        In questo modo, ogni volta che un modello viene considerato il migliore per quella combinazione,\n",
    "        la sua configurazione sarà salvata insieme ai pesi.\n",
    "        Questo ti permetterà, in seguito, di sapere esattamente quali iper-parametri sono stati usati per ottenere quel modello.\n",
    "        \n",
    "        \n",
    "        In sintesi, se hai già usato wandb.config e hai loggato le configurazioni durante le run,\n",
    "        W&B le ha automaticamente salvate nei run logs. \n",
    "        \n",
    "        Se vuoi rendere più esplicita l'associazione tra il modello salvato (.pth) e la sua configurazione, \n",
    "        è utile modificare il tuo codice di TRAINING per salvare ANCHE \n",
    "        \n",
    "        1) il dizionario di configurazione insieme a \n",
    "        2) i pesi nel dizionario best_models oppure nei metadati del file salvato.\n",
    "        \n",
    "        Questo piccolo accorgimento ti consentirà di recuperare facilmente la configurazione ottimale per ogni modello salvato.\n",
    "        \n",
    "        OSSIA\n",
    "        Aggiungendo la chiave \"config\": dict(config) nel dizionario che memorizza il best model,\n",
    "        salvi anche la configurazione degli iper-parametri utilizzata in quella run.\n",
    "        \n",
    "        In questo modo, per ogni modello salvato (.pth) potrai recuperare facilmente sia i pesi che la configurazione ottimale che li ha generati.\n",
    "        \n",
    "        Questo approccio garantisce che ogni modello sia associato in modo esplicito al set di iper-parametri che ha prodotto le migliori performance, \n",
    "        rendendo più semplice il successivo confronto o la replica degli esperimenti.\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        \n",
    "        # ***** ATTENZIONE: CAMBIAMENTI ESEGUITI RISPETTO A PRIMA *****\n",
    "        #1)Al posto di salvarmi solo i migliori pesi (i.e.,  model_file = f\"{model_path}/{best_model_name}.pth\")\n",
    "        #  ora mi salvo anche la MIGLIORE configurazione di iper-parametri trovata rispetto alle 15 RUNS di un certo SWEEP\n",
    "        #  di un certo MODELLO, applicato su un DATASET con una SPECIFICA COMBINAZIONE DI FATTORI\n",
    "        #  condizione sperimentale, tipo di dato e provenienza del dato!\n",
    "        \n",
    "    \n",
    "\n",
    "        if best_models[exp_cond][data_type][category_subject][config.model_name][\"max_val_acc\"] == -float('inf'):\n",
    "\n",
    "            # Salvo il primo best_model per quella combinazione\n",
    "            best_models[exp_cond][data_type][category_subject][config.model_name] = {\n",
    "                \"model\": cp.deepcopy(model),\n",
    "                \"max_val_acc\": accuracy_val,\n",
    "                \"best_epoch\": epoch,\n",
    "                \n",
    "                #***** ATTENZIONE: CAMBIAMENTI ESEGUITI RISPETTO A PRIMA *****\n",
    "                #***** AGGIUNTA DELLA CHIAVE CONFIG CHE PRELEVA AUTOMATICAMENTE LA MIGLIORE CONFIGURAZIONE DI IPER-PARAMETRI DENTRO 'BEST_MODELS'\n",
    "                \n",
    "                # Salva la configurazione degli iper-parametri della migliore run di uno sweep \n",
    "                # in relazione ad un certo modello applicato su un dataset costituito da \n",
    "                # una certa combinazione di fattori: \n",
    "                # condizione sperimentale, tipo di dato EEG usato, provenienza del dato usato\n",
    "                \"config\": dict(config)  \n",
    "            }\n",
    "\n",
    "            best_model_name = f\"{config.model_name}_{exp_cond}_{data_type}_{category_subject}\"\n",
    "\n",
    "            model_path = os.path.join(base_dir, exp_cond, data_type, category_subject)\n",
    "\n",
    "            os.makedirs(model_path, exist_ok=True)\n",
    "            \n",
    "            #***** ATTENZIONE: CAMBIAMENTI ESEGUITI RISPETTO A PRIMA *****\n",
    "            #***** SALVATAGGIO DI UN FILE .PKL, CHE CONTIENE \n",
    "            \n",
    "            # I PESI E BIAS DEL MODELLO DERIVATO DALLA MIGLIORE CONFIGURAZIONE DI IPER-PARAMETRI OTTENUTA DALLA MIGLIORE RUN DI UN CERTO SWEEP\n",
    "            # IN RELAZIONE AD UN CERTO DATASET COSTITUITO DA UNA CERTA COMBINAZIONE DI FATTORI\n",
    "            \n",
    "            '''OLD VERSION (SOLO SALVATAGGIO PESI E BIAS DEL MODELLO!'''\n",
    "            #model_file = f\"{model_path}/{best_model_name}.pth\"\n",
    "            \n",
    "            model_file = f\"{model_path}/{best_model_name}.pkl\"\n",
    "            \n",
    "            '''OLD VERSION (SOLO SALVATAGGIO PESI E BIAS DEL MODELLO!'''\n",
    "            #torch.save(best_model.state_dict(), model_file)\n",
    "            \n",
    "            # Salva un dizionario contenente sia i pesi che la configurazione\n",
    "            torch.save({\n",
    "                \"state_dict\": best_model.state_dict(),\n",
    "                \"config\": dict(config)\n",
    "            }, model_file)\n",
    "\n",
    "            print(f\"Il modello \\n\\033[1m{best_model_name}\\033[0m verrà salvato in questa folder directory: \\n\\033[1m{model_file}\\033[0m\")\n",
    "\n",
    "            #Condizione di aggiornamento:\n",
    "            #Se l'accuracy corrente (accuracy_val) di quel modello di quello sweep supera il valore già salvato in best_models[...], \n",
    "            #allora aggiorniamo il dizionario e sovrascriviamo il file del best model, di quel modello, di quella combinazione di fattori.\n",
    "\n",
    "\n",
    "            # Puoi confrontare e salvare il modello solo se il nuovo è migliore\n",
    "\n",
    "\n",
    "            #Questo assicura che il salvataggio del modello avvenga solo se\n",
    "            #il nuovo modello ha un'accuratezza di validazione (max_val_acc) migliore \n",
    "            #rispetto a quella già memorizzata per la condizione specifica (exp_cond).\n",
    "\n",
    "            #In questo modo, si evita di sovrascrivere il modello salvato con uno peggiore\n",
    "\n",
    "\n",
    "            # Nuovo modello migliore per questa combinazione: aggiorna e sovrascrivi il file\n",
    "\n",
    "\n",
    "        elif accuracy_val > best_models[exp_cond][data_type][category_subject][config.model_name][\"max_val_acc\"]:\n",
    "                best_models[exp_cond][data_type][category_subject][config.model_name] = {\n",
    "                    \"model\": best_model,\n",
    "                    \"max_val_acc\": accuracy_val,\n",
    "                    \"best_epoch\": best_epoch,\n",
    "                    \n",
    "                    # Salva la configurazione degli iper-parametri della migliore run di uno sweep \n",
    "                    # in relazione ad un certo modello applicato su un dataset costituito da \n",
    "                    # una certa combinazione di fattori: \n",
    "                    # condizione sperimentale, tipo di dato EEG usato, provenienza del dato usato\n",
    "                    \"config\": dict(config)  \n",
    "                }\n",
    "                best_model_name = f\"{config.model_name}_{exp_cond}_{data_type}_{category_subject}\"\n",
    "                model_path = os.path.join(base_dir, exp_cond, data_type, category_subject)\n",
    "                os.makedirs(model_path, exist_ok=True)\n",
    "\n",
    "                print(f\"Il modello di questa folder directory:\\n\\033[1m{model_path}\\033[0m\")\n",
    "                print(f\"\\nHa un MIGLIORAMENTO!\")\n",
    "\n",
    "                '''OLD VERSION (SOLO SALVATAGGIO PESI E BIAS DEL MODELLO!'''\n",
    "                #model_file = f\"{model_path}/{best_model_name}.pth\"\n",
    "\n",
    "                model_file = f\"{model_path}/{best_model_name}.pkl\"\n",
    "\n",
    "                if os.path.exists(model_file):\n",
    "\n",
    "                    # Se il file esiste, stampiamo un messaggio di aggiornamento\n",
    "                    print(f\"\\n⚠️ ATTENZIONE: \\nIl modello \\033[1m{best_model_name}\\033[0m verrà AGGIORNATO in \\n\\033[1m{model_path}\\033[0m\")\n",
    "\n",
    "                    # Salva il miglior modello solo se è stato aggiornato\n",
    "                    \n",
    "                    '''OLD VERSION (SOLO SALVATAGGIO PESI E BIAS DEL MODELLO!'''\n",
    "                    #torch.save(best_model.state_dict(), model_file)\n",
    "\n",
    "                    # Salva un dizionario contenente sia i pesi che la configurazione\n",
    "                    torch.save({\n",
    "                        \"state_dict\": best_model.state_dict(),\n",
    "                        \"config\": dict(config)\n",
    "                    }, model_file)\n",
    "                    \n",
    "                    print(f\"\\nIl nome del modello AGGIORNATO è:\\n\\033[1m{best_model_name}\\033[0m\")\n",
    "\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "                #Condizione \"nessun miglioramento\":\n",
    "                #Se il modello corrente non migliora il best già salvato, viene semplicemente stampato un messaggio.\n",
    "\n",
    "                #Questa logica garantisce che per ogni combinazione il file .pth contenga \n",
    "                #sempre i pesi del miglior modello (secondo la validation accuracy) fino a quel momento.\n",
    "                #Adatta eventualmente i nomi delle variabili (es. accuracy_val vs max_val_acc) per essere coerente con il resto del tuo codice.\n",
    "        else:\n",
    "            ''''QUI VA RIDEFINITO LA MODEL_PATH (e anche se vuoi MODE_FILE) ALTRIMENTI IN QUESTO ELSE NON ESISTONO!'''\n",
    "\n",
    "            best_model_name = f\"{config.model_name}_{exp_cond}_{data_type}_{category_subject}\"\n",
    "            model_path = os.path.join(base_dir, exp_cond, data_type, category_subject)\n",
    "            model_file = f\"{model_path}/{best_model_name}.pkl\"\n",
    "            print(f\"Nessun miglioramento per il modello \\033[1m{config.model_name}\\033[0m in \\n\\033[1m{model_path}\\033[0m, ossia \\n\\033[1m{model_file}\\033[0m\")\n",
    "\n",
    "    wandb.finish()\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    return best_models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b131519-bef4-4ae9-bc4c-656584a6f1cb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### **Weight & Biases Procedure Final Edits - EEG Spectrograms - Electrodes x Frequencies ONLY HYPER-PARAMS**\n",
    "#### **Sweep separati per ciascuno dei modelli CNN2D_LSTM_TF, BiLSTM e Transformer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817dbfe0-945e-468b-9585-d3a0f52a236e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "                                        QUI IL LOOP LO ESEGUO SU OGNI SINGOLO SWEEP DI OGNI COMBINAZIONE DI FATTORI!!!\n",
    "                                                            \n",
    "                                                                    VERSIONE C \n",
    "                                                                    \n",
    "                                                                    \n",
    "                                                W&B SWEEPS AND TRAING LAUNCH WITH MULTIPLE GPUs MANAGEMENT\n",
    "                                        \n",
    "Questa volta, invece, andiamo ad iterare rispetto a \n",
    "\n",
    "- sweep_tuple, che la tuple che contiene\n",
    "\n",
    "1) relativo codice stringa univoco dello Sweep ID\n",
    "2  la sua combination_key, che ri-associa allo Sweep ID la combinazione di fattori della relativa condizione sperimentale\n",
    "\n",
    "\n",
    "PRIMA FACEVO IN QUESTO MODO\n",
    "\n",
    "for sweep_id in sweep_ids[condition][data_type][category_subject]:\n",
    "    print(f\"\\033[1mInizio l'agent\\033[0m per sweep_id: \\033[1m{sweep_id}\\033[0m\")\n",
    "    \n",
    "ORA INVECE ITERO SULLA TUPLA!\n",
    "\n",
    "\n",
    "for condition in sweep_ids:\n",
    "    for data_type in sweep_ids[condition]:\n",
    "        for category_subject in sweep_ids[condition][data_type]:\n",
    "            for sweep_tuple in sweep_ids[condition][data_type][data_tuples]:\n",
    "        \n",
    "\n",
    "VERSIONE C (SEMPLIFICATA!)\n",
    "\n",
    "\n",
    "****** ****** ****** ****** ****** ****** ****** ****** ****** ****** ****** ****** ****** ****** ****** ****** ****** ****** ****** ****** ******\n",
    "\n",
    "SPIEGAZIONE\n",
    "\n",
    "GPU counter: Ho aggiunto un contatore (gpu_counter) che cicla tra le GPU disponibili. \n",
    "\n",
    "In questo modo, il primo sweep sarà eseguito sulla GPU 0, il secondo sulla GPU 1, e così via. \n",
    "Quando il contatore raggiunge il numero di GPU disponibili, torna a 0 per riusare la prima GPU.\n",
    "\n",
    "Rotazione delle GPU: All'interno del loop, per ogni sweep, viene assegnata una GPU diversa. \n",
    "Se ci sono più di 1 GPU, il contatore incrementa, e la variabile CUDA_VISIBLE_DEVICES cambia automaticamente per assegnare la GPU corretta.\n",
    "\n",
    "Esecuzione parallela: Ogni sweep viene eseguito su una GPU separata. Se ci sono 2 GPU, il primo sweep va su GPU 0, il secondo su GPU 1, il terzo su GPU 0, e così via.\n",
    "\n",
    "Risposta alla tua domanda:\n",
    "In questo modo, ogni sweep_id viene eseguito una sola volta, ma su GPU diverse (se disponibili). Non ci sono duplicati dello stesso sweep su entrambe le GPU.\n",
    "\n",
    "\n",
    "DOMANDE SUL NUOVO CODICE\n",
    "\n",
    "1) Gli sweep sono eseguiti già in parallelo giusto?\n",
    "No, in questo caso gli sweep non sono eseguiti in parallelo in modo esplicito tramite il codice che hai scritto.\n",
    "\n",
    "Anche se hai assegnato ciascun sweep a una GPU diversa, il codice esegue sequenzialmente ogni sweep, solo che li distribuisce su GPU differenti in modo rotazionale.\n",
    "Ogni volta che il ciclo passa ad un nuovo sweep, assegna un ID GPU e poi esegue l'agent su quella GPU. Non vengono eseguiti in parallelo a livello di codice.\n",
    "\n",
    "2) O semplicemente in questo modo faccio in modo di distribuire ogni sweep sull'altra GPU rispetto a quella usata dallo sweep precedente\n",
    "per \"ottimizzare\" il carico computazionale di ogni GPU?\n",
    "\n",
    "Esatto! Quello che stai facendo è distribuire i vari sweep su GPU diverse, assicurandoti che ogni sweep venga eseguito su una GPU separata (se ne hai di disponibili).\n",
    "Questo permette di ottimizzare l'uso delle risorse, evitando che una GPU venga sovraccaricata da più sweep. Se il numero di GPU disponibili è maggiore di 1, \n",
    "allora i sweep sono distribuiti sulle diverse GPU, ma ogni sweep sarà ancora eseguito singolarmente.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Sì, con il codice che hai fornito, stai distribuendo gli sweep tra le diverse GPU, in modo da ottimizzare il carico computazionale e non sovraccaricare una sola GPU.\n",
    "\n",
    "Dettaglio del funzionamento:\n",
    "Distribuzione delle GPU (rotazionale):\n",
    "\n",
    "Quando ci sono più di una GPU, il codice assegna a ciascun sweep una GPU diversa in modo rotazionale.\n",
    "\n",
    "Per ogni ciclo del loop, la variabile gpu_counter determina a quale GPU assegnare il prossimo sweep.\n",
    "\n",
    "Se ci sono 2 GPU, il primo sweep viene eseguito sulla GPU 0, il secondo sulla GPU 1, il terzo di nuovo sulla GPU 0, e così via.\n",
    "\n",
    "Gestione della GPU:\n",
    "\n",
    "Se hai più di una GPU, os.environ[\"CUDA_VISIBLE_DEVICES\"] imposta il dispositivo GPU corrente su cui il codice deve girare (GPU 0 o GPU 1). Questo permette di gestire quale GPU eseguirà l'addestramento per ciascun sweep.\n",
    "\n",
    "Quando num_gpus > 1, il codice alterna l'assegnazione della GPU per ogni sweep, evitando di sovraccaricare una singola GPU con troppe operazioni contemporaneamente.\n",
    "\n",
    "Ottimizzazione del carico computazionale:\n",
    "\n",
    "L'alternanza tra GPU successive per ciascun sweep aiuta a distribuire il carico in modo equilibrato, specialmente se il numero di sweep è alto.\n",
    "\n",
    "In pratica, se hai 2 GPU e 10 sweep da eseguire, ogni GPU eseguirà 5 sweep, evitando di saturare una singola GPU.\n",
    "\n",
    "Parallelizzazione effettiva:\n",
    "Nel tuo codice non c'è parallelismo vero e proprio tra le GPU (come quello che otterresti con DataParallel o DistributedDataParallel), ma piuttosto distribuisci gli sweep su GPU diverse. Ogni sweep è eseguito sequenzialmente su una GPU diversa, ma non stai parallelizzando il training dello stesso sweep su più GPU.\n",
    "\n",
    "Se volessi fare in modo che un singolo sweep fosse parallelizzato su più GPU (in modo che il lavoro venga diviso tra le GPU per uno stesso sweep), dovresti usare DataParallel o DistributedDataParallel, come descritto in precedenza. Ma in questo caso, ogni sweep è isolato e viene eseguito su una sola GPU, quindi non c'è un vero parallelismo dentro ogni singolo sweep.\n",
    "\n",
    "Domande che potrebbero sorgere:\n",
    "Gli sweep vengono eseguiti in parallelo?\n",
    "\n",
    "No, i sweep sono eseguiti uno alla volta, ma su GPU diverse. Quindi, mentre il primo sweep usa la GPU 0, il secondo usa la GPU 1 e così via. Ogni sweep viene gestito separatamente, ma sfrutti più GPU per parallelizzare l'esecuzione di più sweep contemporaneamente.\n",
    "\n",
    "La distribuzione delle GPU tra gli sweep è ottimizzata?\n",
    "\n",
    "Sì, stai bilanciando il carico computazionale tra le GPU, assegnando a ogni GPU uno sweep alternato. Se hai molte GPU, puoi ottimizzare ulteriormente distribuendo i sweep su più dispositivi.\n",
    "\n",
    "Se volessi parallelizzare più agenti W&B su diverse GPU, il codice che stai utilizzando sarebbe corretto, ma per ottimizzare ulteriormente i tempi di esecuzione, potresti prendere in considerazione anche l'utilizzo di tecniche come DataParallel o DistributedDataParallel per far sì che più GPU lavorino contemporaneamente sullo stesso sweep. Ma la logica che hai già implementato va bene per distribuire più sweep tra le GPU.\n",
    "\n",
    "Se hai bisogno di ulteriori dettagli su come implementare il parallelismo vero e proprio (inclusi DataParallel o DistributedDataParallel), fammi sapere!\n",
    "\n",
    "\n",
    "\n",
    "****** ****** ****** ****** ****** ****** ****** ****** ****** ****** ****** ****** ****** ****** ****** ****** ****** ****** ****** ****** ******\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "Per modificare il loop in modo che accetti i sweeps per ogni modello e gestisca correttamente\n",
    "l'esecuzione del training per ciascun modello con il relativo sweep, dobbiamo fare alcune modifiche.\n",
    "\n",
    "\n",
    "Modifiche principali:\n",
    "\n",
    "1) Funzione make_train_wrapper:\n",
    "La funzione dovrà essere adattata per passare correttamente la configurazione di sweep per ogni modello, \n",
    "invece di passare un'unica configurazione generica (sweep_config).\n",
    "\n",
    "2) Identificazione corretta del modello: \n",
    "Nel loop, per ogni combinazione (condition, data_type, category_subject)\n",
    "e per ogni modello (ad esempio, CNN3D_LSTM_FC e SeparableCNN2D_LSTM_FC), \n",
    "\n",
    "dobbiamo passare al wandb.agent il relativo sweep ID per il modello e la sua configurazione.\n",
    "\n",
    "3) Modifica della funzione make_train_wrapper per gestire ogni modello separatamente: \n",
    "Ogni modello avrà il proprio sweep e la propria configurazione.\n",
    "\n",
    "\n",
    "Spiegazione delle modifiche:\n",
    "\n",
    "1) Funzione make_train_wrapper:\n",
    "\n",
    "Adesso prende anche model_name per passare il relativo sweep_config dal dizionario sweep_config_dict.\n",
    "Passa il sweep_config corretto per ogni modello, a seconda del model_name passato nel ciclo.\n",
    "\n",
    "2) Dizionario sweep_config_dict:\n",
    "\n",
    "Ho creato un dizionario sweep_config_dict che associa ciascun modello (\"CNN3D_LSTM_FC\" e \"SeparableCNN2D_LSTM_FC\")\n",
    "alla sua configurazione di sweep (sweep_config_cnn3d e sweep_config_cnn_sep).\n",
    "Questo permette di usare la corretta configurazione per ogni modello.\n",
    "\n",
    "3) Modifica nel ciclo:\n",
    "\n",
    "Il ciclo ora scorre su model_name (i.e., i modelli CNN3D_LSTM_FC e SeparableCNN2D_LSTM_FC) \n",
    "per ogni combinazione di condition, data_type, category_subject.\n",
    "\n",
    "Per ogni modello, il relativo sweep viene creato ed eseguito.\n",
    "\n",
    "\n",
    "Risultato:\n",
    "Ora, per ogni combinazione di condition, data_type, e category_subject, \n",
    "il codice creerà e gestirà separatamente gli sweeps per ciascun modello,\n",
    "e li eseguirà utilizzando la funzione training_sweep con la relativa configurazione specifica per ogni modello.\n",
    "\n",
    "Questa modifica ti consente di avere il corretto flusso di lavoro per eseguire\n",
    "il training separato per ogni modello con la sua configurazione.\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "import time  # Importa il modulo time\n",
    "\n",
    "\n",
    "# Definiamo una funzione wrapper che \"cattura\" lo sweep_id e le altre variabili\n",
    "\n",
    "'''ATTENZIONE AGGIUNTO model_name tra i parametri di --> make_train_wrapper'''\n",
    "\n",
    "def make_train_wrapper(sweep_id, sweep_tuple, condition, data_type, category_subject, model_name):\n",
    "    def train_wrapper():\n",
    "\n",
    "        # Qui chiamiamo la funzione di training con i parametri appropriati\n",
    "        #print(f\"\\nSetto il training per lo Sweep ID \\033[1m{condition}_{data_type}_{category_subject}\\033[0m con sweep_id {sweep_id}\")\n",
    "        #print(f\"\\nSetting Up Training per lo Sweep ID \\033[1m{sweep_id}\\033[0m --> \\033[1m{combination_key}\\033[0m\")\n",
    "        \n",
    "            \n",
    "        print(f\"\\nSetting Up Training per lo Sweep ID \\033[1m{sweep_id}\\033[0m --> \\033[1m{combination_key}\\033[0m, modello \\033[1m{model_name}\\033[0m\")\n",
    "        training_sweep(\n",
    "            data_dict_preprocessed, \n",
    "            sweep_config_dict[model_name], # Prendi la configurazione per il modello specifico\n",
    "            sweep_ids,\n",
    "            sweep_id,\n",
    "            sweep_tuple,\n",
    "            best_models  # Best models viene aggiornato all'interno della funzione\n",
    "        )\n",
    "    return train_wrapper\n",
    "                        \n",
    "\n",
    "# Dizionari di configurazione per ogni modello\n",
    "\n",
    "# Comodo mapper per il tuo loop\n",
    "\n",
    "#sweep_config_dict = {\n",
    "#    \"CNN2D_LSTM_TF\": sweep_config_cnn2d_lstm_tf,\n",
    "#    \"BiLSTM\": sweep_config_bilstm,\n",
    "#    \"Transformer\": sweep_config_transformer,\n",
    "#}\n",
    "\n",
    "'''AL PRIMO GIRO ABILITA SOLO QUESTO'''\n",
    "#sweep_config_dict = {\n",
    "#    \"CNN2D_LSTM_TF\": sweep_config_cnn2d_lstm_tf,\n",
    "#    \"BiLSTM\": sweep_config_bilstm\n",
    "#}\n",
    "\n",
    "\n",
    "'''AL SECONDO GIRO ABILITA QUESTO'''\n",
    "sweep_config_dict = {\n",
    "    \"Transformer\": sweep_config_transformer\n",
    "}\n",
    "\n",
    "'''AL SECONDO GIRO ABILITA QUESTO'''\n",
    "enabled_models = set(sweep_config_dict.keys())  # {'Transformer'}\n",
    "\n",
    "\n",
    "# Verifica quante GPU sono disponibili\n",
    "num_gpus = torch.cuda.device_count()\n",
    "\n",
    "\n",
    "# Crea un contatore per assegnare un GPU diversa a ciascun sweep\n",
    "gpu_counter = 0\n",
    "\n",
    "# Registra il tempo di inizio\n",
    "start_time = time.time()\n",
    "\n",
    "for condition in sweep_ids:\n",
    "    for data_type in sweep_ids[condition]:\n",
    "        for category_subject in sweep_ids[condition][data_type]:\n",
    "            \n",
    "            for model_name in sweep_ids[condition][data_type][category_subject]:  # Aggiunto loop per il modello\n",
    "                \n",
    "                '''AL SECONDO GIRO ABILITA QUESTO'''\n",
    "                # ⬇️ SKIPPA tutti i modelli non abilitati (CNN2D_LSTM_TF, BiLSTM, ...)\n",
    "                if model_name not in enabled_models:\n",
    "                    print(f\"Skip {model_name}: non abilitato in questo giro\")\n",
    "                    continue\n",
    "                    \n",
    "                #for sweep_tuple in sweep_ids[condition][data_type][category_subject]:\n",
    "                \n",
    "                for sweep_tuple in sweep_ids[condition][data_type][category_subject][model_name]:  # Itera sugli sweep per ciascun modello\n",
    "\n",
    "                    # Esegui l'unpacking della tupla per ottenere solo il primo elemento della tupla (sweep_id, combination_key)\n",
    "                    sweep_id, combination_key = sweep_tuple\n",
    "                    \n",
    "                    \n",
    "                    combination_key = f\"{condition}_{data_type}_{category_subject}\"\n",
    "                    \n",
    "                    # Un modo efficace per \"catturare\" il contesto (come sweep_id e le altre variabili) \n",
    "                    # per ogni iterazione è definire una funzione wrapper locale all'interno del ciclo\n",
    "                    # In questo modo, ogni volta che chiami l'agente, il wrapper avrà già i parametri specifici per quella combinazione\n",
    "\n",
    "\n",
    "                    # Se ci sono più di 1 GPU, assegna a ciascuna GPU uno sweep diverso\n",
    "                    if num_gpus > 1:\n",
    "\n",
    "                        '''ATTENZIONE AGGIUNTO model_name tra i parametri di --> make_train_wrapper''' \n",
    "                        \n",
    "                        # Assegna la GPU in modo rotazionale\n",
    "                        os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(gpu_counter)\n",
    "                        \n",
    "                        agent_function = make_train_wrapper(sweep_id, sweep_tuple, condition, data_type, category_subject, model_name)\n",
    "                    \n",
    "                        #wandb.agent(sweep_id, function=make_train_wrapper(sweep_id, sweep_tuple, condition, data_type, category_subject, model_name), project=f\"{condition}_spectrograms_channels_freqs_new_3d_grid_multiband\", count=200)\n",
    "                        \n",
    "                        #PER TASK 1/3\n",
    "                        wandb.agent(sweep_id, function=make_train_wrapper(sweep_id, sweep_tuple, condition, data_type, category_subject, model_name), project=f\"{condition}_spectrograms_time_freqs_new_3d_grid_multiband\", count=200)\n",
    "                        \n",
    "                        #PER TASK 2/4\n",
    "                        #wandb.agent(sweep_id, function=make_train_wrapper(sweep_id, sweep_tuple, condition, data_type, category_subject, model_name), project=f\"{condition}_spectrograms_time_freqs_new_imagery_3d_grid_multiband\", count=200)\n",
    "                        \n",
    "                        # Passa alla prossima GPU per il prossimo sweep\n",
    "                        gpu_counter = (gpu_counter + 1) % num_gpus\n",
    "\n",
    "                    else:\n",
    "                        \n",
    "                        # Se c'è una sola GPU, esegui il sweep sulla GPU 0\n",
    "                        os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "                        \n",
    "                        agent_function = make_train_wrapper(sweep_id, sweep_tuple, condition, data_type, category_subject, model_name)\n",
    "                        \n",
    "                        #wandb.agent(sweep_id, function=make_train_wrapper(sweep_id, sweep_tuple, condition, data_type, category_subject, model_name), project=f\"{condition}_spectrograms_channels_freqs_new_3d_grid_multiband\", count=200)\n",
    "                        \n",
    "                        #PER TASK 1/3\n",
    "                        wandb.agent(sweep_id, function=make_train_wrapper(sweep_id, sweep_tuple, condition, data_type, category_subject, model_name), project=f\"{condition}_spectrograms_time_freqs_new_3d_grid_multiband\", count=200)\n",
    "                        \n",
    "                        #PER TASK 2/4\n",
    "                        #wandb.agent(sweep_id, function=make_train_wrapper(sweep_id, sweep_tuple, condition, data_type, category_subject, model_name), project=f\"{condition}_spectrograms_time_freqs_new_imagery_3d_grid_multiband\", count=200)\n",
    "\n",
    "\n",
    "                    # Crea la funzione wrapper per l'agent\n",
    "                    '''COMMENTATO'''\n",
    "                    #agent_function = make_train_wrapper(sweep_id, sweep_tuple, condition, data_type, category_subject)\n",
    "\n",
    "\n",
    "                    # NOTA: non assegno il valore di wandb.agent a best_models, lascio che training_sweep aggiorni best_models internamente!\n",
    "                    '''DEVI INSERIRE PER L'AGENTE COME PARAMETRO IL NOME DELLA CONDIZIONE SPERIMENTALE DEL PROGETTO SU  W&B\n",
    "                       ALTRIMENTI CERCA LO SWEEP NEL PROGETTO SBAGLIATO '''\n",
    "\n",
    "                    print(f\"Inizio l'\\033[1magent\\033[0m per \\033[1msweep_id\\033[0m \\tN°: \\033[1m{sweep_tuple}\\033[0m\")\n",
    "\n",
    "                    '''COMMENTATO'''\n",
    "                    #wandb.agent(sweep_id, function=agent_function, project = f\"{condition}_spectrograms_channels_freqs_new_2d_grid_multiband_topomap\", count=15)\n",
    "\n",
    "                    print(f\"\\nLo sweep id corrente \\033[1m{sweep_id}\\033[0m ha la combinazione di fattori stringhe: \\033[1m{condition}; {data_type}; {category_subject}\\033[0m\\n\")\n",
    "\n",
    "                    torch.cuda.empty_cache()\n",
    "\n",
    "# Registra il tempo di fine\n",
    "end_time = time.time()\n",
    "\n",
    "# Calcola il tempo totale\n",
    "total_time = end_time - start_time\n",
    "hours = int(total_time // 3600)\n",
    "minutes = int((total_time % 3600) // 60)\n",
    "seconds = int(total_time % 60)\n",
    "\n",
    "# Stampa il tempo totale in formato leggibile\n",
    "print(f\"\\nTempo totale impiegato: \\033[1m{hours} ore, {minutes} minuti e {seconds} secondi\\033[0m.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e3875d-6c34-483b-b144-98c9b4271b58",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Impostazione **Recupero DL Optimized Models** con **Rappresentazione Tempo-Frequenza dei miei dati EEG** a seconda del Dataset del Task scelto\n",
    "\n",
    "\n",
    "Notebook **\"EEG Data Stats Descriptives & GradCam Checks\"**\n",
    "\n",
    "- Task 1: Motor Execution (Open and close right or left fist) - Unilateral - Runs 3, 7, 11 \n",
    "- Task 2: Motor Imagery (Imagine opening and closing right and left fists) - Unilateral - Runs 4, 8, 12 \n",
    "- Task 3: Motor Execution (Open and close both fists and feet) - Bilateral - Runs 5, 9, 13 \n",
    "- Task 4: Motor Imagery (Imagine opening and closing both fists and feet) - Bilateral - Runs 6, 10, 14 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88b9dec-a7d0-4056-81a9-ae189134ee62",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Implementazione dei Best Models Dopo W&B - EEG SPECTROGRAMS **+ GRADCAM FREQUENCY x TIME (ALL SUBJECTS)**! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423c0dc0-4b5a-41e5-a5bd-00e79f86d820",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Library Importing \n",
    "    \n",
    "import os\n",
    "import math\n",
    "import copy as cp \n",
    "\n",
    "import tqdm\n",
    "from tqdm import tqdm\n",
    "\n",
    "import random \n",
    "\n",
    "#import mne \n",
    "import scipy\n",
    "\n",
    "import numpy as np  # NumPy per operazioni numeriche\n",
    "import matplotlib.pyplot as plt  # Matplotlib per la visualizzazione dei dati\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import random\n",
    "\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ac4657-b2cf-41e4-8ab0-1b2168afb782",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### **NUOVE MODIFICHE SPECIFICHE PER I DATI NON HYPER POST W&B CON GRADCAM**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55204af-4091-4db2-ae0e-7a1025a486f6",
   "metadata": {},
   "source": [
    "Allora le modifche che ho ultimato quindi sono:\n",
    "\n",
    "- **1)Creazione della classe GradCAM**\n",
    "\n",
    "\n",
    "    **GRADCAM CLASS**\n",
    "\n",
    "        import torch\n",
    "        import torch.nn.functional as F\n",
    "        import cv2\n",
    "        import numpy as np\n",
    "        import matplotlib.pyplot as plt\n",
    "\n",
    "        class GradCAM:\n",
    "            def __init__(self, model, target_layer):\n",
    "                self.model = model\n",
    "                self.target_layer = target_layer\n",
    "                self.activations = None\n",
    "                self.gradients = None\n",
    "                # Registra hook per catturare attivazioni e gradienti\n",
    "                self.target_layer.register_forward_hook(self.save_activation)\n",
    "                self.target_layer.register_backward_hook(self.save_gradient)\n",
    "\n",
    "            def save_activation(self, module, input, output):\n",
    "                self.activations = output.detach()\n",
    "\n",
    "            def save_gradient(self, module, grad_input, grad_output):\n",
    "                self.gradients = grad_output[0].detach()\n",
    "\n",
    "\n",
    "- **2)** Creazione della funzione per generare delle immagini associate alla GradCAM compution**\n",
    "\n",
    "    \n",
    "    **FUNCTION FOR CREATING GRAD-CAM MAPS & FIGURES ASSOCIATED TO GRADCAM COMPUTATION**\n",
    "\n",
    "        import cv2\n",
    "        import numpy as np\n",
    "        import matplotlib.pyplot as plt\n",
    "        import io\n",
    "\n",
    "        def compute_gradcam_figure(model, test_loader, exp_cond, data_type, category_subject, device):\n",
    "\n",
    "            \"\"\"\n",
    "            Per il modello CNN2D, seleziona un campione per ciascuna classe (0 e 1),\n",
    "            calcola la GradCAM e costruisce una figura con:\n",
    "              - Riga 1: Heatmap per classe 0 e classe 1.\n",
    "              - Riga 2: Sovrapposizione della heatmap sullo spettrogramma originale.\n",
    "            I titoli della figura vengono personalizzati con exp_cond, data_type, category_subject.\n",
    "            \"\"\"\n",
    "\n",
    "            # Assumiamo che il modello sia CNN2D e che il layer target sia model.conv3\n",
    "            target_layer = model.conv3\n",
    "            gradcam = GradCAM(model, target_layer)\n",
    "\n",
    "            # Dizionari per salvare il campione per ogni classe\n",
    "            samples = {}      # Salveremo il sample input per ogni classe\n",
    "            labels_found = {} # Per tenere traccia delle etichette già trovate\n",
    "\n",
    "            # Itera sul test_loader fino a trovare almeno un esempio per ciascuna classe\n",
    "            for inputs, labels in test_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                for i, label in enumerate(labels):\n",
    "                    label_int = int(label.item())\n",
    "                    if label_int not in labels_found:\n",
    "                        samples[label_int] = inputs[i].unsqueeze(0)  # salva come tensore 4D\n",
    "                        labels_found[label_int] = True\n",
    "                    if 0 in labels_found and 1 in labels_found:\n",
    "                        break\n",
    "                if 0 in labels_found and 1 in labels_found:\n",
    "                    break\n",
    "\n",
    "            # Se non troviamo entrambi gli esempi, esci con un messaggio\n",
    "            if 0 not in samples or 1 not in samples:\n",
    "                print(\"Non sono stati trovati esempi per entrambe le classi nel test_loader.\")\n",
    "                return None\n",
    "\n",
    "            # Per ciascun campione, calcola GradCAM\n",
    "            cams = {}\n",
    "            overlays = {}\n",
    "            for cls in [0, 1]:\n",
    "                sample_input = samples[cls]\n",
    "                sample_input.requires_grad = True  # Abilita gradiente per il campione\n",
    "                cam = gradcam.generate_cam(sample_input)\n",
    "                cams[cls] = cam\n",
    "\n",
    "                # Converti il sample in immagine numpy per la visualizzazione\n",
    "                img = sample_input.squeeze().cpu().detach().numpy().transpose(1, 2, 0)\n",
    "                # Normalizza l'immagine in scala 0-255\n",
    "                img_norm = np.uint8(255 * (img - img.min()) / (img.max() - img.min()))\n",
    "                # Applica la heatmap\n",
    "                heatmap = cv2.applyColorMap(np.uint8(255 * cam), cv2.COLORMAP_JET)\n",
    "                heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)\n",
    "                # Sovrapponi la heatmap all'immagine originale\n",
    "                overlay = cv2.addWeighted(img_norm, 0.6, heatmap, 0.4, 0)\n",
    "                overlays[cls] = overlay\n",
    "\n",
    "            # Crea la figura con due righe e due colonne\n",
    "            fig, axs = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "            # Titolo per la prima riga\n",
    "            title_row1 = f\"Grad-CAM mapping of experimental condition {exp_cond}, EEG {data_type}, Subject {category_subject}\"\n",
    "            # Titolo per la seconda riga\n",
    "            title_row2 = f\"Grad-CAM mapping superimposition over EEG Spectrogram of experimental condition {exp_cond}, Subject {category_subject}\"\n",
    "\n",
    "            # Prima riga: solo le heatmap\n",
    "            for j, cls in enumerate([0, 1]):\n",
    "                axs[0, j].imshow(cv2.cvtColor(cv2.applyColorMap(np.uint8(255 * cams[cls]), cv2.COLORMAP_JET), cv2.COLOR_BGR2RGB))\n",
    "                axs[0, j].set_title(f\"Class {cls} Heatmap\")\n",
    "                axs[0, j].axis('off')\n",
    "            axs[0, 0].set_ylabel(title_row1, fontsize=10)\n",
    "\n",
    "            # Seconda riga: overlay della heatmap sullo spettrogramma originale\n",
    "            for j, cls in enumerate([0, 1]):\n",
    "                axs[1, j].imshow(overlays[cls])\n",
    "                axs[1, j].set_title(f\"Class {cls} Overlay\")\n",
    "                axs[1, j].axis('off')\n",
    "            axs[1, 0].set_ylabel(title_row2, fontsize=10)\n",
    "\n",
    "            # Ottimizza la disposizione della figura\n",
    "            plt.tight_layout()\n",
    "\n",
    "            # Salva la figura in un buffer (che potrai poi passare a save_performance_results)\n",
    "            buf = io.BytesIO()\n",
    "            plt.savefig(buf, format='png')\n",
    "            buf.seek(0)\n",
    "            fig_image = buf.getvalue()\n",
    "            buf.close()\n",
    "            plt.close(fig)\n",
    "\n",
    "            return fig_image\n",
    "\n",
    "\n",
    "- **3) Modifica delle funzioni per il salvataggio delle immagini create tramite la GradCAM compution**\n",
    "\n",
    "    **FUNCTIONS FOR GRADCAM COMPUTATION & SAVING**\n",
    "    \n",
    "    Questa modifica consente di creare ed adattare le path di salvataggio ANCHE delle immagini calcolate dalla classe customizzata di GradCAM, \n",
    "    delle mappe di attivazione prodotte dalle feature maps e della sovrapposizione delle stesse aree decisionali\n",
    "    rilevanti per la migliore classificazione dei dati di esempio di una certa classe,\n",
    "    a partire da un certo dataset composto da una certa combinazione di fattori\n",
    "    (i.e., exp_cond, data_type, category_subject)\n",
    "\n",
    "\n",
    "#NEW VERSIONS FOR SPECTROGRAMS WITH GRADCAM COMPUTATION ON CNN2D!\n",
    "\n",
    "    **Funzione per determinare a quale subfolder appartiene la chiave**\n",
    "    def get_subfolder_from_key(key, model_standardization):\n",
    "\n",
    "        #DEFINIZIONE DELLA PATH DOVE VIENE SALVATO IL FILE\n",
    "        if '_familiar_th' in key:\n",
    "            return 'th_fam'\n",
    "        elif '_unfamiliar_th' in key:\n",
    "            return 'th_unfam'\n",
    "        elif '_familiar_pt' in key:\n",
    "            return 'pt_fam'\n",
    "        elif '_unfamiliar_pt' in key:\n",
    "            return 'pt_unfam'\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "\n",
    "    from PIL import Image\n",
    "    import io\n",
    "    import pickle\n",
    "    import os\n",
    "\n",
    "    **Funzione per salvare i risultati**\n",
    "    def save_performance_results(model_name, \n",
    "                                 my_train_results,\n",
    "                                 my_test_results, \n",
    "                                 key,\n",
    "                                 exp_cond,\n",
    "                                 model_standardization,\n",
    "                                 base_folder,\n",
    "                                 gradcam_image = None):\n",
    "        \"\"\"\n",
    "        Funzione che salva i risultati del modello in base alla combinazione di 'key' e 'model_name'.\n",
    "        Se gradcam_image è fornita, la salva anche in formato PNG con un nome che inizia con 'GradCAM_results'.\n",
    "        \"\"\"\n",
    "\n",
    "        # Identificazione del subfolder in base alla chiave\n",
    "        subfolder = get_subfolder_from_key(key, model_standardization)\n",
    "\n",
    "        # Debug: controllo sulla subfolder\n",
    "        print(f\"\\nDEBUG - Chiave: \\033[1m{key}\\033[0m, Subfolder ottenuto: \\033[1m{subfolder}\\033[0m\")\n",
    "\n",
    "        if subfolder is None:\n",
    "            print(f\"Errore: La chiave \\033[1m{key}\\033[0m non corrisponde a nessun subfolder valido.\\n\")\n",
    "            return\n",
    "\n",
    "        # Determinazione del tipo di dato direttamente dalla chiave\n",
    "        if \"spectrograms\" in key:\n",
    "            data_type_str = \"spectrograms\"\n",
    "        else:\n",
    "            print(f\"Errore: Tipo di dato non riconosciuto nella chiave '{key}'.\")\n",
    "            return\n",
    "\n",
    "        # Creazione del nome del file pickle con l'inclusione della combinazione key + model_name\n",
    "        if model_standardization:\n",
    "            file_name = f\"{model_name}_performances_{exp_cond}_{data_type_str}_{subfolder}_std.pkl\"\n",
    "            folder_path = os.path.join(base_folder, exp_cond, data_type_str, subfolder)\n",
    "        else:\n",
    "            file_name = f\"{model_name}_performances_{exp_cond}_{data_type_str}_{subfolder}.pkl\"\n",
    "            folder_path = os.path.join(base_folder, exp_cond, data_type_str, subfolder)\n",
    "\n",
    "        # Verifica se la cartella di destinazione esiste, altrimenti creala\n",
    "        if not os.path.exists(folder_path):\n",
    "            os.makedirs(folder_path)\n",
    "\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "        # Creazione del dizionario con i risultati\n",
    "        results_dict = {\n",
    "            'my_train_results': my_train_results,\n",
    "            'my_test_results': my_test_results\n",
    "        }\n",
    "\n",
    "        # Salvataggio del dizionario con i risultati\n",
    "        try:\n",
    "            with open(file_path, 'wb') as f:\n",
    "                pickle.dump(results_dict, f)\n",
    "            print(f\"\\n🔬Risultati salvati con successo 👍 in: \\n\\033[1m{file_path}\\033[0m\\n\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌Errore durante il salvataggio dei risultati: {e}\")\n",
    "\n",
    "        # Se è stata fornita l'immagine GradCAM, salvala come file PNG\n",
    "        if gradcam_image is not None:\n",
    "            if model_standardization:\n",
    "                gradcam_file_name = f\"GradCAM_results_{model_name}_{exp_cond}_{data_type_str}_{subfolder}_std.png\"\n",
    "            else:\n",
    "                gradcam_file_name = f\"GradCAM_results_{model_name}_{exp_cond}_{data_type_str}_{subfolder}.png\"\n",
    "\n",
    "            gradcam_file_path = os.path.join(folder_path, gradcam_file_name)\n",
    "\n",
    "            #try:\n",
    "            #    with open(gradcam_file_path, \"wb\") as f_img:\n",
    "            #        f_img.write(gradcam_image)\n",
    "            #    print(f\"\\n📸Immagine GradCAM salvata con successo 👍 in: \\n\\033[1m{gradcam_file_path}\\033[0m\\n\")\n",
    "\n",
    "            try:\n",
    "\n",
    "                '''\n",
    "                Se gradcam_image è un oggetto BytesIO, allora rappresenta un flusso di dati binari in memoria.\n",
    "                Quando si leggono dati da un BytesIO, il cursore interno avanza come in un file normale. \n",
    "                Se il cursore non è all'inizio, Image.open() potrebbe non leggere correttamente l'immagine.\n",
    "                👉 seek(0) riporta il cursore all'inizio del buffer prima di leggerlo con Image.open()\n",
    "\n",
    "                Per maggior info leggi cella successiva!\n",
    "                '''\n",
    "\n",
    "                # 🔄 Se gradcam_image è un buffer, convertirlo in immagine PIL\n",
    "                if isinstance(gradcam_image, io.BytesIO):\n",
    "                    gradcam_image.seek(0)  # 🔄 Reset puntatore del buffer\n",
    "                    gradcam_image = Image.open(gradcam_image)\n",
    "\n",
    "                print(f\"\\n📸Immagine GradCAM salvata con successo 👍 in: \\n\\033[1m{gradcam_file_path}\\033[0m\\n\")\n",
    "                # 🔄 Salvare l'immagine nel percorso specificato\n",
    "                gradcam_image.save(gradcam_file_path, format = \"PNG\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"❌Errore durante il salvataggio dell'immagine GradCAM: {e}\")\n",
    "\n",
    "\n",
    "- **4) Integrazione nel loop di training e test dei punti 1), 2) e 3)**\n",
    "\n",
    "    **INTEGRATION OF GRADCAM COMPUTATION IN THE TRAINING E FOR LOOP**\n",
    "\n",
    "    Nel loop che esegue il training ed il testing, integrazione della parte di inizializzazione della classe custom di GradCAM, con cui si esegue \n",
    "\n",
    "    il calcolo delle mappe di attivazione e della sovrapposizione delle mappe di attivazione stesse sullo spettogramma originale, \n",
    "    riportate poi in due immagini distinte create nella stessa figura che vengono salvate correttamente nella stessa directory path. \n",
    "\n",
    "    Le due immagini dovrebbero rappresentare l'heatmap activation e la sovrapposizione della mappa di attivazione sullo spettogramma originale,\n",
    "    relativo ad un esempio rappresentativo per ciascuna delle due classi possibili presenti nello stesso dataset correntemente iterato.\n",
    "\n",
    "    Il loro contributo è di descrivere se la CNN2D abbia identificato delle (possibili) differenti aree decisionali delle feature maps \n",
    "    (e dunque dello spettrogramma) maggiormente utili ai fini della discriminazione delle due condizioni sperimentali inserite all'interno del dataset correntemente iterato.\n",
    "\n",
    "\n",
    "        ** Dizionario per tracciare la standardizzazione usata per ogni combinazione di dati**\n",
    "        ** Dizionario per salvare informazioni sul modello (es. se i dati sono standardizzati)**\n",
    "\n",
    "        models_info = {}\n",
    "\n",
    "        ** Set per tenere traccia dei dataset già elaborati**\n",
    "        processed_datasets = set()\n",
    "\n",
    "        ** Set per tenere traccia delle combinazioni già elaborate**\n",
    "        processed_models = set()\n",
    "\n",
    "        ** Path delle performance dei modelli ottimizzati con weight and biases**\n",
    "        ** Path per trovare le best performances di ogni modello per ogni combinazione dei dati**\n",
    "        base_folder = \"/home/stefano/Interrogait/WB_spectrograms_best_results\"\n",
    "\n",
    "        ** Path di salvataggio delle performance dei modelli dopo estrazione best models da base_folder**\n",
    "        save_path_folder = \"/home/stefano/Interrogait/spectrograms_best_models_post_WB\"\n",
    "\n",
    "\n",
    "        ** --- LOOP PRINCIPALE (con minime modifiche) ---**\n",
    "        for key, (X_data, y_data) in data_dict.items():\n",
    "\n",
    "            print(f\"\\n\\nEstrazione Dati per il dataset: \\033[1m{key}\\033[0m, \\tShape X: \\033[1m{X_data.shape}\\033[0m, Shape y: \\033[1m{y_data.shape}\\033[0m\")\n",
    "\n",
    "            if key in processed_datasets:\n",
    "                print(f\"ATTENZIONE: Il dataset {key} è già stato elaborato! Salto iterazione...\")\n",
    "                continue\n",
    "\n",
    "            processed_datasets.add(key)\n",
    "\n",
    "            X_train, X_val, X_test, y_train, y_val, y_test = split_data(X_data, y_data)\n",
    "            print(f\"Dataset Splitting: Train: \\033[1m{X_train.shape}\\033[0m, Val: \\033[1m{X_val.shape}\\033[0m, Test: \\033[1m{X_test.shape}\\033[0m\")\n",
    "\n",
    "            for model_name in [\"CNN2D\", \"BiLSTM\", \"Transformer\"]:\n",
    "\n",
    "                model_key = f\"{model_name}_{key}\"\n",
    "                if model_key in processed_models:\n",
    "                    print(f\"ATTENZIONE: Il modello {model_name} per il dataset {key} è già stato addestrato! Salto iterazione...\")\n",
    "                    continue\n",
    "                processed_models.add(model_key)\n",
    "\n",
    "                print(f\"\\nPreparazione dati per il dataset \\033[1m{key}\\033[0m e il modello \\033[1m{model_name}\\033[0m...\")\n",
    "\n",
    "                # Prova a caricare la configurazione e i pesi ottimali dal file .pkl\n",
    "\n",
    "                '''\n",
    "                load_config_if_available --> prende in input 'key' che è la chiave composita (i.e, th_resp_vs_pt_resp_1_20_familiar_th)\n",
    "                parse_combination_key --> prende in input 'key' che suddivide la chiave composita in stringhe separate\n",
    "\n",
    "                exp_cond, data_type, category_subject che sfrutto per crearmi la directory path che mi servirà per caricarmi \n",
    "                pesi del modello e i suoi iper-parametri\n",
    "\n",
    "                Diciamo che in questo caso, sfrutto 'parse_combination_key per qualcosa che serve a 'load_config_if_available' in modo IMPLICITO..\n",
    "                '''\n",
    "\n",
    "                config, best_weights = load_config_if_available(key, model_name, base_folder)\n",
    "\n",
    "                if config is None:\n",
    "                    raise ValueError(f\"\\033[1mNessun file .pkl trovato per {model_name} su {key}\\033[0m. Non posso procedere senza la configurazione ottimale.\")\n",
    "\n",
    "                '''\n",
    "                Successivamente, queste variabili vengono invece create in maniera ESPLICITA per fasi successive del loop\n",
    "                MA in questo caso, parsifica la chiave una VOLTA SOLA e memorizza i valori!\n",
    "                '''\n",
    "\n",
    "                # Parsifica la chiave una volta sola e memorizza i valori\n",
    "                exp_cond, data_type, category_subject = parse_combination_key(key)\n",
    "\n",
    "                '''\n",
    "                Dpodiché, \n",
    "\n",
    "                1) si carica i vari valori degli iper-parametri,\n",
    "                2) si esegue la standardizzazione se servisse,\n",
    "                3) prepara il modello per la divisione in train_loader etc.,\n",
    "                4) si carica la configurazione dei pesi del modello, \n",
    "                5) assegna i vari valori degli iper-parametri del modello corrente per la combinazione di dati correntemente iterata \n",
    "\n",
    "                6) esegue il training e il test e poi\n",
    "\n",
    "                7) si salva il tutto nella path corrispondente...\n",
    "\n",
    "                '''\n",
    "\n",
    "                '''\n",
    "                PER DARE UNIFORMITÀ AL CODICE, CAMBIO IL NOME DELLE VARIABILI, CHE CONTENGONO I VALORI OTTIMIZZATI \n",
    "                DA FORNIRE IN INPUT ALLE VARIE FUNZIONI CHE SONO RICHIAMATE NEL LOOP'''\n",
    "\n",
    "                model_batch_size = config[\"batch_size\"]\n",
    "                model_n_epochs = config[\"n_epochs\"]\n",
    "                model_patience = config[\"patience\"]\n",
    "                model_lr = config[\"lr\"]\n",
    "                model_weight_decay = config[\"weight_decay\"]\n",
    "                model_standardization = config[\"standardization\"]\n",
    "\n",
    "                print(f\"Parametri per \\033[1m{model_name}\\033[0m: batch_size= \\033[1m{model_batch_size}\\033[0m, n_epochs= \\033[1m{model_n_epochs}\\033[0m, patience= \\033[1m{model_patience}\\033[0m, lr= \\033[1m{model_lr}\\033[0m, weight_decay= \\033[1m{model_weight_decay}\\033[0m, standardization= \\033[1m{model_standardization}\\033[0m\")\n",
    "\n",
    "                # Salva nel dizionario se per quella combinazione è stata applicata la standardizzazione ai dati\n",
    "                models_info[model_key] = {\"standardization\": model_standardization}\n",
    "\n",
    "\n",
    "                '''PER MANTENERE LA STESSA LOGICA DEL CODICE (ANCHE SE POTREI INSERIRLA DENTRO PREPARE_DATA_FOR_MODEL MODIFICANDO LA FUNZIONE (SI VEDA IN CELLA SOPRA COME)\n",
    "                IMPONGONO LA STANDARDIZZAZIONE PRIMA DI QUESTA FUNZIONE\n",
    "                '''\n",
    "\n",
    "                if model_standardization:\n",
    "                    X_train, X_val, X_test = standardize_data(X_train, X_val, X_test)\n",
    "                    print(f\"\\033[1mSÌ Standardizzazione Dati!\\033[0m\")\n",
    "                else:\n",
    "                    print(f\"\\033[1mNO Standardizzazione Dati!\\033[0m\")\n",
    "\n",
    "                # Sposta il modello sulla GPU (se disponibile)\n",
    "                device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "                # Preparazione dei dataloaders\n",
    "                train_loader, val_loader, test_loader, class_weights_tensor = prepare_data_for_model(\n",
    "                    X_train, X_val, X_test, y_train, y_val, y_test, model_type = model_name, batch_size = model_batch_size)\n",
    "\n",
    "                # Inizializzazione del modello\n",
    "                if model_name == \"CNN2D\":\n",
    "                    model = CNN2D(input_channels=3, num_classes=2)\n",
    "                elif model_name == \"BiLSTM\":\n",
    "                    model = ReadMEndYou(input_size= 3 * 26, hidden_sizes=[24, 48, 62], output_size=2, bidirectional=True)\n",
    "                elif model_name == \"Transformer\":\n",
    "                    model = ReadMYMind(d_model=16, num_heads=4, num_layers=2, num_classes=2, channels=3, freqs=26)\n",
    "                else:\n",
    "                    raise ValueError(f\"Modello {model_name} non riconosciuto.\")\n",
    "\n",
    "                # Se abbiamo caricato i pesi ottimali, li carichiamo nel modello\n",
    "                if best_weights is not None:\n",
    "                    try:\n",
    "                        model.load_state_dict(best_weights)\n",
    "                        print(f\"📊 Modello \\033[1m{model_name}\\033[0m inizializzato con \\033[01i pesi ottimizzati\\033[0m tramite hyper-parameter tuning su \\033[1mWeight & Biases\\033[0m\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"⚠️Errore nel caricamento dei pesi per {model_name} su {key}: {e}\")\n",
    "                        continue\n",
    "\n",
    "\n",
    "                # Definizione del criterio di perdita\n",
    "                criterion = nn.CrossEntropyLoss(weight = class_weights_tensor)\n",
    "\n",
    "                # Definizione dell'ottimizzatore con i parametri aggiornati\n",
    "                optimizer = torch.optim.Adam(model.parameters(), lr = model_lr, weight_decay = model_weight_decay)\n",
    "\n",
    "                print(f\"🏋️‍♂️Avvio del training per \\033[1m{model_name}\\033[0m sul dataset \\033[1m{key}\\033[0m...\")\n",
    "                my_train_results = training(model, train_loader, val_loader, optimizer, criterion, n_epochs = model_n_epochs, patience = model_patience)\n",
    "\n",
    "                print(f\"Avvio del testing per \\033[1m{model_name}\\033[0m sul dataset \\033[1m{key}\\033[0m...\")\n",
    "                my_test_results = testing(my_train_results, test_loader, criterion)\n",
    "\n",
    "                '''\n",
    "                GRADCAM COMPUTATION PER IL MODELLO CNN2D\n",
    "\n",
    "                La funzione compute_gradcam_figure estrae due campioni (uno per ogni classe) e crea una figura con le due righe richieste.\n",
    "\n",
    "                Il parametro gradcam_image (un buffer binario o un'immagine) viene passato alla funzione di salvataggio, \n",
    "                'save_performance_results', in modo da essere salvato nella path corretta. \n",
    "\n",
    "                La funzione 'save_performance_results' è stata modificata \n",
    "                per gestire ANCHE questo nuovo input dell'immagine \n",
    "\n",
    "                (ossia, per salvare il file con un nome che inizia con 'GradCAM_results_'\n",
    "                seguito da tutte le altre stringhe corrispondenti alla combinazione di fattori che costituiscono il dataset corrente:\n",
    "\n",
    "                - coppia di condizioni sperimentali da cui provengono i dati (i.e., th_resp_vs_pt_resp )\n",
    "                - tipologia di dato EEG prelevato (i.e., spectrograms) \n",
    "                - provenienza del dato stesso (i.e., familiar_th)\n",
    "                )\n",
    "\n",
    "                '''\n",
    "\n",
    "                # Se il modello è CNN2D, calcola anche GradCAM per la visualizzazione\n",
    "                gradcam_image = None\n",
    "\n",
    "                if model_name == \"CNN2D\":\n",
    "                    gradcam_image = compute_gradcam_figure(model, test_loader, exp_cond, data_type, category_subject, device)\n",
    "                    if gradcam_image is not None:\n",
    "                        print(f\"GradCAM image computed successfully for {model_name}.\")\n",
    "\n",
    "                print(f\"Salvataggio dei risultati per \\033[1m{model_name}\\033[0m sul dataset \\033[1m{key}\\033[0m...\")\n",
    "                save_performance_results(model_name,\n",
    "                                         my_train_results,\n",
    "                                         my_test_results,\n",
    "                                         key,\n",
    "                                         exp_cond,\n",
    "                                         model_standardization,\n",
    "                                         base_folder = save_path_folder,\n",
    "                                         gradcam_image = gradcam_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb6f047-fc85-49e4-a445-e67c41ad896e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### **UTILS DATI NON HYPER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ddd023-d1ef-473a-9a4c-509d89cbb641",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def load_data(data_type, category, subject_type, condition = \"th_resp_vs_pt_resp\"):\n",
    "    \"\"\"\n",
    "    Carica i dati EEG dalla directory appropriata, già salvati con la finestra temporale (0°-640° punto)\n",
    "\n",
    "    Parameters:\n",
    "    - data_type: str, \"spectrograms\",\n",
    "    - category: str, \"task_1\"\n",
    "    - subject_type: str, \"th\" (terapisti)\n",
    "    - condition: str, condizione sperimentale da selezionare\n",
    "    \n",
    "\n",
    "    Returns:\n",
    "    - X: Dati EEG sotto-selezionati (50°-300° punto e canali selezionati se applicabile)\n",
    "    - y: Etichette corrispondenti\n",
    "    \"\"\"\n",
    "\n",
    "    # Definizione dei percorsi base\n",
    "    base_paths = {\n",
    "        \"spectrograms\": {\n",
    "            \"familiar\": \"/home/stefano/Interrogait/all_datas/Spectrograms_motor_tasks/\"\n",
    "            #\"unfamiliar\": \"/home/stefano/Interrogait/all_datas/Unfamiliar_Spectrograms/\"\n",
    "        },\n",
    "    }\n",
    "\n",
    "    # Seleziona il path corretto\n",
    "    base_path = base_paths[data_type][category]\n",
    "\n",
    "    # Determina il nome del file corretto\n",
    "    if data_type in [\"spectrograms\"]:\n",
    "        filename = f\"new_all_{subject_type}_concat_spectrograms_coupled_exp_task_1.pkl\"\n",
    "    else:\n",
    "        raise ValueError(\"data_type non valido!\")\n",
    "        \n",
    "    # Caricamento del file\n",
    "    filepath = base_path + filename\n",
    "    \n",
    "    with open(filepath, \"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "    \n",
    "    '''\n",
    "    Per i dati spectrogram, la funzione seleziona la condizione desiderata (i.e., condition = \"th_resp_vs_pt_resp\") \n",
    "    e preleva i dati e le etichette associati a quella condizione.\n",
    "    '''\n",
    "    \n",
    "    # Selezione della finestra temporale e delle etichette\n",
    "    X = data[condition][\"data\"]\n",
    "    y = data[condition][\"labels\"]\n",
    "\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "\n",
    "def select_channels(data, channels=[12, 30, 48]):\n",
    "    \"\"\"\n",
    "    Seleziona i canali EEG specificati SOLO per i dati 1-20 e 1-45.\n",
    "\n",
    "    Parameters:\n",
    "    - data: array NumPy, dati EEG con shape (n_trials, n_channels, n_timepoints)\n",
    "    - channels: list, indici dei canali da selezionare\n",
    "\n",
    "    Returns:\n",
    "    - data filtrato sui canali specificati\n",
    "    \"\"\"\n",
    "    return data[:, channels, :]\n",
    "\n",
    "\n",
    "# Funzione per train-test split\n",
    "def split_data(X, y, test_size=0.2, val_size=0.2):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=val_size, random_state=42)\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test\n",
    "\n",
    "\n",
    "'''ATTENZIONE CAMBIATA'''\n",
    "# Funzione per standardizzare i dati\n",
    "def standardize_data(X_train, X_val, X_test, eps = 1e-8):\n",
    "    \n",
    "    mean = X_train.mean(axis=0, keepdims=True)\n",
    "    std = X_train.std(axis=0, keepdims=True)\n",
    "    \n",
    "    X_train = (X_train - mean) / (std + eps)\n",
    "    X_val = (X_val - mean) / (std + eps)\n",
    "    X_test = (X_test - mean) / (std + eps)\n",
    "    \n",
    "    return X_train, X_val, X_test\n",
    "\n",
    "# Import modelli (definisci le classi CNN1D, ReadMEndYou, ReadMYMind)\n",
    "#from models import CNN1D, ReadMEndYou, ReadMYMind  # Assicurati di avere i modelli definiti in 'models.py'\n",
    "\n",
    "# Funzione per inizializzare i modelli\n",
    "def initialize_models():\n",
    "    #model = CNN1D(input_channels=3, num_classes=2)\n",
    "    #model_CNN = CNN2D(input_channels=3, num_classes=2)\n",
    "    \n",
    "    model_CNN = CNN2D(input_channels=64, num_classes=2)\n",
    "    \n",
    "    #model_LSTM = ReadMEndYou(input_size=3, hidden_sizes=[24, 48, 62], output_size=2, bidirectional=True)\n",
    "    #model_LSTM = ReadMEndYou(input_size=3 * 26, hidden_sizes=[24, 48, 62], output_size=2, bidirectional=True)\n",
    "    \n",
    "    model_LSTM = ReadMEndYou(input_size=64 * 81, hidden_sizes=[24, 48, 62], output_size=2, bidirectional=True)\n",
    "    \n",
    "    #model_Transformer = ReadMYMind(num_channels=3, seq_length=250, d_model=16, num_heads=4, num_layers=2, num_classes=2)\n",
    "    #model_Transformer = ReadMYMind(d_model=16, num_heads=4, num_layers=2, num_classes=2, channels=3, freqs=26)\n",
    "    \n",
    "    model_Transformer = ReadMYMind(d_model=16, num_heads=4, num_layers=2, num_classes=2, channels=64, freqs=81)\n",
    "    \n",
    "    \n",
    "    return model_CNN, model_LSTM, model_Transformer\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "\n",
    "'''\n",
    "Questa funzione prende in input i dati di training, validation e test, \n",
    "il tipo di modello scelto e la dimensione del batch. Si occupa di:\n",
    "\n",
    "Calcolare i pesi delle classi.\n",
    "Convertire i dati in tensori PyTorch, con le opportune trasformazioni per CNN, LSTM o Transformer.\n",
    "Creare i dataset e i dataloader per il training.\n",
    "'''\n",
    "\n",
    "\n",
    "def prepare_data_for_model(X_train, X_val, X_test, y_train, y_val, y_test, model_type, batch_size=48):\n",
    "    \n",
    "    # Calcolo dei pesi delle classi\n",
    "    class_weights = compute_class_weight(class_weight='balanced', \n",
    "                                         classes=np.unique(y_train), \n",
    "                                         y=y_train)\n",
    "    \n",
    "    class_weights_tensor = torch.tensor(class_weights, dtype=torch.float32)\n",
    "    class_weights_tensor = class_weights_tensor.to(dtype=torch.float32, device=device)\n",
    "    \n",
    "    # Conversione delle etichette in interi\n",
    "    y_train = y_train.astype(int)\n",
    "    y_val = y_val.astype(int)\n",
    "    y_test = y_test.astype(int)\n",
    "    \n",
    "    # Conversione dei dati in tensori PyTorch con permutazione se necessario\n",
    "    #if model_type == \"CNN2D\":\n",
    "    \n",
    "    if model_type == 'CNN2D_LSTM_TF':\n",
    "        \n",
    "        X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "        X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "        X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "    \n",
    "    #BiLSTM (ReadMEndYou):\n",
    "    #Ora il modello si aspetta l’input con shape (batch, canali, frequenze, tempo) \n",
    "    #e, al suo interno, \n",
    "    #esegue la permutazione per avere il tempo come dimensione sequenziale. \n",
    "    #Non serve quindi applicare una permutazione anche qui.\n",
    "    \n",
    "    elif model_type == \"BiLSTM\":\n",
    "            \n",
    "        X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "        X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "        X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "    \n",
    "    #Transformer (ReadMYMind):\n",
    "    #Analogamente, il modello gestisce internamente la riorganizzazione dell’input, quindi lasciamo i dati nella loro forma originale.\n",
    "    elif model_type == \"Transformer\":\n",
    "        X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "        X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "        X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(\"Modello non riconosciuto. Scegli tra 'CNN', 'BiLSTM' o 'Transformer'.\")\n",
    "    \n",
    "    # Conversione delle etichette in tensori\n",
    "    y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "    y_val_tensor = torch.tensor(y_val, dtype=torch.long)\n",
    "    y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "    \n",
    "    # Creazione dei dataset\n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "    test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "    \n",
    "    # Creazione dei dataloader\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    return train_loader, val_loader, test_loader, class_weights_tensor\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "OLD VERSIONS BEFORE GRADCAM COMPUTATION ON CNN2D\n",
    "\n",
    "# Funzione per determinare a quale subfolder appartiene la chiave\n",
    "def get_subfolder_from_key(key, model_standardization):\n",
    "    \n",
    "    #DEFINIZIONE DELLA PATH DOVE VIENE SALVATO IL FILE\n",
    "    if '_familiar_th' in key:\n",
    "        return 'th_fam'\n",
    "    elif '_unfamiliar_th' in key:\n",
    "        return 'th_unfam'\n",
    "    elif '_familiar_pt' in key:\n",
    "        return 'pt_fam'\n",
    "    elif '_unfamiliar_pt' in key:\n",
    "        return 'pt_unfam'\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "     \n",
    "# Funzione per salvare i risultati\n",
    "def save_performance_results(model_name, my_train_results, my_test_results, key, exp_cond, model_standardization, base_folder):\n",
    "    \"\"\"\n",
    "    Funzione che salva i risultati del modello in base alla combinazione di 'key' e 'model_name'.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Identificazione del subfolder in base alla chiave\n",
    "    subfolder = get_subfolder_from_key(key, model_standardization)\n",
    "    \n",
    "    # Debug: controllo sulla subfolder\n",
    "    print(f\"\\nDEBUG - Chiave: \\033[1m{key}\\033[0m, Subfolder ottenuto: \\033[1m{subfolder}\\033[0m\")\n",
    "    \n",
    "    if subfolder is None:\n",
    "        print(f\"Errore: La chiave \\033[1m{key}\\033[0m non corrisponde a nessun subfolder valido.\\n\")\n",
    "        return\n",
    "    \n",
    "    # Determinazione del tipo di dato direttamente dalla chiave\n",
    "    if \"spectrograms\" in key:\n",
    "        data_type_str = \"spectrograms\"\n",
    "    else:\n",
    "        print(f\"Errore: Tipo di dato non riconosciuto nella chiave '{key}'.\")\n",
    "        return\n",
    "\n",
    "    # Creazione del nome del file con l'inclusione della combinazione key + model_name\n",
    "    if model_standardization:\n",
    "        file_name = f\"{model_name}_performances_{exp_cond}_{data_type_str}_{subfolder}_std.pkl\"\n",
    "        folder_path = os.path.join(base_folder, exp_cond, data_type_str, subfolder)\n",
    "        \n",
    "    else:\n",
    "        file_name = f\"{model_name}_performances_{exp_cond}_{data_type_str}_{subfolder}.pkl\"\n",
    "        folder_path = os.path.join(base_folder, exp_cond, data_type_str, subfolder)\n",
    "    \n",
    "    # Verifica se la cartella di destinazione esiste, altrimenti creala\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "    \n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "    # Creazione del dizionario con i risultati\n",
    "    results_dict = {\n",
    "        \n",
    "        'my_train_results': my_train_results,\n",
    "        'my_test_results': my_test_results\n",
    "    }\n",
    "\n",
    "    # Salvataggio del dizionario con i risultati\n",
    "    try:\n",
    "        with open(file_path, 'wb') as f:\n",
    "            pickle.dump(results_dict, f)\n",
    "        print(f\"\\nRisultati salvati con successo 👍 in: \\n\\033[1m{file_path}\\033[0m\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌Errore durante il salvataggio dei risultati: {e}\")\n",
    "'''\n",
    "\n",
    "\n",
    "#NEW VERSIONS FOR SPECTROGRAMS WITH GRADCAM COMPUTATION ON CNN2D!\n",
    "\n",
    "# Funzione per determinare a quale subfolder appartiene la chiave\n",
    "def get_subfolder_from_key(key, model_standardization):\n",
    "    \n",
    "    #DEFINIZIONE DELLA PATH DOVE VIENE SALVATO IL FILE\n",
    "    if '_familiar_th' in key:\n",
    "        return 'th_fam'\n",
    "    elif '_unfamiliar_th' in key:\n",
    "        return 'th_unfam'\n",
    "    elif '_familiar_pt' in key:\n",
    "        return 'pt_fam'\n",
    "    elif '_unfamiliar_pt' in key:\n",
    "        return 'pt_unfam'\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "import io\n",
    "import pickle\n",
    "import os\n",
    "     \n",
    "# Funzione per salvare i risultati\n",
    "def save_performance_results(model_name, \n",
    "                             my_train_results,\n",
    "                             my_test_results, \n",
    "                             key,\n",
    "                             exp_cond,\n",
    "                             model_standardization,\n",
    "                             base_folder,\n",
    "                             gradcam_image = None):\n",
    "    \"\"\"\n",
    "    Funzione che salva i risultati del modello in base alla combinazione di 'key' e 'model_name'.\n",
    "    Se gradcam_image è fornita, la salva anche in formato PNG con un nome che inizia con 'GradCAM_results'.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Identificazione del subfolder in base alla chiave\n",
    "    subfolder = get_subfolder_from_key(key, model_standardization)\n",
    "    \n",
    "    # Debug: controllo sulla subfolder\n",
    "    print(f\"\\nDEBUG - Chiave: \\033[1m{key}\\033[0m, Subfolder ottenuto: \\033[1m{subfolder}\\033[0m\")\n",
    "    \n",
    "    if subfolder is None:\n",
    "        print(f\"Errore: La chiave \\033[1m{key}\\033[0m non corrisponde a nessun subfolder valido.\\n\")\n",
    "        return\n",
    "    \n",
    "    # Determinazione del tipo di dato direttamente dalla chiave\n",
    "    if \"spectrograms\" in key:\n",
    "        data_type_str = \"spectrograms\"\n",
    "    else:\n",
    "        print(f\"Errore: Tipo di dato non riconosciuto nella chiave '{key}'.\")\n",
    "        return\n",
    "\n",
    "    # Creazione del nome del file pickle con l'inclusione della combinazione key + model_name\n",
    "    if model_standardization:\n",
    "        file_name = f\"{model_name}_performances_{exp_cond}_{data_type_str}_{subfolder}_std.pkl\"\n",
    "        folder_path = os.path.join(base_folder, exp_cond, data_type_str, subfolder)\n",
    "    else:\n",
    "        file_name = f\"{model_name}_performances_{exp_cond}_{data_type_str}_{subfolder}.pkl\"\n",
    "        folder_path = os.path.join(base_folder, exp_cond, data_type_str, subfolder)\n",
    "    \n",
    "    # Verifica se la cartella di destinazione esiste, altrimenti creala\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "    \n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "    # Creazione del dizionario con i risultati\n",
    "    results_dict = {\n",
    "        'my_train_results': my_train_results,\n",
    "        'my_test_results': my_test_results\n",
    "    }\n",
    "\n",
    "    # Salvataggio del dizionario con i risultati\n",
    "    try:\n",
    "        with open(file_path, 'wb') as f:\n",
    "            pickle.dump(results_dict, f)\n",
    "        print(f\"\\n🔬Risultati salvati con successo 👍 in: \\n\\033[1m{file_path}\\033[0m\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌Errore durante il salvataggio dei risultati: {e}\")\n",
    "    \n",
    "    # Se è stata fornita l'immagine GradCAM, salvala come file PNG\n",
    "    if gradcam_image is not None:\n",
    "        if model_standardization:\n",
    "            gradcam_file_name = f\"GradCAM_results_{model_name}_{exp_cond}_{data_type_str}_{subfolder}_std.png\"\n",
    "        else:\n",
    "            gradcam_file_name = f\"GradCAM_results_{model_name}_{exp_cond}_{data_type_str}_{subfolder}.png\"\n",
    "        \n",
    "        gradcam_file_path = os.path.join(folder_path, gradcam_file_name)\n",
    "        \n",
    "        #try:\n",
    "        #    with open(gradcam_file_path, \"wb\") as f_img:\n",
    "        #        f_img.write(gradcam_image)\n",
    "        #    print(f\"\\n📸Immagine GradCAM salvata con successo 👍 in: \\n\\033[1m{gradcam_file_path}\\033[0m\\n\")\n",
    "        \n",
    "        try:\n",
    "            \n",
    "            '''\n",
    "            Se gradcam_image è un oggetto BytesIO, allora rappresenta un flusso di dati binari in memoria.\n",
    "            Quando si leggono dati da un BytesIO, il cursore interno avanza come in un file normale. \n",
    "            Se il cursore non è all'inizio, Image.open() potrebbe non leggere correttamente l'immagine.\n",
    "            👉 seek(0) riporta il cursore all'inizio del buffer prima di leggerlo con Image.open()\n",
    "            \n",
    "            Per maggior info leggi cella successiva!\n",
    "            '''\n",
    "            \n",
    "            # 🔄 Se gradcam_image è un buffer, convertirlo in immagine PIL\n",
    "            if isinstance(gradcam_image, io.BytesIO):\n",
    "                gradcam_image.seek(0)  # 🔄 Reset puntatore del buffer\n",
    "                gradcam_image = Image.open(gradcam_image)\n",
    "            \n",
    "            '''\n",
    "            Il messaggio di errore indica che il tuo oggetto gradcam_image è di tipo bytes e non ha il metodo save(), \n",
    "            che è tipico di un oggetto PIL. \n",
    "            \n",
    "            Per risolvere questo, devi convertire i byte in un'immagine PIL. \n",
    "            Per farlo, controlla se gradcam_image sia un oggetto di tipo bytes e,\n",
    "            in tal caso, usa io.BytesIO per creare un buffer da passare a Image.open(). \n",
    "            \n",
    "            Inserisci questa conversione all'interno del blocco che salva l'immagine, così da assicurarti che,\n",
    "            indipendentemente dal tipo, gradcam_image diventi un oggetto PIL e possa chiamare il metodo save().\n",
    "            '''\n",
    "            \n",
    "            if isinstance(gradcam_image, bytes):\n",
    "                gradcam_image = io.BytesIO(gradcam_image)\n",
    "                gradcam_image.seek(0)\n",
    "                gradcam_image = Image.open(gradcam_image)\n",
    "            \n",
    "            \n",
    "            print(f\"\\n📸Immagine \\033[1mGradCAM salvata\\033[0m con successo 👍 in: \\n\\033[1m{gradcam_file_path}\\033[0m\\n\")\n",
    "            # 🔄 Salvare l'immagine nel percorso specificato\n",
    "            gradcam_image.save(gradcam_file_path, format = \"PNG\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌Errore durante il salvataggio dell'immagine GradCAM: {e}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7199a08f-6bdb-4428-ace4-6aee6ce97c2f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "Quando si parla di buffer o file, immagina che ci sia un piccolo cursore invisibile che tiene traccia di dove ci troviamo nella lettura/scrittura.\n",
    "\n",
    "📌 Cos'è il cursore di un file o buffer?\n",
    "Il cursore interno è un puntatore che indica la posizione attuale nel file (o buffer).\n",
    "\n",
    "Quando scrivi dati, il cursore avanza alla fine di ciò che hai scritto.\n",
    "Quando leggi, il cursore avanza man mano che scorri i dati.\n",
    "Se tenti di leggere senza riportare il cursore all'inizio, potresti ottenere dati incompleti o un errore.\n",
    "📌 Esempio con un file\n",
    "Immagina un file di testo chiamato esempio.txt con questo contenuto:\n",
    "\n",
    "Copia\n",
    "Modifica\n",
    "Ciao, come stai?\n",
    "Ora vediamo cosa succede quando lo leggiamo:\n",
    "\n",
    "python\n",
    "Copia\n",
    "Modifica\n",
    "# Apriamo il file in modalità lettura\n",
    "with open(\"esempio.txt\", \"r\") as f:\n",
    "    print(f.read())  # ✅ Leggiamo tutto -> \"Ciao, come stai?\"\n",
    "    \n",
    "    print(f.read())  # ❌ Ora il cursore è alla fine -> \"\" (stringa vuota!)\n",
    "Il secondo read() non restituisce nulla perché il cursore è già alla fine del file.\n",
    "Per rileggere il file dobbiamo spostare il cursore all'inizio con seek(0):\n",
    "\n",
    "python\n",
    "Copia\n",
    "Modifica\n",
    "with open(\"esempio.txt\", \"r\") as f:\n",
    "    print(f.read())  # ✅ Legge tutto -> \"Ciao, come stai?\"\n",
    "    \n",
    "    f.seek(0)  # 🔄 Riporta il cursore all'inizio\n",
    "    \n",
    "    print(f.read())  # ✅ Ora rilegge tutto -> \"Ciao, come stai?\"\n",
    "📌 Esempio con BytesIO (buffer in memoria)\n",
    "Un BytesIO funziona come un file, ma è in RAM. Vediamo cosa succede senza seek(0):\n",
    "\n",
    "python\n",
    "Copia\n",
    "Modifica\n",
    "import io\n",
    "\n",
    "# Creiamo un buffer\n",
    "buffer = io.BytesIO()\n",
    "buffer.write(b\"Ciao, come stai?\")  # ✍️ Scriviamo qualcosa\n",
    "\n",
    "print(buffer.read())  # ❌ \"\" perché il cursore è alla fine!\n",
    "\n",
    "buffer.seek(0)  # 🔄 Riportiamo il cursore all'inizio\n",
    "print(buffer.read())  # ✅ \"Ciao, come stai?\"\n",
    "📌 Applicazione al tuo codice GradCAM\n",
    "Nel tuo caso, la sequenza è questa:\n",
    "\n",
    "1️⃣ Crei un BytesIO()\n",
    "2️⃣ Salvi l'immagine nel buffer → il cursore ora è alla fine\n",
    "3️⃣ Per poterla leggere con Image.open(), devi riportarlo all'inizio con seek(0)\n",
    "\n",
    "python\n",
    "Copia\n",
    "Modifica\n",
    "buf = io.BytesIO()\n",
    "plt.savefig(buf, format='png')  # ✍️ Salvataggio avanza il cursore\n",
    "buf.seek(0)  # 🔄 Riporta il cursore all'inizio per poterlo leggere\n",
    "fig_image = buf.getvalue()  # Ora possiamo leggere i byte correttamente!\n",
    "buf.close()\n",
    "E quando passi il buffer a save_performance_results, devi ripetere il seek(0) prima di aprirlo con Image.open().\n",
    "\n",
    "💡 Conclusione:\n",
    "Il cursore è come un segnalibro in un file o buffer. Se non lo riporti all'inizio, leggere i dati successivamente potrebbe fallire! 🚀"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6b92b7-d80c-4633-b3c9-4b72a48c9de0",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### **NUOVE UTILS DATI NON HYPER POST W&B**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154cb75c-ba7d-45ff-b0ee-965570e51f38",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "###### **IMPLEMENTAZIONE ADOTTATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab32858-bcc5-46de-891a-b3a84aef1273",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Parsing della chiave e costruzione del path:\n",
    "Usando la funzione parse_combination_key si estraggono \n",
    "\n",
    "exp_cond, data_type e category_subject dalla chiave del dataset. \n",
    "\n",
    "Questi vengono usati per costruire il percorso in cui cercare i file .pkl.\n",
    "'''\n",
    "import re \n",
    "\n",
    "# Funzione per parsare la chiave\n",
    "def parse_combination_key(combination_key):\n",
    "    \"\"\"\n",
    "    Estrae (exp_cond, data_type, category_subject) da combination_key.\n",
    "    Il formato atteso è:\n",
    "    \"th_resp_vs_pt_resp|pt_resp_vs_shared_resp|th_resp_vs_shared_resp\" _ \n",
    "    \"1_20|1_45|wavelet\" _ \n",
    "    \"familiar_th|familiar_pt|unfamiliar_th|unfamiliar_pt\"\n",
    "    \"\"\"\n",
    "    match = re.match(\n",
    "        #r\"^(th_resp_vs_pt_resp|pt_resp_vs_shared_resp|th_resp_vs_shared_resp)_(spectrograms)_(familiar_th|familiar_pt|unfamiliar_th|unfamiliar_pt)$\", \n",
    "        #r\"^(rest_vs_left_fist|rest_vs_right_fist|left_fist_vs_right_fist)_spectrograms_(familiar_th|familiar_pt|unfamiliar_th|unfamiliar_pt)$\",\n",
    "        r\"^(rest_vs_left_fist|rest_vs_right_fist|left_fist_vs_right_fist)_(spectrograms)_(familiar_th|familiar_pt|unfamiliar_th|unfamiliar_pt)$\",\n",
    "        combination_key\n",
    "    )\n",
    "    if match:\n",
    "        return match.groups()  # (exp_cond, data_type, category_subject)\n",
    "    else:\n",
    "        raise ValueError(f\"Formato non valido: {combination_key}\")\n",
    "        \n",
    "\n",
    "'''CELLA DI ESEMPIO PER VERIFICARE SE QUESTA FUNZIONE FACESSE IL PARSING DELLE STRINGHE DELLE COMBINAZIONI DI FATTORI CORRETTAMENTE'''\n",
    "\n",
    "# Test\n",
    "combination_key = \"rest_vs_left_fist_spectrograms_familiar_th\"\n",
    "condition_experiment, data_type, subject_key = parse_combination_key(combination_key)\n",
    "\n",
    "print(\"Condizione:\", condition_experiment)\n",
    "print(\"Data Type:\", data_type)\n",
    "print(\"Soggetto:\", subject_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8b576c-ebc4-4c7f-9740-380b28b2b98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Verifica del file .pkl:\n",
    "La funzione load_config_if_available cerca, per ogni modello, il file con nome del tipo\n",
    "\"{model_name}_{exp_cond}_{data_type}_{category_subject}.pkl\"\n",
    "all’interno della struttura di cartelle basata su base_path. \n",
    "\n",
    "Se il file esiste, allora viene passata poi a load_model_config_and_weights, \n",
    "che carica il dizionario di partenza \n",
    "e da questo estrae i 2 sotto-dizionari 'config' e 'state_dict'.\n",
    "'''\n",
    "\n",
    "def load_config_if_available(dataset_key, model_name, base_path):\n",
    "    \"\"\"\n",
    "    Data una chiave (es. \"th_resp_vs_pt_resp_wavelet_familiar_th\") e il nome del modello,\n",
    "    cerca il file .pkl corrispondente e ritorna (config, state_dict).\n",
    "    Se non esiste, restituisce (None, None).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        exp_cond, data_type, category_subject = parse_combination_key(dataset_key)\n",
    "        config, state_dict = load_model_config_and_weights(exp_cond, data_type, category_subject, model_name, base_path)\n",
    "        print(f\"✅ File .pkl trovato per \\033[1m{model_name}\\033[0m su \\033[1m{dataset_key}\\033[0m\")\n",
    "        \n",
    "        return config, state_dict\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Nessun file .pkl per {model_name} su {dataset_key} - uso parametri di default. ({e})\")\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84248cda-ff35-406f-81fc-8b795c6725f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Caricamento del file .pkl:\n",
    "La funzione load_model_config_and_weights cerca, per ogni modello, il file con nome del tipo\n",
    "\"{model_name}_{exp_cond}_{data_type}_{category_subject}.pkl\"\n",
    "all’interno della struttura di cartelle basata su base_path. Se il file esiste, vengono restituiti config e state_dict.\n",
    "'''\n",
    "\n",
    "# Funzione per caricare il file .pkl con la configurazione e i pesi ottimali\n",
    "def load_model_config_and_weights(exp_cond, data_type, category_subject, model_name, base_path):\n",
    "    \"\"\"\n",
    "    Costruisce il path usando:\n",
    "        base_path / exp_cond / data_type / category_subject\n",
    "    e il nome del file:\n",
    "        {model_name}_{exp_cond}_{data_type}_{category_subject}.pkl\n",
    "    Se il file esiste, lo carica e restituisce (config, state_dict).\n",
    "    \"\"\"\n",
    "    \n",
    "    file_name = f\"{model_name}_{exp_cond}_{data_type}_{category_subject}.pkl\"\n",
    "    file_path = os.path.join(base_path, exp_cond, data_type, category_subject, file_name)\n",
    "    \n",
    "    if os.path.exists(file_path):\n",
    "        print(f\"🕵️‍♂️🔍Caricamento file .pkl: \\033[1m{file_path}\\033[0m\")\n",
    "        \n",
    "        # Il file .pkl è stato salvato con torch.save() e contiene un dizionario con chiavi al suo interno che sono: \"config\" e \"state_dict\"\n",
    "        with open(file_path, \"rb\") as f:\n",
    "            data = torch.load(f)\n",
    "        return data[\"config\"], data[\"state_dict\"]\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"File {file_path} non trovato.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c701fd2d-a6fc-4fc9-aa52-b4707c1cfc70",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### **TRAINING (NON DEVI ESEGUIRLA VAI DIRETTAMENTE AL TESTING!)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c38e80-1a70-4e04-bd3b-f9bde1673eaf",
   "metadata": {
    "tags": []
   },
   "source": [
    "###### **VERSIONE POST- WEIGHT AND BIASES (W&B)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7864c7-ee39-4aef-86df-d4d02341f15f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''UFFICIALE - VERSIONE POST- WEIGHT AND BIASES SENZA COMMENTI'''\n",
    "\n",
    "\n",
    "import io\n",
    "from PIL import Image\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience = 10, min_delta = 0.001, mode = 'max'):\n",
    "        \n",
    "            \n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.mode = mode\n",
    "        self.best_score = None # Tiene traccia del miglior punteggio osservato\n",
    "        self.counter = 0 # Conta quante epoche consecutive non migliorano\n",
    "        self.early_stop = False # Flag che indica se attivare l'early stopping\n",
    "        \n",
    "        #Ogni volta che si chiama la classe con early_stopping(current_score), controlla se il modello sta migliorando o meno.\n",
    "\n",
    "    def __call__(self, current_score):\n",
    "        \n",
    "        #Caso 1: Prima iterazione (best_score ancora None)\n",
    "        #→ Se non esiste ancora un miglior punteggio, lo inizializza con il primo valore ricevuto.\n",
    "        \n",
    "        if self.best_score is None:\n",
    "            self.best_score = current_score\n",
    "            \n",
    "        #Caso 2: Il modello migliora\n",
    "        #→ Se il valore migliora di almeno min_delta, aggiorna best_score e resetta il contatore.\n",
    "\n",
    "        elif (self.mode == 'min' and current_score < self.best_score - self.min_delta) or \\\n",
    "             (self.mode == 'max' and current_score > self.best_score + self.min_delta):\n",
    "            self.best_score = current_score\n",
    "            self.counter = 0  # Reset contatore se migliora\n",
    "            \n",
    "        #Caso 3: Il modello NON migliora\n",
    "        \n",
    "        #→ Se il valore non migliora, incrementa il contatore.\n",
    "        #→ Se il contatore raggiunge patience, imposta early_stop = True, segnalando che il training deve essere interrotto.\n",
    "        \n",
    "        else:\n",
    "            self.counter += 1  # Incrementa se non migliora\n",
    "            if self.counter >= self.patience:\n",
    "                print(f\"🛑 Early stopping attivato! Nessun miglioramento per {self.patience} epoche consecutive.\")\n",
    "                self.early_stop = True\n",
    "                \n",
    "\n",
    "def plot_training_results(loss_train_history, loss_val_history, accuracy_train_history, accuracy_val_history):\n",
    "    \n",
    "    '''\n",
    "    # Creazione di una figura con 2 subplot\n",
    "    fig, ax = plt.subplots(2, 1, figsize=(10, 8))  # 2 righe, 1 colonna, dimensione figura\n",
    "\n",
    "    # Plot della loss\n",
    "    ax[0].plot(loss_train_history, label='Train Loss', color='blue')\n",
    "    ax[0].plot(loss_val_history, label='Validation Loss', color='orange')\n",
    "    #ax[0].set_title(f'Loss during Training: {exp_cond_1} vs {exp_cond_2}', fontsize=16)  # Titolo più grande\n",
    "    ax[0].set_title(f'Loss during Training: ', fontsize=12)  # Titolo più grande\n",
    "    ax[0].set_xlabel('Epochs', fontsize=12)  # Dimensione font asse x\n",
    "    ax[0].set_ylabel('Loss', fontsize=12)    # Dimensione font asse y\n",
    "    ax[0].legend(fontsize=12)  # Dimensione font legenda\n",
    "    ax[0].grid(True)\n",
    "\n",
    "    # Plot dell'accuracy\n",
    "    ax[1].plot(accuracy_train_history, label='Train Accuracy', color='blue')\n",
    "    ax[1].plot(accuracy_val_history, label='Validation Accuracy', color='orange')\n",
    "    #ax[1].set_title(f'Accuracy during Training: {exp_cond_1} vs {exp_cond_2}', fontsize=16)  # Titolo più grande\n",
    "    ax[1].set_title(f'Accuracy during Training: ', fontsize=12)  # Titolo più grande\n",
    "    ax[1].set_xlabel('Epochs', fontsize=12)  # Dimensione font asse x\n",
    "    ax[1].set_ylabel('Accuracy', fontsize=12)  # Dimensione font asse y\n",
    "    ax[1].legend(fontsize=12)  # Dimensione font legenda\n",
    "    ax[1].grid(True)\n",
    "    \n",
    "    # Regolare la spaziatura tra i subplot\n",
    "    #plt.tight_layout()  # Alternativa: fig.subplots_adjust(hspace=0.3)\n",
    "    '''\n",
    "    \n",
    "    # Salvare il plot in un buffer di memoria\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='png')  # Salviamo il plot in formato PNG\n",
    "    buf.seek(0)  # Torniamo all'inizio del buffer\n",
    "\n",
    "    # Convertire il buffer in un'immagine PIL (opzionale, per visualizzarla)\n",
    "    img = Image.open(buf)\n",
    "\n",
    "    # Aggiungere i dati dell'immagine nel dizionario\n",
    "    plot_image_data = buf.getvalue()  # Otteniamo i dati binari dell'immagine\n",
    "    buf.close()\n",
    "\n",
    "    # Ritorniamo i dati dell'immagine da salvare nel dizionario\n",
    "    return plot_image_data\n",
    "\n",
    "\n",
    "\n",
    "def training(model, dataset_train_loader, dataset_val_loader, optimizer, criterion, n_epochs = 100, patience = 12):\n",
    "    \n",
    "    # Sposta il modello sulla GPU (se disponibile)\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    model.to(device)\n",
    "    \n",
    "    #Setta il modello in fase di training\n",
    "    model.train()\n",
    "    \n",
    "    # Storico delle metriche per ogni epoca\n",
    "    loss_train_history = []  # History of Training loss\n",
    "    loss_val_history = []    # History of Validation loss\n",
    "    accuracy_train_history = []  # History of Training Accuracy\n",
    "    accuracy_val_history = []    # History of Validation Accuracy\n",
    "    \n",
    "    '''OLD VERSION'''\n",
    "    #early_stopping = EarlyStopping(patience=patience, mode='max')\n",
    "    \n",
    "    '''NEW VERSION'''\n",
    "    # -- Early stopping su val_loss --\n",
    "    early_stopping = EarlyStopping(patience=patience, mode='min')\n",
    "    \n",
    "    # Liste per le metriche di valutazione (precision, recall, F1, AUC)\n",
    "    precision_train_history = []\n",
    "    recall_train_history = []\n",
    "    f1_train_history = []\n",
    "    auc_train_history = []\n",
    "    \n",
    "    #Questa sarebbe la migliore accuratezza ottenuta sul validation set\n",
    "    #in base alla quale viene preso il modello migliore!\n",
    "    \n",
    "    max_val_acc = 0\n",
    "    best_model = None\n",
    "    \n",
    "    best_epoch = 0  # Epoca con la migliore validazione\n",
    "    \n",
    "    best_metrics = {} # Dizionario con le metriche del migliore modello nel set di validazione\n",
    "    \n",
    "    # Variabili per memorizzare le etichette vere e predette per l'intero training\n",
    "    y_true_train_list = []\n",
    "    y_pred_train_list = []\n",
    "    \n",
    "    \n",
    "    pbar = tqdm(range(n_epochs))\n",
    "\n",
    "    for epoch in pbar:\n",
    "        \n",
    "        #Create a list for temporary monitoring of train loss and accuracy at each epoch\n",
    "        train_loss_tmp = [] \n",
    "        correct_train = 0 \n",
    "        \n",
    "        \n",
    "        #'''STARTING OF THE TRAINING PHASE'''\n",
    "        \n",
    "        #Iterating for every batch inside dataset_train_loader\n",
    "        for x, y in dataset_train_loader:\n",
    "            \n",
    "            x, y = x.to(device), y.to(device)\n",
    "            \n",
    "            #Run forward pass through my network and get a prediction\n",
    "            y_pred = model(x)\n",
    "            \n",
    "            train_loss = criterion(y_pred, y.view(-1))\n",
    "            optimizer.zero_grad() #so essentially finding where gradients is 0\n",
    "                                  #we're looking for minimum's there\n",
    "\n",
    "            train_loss.backward() #performing the backprop step\n",
    "            optimizer.step() #update the model's hyperparameters based off of the step\n",
    "        \n",
    "            train_loss_tmp.append(train_loss.item()) #append the loss at each epoch in the temporary train loss list inside each epoch\n",
    "            \n",
    "            # Calculate the Accuracy Score during the Training Phase\n",
    "                \n",
    "            #qui il \"_,\"\n",
    "            _, predicted_train = torch.max(y_pred, 1)\n",
    "            correct_train += (predicted_train == y).sum().item()\n",
    "            \n",
    "            # Aggiungere le etichette vere e quelle predette alla lista\n",
    "            y_true_train_list.extend(y.cpu().numpy())\n",
    "            y_pred_train_list.extend(predicted_train.cpu().numpy())\n",
    "        \n",
    "        # Save the results of training set for every epoch\n",
    "        \n",
    "        #i.e., append the results in the whole train loss history list outside the cycle of each epoch \n",
    "        loss_train_history.append(np.mean(train_loss_tmp))\n",
    "        accuracy_train = correct_train / len(dataset_train_loader.dataset)\n",
    "        accuracy_train_history.append(accuracy_train)\n",
    "        \n",
    "        # Calcolare precision, recall, F1-score e AUC durante il training\n",
    "        precision_train = precision_score(y_true_train_list, y_pred_train_list, average='weighted')\n",
    "        recall_train = recall_score(y_true_train_list, y_pred_train_list, average='weighted')\n",
    "        f1_train = f1_score(y_true_train_list, y_pred_train_list, average='weighted')\n",
    "        auc_train = roc_auc_score(y_true_train_list, y_pred_train_list, average='weighted')\n",
    "        \n",
    "        precision_train_history.append(precision_train)\n",
    "        recall_train_history.append(recall_train)\n",
    "        f1_train_history.append(f1_train)\n",
    "        auc_train_history.append(auc_train)\n",
    "        \n",
    "        # '''STARTING OF THE VALIDATION PHASE'''\n",
    "        \n",
    "        #Setta il modello in fase di validation\n",
    "        #model.eval() \n",
    "        \n",
    "        loss_tmp_val = []  #create a list for temporary val list at each epoch\n",
    "        correct_val = 0\n",
    "        \n",
    "        y_true_list = []\n",
    "        y_pred_list = []\n",
    "        \n",
    "        #Here we disable gradient computation for the validation phase!\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            for x, y in dataset_val_loader:\n",
    "                \n",
    "                x, y = x.to(device), y.to(device)\n",
    "                \n",
    "                #Run forward pass through my network and get a prediction\n",
    "                y_pred = model(x)\n",
    "\n",
    "                #Calculate Validation Loss\n",
    "\n",
    "                #remember: since we use CrossEntropyLoss we DO NOT need\n",
    "                #to do any ONE HOT ENCODING between y_pred and y_train \n",
    "                \n",
    "                #loss = criterion(y_pred.to(device), y.view(-1).to(device))\n",
    "                \n",
    "                val_loss = criterion(y_pred, y.view(-1))\n",
    "\n",
    "                #Perform Backpropagation\n",
    "\n",
    "                #HOW TO ADJUST THE VALUES (weights and biases)?\n",
    "                #well, at every step the gradients will accumulate with every backprop,\n",
    "                #so to prevent 'compounding', we need to reset the stored gradient for each new epoch!\n",
    "\n",
    "                loss_tmp_val.append(val_loss.item()) #append the loss at each epoch in the temporary val loss list inside each epoch \n",
    "                \n",
    "                # Calculate the Accuracy Score during the Validation Phase\n",
    "                _, predicted_val = torch.max(y_pred, 1)\n",
    "                correct_val += (predicted_val == y).sum().item()\n",
    "                \n",
    "                # Aggiungi le etichette e le predizioni per la confusion matrix\n",
    "                y_true_list.extend(y.cpu().numpy())\n",
    "                y_pred_list.extend(predicted_val.cpu().numpy())\n",
    "\n",
    "                \n",
    "        # Save the results of validation set for every epoch\n",
    "        \n",
    "        #i.e., append the results in the whole train loss history list outside the cycle of each epoch \n",
    "        \n",
    "        loss_val_history.append(np.mean(loss_tmp_val)) \n",
    "        accuracy_val = correct_val / len(dataset_val_loader.dataset)\n",
    "        accuracy_val_history.append(accuracy_val)\n",
    "        \n",
    "        #L'early stopping deve essere basato sulla val accuracy,\n",
    "        #ma quando il training si interrompe, \n",
    "        #dobbiamo salvare le migliori performance ottenute sul training in corrispondenza dell'epoca in cui\n",
    "        #la val accuracy era massima\n",
    "        \n",
    "        # Controllo della miglior validazione\n",
    "        if accuracy_val > max_val_acc:\n",
    "            max_val_acc = accuracy_val\n",
    "            best_epoch = epoch\n",
    "            \n",
    "            best_metrics = {\n",
    "                \"train_loss\": [round(loss_train_history[best_epoch], 4)],\n",
    "                \"train_accuracy\": [round(accuracy_train_history[best_epoch], 4)],\n",
    "                \"train_precision\": [round(precision_train, 4)],\n",
    "                \"train_recall\": [round(recall_train, 4)],\n",
    "                \"train_f1_score\": [round(f1_train, 4)],\n",
    "                \"train_auc\": [round(auc_train, 4)]\n",
    "            }\n",
    "            best_model = cp.deepcopy(model)  # Salvo il miglior modello\n",
    "\n",
    "        # Controllo Early Stopping\n",
    "        early_stopping(accuracy_val)\n",
    "        if early_stopping.early_stop:\n",
    "            print(f\"⚠️ Early stopping attivato all'epoca \\033[1m{epoch}\\033[0m, recupero il modello dell'epoca \\033[1m{best_epoch}\\033[0m\")\n",
    "            break\n",
    "\n",
    "        # Update of the progress bar\n",
    "        pbar.set_description(f\"Epoch {epoch+1}/{n_epochs}, Train Loss: {loss_train_history[-1]:.4f}, Val Loss: {loss_val_history[-1]:.4f}, Train Acc: {accuracy_train:.4f}, Val Acc: {accuracy_val:.4f}\")\n",
    "\n",
    "        # Calculate the confusion matrix and the classification report after all epochs in the Validation Phase\n",
    "        conf_matrix = confusion_matrix(y_true_list, y_pred_list)\n",
    "        class_report = classification_report(y_true_list, y_pred_list)\n",
    "\n",
    "    # Salvataggio della configurazione del modello e iper-parametri\n",
    "    model_config = {\n",
    "        \"model_architecture\": str(model),\n",
    "        \"batch_size_train\": train_loader.batch_size,\n",
    "        \"batch_size_val\": val_loader.batch_size,\n",
    "        \"batch_size_test\": test_loader.batch_size,\n",
    "        \"n_epochs\": n_epochs\n",
    "    }\n",
    "\n",
    "    # Dizionario degli iper-parametri\n",
    "    hyperparams = {\n",
    "    \"optimizer\": str(optimizer),\n",
    "    \"loss_function\": str(criterion),\n",
    "    \"learning_rate\": optimizer.param_groups[0]['lr'],\n",
    "   }\n",
    "\n",
    "    \n",
    "    # Plot dei risultati\n",
    "    #plot_training_results(loss_train_history, loss_val_history, accuracy_train_history, accuracy_val_history, exp_cond_1, exp_cond_2)\n",
    "    training_plot = plot_training_results(loss_train_history, loss_val_history, accuracy_train_history, accuracy_val_history)\n",
    "\n",
    "    \n",
    "    # Restituire tutti i risultati in un dizionario\n",
    "    train_results = {\n",
    "        \"training_performances\": best_metrics,  # Aggiungi il dizionario delle performance\n",
    "        \"loss_train_history\": loss_train_history,\n",
    "        \"loss_val_history\": loss_val_history,\n",
    "        \"accuracy_train_history\": accuracy_train_history,\n",
    "        \"accuracy_val_history\": accuracy_val_history,\n",
    "        \"best_model\": best_model,\n",
    "        \"confusion_matrix_val\": conf_matrix,\n",
    "        \"classification_report\": class_report,\n",
    "        \"model_configuration\": model_config,\n",
    "        \"hyperparameters\": hyperparams,\n",
    "        \"training_plot\": training_plot  # Salviamo il buffer con il plot\n",
    "    }\n",
    "\n",
    "    return train_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944e5341-3bae-4060-a2f3-73b15b445fda",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### **TESTING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485c8759-02e4-4ecd-9c69-8cca32296cf5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "TESTING FUNCTION: CORRETTA ANCHE PER IL GRAD-CAM\n",
    "\n",
    "SUCCESSIVAMENTE, DENTRO AL FOR LOOP DEL TRAINING E TESTING, \n",
    "SI RICHIAMA LA FUNZIONE DIRETTAMENTE DI \n",
    "\n",
    "1) compute_gradcam_figure, LA QUALE AL SUO INTERNO PRESENTA GIÀ \n",
    "TUTTO QUELLO CHE SERVE PER CALCOLARE IL GRADCAM, DI MODO CHE VADA A \n",
    "\n",
    "Selezionare esempi rappresentativi per ciascuna classe.\n",
    "Calcolare le mappe GradCAM e gli overlay.\n",
    "Creare una figura con le heatmap e le sovrapposizioni, completa di titoli esplicativi.\n",
    "Restituire un'immagine (buffer) pronta per essere salvata\n",
    "\n",
    "SUCCESSIVAMENTE, QUINDI, IL PROCEDIMENTO DIVENTA COME SEGUE:\n",
    "\n",
    "1) Si esegue il TESTING, per ottenere le metriche e salvare i risultati (senza GradCAM)\n",
    "\n",
    "2) Nel loop principale di TRAINING & TESTING, se il modello è CNN2D, allora \n",
    "\n",
    " - richiama la funzione 'compute_gradcam_figure', la quale va a\n",
    "    - calcolare le mappe di attivazione e successivamente creo le immagini che gli ho chiesto\n",
    "    - passa l'immagine ottenuta da GradCAM alla funzione 'save_performance_results', la quale va a \n",
    "        - salvare i risultati di test ottenuti dalla funzione di 'testing'\n",
    "        - salvare l'immagine risultatante del GradCAM e la sovrapposizione del GradCAM sullo spettrogramma originale della classe risultante\n",
    "        \n",
    "        \n",
    "Questo approccio garantisce chiarezza e separa la parte di performance (testing) dalla parte di explainability (GradCAM).\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import io\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "\n",
    "def testing(results, test_loader, criterion):\n",
    "    \n",
    "    # Recupera il miglior modello ottenuto durante la validazione\n",
    "    model = results['best_model']\n",
    "    model.to(device)\n",
    "    \n",
    "    model.eval()  # Imposta il modello in modalità valutazione\n",
    "\n",
    "    y_true_list = []  # Lista per salvare le etichette reali\n",
    "    y_pred_list = []  # Lista per salvare le previsioni del modello\n",
    "    \n",
    "    '''AGGIUNTA NUOVA PER CALCOLO AUC-ROC'''\n",
    "    y_score_list = []   # <— Lista per salvare gli score per le probabilità della classe positiva (per auc-roc!)\n",
    "    \n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    test_performances = {\n",
    "        \"test_loss\": [],\n",
    "        \"test_accuracy\": [],\n",
    "        \"test_precision\": [],\n",
    "        \"test_recall\": [],\n",
    "        \"test_f1_score\": [],\n",
    "        \"test_auc\": []\n",
    "    }\n",
    "    \n",
    "\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        pbar = tqdm(test_loader, desc=\"Testing\")\n",
    "        \n",
    "        for inputs, labels in pbar:\n",
    "            \n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # Ottenere le predizioni del modello\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            '''AGGIUNTA NUOVA PER CALCOLO AUC-ROC'''\n",
    "            # aggiungi queste due righe\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            y_score_list.extend(probs[:,1].cpu().numpy())\n",
    "\n",
    "            # Calcolare la loss\n",
    "            test_loss = criterion(outputs, labels)\n",
    "            total_loss += test_loss.item()\n",
    "\n",
    "            # Memorizzare predizioni ed etichette vere\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            y_pred_list.extend(predicted.cpu().numpy())\n",
    "            y_true_list.extend(labels.cpu().numpy())\n",
    "\n",
    "            # Aggiornare il numero di predizioni corrette\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            pbar.set_description(f\"Loss: {test_loss.item():.4f}\")\n",
    "\n",
    "    # Calcolare l'accuratezza complessiva\n",
    "    accuracy = correct / len(test_loader.dataset)\n",
    "    \n",
    "    \n",
    "    # Calcolare precision, recall, F1-score, AUC durante il testing\n",
    "    precision_test = precision_score(y_true_list, y_pred_list, average='weighted')\n",
    "    recall_test = recall_score(y_true_list, y_pred_list, average='weighted')\n",
    "    f1_test = f1_score(y_true_list, y_pred_list, average='weighted')\n",
    "    \n",
    "    '''OLD VERSION'''\n",
    "    #auc_test = roc_auc_score(y_true_list, y_pred_list, average='weighted')  # Assicurati che il problema sia binario o multi-class\n",
    "    \n",
    "    '''AGGIUNTA NUOVA PER CALCOLO AUC-ROC\n",
    "    \n",
    "    In questo modo l’roc_auc_score calcola l’area sotto tutta la curva ROC (tutte le soglie), \n",
    "    invece di valutare un solo punto corrispondente alla soglia 0.5\n",
    "    '''\n",
    "    \n",
    "    #https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html\n",
    "    auc_test = roc_auc_score(y_true_list, y_score_list)\n",
    "\n",
    "\n",
    "    # Aggiungere questi valori nel dizionario delle performance (arrotondando a 4 decimali)\n",
    "    test_performances[\"test_loss\"].append(round(total_loss / len(test_loader), 4))  # Media della loss\n",
    "    test_performances[\"test_accuracy\"].append(round(accuracy, 4))\n",
    "    test_performances[\"test_precision\"].append(round(precision_test, 4))\n",
    "    test_performances[\"test_recall\"].append(round(recall_test, 4))\n",
    "    test_performances[\"test_f1_score\"].append(round(f1_test, 4))\n",
    "    test_performances[\"test_auc\"].append(round(auc_test, 4))\n",
    "    \n",
    "    # Creare la confusion matrix\n",
    "    conf_matrix = confusion_matrix(y_true_list, y_pred_list)\n",
    "    \n",
    "    # Stampare classification report\n",
    "    class_report = classification_report(y_true_list, y_pred_list)\n",
    "\n",
    "    print(f\"\\nTest Accuracy: {accuracy:.4f}\")\n",
    "    print(\"\\nClassification Report:\\n\", class_report)\n",
    "\n",
    "    # Visualizzare la confusion matrix\n",
    "    #plt.figure(figsize=(8, 6))\n",
    "    #sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "    #plt.title(\"Confusion Matrix\")\n",
    "    #plt.xlabel(\"Predicted\")\n",
    "    #plt.ylabel(\"True\")\n",
    "    #plt.show()\n",
    "    \n",
    "    # Salviamo l'immagine della confusion matrix in un buffer\n",
    "    #buf = io.BytesIO()\n",
    "    #plt.savefig(buf, format='png')\n",
    "    #buf.seek(0)\n",
    "    #conf_matrix_image_data = buf.getvalue()\n",
    "    #buf.close()\n",
    "    \n",
    "    \n",
    "    # Salviamo l'immagine della confusion matrix in un buffer\n",
    "    buf = io.BytesIO()\n",
    "    plt.figure(figsize=(8, 6))  # Nuova figura per evitare sovrapposizioni\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.savefig(buf, format='png')  # Salva l'immagine nel buffer\n",
    "    buf.seek(0)  # Torna all'inizio del buffer\n",
    "    conf_matrix_image_data = buf.getvalue()  # Ottieni l'immagine in formato binario\n",
    "    buf.close()  # Chiudi il buffer\n",
    "\n",
    "    # Mostra la confusion matrix (opzionale)\n",
    "    #plt.show()\n",
    "    \n",
    "    # Salvataggio della configurazione del modello e iper-parametri\n",
    "    '''COMMENTATO'''\n",
    "    #model_config = {\n",
    "        #\"model_architecture\": str(model),\n",
    "        #\"batch_size_test\": test_loader.batch_size,\n",
    "    #}\n",
    "    \n",
    "    '''COMMENTATO'''\n",
    "    # Dizionario degli iper-parametri\n",
    "    #hyperparams = {\n",
    "        #\"optimizer\": str(optimizer),\n",
    "        #\"loss_function\": str(criterion),\n",
    "        #\"learning_rate\": optimizer.param_groups[0]['lr'],\n",
    "    #}\n",
    "\n",
    "    \n",
    "    '''COMMENTATO'''\n",
    "    # Restituisci i risultati come dizionario\n",
    "    #test_results = {\n",
    "        #\"test_performances\": test_performances,  # Aggiungi il dizionario delle performance\n",
    "        #\"confusion_matrix\": conf_matrix,\n",
    "        #\"classification_report\": class_report,\n",
    "        #\"model_configuration\": model_config,\n",
    "        #\"hyperparameters\": hyperparams,  # Aggiunti i due nuovi dizionari\n",
    "        #\"confusion_matrix_image\": conf_matrix_image_data,  # Aggiunta l'immagine della confusion matrix\n",
    "    #}\n",
    "    \n",
    "    \n",
    "    # Restituisci i risultati come dizionario\n",
    "    test_results = {\n",
    "        \"test_performances\": test_performances,  # Aggiungi il dizionario delle performance\n",
    "        \"confusion_matrix\": conf_matrix,\n",
    "        \"classification_report\": class_report,\n",
    "        \"confusion_matrix_image\": conf_matrix_image_data,  # Aggiunta l'immagine della confusion matrix\n",
    "    }   \n",
    "        \n",
    "    return test_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55fdfc79-197b-4aa1-b10d-dc428633d0d0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### **CREAZIONE CLASSE GRADCAM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae75027-dba8-4516-b87f-e4bdcbf758e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##### **CREAZIONE CLASSE GRADCAM**\n",
    "\n",
    "'''\n",
    "Creazione della classe GradCAM\n",
    "\n",
    "-----1. Costruttore (init)-----\n",
    "\n",
    "Cosa fa:\n",
    "\n",
    "Salva il modello e il layer target (ad esempio, l'ultimo strato convoluzionale) su cui calcolare le mappe di attivazione.\n",
    "\n",
    "A) Inizializza due variabili, \n",
    "\n",
    "1) self.activations e 2) self.gradients, che verranno usate per memorizzare rispettivamente \n",
    "1) le attivazioni (feature maps) e 2) i gradienti di quel layer\n",
    "\n",
    "B) Registra due hook sul target_layer:\n",
    "\n",
    "1) Forward Hook: Quando il modello effettua la forward pass, viene eseguito save_activation per salvare le attivazioni\n",
    "2) Backward Hook: Durante la backward pass, save_gradient viene chiamato per salvare i gradienti\n",
    "\n",
    "\n",
    "-----2. Hook per Salvare Attivazioni e Gradienti-----\n",
    "\n",
    "B) Save Activation\n",
    "\n",
    "def save_activation(self, module, input, output):\n",
    "    self.activations = output.detach()\n",
    "\n",
    "Cosa fa:\n",
    "\n",
    "Quando viene eseguita la forward pass sul target_layer, questo hook cattura l'output (le attivazioni) del layer.\n",
    "Usa detach() per ottenere una copia dei dati senza il tracking dei gradienti, in modo da non interferire con la retropropagazione.\n",
    "\n",
    "C) Save Gradient\n",
    "\n",
    "def save_gradient(self, module, grad_input, grad_output):\n",
    "    self.gradients = grad_output[0].detach()\n",
    "\n",
    "\n",
    "Cosa fa:\n",
    "\n",
    "Durante la backward pass, questo hook cattura i gradienti che fluiscono attraverso il target_layer.\n",
    "grad_output è una tupla; solitamente il primo elemento contiene i gradienti utili. \n",
    "\n",
    "Anche qui si usa detach() per isolare i dati dai grafi di calcolo.\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class GradCAM:\n",
    "    def __init__(self, model, target_layer):\n",
    "        self.model = model\n",
    "        self.target_layer = target_layer\n",
    "        self.activations = None\n",
    "        self.gradients = None\n",
    "        \n",
    "        # Registra hook per catturare attivazioni e gradienti\n",
    "        self.target_layer.register_forward_hook(self.save_activation)\n",
    "        self.target_layer.register_backward_hook(self.save_gradient)\n",
    "\n",
    "    def save_activation(self, module, input, output):\n",
    "        self.activations = output.detach()\n",
    "\n",
    "    def save_gradient(self, module, grad_input, grad_output):\n",
    "        self.gradients = grad_output[0].detach()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4f21f2ab-1889-4333-b117-2253843c1025",
   "metadata": {
    "tags": []
   },
   "source": [
    "'''\n",
    "Creazione della funzione per generare le immagini associate alla GradCAM compution\n",
    "\n",
    "PRE- FINAL VERSION WITH STILL SOME EDITING PHASES\n",
    "\n",
    "\n",
    "Spiegazione:\n",
    "\n",
    "1) Selezione dei Campioni:\n",
    "La funzione itera sul test_loader e salva il primo campione trovato per ciascuna delle due classi (0 e 1).\n",
    "\n",
    "2) Calcolo GradCAM per ciascun campione:\n",
    "\n",
    "Per ogni campione, si abilita il gradiente e si esegue la forward pass.\n",
    "Viene scelto il target (se non specificato, quello predetto) e si esegue la backward pass per calcolare i gradienti.\n",
    "\n",
    "- I pesi vengono calcolati come la media dei gradienti lungo le dimensioni spaziali (dim=(2,3)) e usati per eseguire una somma pesata sulle attivazioni.\n",
    "- La mappa risultante viene passata attraverso una ReLU, normalizzata e upsampled per avere la stessa dimensione dell’input.\n",
    "\n",
    "Creazione degli Overlay:\n",
    "Viene normalizzata l’immagine originale e viene applicata una heatmap (usando OpenCV), quindi l’overlay viene ottenuto con cv2.addWeighted.\n",
    "\n",
    "Costruzione della Figura:\n",
    "Viene creata una figura con due righe e due colonne:\n",
    "\n",
    "- La prima riga mostra le heatmap per ciascuna classe.\n",
    "- La seconda riga mostra le sovrapposizioni (overlay) tra heatmap e spettrogramma originale.\n",
    "\n",
    "I titoli sono personalizzati in base a exp_cond, data_type e category_subject.\n",
    "\n",
    "Questa struttura mantiene tutta la logica necessaria (incluso il calcolo dei pesi) e la rende simile alla versione precedente,\n",
    "con la differenza che il calcolo della CAM viene eseguito per campioni rappresentativi di entrambe le classi. \n",
    "\n",
    "'''\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "\n",
    "\n",
    "#La funzione compute_gradcam_figure serve a calcolare e visualizzare \n",
    "#le mappe di attivazione Grad-CAM per un modello CNN2D, applicandole a spettrogrammi EEG. \n",
    "\n",
    "#In particolare, seleziona un campione per ciascuna classe (0 e 1), calcola la Grad-CAM e costruisce una figura con:\n",
    "\n",
    "#Prima riga → Heatmap della Grad-CAM per entrambe le classi.\n",
    "#Seconda riga → Heatmap sovrapposta allo spettrogramma originale.\n",
    "#Questa visualizzazione aiuta a interpretare su quali parti dell'immagine il modello si sta concentrando per prendere decisioni.\n",
    "\n",
    "\n",
    "\n",
    "#Questa funzione aiuta a visualizzare le regioni attivate dalla rete CNN su immagini di spettrogrammi EEG,\n",
    "#evidenziando le aree più importanti per la classificazione.\n",
    "\n",
    "#🔹 Esempio finale:\n",
    "#La figura risultante avrà due righe:\n",
    "\n",
    "#Heatmap puro della Grad-CAM.\n",
    "#Heatmap sovrapposta allo spettrogramma EEG originale.\n",
    "\n",
    "def compute_gradcam_figure(model, test_loader, exp_cond, data_type, category_subject, device):\n",
    "    \"\"\"\n",
    "    Per il modello CNN2D, seleziona un campione per ciascuna classe (0 e 1),\n",
    "    calcola la GradCAM e costruisce una figura con:\n",
    "    \n",
    "      - Riga 1: Heatmap per classe 0 e classe 1.\n",
    "      - Riga 2: Sovrapposizione della heatmap sullo spettrogramma originale.\n",
    "      \n",
    "    I titoli e le etichette degli assi sono personalizzati:\n",
    "    \n",
    "    - L'asse x rappresenta il tempo (ms) e l'asse y le frequenze (Hz) (solo per la riga overlay)    \n",
    "    - I titoli dei subplot usano i nomi delle condizioni estratte automaticamente da 'exp_cond'\n",
    "        (assumendo che exp_cond sia del tipo \"th_resp_vs_pt_resp\"), data_type e category_subject\n",
    "    \n",
    "    Il calcolo della CAM include il passaggio:\n",
    "       weights = torch.mean(gradients, dim=(2, 3), keepdim=True)\n",
    "       cam = torch.sum(weights * activations, dim=1)\n",
    "       cam = F.relu(cam)\n",
    "    \"\"\"\n",
    "    \n",
    "    #Passaggio 1: Impostazione del layer target e istanziazione di GradCAM\n",
    "    \n",
    "    #Qui si definisce quale layer convoluzionale sarà usato per la Grad-CAM.\n",
    "    #In questo caso, conv3 è il terzo layer convoluzionale del modello model.\n",
    "    \n",
    "    #Grad-CAM calcola la mappa di attivazione basandosi sulle feature generate da questo livello.\n",
    "    \n",
    "    #🔹 Esempio:Se model.conv3 è un layer convoluzionale con 128 feature map,\n",
    "    #la Grad-CAM genererà una mappa di attivazione basata su queste 128 feature.)\n",
    "\n",
    "\n",
    "    # -------------------------------\n",
    "    # Passaggio 1: Impostazione del layer target e istanziazione di GradCAM\n",
    "    # -------------------------------\n",
    "    \n",
    "    # Imposta il layer target (ad esempio conv3) e crea un'istanza di GradCAM\n",
    "    target_layer = model.conv3\n",
    "    gradcam = GradCAM(model, target_layer)\n",
    "    \n",
    "    # Estrai i nomi delle condizioni separando exp_cond (es: \"th_resp_vs_pt_resp\")\n",
    "    condition_names = exp_cond.split(\"_vs_\") if \"_vs_\" in exp_cond else [\"Class 0\", \"Class 1\"]\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Passaggio 2: Selezione di un campione per ogni classe\n",
    "    \n",
    "    #Qui la funzione cerca almeno un campione per ciascuna delle due classi (0 e 1) nel test_loader.\n",
    "    \n",
    "    #🔹 Esempio pratico:\n",
    "    #Se il batch contiene:\n",
    "        \n",
    "    #labels = [1, 0, 1, 0, 1]  \n",
    "    #inputs.shape = (5, 1, 64, 64)  # 5 immagini 64x64 in scala di grigi\n",
    "    \n",
    "    #Il codice estrae:\n",
    "\n",
    "    #samples[0] = inputs[1] (il primo esempio della classe 0)\n",
    "    #samples[1] = inputs[0] (il primo esempio della classe 1)\n",
    "    #Se il test_loader non contiene entrambe le classi, la funzione stampa un messaggio di errore e termina.\n",
    "    \n",
    "    # -------------------------------\n",
    "    # Passaggio 2: Selezione dei campioni per ciascuna classe\n",
    "    # -------------------------------\n",
    "    \n",
    "    # Dizionari per salvare un campione per ciascuna classe\n",
    "    samples = {}      # Qui salveremo il sample input per ogni classe \n",
    "    labels_found = {} # Per tracciare se abbiamo già trovato un esempio per ciascuna classe di etichette\n",
    "    \n",
    "\n",
    "    # Itera sul test_loader fino a trovare almeno un esempio per ciascuna classe (0 e 1)\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        for i, label in enumerate(labels):\n",
    "            label_int = int(label.item())\n",
    "            if label_int not in labels_found:\n",
    "                samples[label_int] = inputs[i].unsqueeze(0)  # Salva come tensore 4D\n",
    "                labels_found[label_int] = True\n",
    "            if 0 in labels_found and 1 in labels_found:\n",
    "                break\n",
    "        if 0 in labels_found and 1 in labels_found:\n",
    "            break\n",
    "\n",
    "    # Se non troviamo entrambi gli esempi, esci con un messaggio\n",
    "    if 0 not in samples or 1 not in samples:\n",
    "        print(\"Non sono stati trovati esempi per entrambe le classi nel test_loader.\")\n",
    "        return None\n",
    "\n",
    "    #Passaggio 3: Calcolo della Grad-CAM\n",
    "    \n",
    "    # Qui il codice:\n",
    "\n",
    "    #Passa l'input al modello per ottenere le predizioni.\n",
    "    #Identifica la classe predetta (target_class).\n",
    "    #Fa il backpropagation per calcolare i gradienti rispetto alla classe target.\n",
    "\n",
    "    #🔹 Esempio pratico:\n",
    "    #Se output = [0.3, 0.7], il modello predice la classe 1, quindi target_class = 1 e il backpropagation calcola il gradiente rispetto a questa classe.\n",
    "    \n",
    "    \n",
    "    # -------------------------------\n",
    "    # Passaggio 3: Calcolo della Grad-CAM per ciascun campione\n",
    "    # -------------------------------\n",
    "    \n",
    "    # Per ciascun campione, calcola la GradCAM\n",
    "    cams = {} # Qui salveremo la mappa CAM per ogni classe\n",
    "    overlays = {} # Qui salveremo l'overlay (CAM + spettrogramma)\n",
    "    \n",
    "    for cls in [0, 1]:\n",
    "        sample_input = samples[cls]\n",
    "        sample_input.requires_grad = True  # Abilita il gradiente per il campione\n",
    "\n",
    "        # Esegui forward pass per ottenere l'output del modello\n",
    "        output = model(sample_input)\n",
    "        \n",
    "        # Se non viene specificata una classe target, seleziona quella predetta\n",
    "        target_class = output.argmax(dim=1).item()\n",
    "\n",
    "        # Azzeramento dei gradienti e backward pass per la classe target\n",
    "        # Azzera i gradienti e fai backpropagation rispetto al punteggio della target_class\n",
    "        model.zero_grad()\n",
    "        target = output[0, target_class]\n",
    "        target.backward()\n",
    "        \n",
    "        #Passaggio 4: Computazione della mappa Grad-CAM\n",
    "        \n",
    "        #Qui si calcola la mappa CAM:\n",
    "\n",
    "        #I pesi Grad-CAM sono la media dei gradienti lungo height & width.\n",
    "        #La mappa CAM è la somma pesata delle attivazioni del layer target.\n",
    "        #Si applica ReLU per eliminare i valori negativi.\n",
    "        \n",
    "        #🔹 Esempio pratico:\n",
    "        #Se abbiamo 128 feature map in conv3, il calcolo sarà:\n",
    "        \n",
    "        #weights = torch.mean(gradcam.gradients, dim=(2, 3), keepdim=True)  # (batch, 128, 1, 1)\n",
    "        #cam = torch.sum(weights * gradcam.activations, dim=1)  # (batch, height, width)\n",
    "        \n",
    "        # -------------------------------\n",
    "        # Passaggio 4: Computazione della mappa Grad-CAM\n",
    "        # -------------------------------\n",
    "        \n",
    "        # Calcola i pesi: media dei gradienti lungo le dimensioni spaziali (height e width)\n",
    "        weights = torch.mean(gradcam.gradients, dim=(2, 3), keepdim=True)\n",
    "        \n",
    "        # Calcola la mappa CAM: somma pesata delle attivazioni\n",
    "        cam = torch.sum(weights * gradcam.activations, dim=1)\n",
    "        \n",
    "        # Calcola la CAM: applica ReLU per eliminare i valori negativi\n",
    "        cam = F.relu(cam)\n",
    "        \n",
    "        #Passaggio 5: Normalizzazione e upsampling\n",
    "        \n",
    "        #La mappa CAM viene normalizzata tra 0 e 1.\n",
    "        #Viene ridimensionata (upsampling) per adattarsi alla dimensione originale dell'immagine\n",
    "        \n",
    "        #🔹 Esempio pratico:\n",
    "        #Se cam ha dimensione 16x16 e l'immagine originale è 64x64, viene interpolata per adattarsi.\n",
    "\n",
    "        # -------------------------------\n",
    "        # Passaggio 5: Normalizzazione e upsampling della CAM\n",
    "        # ---------------------------\n",
    "        \n",
    "        # Normalizza la mappa\n",
    "        cam = cam - cam.min()\n",
    "        cam = cam / (cam.max() + 1e-8)\n",
    "\n",
    "        # Upsample alla dimensione dell'immagine di input\n",
    "        cam = F.interpolate(cam.unsqueeze(1), size=sample_input.shape[2:], mode='bilinear', align_corners=False)\n",
    "        cam = cam.squeeze().cpu().numpy()\n",
    "        cams[cls] = cam\n",
    "        \n",
    "        \n",
    "        #Passaggio 6: Creazione dell’overlay Grad-CAM\n",
    "        \n",
    "        #L'immagine originale viene convertita in un array numpy.\n",
    "        #La mappa CAM viene colorata con COLORMAP_JET.\n",
    "        #Si sovrappone l'heatmap all'immagine originale.\n",
    "\n",
    "        #🔹 Esempio pratico:\n",
    "        #Se il CAM ha valori alti in alcune regioni, il colormap evidenzierà in rosso le aree più attivate.\n",
    "        \n",
    "        # -------------------------------\n",
    "        # Passaggio 6: Creazione dell'Overlay\n",
    "        # -------------------------------\n",
    "        \n",
    "        # Converte l'immagine originale in numpy; considerando che l'input è (batch, canali, frequenze, tempo)\n",
    "        # dopo squeeze si ottiene (canali, frequenze, tempo). Per visualizzare come immagine color, trasformiamo in (frequenze, tempo, canali).\n",
    "        \n",
    "        # Prepara l'immagine originale per la visualizzazione\n",
    "        img = sample_input.squeeze().cpu().detach().numpy().transpose(1, 2, 0)\n",
    "        \n",
    "        # Normalizza l'immagine in scala 0-255\n",
    "        img_norm = np.uint8(255 * (img - img.min()) / (img.max() - img.min()))\n",
    "        \n",
    "        # Applica la heatmap usando OpenCV\n",
    "        #Per l'Overlay possiamo scegliere un colormap alternativo,\n",
    "        # ad esempio COLORMAP_HOT o COLORMAP_INFERNO, per contrastare lo spettrogramma originale\n",
    "        \n",
    "        '''\n",
    "        OLD VERSIONS\n",
    "        heatmap = cv2.applyColorMap(np.uint8(255 * cam), cv2.COLORMAP_JET)\n",
    "        heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)\n",
    "        '''\n",
    "        \n",
    "        '''COMMENTATO'''\n",
    "        #heatmap = cv2.applyColorMap(np.uint8(255 * cam), cv2.COLORMAP_INFERNO)\n",
    "        \n",
    "        heatmap = cv2.applyColorMap(np.uint8(255 * cam), cv2.COLORMAP_VIRIDIS)\n",
    "        \n",
    "        heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Sovrapponi la heatmap all'immagine originale\n",
    "        # Crea l'overlay: scegliendo pesi diversi per ottenere un contrasto chiaro\n",
    "        \n",
    "        '''\n",
    "        OLD VERSIONS\n",
    "        overlay = cv2.addWeighted(img_norm, 0.6, heatmap, 0.4, 0)\n",
    "        overlays[cls] = overlay\n",
    "        '''\n",
    "        \n",
    "        overlay = cv2.addWeighted(img_norm, 0.5, heatmap, 0.5, 0)\n",
    "        overlays[cls] = overlay\n",
    "    \n",
    "    #Passaggio 7: Creazione della figura finale\n",
    "    \n",
    "    #La prima riga mostra solo le heatmap Grad-CAM.\n",
    "    #La seconda riga mostra le heatmap sovrapposte agli spettrogrammi.\n",
    "\n",
    "    # Crea la figura con due righe e due colonne\n",
    "\n",
    "    # -------------------------------\n",
    "    # Passaggio 7: Creazione della figura finale\n",
    "    # -------------------------------\n",
    "    # Creiamo una figura con 2 righe e 2 colonne:\n",
    "    # - Prima riga: le heatmap CAM (da 0 a 1) per ciascuna condizione.\n",
    "    # - Seconda riga: l'overlay (CAM + spettrogramma) per ciascuna condizione, con etichette per gli assi.\n",
    "    \n",
    "    fig, axs = plt.subplots(2, 2, figsize=(12, 10))\n",
    "    \n",
    "    '''\n",
    "    OLD VERSION\n",
    "    # Titoli personalizzati per le righe\n",
    "    title_row1 = f\"Grad-CAM mapping of experimental condition {exp_cond}, EEG {data_type}, Subject {category_subject}\"\n",
    "    title_row2 = f\"Grad-CAM mapping superimposition over EEG Spectrogram of experimental condition {exp_cond}, Subject {category_subject}\"\n",
    "    \n",
    "    # Prima riga: visualizza solo le heatmap\n",
    "    for j, cls in enumerate([0, 1]):\n",
    "        # Visualizza la heatmap applicata sul colore (questo step può essere ripetuto, oppure si visualizza la mappa grezza)\\n\n",
    "        axs[0, j].imshow(cv2.cvtColor(cv2.applyColorMap(np.uint8(255 * cams[cls]), cv2.COLORMAP_JET), cv2.COLOR_BGR2RGB))\n",
    "        axs[0, j].set_title(f\"Class {cls} Heatmap\")\n",
    "        axs[0, j].axis('off')\n",
    "    axs[0, 0].set_ylabel(title_row1, fontsize=10)\n",
    "    \n",
    "    # Seconda riga: visualizza l'overlay della heatmap sullo spettrogramma originale\n",
    "    for j, cls in enumerate([0, 1]):\n",
    "        axs[1, j].imshow(overlays[cls])\n",
    "        axs[1, j].set_title(f\"Class {cls} Overlay\")\n",
    "        axs[1, j].axis('off')\n",
    "    axs[1, 0].set_ylabel(title_row2, fontsize=10)\n",
    "    \n",
    "    # Ottimizza la disposizione della figura\n",
    "    plt.tight_layout()\n",
    "    '''\n",
    "    \n",
    "    # Imposta un titolo generale per la figura\n",
    "    plt.suptitle(f\"Grad-CAM Mapping for {exp_cond} - EEG {data_type} - Subject {category_subject}\", fontsize=15)\n",
    "    \n",
    "    # Prima riga: Visualizza solo le heatmap (CAM)\n",
    "    for j, cls in enumerate([0, 1]):\n",
    "        \n",
    "        # Qui usiamo il colormap INFERNO per la CAM, ma puoi modificare se preferisci\n",
    "        cam_img = cv2.applyColorMap(np.uint8(255 * cams[cls]), cv2.COLORMAP_INFERNO)\n",
    "        cam_img = cv2.cvtColor(cam_img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        '''QUI AGGIUNGIAMO L'INVERSIONE DEGLI ASSI'''\n",
    "        # Se necessario, inverti gli assi per ottenere la visualizzazione desiderata\n",
    "        cam_img = np.flipud(cam_img)  # Inverte verticalmente\n",
    "        \n",
    "        #axs[0, j].imshow(cam_img)\n",
    "        \n",
    "        # Se conosci i limiti temporali e di frequenza, puoi usare l'argomento extent\n",
    "        axs[0, j].imshow(cam_img, extent=[0, 1000, 0, 25], aspect='auto')\n",
    "        \n",
    "        axs[0, j].set_title(f\"{condition_names[cls]} Heatmap\", fontsize=12)\n",
    "        axs[0, j].axis('off')\n",
    "    \n",
    "    # Seconda riga: Visualizza gli overlay con etichette degli assi\n",
    "    for j, cls in enumerate([0, 1]):\n",
    "        \n",
    "        '''COMMENTATO PER L'OVERLAY SOLO RAPPRESENTARE L'ASSE DEL TEMPO IN FORMATO DI MILLISECONDI E NON DI FINESTRE STFT'''\n",
    "        #axs[1, j].imshow(overlays[cls])\n",
    "        \n",
    "        # Qui, se vuoi che l'asse y (frequenze) venga ordinato in modo crescente,\n",
    "        # puoi anche invertire l'immagine verticalmente, se non è già corretto.\n",
    "        overlay_img = np.flipud(overlays[cls])\n",
    "        \n",
    "        # Se conosci i limiti temporali e di frequenza, puoi usare l'argomento extent\n",
    "        axs[1, j].imshow(overlay_img, extent=[0, 1000, 0, 25], aspect='auto')\n",
    "        \n",
    "        axs[1, j].set_title(f\"{condition_names[cls]} Overlay\", fontsize=12)\n",
    "        axs[1, j].set_xlabel(\"Time (mms)\", fontsize=10)\n",
    "        axs[1, j].set_ylabel(\"Frequency (Hz)\", fontsize=10)\n",
    "        axs[1, j].axis('on')\n",
    "    \n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    \n",
    "    \n",
    "    #Passaggio 8: Salvataggio della figura\n",
    "    #Qui la figura viene salvata in un buffer di memoria, pronto per essere salvato o inviato altrove\n",
    "    \n",
    "    # -------------------------------\n",
    "    # Passaggio 8: Salvataggio della figura in un buffer\n",
    "    # -------------\n",
    "\n",
    "    # Salva la figura in un buffer (che potrai poi passare a save_performance_results)\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='png')\n",
    "    buf.seek(0)\n",
    "    fig_image = buf.getvalue()\n",
    "    buf.close()\n",
    "    plt.close(fig)\n",
    "    \n",
    "    return fig_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9468549a-7fdf-44c2-b6d9-fd3250d3fc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Creazione della funzione per generare le immagini associate alla GradCAM compution\n",
    "\n",
    "FINAL VERSION WITH ULTIMATED EDITING PHASES\n",
    "\n",
    "\n",
    "Spiegazione:\n",
    "\n",
    "1) Selezione dei Campioni:\n",
    "La funzione itera sul test_loader e salva il primo campione trovato per ciascuna delle due classi (0 e 1).\n",
    "\n",
    "2) Calcolo GradCAM per ciascun campione:\n",
    "\n",
    "Per ogni campione, si abilita il gradiente e si esegue la forward pass.\n",
    "Viene scelto il target (se non specificato, quello predetto) e si esegue la backward pass per calcolare i gradienti.\n",
    "\n",
    "- I pesi vengono calcolati come la media dei gradienti lungo le dimensioni spaziali (dim=(2,3)) e usati per eseguire una somma pesata sulle attivazioni.\n",
    "- La mappa risultante viene passata attraverso una ReLU, normalizzata e upsampled per avere la stessa dimensione dell’input.\n",
    "\n",
    "Creazione degli Overlay:\n",
    "Viene normalizzata l’immagine originale e viene applicata una heatmap (usando OpenCV), quindi l’overlay viene ottenuto con cv2.addWeighted.\n",
    "\n",
    "Costruzione della Figura:\n",
    "Viene creata una figura con due righe e due colonne:\n",
    "\n",
    "- La prima riga mostra le heatmap per ciascuna classe.\n",
    "- La seconda riga mostra le sovrapposizioni (overlay) tra heatmap e spettrogramma originale.\n",
    "\n",
    "I titoli sono personalizzati in base a exp_cond, data_type e category_subject.\n",
    "\n",
    "Questa struttura mantiene tutta la logica necessaria (incluso il calcolo dei pesi) e la rende simile alla versione precedente,\n",
    "con la differenza che il calcolo della CAM viene eseguito per campioni rappresentativi di entrambe le classi. \n",
    "\n",
    "\n",
    "\n",
    "Ciao ho bisogno che in questo calcolo del gradcam, tu qui nella funzione di calcolo del gradcam...\n",
    "tu mi presenti poi le immagini (sia gradcam che per l'overlay) non solo un esempio, ma il valore medio di attivazione per la relativa condizione sperimentale...\n",
    "ossia, anziché prendere un solo esempio e presentare il gradcam e l'overlay del solo esempio della classe 0, dovresti mostrarmi il valore medio, \n",
    "e allo stesso modo della classe 1.\n",
    "\n",
    "quindi sia nel gradcam che nell'overlay dovrei avere una rappresentazione media sia delle regioni delle feature maps per la relativa condizione sperimentale,\n",
    "sia dell'overlay risultante....\n",
    "\n",
    "Ti è chiaro che cosa voglio?\n",
    "\n",
    "\n",
    "\n",
    "Esatto, ho capito. Invece di estrarre un singolo campione per ciascuna classe, la funzione dovrebbe:\n",
    "Accumulare le mappe GradCAM e gli overlay per tutti i campioni appartenenti a ciascuna classe\n",
    "Calcolare la media delle mappe GradCAM ottenute per ciascuna condizione sperimentale.\n",
    "Calcolare la media degli overlay corrispondenti, in modo da ottenere una rappresentazione aggregata della risposta del modello.\n",
    "Quindi, anziché mostrare l'attivazione per un solo esempio, la figura finale presenterà:\n",
    "Una heatmap media della GradCAM per la classe 0 e per la classe 1.\n",
    "Un overlay medio (CAM + spettrogramma) per la classe 0 e per la classe 1.\n",
    "\n",
    "\n",
    "\n",
    "Puoi implementare la media delle mappe GradCAM e degli overlay per ogni classe modificando la funzione nel modo seguente. \n",
    "In sostanza, invece di fermarti al primo campione trovato per ciascuna classe, raccogli tutti (o un sottoinsieme rappresentativo) e poi calcola la media.\n",
    "Ecco i passaggi principali con qualche suggerimento su dove inserire il nuovo codice:\n",
    "\n",
    "\n",
    "1. Raccogliere le mappe e gli overlay per ogni classe\n",
    "Dove modificare:\n",
    "\n",
    "Dopo il passaggio 3 (calcolo della GradCAM per ciascun campione), invece di elaborare un solo esempio per ciascuna classe, \n",
    "crea due liste (una per la classe 0 e una per la classe 1) in cui accumulare le mappe CAM e gli overlay per ogni campione processato.\n",
    "\n",
    "Cosa fare:\n",
    "\n",
    "Invece di usare un dizionario samples che salva solo il primo esempio trovato, modifica il ciclo sul test_loader per salvare tutti gli esempi \n",
    "(o un numero sufficiente di campioni) per ciascuna classe.\n",
    "\n",
    "Per ogni campione, calcola la GradCAM e l'overlay e aggiungili alle rispettive liste, per esempio:\n",
    "\n",
    "    cams_list[cls].append(cam)\n",
    "    overlays_list[cls].append(overlay)\n",
    "\n",
    "\n",
    "2. Calcolare la media delle mappe\n",
    "Dove modificare:\n",
    "\n",
    "Dopo aver processato tutti i campioni (o quelli desiderati) per ciascuna classe, \n",
    "aggiungi un nuovo passaggio per calcolare la media lungo l'asse delle mappe accumulate.\n",
    "\n",
    "Cosa fare:\n",
    "\n",
    "Per ogni classe, converti la lista in un array NumPy e calcola la media. Ad esempio:\n",
    "\n",
    "\n",
    "    mean_cam = np.mean(np.array(cams_list[cls]), axis=0)\n",
    "    mean_overlay = np.mean(np.array(overlays_list[cls]), axis=0).astype(np.uint8)\n",
    "    \n",
    "Salva questi valori medi in due nuovi dizionari (ad es. mean_cams e mean_overlays).\n",
    "\n",
    "\n",
    "3. Utilizzare le mappe medie per la visualizzazione\n",
    "Dove modificare:\n",
    "\n",
    "Nel passaggio 7, durante la creazione della figura finale, utilizza mean_cams e mean_overlays anziché le mappe di un singolo esempio.\n",
    "\n",
    "Cosa fare:\n",
    "\n",
    "Nel ciclo che disegna le immagini, usa ad esempio:\n",
    "\n",
    "    cam_img = cv2.applyColorMap(np.uint8(255 * mean_cams[cls]), cv2.COLORMAP_INFERNO)\n",
    "\n",
    "E per l'overlay:\n",
    "\n",
    "    overlay_img = np.flipud(mean_overlays[cls])\n",
    "\n",
    "In questo modo la figura finale rappresenterà la media delle attivazioni per ogni condizione sperimentale.\n",
    "\n",
    "Considerazioni finali\n",
    "Selezione del campione: Se il dataset è molto grande, potresti voler limitare il numero di campioni per evitare calcoli troppo onerosi.\n",
    "Ad esempio, puoi considerare i primi N campioni per ogni classe oppure usare un campionamento casuale.\n",
    "\n",
    "Prestazioni: Calcolare la media su molti campioni potrebbe essere intensivo, quindi valuta se sia il caso di eseguire questo calcolo\n",
    "su un sottoinsieme rappresentativo.\n",
    "\n",
    "Visualizzazione: Assicurati che la normalizzazione sia coerente per la media.\n",
    "                A volte, potrebbe essere utile normalizzare ogni mappa individualmente prima di calcolare la media \n",
    "                oppure normalizzare l'immagine media risultante.\n",
    "\n",
    "Questi passaggi ti permetteranno di ottenere una rappresentazione aggregata (media) sia della GradCAM che dell'overlay, \n",
    "fornendo una visione più robusta della risposta del modello per ogni condizione sperimentale.\n",
    "\n",
    "---- ---- ---- ---- ---- ----  ---- ---- ----  ---- ---- ----  ---- ---- ---- ---- ---- ----  ---- ---- ---- ---- ---- ----  ---- ---- ---- ---- ---- ----  ---- ---- ---- \n",
    "Riepilogo delle parti modificate\n",
    "Selezione dei campioni:\n",
    "\n",
    "Sostituisci la logica che si ferma al primo campione per ogni classe con la raccolta di tutti i campioni (o un campione rappresentativo) \n",
    "per ciascuna classe, salvandoli in un dizionario di liste.\n",
    "\n",
    "Calcolo della Grad-CAM e Overlay:\n",
    "\n",
    "Per ogni campione in ciascuna classe, calcola la mappa CAM e l'overlay e aggiungili a liste (cams_list e overlays_list).\n",
    "\n",
    "Calcolo della media:\n",
    "\n",
    "Dopo il ciclo, calcola la media per ogni classe usando np.mean.\n",
    "\n",
    "Visualizzazione:\n",
    "\n",
    "Nel passaggio di creazione della figura, utilizza le mappe medie (mean_cams e mean_overlays) al posto dei singoli campioni.\n",
    "\n",
    "Queste modifiche ti permetteranno di ottenere, per ciascuna classe (0 e 1), una rappresentazione media sia della mappa Grad-CAM che dell'overlay, come richiesto.\n",
    "---- ---- ---- ---- ---- ----  ---- ---- ----  ---- ---- ----  ---- ---- ---- ---- ---- ----  ---- ---- ---- ---- ---- ----  ---- ---- ---- ---- ---- ----  ---- ---- ---- \n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "\n",
    "\n",
    "#La funzione compute_gradcam_figure serve a calcolare e visualizzare \n",
    "#le mappe di attivazione Grad-CAM per un modello CNN2D, applicandole a spettrogrammi EEG. \n",
    "\n",
    "#In particolare, seleziona un campione per ciascuna classe (0 e 1), calcola la Grad-CAM e costruisce una figura con:\n",
    "\n",
    "#Prima riga → Heatmap della Grad-CAM per entrambe le classi.\n",
    "#Seconda riga → Heatmap sovrapposta allo spettrogramma originale.\n",
    "#Questa visualizzazione aiuta a interpretare su quali parti dell'immagine il modello si sta concentrando per prendere decisioni.\n",
    "\n",
    "\n",
    "\n",
    "#Questa funzione aiuta a visualizzare le regioni attivate dalla rete CNN su immagini di spettrogrammi EEG,\n",
    "#evidenziando le aree più importanti per la classificazione.\n",
    "\n",
    "#🔹 Esempio finale:\n",
    "#La figura risultante avrà due righe:\n",
    "\n",
    "#Heatmap puro della Grad-CAM.\n",
    "#Heatmap sovrapposta allo spettrogramma EEG originale.\n",
    "\n",
    "def compute_gradcam_figure(model, test_loader, exp_cond, data_type, category_subject, device):\n",
    "    \"\"\"\n",
    "    Per il modello CNN2D, seleziona un campione per ciascuna classe (0 e 1),\n",
    "    calcola la GradCAM e costruisce una figura con:\n",
    "    \n",
    "      - Riga 1: Heatmap per classe 0 e classe 1.\n",
    "      - Riga 2: Sovrapposizione della heatmap sullo spettrogramma originale.\n",
    "      \n",
    "    I titoli e le etichette degli assi sono personalizzati:\n",
    "    \n",
    "    - L'asse x rappresenta il tempo (ms) e l'asse y le frequenze (Hz) (solo per la riga overlay)    \n",
    "    - I titoli dei subplot usano i nomi delle condizioni estratte automaticamente da 'exp_cond'\n",
    "        (assumendo che exp_cond sia del tipo \"th_resp_vs_pt_resp\"), data_type e category_subject\n",
    "    \n",
    "    Il calcolo della CAM include il passaggio:\n",
    "       weights = torch.mean(gradients, dim=(2, 3), keepdim=True)\n",
    "       cam = torch.sum(weights * activations, dim=1)\n",
    "       cam = F.relu(cam)\n",
    "    \"\"\"\n",
    "    \n",
    "    #Passaggio 1: Impostazione del layer target e istanziazione di GradCAM\n",
    "    \n",
    "    #Qui si definisce quale layer convoluzionale sarà usato per la Grad-CAM.\n",
    "    #In questo caso, conv3 è il terzo layer convoluzionale del modello model.\n",
    "    \n",
    "    #Grad-CAM calcola la mappa di attivazione basandosi sulle feature generate da questo livello.\n",
    "    \n",
    "    #🔹 Esempio:Se model.conv3 è un layer convoluzionale con 128 feature map,\n",
    "    #la Grad-CAM genererà una mappa di attivazione basata su queste 128 feature.)\n",
    "\n",
    "\n",
    "    # -------------------------------\n",
    "    # Passaggio 1: Impostazione del layer target e istanziazione di GradCAM\n",
    "    # -------------------------------\n",
    "    \n",
    "    # Imposta il layer target (ad esempio conv3) e crea un'istanza di GradCAM\n",
    "    target_layer = model.conv3\n",
    "    gradcam = GradCAM(model, target_layer)\n",
    "    \n",
    "    # Estrai i nomi delle condizioni separando exp_cond (es: \"th_resp_vs_pt_resp\")\n",
    "    condition_names = exp_cond.split(\"_vs_\") if \"_vs_\" in exp_cond else [\"Class 0\", \"Class 1\"]\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Passaggio 2: Selezione di un campione per ogni classe\n",
    "    \n",
    "    #Qui la funzione cerca almeno un campione per ciascuna delle due classi (0 e 1) nel test_loader.\n",
    "    \n",
    "    #🔹 Esempio pratico:\n",
    "    #Se il batch contiene:\n",
    "        \n",
    "    #labels = [1, 0, 1, 0, 1]  \n",
    "    #inputs.shape = (5, 1, 64, 64)  # 5 immagini 64x64 in scala di grigi\n",
    "    \n",
    "    #Il codice estrae:\n",
    "\n",
    "    #samples[0] = inputs[1] (il primo esempio della classe 0)\n",
    "    #samples[1] = inputs[0] (il primo esempio della classe 1)\n",
    "    #Se il test_loader non contiene entrambe le classi, la funzione stampa un messaggio di errore e termina.\n",
    "    \n",
    "    # -------------------------------\n",
    "    # Passaggio 2: Selezione dei campioni per ciascuna classe\n",
    "    # -------------------------------\n",
    "    \n",
    "    '''SOLO UN ESEMPIO'''\n",
    "    # Dizionari per salvare un campione per ciascuna classe\n",
    "    #samples = {}      # Qui salveremo il sample input per ogni classe \n",
    "    #labels_found = {} # Per tracciare se abbiamo già trovato un esempio per ciascuna classe di etichette\n",
    "    \n",
    "    '''CON MEDIA'''\n",
    "    \n",
    "    #Ora che ogni classe ha una sua chiave nel dizionario samples, non c'è più bisogno di usare labels_found \n",
    "    #per verificare la presenza di entrambe le classi.\n",
    "    #In precedenza, stavi iterando nel test_loader e verificando la presenza di almeno un esempio per entrambe le classi (0 e 1),\n",
    "    #ma ora i dati vengono direttamente organizzati nel dizionario in base alla loro classe. Quindi, se la classe non esiste nel dataset,\n",
    "    #semplicemente non avrà una chiave nel dizionario samples.\n",
    "    #Il controllo finale if 0 not in samples or 1 not in samples: è ancora necessario per assicurarsi che entrambe le classi siano presenti.\n",
    "    #Se manca una classe, possiamo ancora uscire con un messaggio di errore.\n",
    "    \n",
    "    # Dizionari per salvare tutti i campioni per ciascuna classe\n",
    "    samples = {0: [], 1: []}\n",
    "\n",
    "    # Itera sul test_loader fino a trovare almeno un esempio per ciascuna classe (0 e 1)\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        for i, label in enumerate(labels):\n",
    "            label_int = int(label.item())\n",
    "            \n",
    "            # Aggiungi il campione alla lista della classe corrispondente\n",
    "            if label_int in samples:  # Assumendo solo classi 0 e 1\n",
    "                samples[label_int].append(inputs[i].unsqueeze(0))\n",
    "                \n",
    "            '''SOLO UN ESEMPIO'''\n",
    "            #if label_int not in labels_found:\n",
    "            #    samples[label_int] = inputs[i].unsqueeze(0)  # Salva come tensore 4D\n",
    "                \n",
    "                \n",
    "                #labels_found[label_int] = True\n",
    "            #if 0 in labels_found and 1 in labels_found:\n",
    "            #    break\n",
    "        #if 0 in labels_found and 1 in labels_found:\n",
    "        #    break\n",
    "\n",
    "    # Se non troviamo entrambi gli esempi, esci con un messaggio\n",
    "    #if 0 not in samples or 1 not in samples:\n",
    "    #    print(\"Non sono stati trovati esempi per entrambe le classi nel test_loader.\")\n",
    "    #    return None\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #Passaggio 3: Calcolo della Grad-CAM\n",
    "    \n",
    "    # Qui il codice:\n",
    "\n",
    "    #Passa l'input al modello per ottenere le predizioni.\n",
    "    #Identifica la classe predetta (target_class).\n",
    "    #Fa il backpropagation per calcolare i gradienti rispetto alla classe target.\n",
    "\n",
    "    #🔹 Esempio pratico:\n",
    "    #Se output = [0.3, 0.7], il modello predice la classe 1, quindi target_class = 1 e il backpropagation calcola il gradiente rispetto a questa classe.\n",
    "    \n",
    "    \n",
    "    # -------------------------------\n",
    "    # Passaggio 3: Calcolo della Grad-CAM per ciascun campione\n",
    "    # -------------------------------\n",
    "    \n",
    "    '''SOLO UN ESEMPIO'''\n",
    "    # Per ciascun campione, calcola la GradCAM\n",
    "    #cams = {} # Qui salveremo la mappa CAM per ogni classe\n",
    "    #overlays = {} # Qui salveremo l'overlay (CAM + spettrogramma)\n",
    "    \n",
    "    '''\n",
    "    L'errore si verifica perché ora la variabile samples[cls] è una lista di tensori (cioè, più campioni) e non un singolo tensore. \n",
    "    Di conseguenza, cercando di eseguire samples[cls].requires_grad ottieni l'errore (dato che la lista non ha l'attributo requires_grad).\n",
    "    Per risolvere il problema devi iterare sui singoli campioni all'interno della lista per ciascuna classe. Ad esempio, sostituisci questo blocco:\n",
    "    \n",
    "    In questo modo, per ogni classe iteri su ciascun campione, calcoli la Grad-CAM e l'overlay, e li accumuli nelle rispettive liste \n",
    "    (cams_list e overlays_list). Successivamente potrai calcolare la media per ciascuna classe e utilizzarla per la visualizzazione.\n",
    "    Con questa modifica non otterrai più l'errore e la logica sarà coerente con l'obiettivo di aggregare i risultati su più campioni.\n",
    "    '''\n",
    "    \n",
    "    '''CON MEDIA'''\n",
    "    cams_list = {0: [], 1: []}\n",
    "    overlays_list = {0: [], 1: []}\n",
    "    \n",
    "    for cls in [0, 1]:\n",
    "        for sample_input in samples[cls]:\n",
    "        \n",
    "        #sample_input = samples[cls]\n",
    "        \n",
    "            sample_input.requires_grad = True  # Abilita il gradiente per il campione\n",
    "\n",
    "            # Esegui forward pass per ottenere l'output del modello\n",
    "            output = model(sample_input)\n",
    "\n",
    "            # Se non viene specificata una classe target, seleziona quella predetta\n",
    "            target_class = output.argmax(dim=1).item()\n",
    "\n",
    "            # Azzeramento dei gradienti e backward pass per la classe target\n",
    "            # Azzera i gradienti e fai backpropagation rispetto al punteggio della target_class\n",
    "            model.zero_grad()\n",
    "            target = output[0, target_class]\n",
    "            target.backward()\n",
    "\n",
    "            #Passaggio 4: Computazione della mappa Grad-CAM\n",
    "\n",
    "            #Qui si calcola la mappa CAM:\n",
    "\n",
    "            #I pesi Grad-CAM sono la media dei gradienti lungo height & width.\n",
    "            #La mappa CAM è la somma pesata delle attivazioni del layer target.\n",
    "            #Si applica ReLU per eliminare i valori negativi.\n",
    "\n",
    "            #🔹 Esempio pratico:\n",
    "            #Se abbiamo 128 feature map in conv3, il calcolo sarà:\n",
    "\n",
    "            #weights = torch.mean(gradcam.gradients, dim=(2, 3), keepdim=True)  # (batch, 128, 1, 1)\n",
    "            #cam = torch.sum(weights * gradcam.activations, dim=1)  # (batch, height, width)\n",
    "\n",
    "            # -------------------------------\n",
    "            # Passaggio 4: Computazione della mappa Grad-CAM\n",
    "            # -------------------------------\n",
    "\n",
    "            # Calcola i pesi: media dei gradienti lungo le dimensioni spaziali (height e width)\n",
    "            weights = torch.mean(gradcam.gradients, dim=(2, 3), keepdim=True)\n",
    "\n",
    "            # Calcola la mappa CAM: somma pesata delle attivazioni\n",
    "            cam = torch.sum(weights * gradcam.activations, dim=1)\n",
    "\n",
    "            # Calcola la CAM: applica ReLU per eliminare i valori negativi\n",
    "            cam = F.relu(cam)\n",
    "\n",
    "            #Passaggio 5: Normalizzazione e upsampling\n",
    "\n",
    "            #La mappa CAM viene normalizzata tra 0 e 1.\n",
    "            #Viene ridimensionata (upsampling) per adattarsi alla dimensione originale dell'immagine\n",
    "\n",
    "            #🔹 Esempio pratico:\n",
    "            #Se cam ha dimensione 16x16 e l'immagine originale è 64x64, viene interpolata per adattarsi.\n",
    "\n",
    "            # -------------------------------\n",
    "            # Passaggio 5: Normalizzazione e upsampling della CAM\n",
    "            # ---------------------------\n",
    "\n",
    "            # Normalizza la mappa\n",
    "            cam = cam - cam.min()\n",
    "            cam = cam / (cam.max() + 1e-8)\n",
    "\n",
    "            # Upsample alla dimensione dell'immagine di input\n",
    "            cam = F.interpolate(cam.unsqueeze(1), size=sample_input.shape[2:], mode='bilinear', align_corners=False)\n",
    "            cam = cam.squeeze().cpu().numpy()\n",
    "\n",
    "            '''SOLO UN ESEMPIO'''\n",
    "            #cams[cls] = cam\n",
    "\n",
    "\n",
    "            '''CON MEDIA'''\n",
    "            # Aggiungi la mappa alla lista per la classe\n",
    "            cams_list[cls].append(cam)\n",
    "\n",
    "\n",
    "            #Passaggio 6: Creazione dell’overlay Grad-CAM\n",
    "\n",
    "            #L'immagine originale viene convertita in un array numpy.\n",
    "            #La mappa CAM viene colorata con COLORMAP_JET.\n",
    "            #Si sovrappone l'heatmap all'immagine originale.\n",
    "\n",
    "            #🔹 Esempio pratico:\n",
    "            #Se il CAM ha valori alti in alcune regioni, il colormap evidenzierà in rosso le aree più attivate.\n",
    "\n",
    "            # -------------------------------\n",
    "            # Passaggio 6: Creazione dell'Overlay\n",
    "            # -------------------------------\n",
    "\n",
    "            # Converte l'immagine originale in numpy; considerando che l'input è (batch, canali, frequenze, tempo)\n",
    "            # dopo squeeze si ottiene (canali, frequenze, tempo). Per visualizzare come immagine color, trasformiamo in (frequenze, tempo, canali).\n",
    "\n",
    "            # Prepara l'immagine originale per la visualizzazione\n",
    "            img = sample_input.squeeze().cpu().detach().numpy().transpose(1, 2, 0)\n",
    "\n",
    "            # Normalizza l'immagine in scala 0-255\n",
    "            img_norm = np.uint8(255 * (img - img.min()) / (img.max() - img.min()))\n",
    "\n",
    "            # Applica la heatmap usando OpenCV\n",
    "            #Per l'Overlay possiamo scegliere un colormap alternativo,\n",
    "            # ad esempio COLORMAP_HOT o COLORMAP_INFERNO, per contrastare lo spettrogramma originale\n",
    "\n",
    "            '''\n",
    "            Il processo è lo stesso di quello descritto per le cam:\n",
    "\n",
    "            I valori del CAM (normalizzati) vengono scalati a 255 e convertiti in un'immagine in scala di grigi.\n",
    "            Il colormap INFERNO viene applicato per ottenere una rappresentazione colorata (dove i valori elevati diventano in genere rossi/gialli).\n",
    "            La conversione BGR→RGB assicura una visualizzazione corretta\n",
    "            '''\n",
    "\n",
    "            heatmap = cv2.applyColorMap(np.uint8(255 * cam), cv2.COLORMAP_VIRIDIS)\n",
    "            heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            # Sovrapponi la heatmap all'immagine originale\n",
    "            # Crea l'overlay: scegliendo pesi diversi per ottenere un contrasto chiaro\n",
    "\n",
    "\n",
    "            '''\n",
    "            Overlay troppo sfocato e colori discordanti\n",
    "            Il problema che descrivi (overlay con toni azzurri/turchesi anziché il rosso della heatmap) può derivare da:\n",
    "\n",
    "            Differenza di colormap e blending:\n",
    "            L'overlay viene creato con una combinazione di due immagini: \n",
    "                1)lo spettrogramma originale (che potrebbe avere un proprio mapping di colori) e\n",
    "                2) la heatmap\n",
    "\n",
    "            Se il bilanciamento (i pesi) è 0.5-0.5, l'influenza dello spettrogramma può \"modificare\" i colori della heatmap.\n",
    "\n",
    "            Suggerimenti:\n",
    "\n",
    "            a) Modifica i pesi in cv2.addWeighted:\n",
    "            Ad esempio, prova con 0.3 per l'immagine originale e 0.7 per la heatmap, in modo che il colore della heatmap (ad es. il rosso) prevalga.\n",
    "\n",
    "            b) Uniforma il formato dell'immagine originale:\n",
    "            Se lo spettrogramma originale è in scala di grigi o usa un colormap diverso,\n",
    "            considera di convertirlo in un'immagine in scala di grigi a 8 bit prima di creare l'overlay.\n",
    "\n",
    "            c) Usa lo stesso colormap: \n",
    "            Se vuoi che l'overlay abbia colori simili a quelli della heatmap, \n",
    "            usa lo stesso colormap (qui COLORMAP_INFERNO) per entrambe e regola il blending.\n",
    "\n",
    "            '''\n",
    "            overlay = cv2.addWeighted(img_norm, 0.4, heatmap, 0.6, 0)\n",
    "            #overlay = cv2.addWeighted(img_norm, 0.5, heatmap, 0.5, 0)\n",
    "\n",
    "            '''SOLO UN ESEMPIO'''\n",
    "            #overlays[cls] = overlay\n",
    "\n",
    "            '''CON MEDIA'''\n",
    "            # Aggiungi l'overlay alla lista per la classe\n",
    "            overlays_list[cls].append(overlay)\n",
    "    \n",
    "    \n",
    "    mean_cams = {}\n",
    "    mean_overlays = {}\n",
    "    \n",
    "    for cls in [0, 1]:\n",
    "        mean_cams[cls] = np.mean(np.array(cams_list[cls]), axis=0)\n",
    "        mean_overlays[cls] = np.mean(np.array(overlays_list[cls]), axis=0).astype(np.uint8)\n",
    "        \n",
    "    #Passaggio 7: Creazione della figura finale\n",
    "    \n",
    "    #La prima riga mostra solo le heatmap Grad-CAM.\n",
    "    #La seconda riga mostra le heatmap sovrapposte agli spettrogrammi.\n",
    "\n",
    "    # Crea la figura con due righe e due colonne\n",
    "\n",
    "    # -------------------------------\n",
    "    # Passaggio 7: Creazione della figura finale\n",
    "    # -------------------------------\n",
    "    # Creiamo una figura con 2 righe e 2 colonne:\n",
    "    # - Prima riga: le heatmap CAM (da 0 a 1) per ciascuna condizione.\n",
    "    # - Seconda riga: l'overlay (CAM + spettrogramma) per ciascuna condizione, con etichette per gli assi.\n",
    "    \n",
    "    fig, axs = plt.subplots(2, 2, figsize=(12, 10))\n",
    "    \n",
    "    # Imposta un titolo generale per la figura\n",
    "    \n",
    "    #plt.suptitle(f\"Grad-CAM Mapping - Experimental Condition: {exp_cond} - Subject: {category_subject}\", fontsize=12)\n",
    "    \n",
    "    #plt.suptitle(f\"Grad-CAM Mapping and Resulting Overlay over EEG trial Spectrogram\\nExperimental Condition: {exp_cond} - Subject: {category_subject}\",\n",
    "    #fontsize=10,\n",
    "    #y=0.95  # Puoi regolare la posizione verticale se necessario\n",
    "    #)\n",
    "    \n",
    "    plt.suptitle(f\"Grad-CAM Mapping and Resulting Overlay over EEG Trial Spectrogram\\nExperimental Conditions: {exp_cond} - Subject: {category_subject}\", fontsize=15)\n",
    "    \n",
    "    \n",
    "    # Prima riga: Visualizza solo le heatmap (CAM)\n",
    "    for j, cls in enumerate([0, 1]):\n",
    "        \n",
    "        # Qui usiamo il colormap INFERNO per la CAM, ma puoi modificare se preferisci\n",
    "        \n",
    "        '''\n",
    "        np.uint8(255 * cams[cls]):\n",
    "        La mappa CAM (calcolata e normalizzata) ha valori compresi tra 0 e 1.\n",
    "        Moltiplicando per 255 e convertendo in uint8, ottieni un'immagine in scala di grigi a 8 bit (0-255).\n",
    "        \n",
    "        cv2.applyColorMap(..., cv2.COLORMAP_INFERNO):\n",
    "        Applica il colormap INFERNO che trasforma la scala di grigi in un'immagine a colori, \n",
    "        dove i valori bassi saranno scuri e quelli alti appariranno in toni caldi (ad es. giallo/rosso).\n",
    "        \n",
    "        cv2.cvtColor(..., cv2.COLOR_BGR2RGB):\n",
    "        OpenCV usa il formato BGR per impostazione predefinita. \n",
    "        Convertire in RGB assicura che l'immagine venga visualizzata correttamente (matplotlib si aspetta RGB).\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        '''SOLO UN ESEMPIO'''\n",
    "        #cam_img = cv2.applyColorMap(np.uint8(255 * cams[cls]), cv2.COLORMAP_INFERNO)\n",
    "        \n",
    "        '''CON MEDIA'''\n",
    "        cam_img = cv2.applyColorMap(np.uint8(255 * mean_cams[cls]), cv2.COLORMAP_INFERNO)\n",
    "        \n",
    "        cam_img = cv2.cvtColor(cam_img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        '''QUI AGGIUNGIAMO L'INVERSIONE DEGLI ASSI'''\n",
    "        # Se necessario, inverti gli assi per ottenere la visualizzazione desiderata\n",
    "        cam_img = np.flipud(cam_img)  # Inverte verticalmente\n",
    "        \n",
    "        '''COMMENTATO PER L'OVERLAY SOLO RAPPRESENTARE L'ASSE DEL TEMPO IN FORMATO DI MILLISECONDI E NON DI FINESTRE STFT'''\n",
    "        #axs[0, j].imshow(cam_img)\n",
    "        \n",
    "        # Se conosci i limiti temporali e di frequenza, puoi usare l'argomento extent\n",
    "        axs[0, j].imshow(cam_img, extent=[0, 1000, 0, 26], aspect='auto')\n",
    "        \n",
    "        axs[0, j].set_title(f\"Grad-CAM Mean Heatmap for Class {condition_names[cls]}\", fontsize=12)\n",
    "        axs[0, j].axis('off')\n",
    "    \n",
    "    # Seconda riga: Visualizza gli overlay con etichette degli assi\n",
    "    for j, cls in enumerate([0, 1]):\n",
    "        \n",
    "        '''COMMENTATO PER L'OVERLAY SOLO RAPPRESENTARE L'ASSE DEL TEMPO IN FORMATO DI MILLISECONDI E NON DI FINESTRE STFT'''\n",
    "        #axs[1, j].imshow(overlays[cls])\n",
    "        \n",
    "        # Qui, se vuoi che l'asse y (frequenze) venga ordinato in modo crescente,\n",
    "        # puoi anche invertire l'immagine verticalmente, se non è già corretto.\n",
    "        \n",
    "        '''SOLO UN ESEMPIO'''\n",
    "        #overlay_img = np.flipud(overlays[cls])\n",
    "        \n",
    "        '''CON MEDIA'''\n",
    "        overlay_img = np.flipud(mean_overlays[cls])\n",
    "        \n",
    "        \n",
    "        # Se conosci i limiti temporali e di frequenza, puoi usare l'argomento extent\n",
    "        axs[1, j].imshow(overlay_img, extent=[0, 1000, 0, 26], aspect='auto')\n",
    "        \n",
    "        axs[1, j].set_title(f\"Overlay of Grad-CAM Heatmap for Class {condition_names[cls]}\", fontsize=12)\n",
    "        axs[1, j].set_xlabel(\"Time (mms)\", fontsize=10)\n",
    "        axs[1, j].set_ylabel(\"Frequency (Hz)\", fontsize=10)\n",
    "        axs[1, j].axis('on')\n",
    "    \n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    \n",
    "    \n",
    "    #Passaggio 8: Salvataggio della figura\n",
    "    #Qui la figura viene salvata in un buffer di memoria, pronto per essere salvato o inviato altrove\n",
    "    \n",
    "    # -------------------------------\n",
    "    # Passaggio 8: Salvataggio della figura in un buffer\n",
    "    # -------------\n",
    "\n",
    "    # Salva la figura in un buffer (che potrai poi passare a save_performance_results)\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='png')\n",
    "    buf.seek(0)\n",
    "    fig_image = buf.getvalue()\n",
    "    buf.close()\n",
    "    plt.close(fig)\n",
    "    \n",
    "    return fig_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edefe061-90f6-4bc5-b93a-c89a46385f83",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### **FINAL IMPLEMENTATION OF GRADCAM COMPUTATION PER EEG STATS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b847ff4-7fae-40f0-af76-ddf38539eb89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''GRADCAM ALGORITHM PER RAPPRESENTAZIONE EEG TEMPO x FREQUENZA NUOVA CON \n",
    "\n",
    "1) gestione del cudrnn per modelli con layer LSTM per far sì che il contesto imposta train() per sbloccare CuDNN-RNN, \n",
    "congela BN/Dropout in eval(), abilita i gradienti e ripristina tutto alla fine.\n",
    "\n",
    "2) integri la gestione del test loader in formato raw per i plot sullo spettogramma\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                                                VERSIONE NUOVA PER RAPPRESENTAZIONE TEMPO x FREQUENZA\n",
    "                                                \n",
    "                                                            (POST 27/06 ULTIMA VERSIONE DATATA)\n",
    "                                                                        \n",
    "                                                                        17/09/2025\n",
    "                                                                    \n",
    "                                                                \n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "def model_has_cudnn_rnn(model):\n",
    "    \"\"\"Ritorna True se il modello usa LSTM/GRU/RNN supportati da CuDNN.\"\"\"\n",
    "    return any(isinstance(m, (nn.LSTM, nn.GRU, nn.RNN)) for m in model.modules())\n",
    "    \n",
    "\n",
    "'''RICORDATI: aggiunto parametro TEST_LOADER_RAW per i plots della POTENZA SPETTRALE MEDIA PER BANDA (i.e., test_loader_raw)'''\n",
    "def compute_gradcam_figure(model, test_loader, test_loader_raw, exp_cond, data_type, category_subject, device):\n",
    "    \n",
    "    \n",
    "    '''SOLO PER I MODELLI OTTIMIZZATI CON ANCHE LA LSTM'''\n",
    "    \n",
    "    #Solo i modelli con LSTM entrano in questo giro; gli altri non cambiano di stato.\n",
    "    #Con questa sequenza:\n",
    "    #non ottieni più l’errore “cudnn RNN backward…”;\n",
    "    #la rete “si comporta” come in eval (Dropout off, BN congelato) mentre calcoli le CAM;\n",
    "    #l’ambiente di chiamata (il tuo loop di testing) riceve il modello esattamente nello stato in cui l’aveva passato alla funzione compute_gradcam_figure\n",
    "    \n",
    "\n",
    "    ### Perché serve model.train() anche se la CAM è presa prima della LSTM\n",
    "    \n",
    "    #Il backward, per arrivare dal loss (o dal logit scelto) fino al tuo layer conv3, deve comunque attraversare l’LSTM che sta più avanti nella rete.\n",
    "    #Le implementazioni CuDNN degli RNN (LSTM/GRU) alzano un’eccezione se provi a chiamare tensor.backward() mentre il modulo è in modalità eval().\n",
    "    #RuntimeError: cudnn RNN backward can only be called in training mode\n",
    "    #Quindi, anche se la CAM è calcolata su conv3, devi mettere l’intero modello in train() per il tempo del backward.\n",
    "    #condition_names = exp_cond.split(\"_vs_\") if \"_vs_\" in exp_cond else [\"Class 0\", \"Class 1\"]\n",
    "    \n",
    "    \n",
    "    ### Che cos’è model.training\n",
    "    \n",
    "    #model.training è un semplice flag booleano (impostato da nn.Module.train() / nn.Module.eval()), ereditato da tutti i sotto‑moduli.\n",
    "    #Con was_training = model.training ricordi in che stato era il modello (quasi sempre False, cioè eval, nel tuo flusso)\n",
    "    #per poterlo ripristinare dopo.\n",
    "    \n",
    "    #Facendo così\n",
    "    \n",
    "    #for m in model.modules():\n",
    "    #if isinstance(m, (nn.BatchNorm1d, nn.BatchNorm2d, nn.BatchNorm3d,\n",
    "                      #nn.Dropout, nn.Dropout2d, nn.Dropout3d)):\n",
    "        #if m.training:         # cioè erano in train\n",
    "            #m.eval()\n",
    "            #frozen_layers.append(m)\n",
    "    \n",
    "    #Li sposti in eval uno per uno, senza toccare il resto della rete che deve restare in train() per far funzionare CuDNN‑RNN.\n",
    "    \n",
    "    \n",
    "    ### Perché, a fine blocco, servono due ripristini\n",
    "    \n",
    "    #1) Riattivo i BatchNorm / Dropout che avevo forzato in eval:\n",
    "    \n",
    "    #for m in frozen_layers:\n",
    "        #m.train()              # torna come prima\n",
    "    \n",
    "    #2) Riporto l’intero modello nello stato in cui si trovava prima del Grad‑CAM:\n",
    "    \n",
    "    #model.train(was_training)  # se era eval() torna eval, altrimenti resta train\n",
    "    \n",
    "    #Se non facessi il punto 1, lasceresti quei moduli permanentemente in eval anche quando, più tardi, \n",
    "    #rientri in training (per esempio in un fine‑tuning).\n",
    "    #Se non facessi il punto 2, lasceresti tutto il modello in train → dropout attivo, BN che accumula statistiche, ecc.\n",
    "\n",
    "    \n",
    "    \n",
    "    # ------------------------------------------------------------ ------------------------------------------------------------\n",
    "    # ❶ — se serve, abilito temporaneamente la modalità train per il modello ottimizzato che aveva ANCHE la LSTM... \n",
    "    # ------------------------------------------------------------ ------------------------------------------------------------\n",
    "    \n",
    "    needs_train_mode = model_has_cudnn_rnn(model)\n",
    "    \n",
    "    if needs_train_mode:\n",
    "        was_training = model.training      # salvo lo stato\n",
    "        model.train()                      # abilito backward su CuDNN‑RNN\n",
    "        \n",
    "        # ➊ salvo lo stato di OGNI BN/Dropout\n",
    "        \n",
    "        saved = [(m, m.training) for m in model.modules()\n",
    "             if isinstance(m, (nn.BatchNorm1d, nn.BatchNorm2d, nn.BatchNorm3d,\n",
    "                               nn.Dropout, nn.Dropout2d, nn.Dropout3d))]\n",
    "        \n",
    "        model.train()                              # abilita backward su CuDNN‑RNN\n",
    "        \n",
    "        # ➋ congelo in ogni layer della rete gli strati di BatchNorm e Dropout\n",
    "        for m, _ in saved:\n",
    "            m.eval()\n",
    "    \n",
    "    # ------------------------------------------------------------\n",
    "    # ❷ — QUI sotto metti tutto il tuo codice Grad‑CAM\n",
    "    #      (forward, backward, costruzione delle mappe, plot, …)\n",
    "    # ------------------------------------------------------------\n",
    "\n",
    "    # … il tuo lunghissimo corpo della funzione rimane invariato …\n",
    "    # → al momento di fare backward NON avrà più l’eccezione\n",
    "    #   “cudnn RNN backward can only be called in training mode”\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Passaggio 1: Impostazione del layer target e istanziazione di GradCAM\n",
    "    \n",
    "    #Qui si definisce quale layer convoluzionale sarà usato per la Grad-CAM.\n",
    "    #In questo caso, conv3 è il terzo layer convoluzionale del modello model.\n",
    "    \n",
    "    #Grad-CAM calcola la mappa di attivazione basandosi sulle feature generate da questo livello.\n",
    "    \n",
    "    #🔹 Esempio:Se model.conv3 è un layer convoluzionale con 128 feature map,\n",
    "    #la Grad-CAM genererà una mappa di attivazione basata su queste 128 feature.)\n",
    "\n",
    "\n",
    "    # -------------------------------\n",
    "    # Passaggio 1: Impostazione del layer target e istanziazione di GradCAM\n",
    "    # -------------------------------\n",
    "    \n",
    "    target_layer = model.conv3\n",
    "    gradcam = GradCAM(model, target_layer)\n",
    "    \n",
    "    # Determina il target layer in base al tipo di modello\n",
    "    #if isinstance(model, SeparableCNN2D_LSTM_FC):\n",
    "        #target_layer = model.dw_conv1  # Per il modello separabile 2D\n",
    "    #else:\n",
    "        #target_layer = model.conv3  # Per il modello CNN3D\n",
    "        \n",
    "\n",
    "    condition_names = exp_cond.split(\"_vs_\") if \"_vs_\" in exp_cond else [\"Class 0\", \"Class 1\"]\n",
    "    \n",
    "    \n",
    "    #Passaggio 2: Selezione di un campione per ogni classe\n",
    "    \n",
    "    #Qui la funzione cerca almeno un campione per ciascuna delle due classi (0 e 1) nel test_loader.\n",
    "    \n",
    "    #🔹 Esempio pratico:\n",
    "    #Se il batch contiene:\n",
    "        \n",
    "    #labels = [1, 0, 1, 0, 1]  \n",
    "    #inputs.shape = (5, 1, 64, 64)  # 5 immagini 64x64 in scala di grigi\n",
    "    \n",
    "    #Il codice estrae:\n",
    "\n",
    "    #samples[0] = inputs[1] (il primo esempio della classe 0)\n",
    "    #samples[1] = inputs[0] (il primo esempio della classe 1)\n",
    "    #Se il test_loader non contiene entrambe le classi, la funzione stampa un messaggio di errore e termina.\n",
    "    \n",
    "    # -------------------------------\n",
    "    # Passaggio 2: Selezione dei campioni per ciascuna classe\n",
    "    # -------------------------------\n",
    "    \n",
    "    \n",
    "    # ✅ Raccogli TUTTI i campioni per ciascuna classe\n",
    "    # Itera sul test_loader fino a trovare almeno un esempio per ciascuna classe (0 e 1)\n",
    "    \n",
    "    '''DATI ORIGINALI DEL TEST LOADER'''\n",
    "    samples = {0: [], 1: []}\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        for i, label in enumerate(labels):\n",
    "            label_int = int(label.item())\n",
    "            if label_int in samples:  # Assumendo solo classi 0 e 1\n",
    "                \n",
    "                samples[label_int].append(inputs[i].unsqueeze(0))\n",
    "                \n",
    "    \n",
    "    '''TEST_LOADER RAW (DATI NON STANDARDIZZATI)'''\n",
    "    samples_raw = {0: [], 1: []}\n",
    "    for inputs, labels in test_loader_raw:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        for i, label in enumerate(labels):\n",
    "            label_int = int(label.item())\n",
    "            if label_int in samples_raw:  # Assumendo solo classi 0 e 1\n",
    "                \n",
    "                samples_raw[label_int].append(inputs[i].unsqueeze(0))\n",
    "                \n",
    "    \n",
    "    #Passaggio 3: Calcolo della Grad-CAM\n",
    "    \n",
    "    # Qui il codice:\n",
    "\n",
    "    #Passa l'input al modello per ottenere le predizioni.\n",
    "    #Identifica la classe predetta (target_class).\n",
    "    #Fa il backpropagation per calcolare i gradienti rispetto alla classe target.\n",
    "\n",
    "    #🔹 Esempio pratico:\n",
    "    #Se output = [0.3, 0.7], il modello predice la classe 1, quindi target_class = 1 e il backpropagation calcola il gradiente rispetto a questa classe.\n",
    "    \n",
    "    \n",
    "    # -------------------------------\n",
    "    # Passaggio 3: Calcolo della Grad-CAM per ciascun campione\n",
    "    # -------------------------------\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    L'errore si verifica perché ora la variabile samples[cls] è una lista di tensori (cioè, più campioni) e non un singolo tensore. \n",
    "    Di conseguenza, cercando di eseguire samples[cls].requires_grad ottieni l'errore (dato che la lista non ha l'attributo requires_grad).\n",
    "    Per risolvere il problema devi iterare sui singoli campioni all'interno della lista per ciascuna classe. Ad esempio, sostituisci questo blocco:\n",
    "    \n",
    "    In questo modo, per ogni classe iteri su ciascun campione, calcoli la Grad-CAM e l'overlay, e li accumuli nelle rispettive liste \n",
    "    (cams_list e overlays_list). Successivamente potrai calcolare la media per ciascuna classe e utilizzarla per la visualizzazione.\n",
    "    Con questa modifica non otterrai più l'errore e la logica sarà coerente con l'obiettivo di aggregare i risultati su più campioni.\n",
    "    '''\n",
    "    \n",
    "    '''CON MEDIA'''\n",
    "    cams_list = {0: [], 1: []}\n",
    "    overlays_list = {0: [], 1: []}\n",
    "    \n",
    "    for cls in [0, 1]:\n",
    "        for sample_input in samples[cls]:\n",
    "        \n",
    "        #sample_input = samples[cls]\n",
    "        \n",
    "            sample_input.requires_grad = True  # Abilita il gradiente per il campione\n",
    "\n",
    "            # Esegui forward pass per ottenere l'output del modello\n",
    "            output = model(sample_input)\n",
    "\n",
    "            # Se non viene specificata una classe target, seleziona quella predetta\n",
    "            target_class = output.argmax(dim=1).item()\n",
    "\n",
    "            # Azzeramento dei gradienti e backward pass per la classe target\n",
    "            # Azzera i gradienti e fai backpropagation rispetto al punteggio della target_class\n",
    "            model.zero_grad()\n",
    "            target = output[0, target_class]\n",
    "            target.backward()\n",
    "\n",
    "            #Passaggio 4: Computazione della mappa Grad-CAM\n",
    "\n",
    "            #Qui si calcola la mappa CAM:\n",
    "\n",
    "            #I pesi Grad-CAM sono la media dei gradienti lungo height & width.\n",
    "            #La mappa CAM è la somma pesata delle attivazioni del layer target.\n",
    "            #Si applica ReLU per eliminare i valori negativi.\n",
    "\n",
    "            #🔹 Esempio pratico:\n",
    "            #Se abbiamo 128 feature map in conv3, il calcolo sarà:\n",
    "\n",
    "            #weights = torch.mean(gradcam.gradients, dim=(2, 3), keepdim=True)  # (batch, 128, 1, 1)\n",
    "            #cam = torch.sum(weights * gradcam.activations, dim=1)  # (batch, height, width)\n",
    "\n",
    "            # -------------------------------\n",
    "            # Passaggio 4: Computazione della mappa Grad-CAM\n",
    "            # -------------------------------\n",
    "\n",
    "            # Calcola i pesi: media dei gradienti lungo le dimensioni spaziali (height e width)\n",
    "            weights = torch.mean(gradcam.gradients, dim=(2, 3), keepdim=True)\n",
    "\n",
    "            # Calcola la mappa CAM: somma pesata delle attivazioni\n",
    "            cam = torch.sum(weights * gradcam.activations, dim=1)\n",
    "\n",
    "            # Calcola la CAM: applica ReLU per eliminare i valori negativi\n",
    "            cam = F.relu(cam)\n",
    "            \n",
    "            \n",
    "            '''\n",
    "            \n",
    "            TUTTO IL PASSAGGIO DELLO STEP 5 \n",
    "            \n",
    "            OSSIA NORMALIZZAZIONE i.e.,  NEL SENSO DI RISCALATURA NEL RANGE 0-1 + UPSAMPLING \n",
    "            \n",
    "            (CHE SERVIVA PER UNIFORMARE I VALORI E ADATTARSI ALLA DIMENSIONE DELLA IMMAGINE ORIGINALE \n",
    "            PER VEDERE UN SOLO ESEMPIO DELLA CLASSE RISPETTO ALLA MAPPA DI ATTIVAZIONE E ALL'OVERLAY\n",
    "            DEL GRADCAM RISPETTO ALLA IMMAGINE ORIGINALE)\n",
    "\n",
    "            #🔹 Esempio pratico:\n",
    "            #Se cam ha dimensione 16x16 e l'immagine originale è 64x64, viene interpolata per adattarsi.\n",
    "\n",
    "            \n",
    "            NON SERVE PIU', AD ECCEZIONE DI QUESTE RIGHE CHE ORA TI RIMETTO QUI SOTTO!'''\n",
    "            \n",
    "            '''\n",
    "            \n",
    "            \n",
    "            ✅ Cosa fa correttamente questo codice:\n",
    "            \n",
    "            Estrae i campioni da test_loader separandoli in samples[0] e samples[1].\n",
    "            \n",
    "            Per ogni campione di ogni classe:\n",
    "            \n",
    "            Calcola la Grad-CAM raw (senza riscaling),\n",
    "            La interpola per adattarla alla dimensione originale (n_freq, n_time)\n",
    "            Applica ReLU per tenere solo le attivazioni positive (come da standard Grad-CAM)\n",
    "            La converte in NumPy e la salva in cams_list[cls].\n",
    "            \n",
    "            Alla fine, fa la media delle CAM raw per ciascuna classe:\n",
    "            \n",
    "            mean_cams[cls] = np.mean(np.array(cams_list[cls]), axis=0)\n",
    "            \n",
    "            🔍 Stato attuale del dato\n",
    "            \n",
    "            cams_list[cls] → lista di array cam 2D non normalizzati, uno per ogni trial.\n",
    "            mean_cams[cls] → array 2D (frequenza × tempo), media dei trial per ciascuna classe.\n",
    "            \n",
    "            La normalizzazione Z-score congiunta la farai dopo, sulla base di mean_cams.\n",
    "            \n",
    "            '''\n",
    "            \n",
    "            target_size = (sample_input.shape[2:]) # -> (n_freq, n_time)\n",
    "            \n",
    "            cam = F.interpolate(cam.unsqueeze(1), size = target_size, mode='bilinear', align_corners=False)\n",
    "            \n",
    "            # squeeze\n",
    "            cam = cam.squeeze()                 # tensor 2D\n",
    "            \n",
    "            # Infine sposti su CPU e passi a numpy\n",
    "            cam = cam.cpu().numpy()\n",
    "\n",
    "\n",
    "            '''CON MEDIA'''\n",
    "            # Aggiungi la mappa del singolo esempio alla lista per la classe (per poi dopo farci la media dentro mean_cams!)\n",
    "            cams_list[cls].append(cam)\n",
    "            \n",
    "    \n",
    "    # ============================================================\n",
    "    # Calcolo dello heatmap media dei valori (raw) per ciascuna classe\n",
    "    # ============================================================\n",
    "    \n",
    "    mean_cams = {}\n",
    "    \n",
    "    for cls in [0, 1]:\n",
    "        mean_cams[cls] = np.mean(np.array(cams_list[cls]), axis=0)\n",
    "    \n",
    "    \n",
    "    # ============================================================\n",
    "    # Calcolo dello spettrogramma medio (raw) per ciascuna classe\n",
    "    # ============================================================\n",
    "    \n",
    "    mean_raw_spectrograms = {}\n",
    "    for cls in [0, 1]:\n",
    "        if len(samples_raw[cls]) > 0:\n",
    "            \n",
    "            mean_raw_spectrograms[cls] = torch.cat(samples_raw[cls], dim=0).mean(dim =(0, 1)).detach().cpu().numpy()\n",
    "        else:\n",
    "            mean_raw_spectrograms[cls] = None\n",
    "            \n",
    "            #mean_raw_spectrograms[cls] = torch.cat(samples[cls], dim=0).mean(dim=0).squeeze().cpu().numpy()\n",
    "            '''\n",
    "            🔍 Perché dovrebbe funzionare?\n",
    "            .detach(): Disattiva il tracciamento del gradiente (rende il tensore statico, senza dipendenze dalla computational graph di PyTorch).\n",
    "            .cpu(): Porta il tensore sulla CPU (necessario per numpy()).\n",
    "            .numpy(): Converte il tensore in un array NumPy.\n",
    "            '''\n",
    "            \n",
    "            \n",
    "            '''\n",
    "            \n",
    "            1) Calcolo della media degli spettrogrammi (rimozione dei canali)\n",
    "            L'errore \"Invalid shape (3, 26, 11)\" con questa riga commentata sopra ☝️\n",
    "            \n",
    "            #mean_raw_spectrograms[cls] = torch.cat(samples[cls], dim=0).mean(dim=0).squeeze().detach().cpu().numpy()\n",
    "             \n",
    "            indica che l'array finale ha 3 canali in più (la prima dimensione) che non ti aspetti. \n",
    "            I tuoi dati originali hanno la forma:\n",
    "\n",
    "            (trials, canali, frequenze, tempo)\n",
    "\n",
    "            Se vuoi ottenere una rappresentazione media dello spettrogramma per tutti i trial di una classe, mediando anche sui canali, \n",
    "            allora devi calcolare la media lungo la dimensione dei trial e quella dei canali.\n",
    "            \n",
    "            Dovresti fare:\n",
    "            \n",
    "            mean_raw_spectrograms[cls] = torch.cat(samples[cls], dim=0).mean(dim=(0, 1)).detach().cpu().numpy()\n",
    "            \n",
    "            ************ ************ ************ ************ ************ ************ ************ ************ ************ ************\n",
    "            SPIEGAZIONE:\n",
    "\n",
    "            torch.cat(samples[cls], dim=0)\n",
    "            => Concatena tutti i trial per quella classe lungo la dimensione 0, ottenendo un tensore con forma:\n",
    "            (num_trials, canali, frequenze, tempo).\n",
    "\n",
    "            .mean(dim=(0, 1))\n",
    "            => Calcola la media prima lungo la dimensione dei trial (dim=0) e poi lungo quella dei canali (dim=1) in un'unica operazione, \n",
    "            ottenendo un tensore di forma (frequenze, tempo).\n",
    "\n",
    "            .detach().cpu().numpy()\n",
    "            => Rimuove il tracking del gradiente, sposta il tensore sulla CPU e lo converte in un array NumPy, pronto per imshow.\n",
    "\n",
    "            Questo ti darà l'array 2D (frequenze × tempo) che imshow si aspetta.\n",
    "            \n",
    "            \n",
    "            CHAGPT:\n",
    "            \n",
    "            Nel contesto del tuo esempio:\n",
    "\n",
    "            La forma iniziale dei dati EEG in un formato tempo-frequenza era (batch, canali, frequenze, tempo), che è una matrice 4D. \n",
    "            \n",
    "            Qui, hai un batch di dati, dove ogni dato ha la dimensione dei canali, frequenze, e tempo.\n",
    "\n",
    "            Usando il codice:\n",
    "\n",
    "                mean_raw_spectrograms[cls] = torch.cat(samples[cls], dim=0).mean(dim=(0,1)).detach().cpu().numpy()\n",
    "                \n",
    "            Stai concatenando lungo la dimensione del batch (dim=0), quindi ottieni una matrice che somma tutte le informazioni sul batch. \n",
    "            Successivamente, con .mean(dim=(0,1)) stai calcolando la media lungo le dimensioni dei canali (0) e del batch (1), \n",
    "            riducendo il risultato a una matrice 2D con la forma (frequenze, tempo), che è quella che desideri, ovvero \n",
    "            \n",
    "            --> la media delle frequenze e del tempo su tutto il batch e i canali.\n",
    "\n",
    "            Quindi sì, la forma risultante di mean_raw_spectrograms[cls] sarà una matrice 2D che rappresenta \n",
    "                1) le frequenze sulle righe e \n",
    "                2) il tempo sulle colonne\n",
    "            ************ ************ ************ ************ ************ ************ ************ ************ ************ ************\n",
    "\n",
    "            '''\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    # =======================================================\n",
    "    # Passaggio Finale: Creazione della figura finale\n",
    "    # Ora la figura ha 3 righe:\n",
    "    \n",
    "    #  - Riga 1: Istogramma della distribuzione dei valori della heatmap media per ciascuna classe \n",
    "    #            normalizzata rispetto alla distribuzione congiunta!\n",
    "    \n",
    "    #  - Riga 2: GradCAM medio della distribuzione dei valori della heatmap media per ogni classe, \n",
    "    #            a seguito della normalizzazione rispetto alla distribuzione congiunta!\n",
    "    \n",
    "    #  - Riga 3: Spettrogramma medio (raw) rispetto ai Trial della Stessa Classe, su range logaritmico \n",
    "    # =======================================================\n",
    "    \n",
    "    \n",
    "    Quando devo plottare l'istogramma dei valori di ogni heatmap media solamente (riga 3), \n",
    "    devo plottarli in base alla normalizzazione rispetto alla distribuzione congiunta.\n",
    "    \n",
    "    Quindi, devo plottarli in base al range minimo e massimo della intera distribuzione congiunta, quando è stata normalizzata!\n",
    "    Di conseguenza devo fare\n",
    "    \n",
    "    1) Prendere la Media delle CAM per ogni classe (già fatto)\n",
    "    2) Costruzione distribuzione congiunta raw\n",
    "    3) Calcolo Media e Deviazione Standard della Distribuzione Congiunta\n",
    "    4) Normalizzazione Z-score della Distribuzione Congiunta\n",
    "    \n",
    "    5) Prendo il range minimo e massimo della Distribuzione Congiunta Normalizzata\n",
    "    \n",
    "    Ossia, il range minimo e massimo su cui plottare entrambe le heatmap medie normalizzate in base alla distribuzione congiunta,\n",
    "    dovrà essere rispetto alla distribuzione congiunta a seguito della normalizzazione.\n",
    "    \n",
    "    Quindi, dovrei ricreare un'altra variabile che contiene i valori normalizzati di entrambe le distribuzioni assieme,\n",
    "    ossia una cosa del tipo\n",
    "    \n",
    "    normalized_all_vals = np.concatenate([normalized_mean_cams[0].flatten(), normalized_mean_cams[1].flatten()])\n",
    "    \n",
    "    e da questa prendere il minimo ed il massimo!\n",
    "    \n",
    "    \n",
    "    '''\n",
    "   \n",
    "\n",
    "    # Creiamo una figura con 4 righe e 2 colonne\n",
    "    #fig, axs = plt.subplots(3, 2, figsize=(12, 15))\n",
    "    #plt.suptitle(f\"Grad-CAM Mapping and Overlay over EEG Spectrogram\\nExperimental Conditions: {exp_cond} - Subject: {category_subject}\", fontsize=15)\n",
    "    \n",
    "    #fig, axs = plt.subplots(4, 2, figsize=(12, 20))\n",
    "    #plt.suptitle(f\"Grad-CAM Mapping and Resulting Overlay over EEG Trial Spectrogram\\nExperimental Conditions: {exp_cond} - Subject: {category_subject}\", fontsize=15)\n",
    "    \n",
    "    # Creiamo una figura con 3 righe e 2 colonne\n",
    "    fig, axs = plt.subplots(3, 2, figsize=(12, 15))\n",
    "    plt.suptitle(f\"Grad-CAM Mapping over EEG Trials\\nExperimental Conditions: {exp_cond}\", fontsize=15)\n",
    "    \n",
    "    plt.tight_layout()  # Regola automaticamente la spaziatura globale\n",
    "    plt.subplots_adjust(hspace = 0.5, wspace = 0.4)  # Fine tuning della spaziatura tra subplot\n",
    "    \n",
    "\n",
    "    \n",
    "        \n",
    "    # PLOT RIGA 1: Visualizzazione degli istogrammi della distribuzione dei valori delle heatmap medie RAW\n",
    "    # RISPETTO ALLA DISTRIBUZIONE CONGIUNTA\n",
    "        \n",
    "    '''\n",
    "    Questi valori rappresentano la distribuzione delle attivazioni di entrambe le classi, \n",
    "    rispetto alla DISTRIBUZIONE CONGIUNTA\n",
    "    \n",
    "    Quindi si tratta di valori di attivazione della mappa Grad-CAM media rispetto alla distribuzione congiunta!\n",
    "\n",
    "    Per chiarire meglio il processo:\n",
    "\n",
    "        1) Valori di attivazione: Quando si calcola la Grad-CAM, ottieni una mappa di attivazione per ciascun pixel. \n",
    "                               Questa mappa mostra quanto ciascun pixel contribuisce alla decisione del modello.\n",
    "                               Questi valori di attivazione sono pesati in base ai gradienti della classe di interesse.\n",
    "\n",
    "        2) Mediati per classe: Nel tuo caso, stai calcolando la media di queste attivazioni per ogni classe (ad esempio, classe 0 e classe 1). \n",
    "                            Questo processo permette di ottenere una rappresentazione complessiva di come la rete percepisce l'importanza di ogni pixel \n",
    "                            rispetto alla classe.\n",
    "\n",
    "        3) Istogramma dei valori raw medi di ogni classe (su distribuzione congiunta!): Stai visualizzando un istogramma di questi valori medi, \n",
    "                                                           sulla distribuzione congiunta, ossia\n",
    "                                                           \n",
    "                                                           - prendo i valori (raw)delle heatmap media di entrambe le classi\n",
    "                                                           - calcolare la distribuzione congiunta dei valori (all_vals = ...)\n",
    "                                                           - ottengo quindi la nuova distribuzione congiunta dalle heatmap medie di entrambe le classi\n",
    "                                                          \n",
    "                                                           - calcolo minimo e massimo a seguito della normalizzazione (?) e non prima\n",
    "                                                           - faccio i plot di entrambe delle heatmap medie raw,\n",
    "                                                             ma rispetto a distribuzione congiunta\n",
    "                                                             \n",
    "                                                           \n",
    "                                                           Questo darebbe una visione della distribuzione delle attivazioni,\n",
    "                                                           per capire come i valori siano distribuiti tra le 2 classi (che ora son confrontabili!)\n",
    "                                                           a livello RAW!\n",
    "                                                        \n",
    "    \n",
    "    N.B. PER IL NOME DEL TITOLO DEL PLOT\n",
    "    \n",
    "    Perché \"Grad-CAM value\" può creare confusione:\n",
    "    Il termine \"Grad-CAM value\" potrebbe sembrare che faccia riferimento direttamente ai valori generati dalla mappa Grad-CAM finale. \n",
    "    Ma in realtà, i valori che stai trattando sono le attivazioni mediate e clippate, che formano la heatmap. \n",
    "    L'istogramma che stai tracciando rappresenta la distribuzione delle attivazioni prima della normalizzazione.\n",
    "\n",
    "    Riepilogo\n",
    "    Quindi, questi valori sono attivazioni pesate per ciascun pixel della mappa Grad-CAM, e mediati per classe. \n",
    "    Il processo di normalizzazione che segue (basato sui percentili) serve a enfatizzare il contrasto in modo da focalizzarsi sulle aree più significative \n",
    "    per la previsione.\n",
    "\n",
    "    Per rispondere alla tua domanda: sì, è corretto dire che stai visualizzando la distribuzione delle attivazioni pesate prima della normalizzazione\n",
    "    per migliorare il contrasto, ma è meglio riferirsi a questi valori come valori di attivazione della mappa Grad-CAM o valori della heatmap Grad-CAM, \n",
    "    piuttosto che \"Grad-CAM value\" che potrebbe risultare ambiguo.\n",
    "\n",
    "    Se vuoi, puoi anche aggiungere una nota nella visualizzazione dell'istogramma che chiarisca il processo:\n",
    "    \n",
    "    axs[2, j].set_title(f\"Histogram of Heatmap Activation Values (Raw, before Normalization) Class {condition_names[cls]}\", fontsize=12)\n",
    "    oppure\n",
    "    axs[2, j].set_title(f\"Histogram of Mean Heatmap Activation Values - Class {condition_names[cls]}\", fontsize=12)\n",
    "    \n",
    "    è molto chiara e corretta!\n",
    "    Indica perfettamente che stai visualizzando l'istogramma dei valori di attivazione medi della heatmap, \n",
    "    senza fare confusione sul fatto che si tratti di valori medi per ciascuna classe.\n",
    "    \n",
    "    In sintesi, questa frase comunica in modo preciso che stai mostrando la distribuzione delle attivazioni mediate dalla mappa Grad-CAM\n",
    "    per una specifica classe. Quindi sì, va benissimo!\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    #PER PLOT RIGA 1 \n",
    "    \n",
    "    # Creo la distribuzione congiunta dei valori di ogni heatmap media RAW delle due classi, srotolando i valori di entrambe\n",
    "    \n",
    "    '''PRE 45 Hz'''\n",
    "    #all_vals_raw = np.concatenate([mean_cams[0].flatten(), mean_cams[1].flatten()])\n",
    "    \n",
    "    '''MODIFICA PER FREQUENZA FINO A 45Hz'''\n",
    "    all_vals_raw = np.concatenate([mean_cams[0][:46, :].flatten(), mean_cams[1][:46, :].flatten()])\n",
    "    \n",
    "    # Il range minimo e massimo su cui plottare entrambe le heatmap medie raw in base alla distribuzione congiunta (riga 3)\n",
    "    # dovrà essere rispetto alla distribuzione congiunta raw\n",
    "    \n",
    "    vmin_raw = all_vals_raw.min()\n",
    "    vmax_raw = all_vals_raw.max()\n",
    "    \n",
    "    \n",
    "    # Prima riga: Visualizza l'istogramma della heatmap media rispetto alla distribuzione congiunta!\n",
    "    for j, cls in enumerate([0, 1]):\n",
    "        \n",
    "        # Calcola l'istogramma dei valori della heatmap media (prima della normalizzazione robusta)\n",
    "        \n",
    "        '''PRE 45 Hz'''\n",
    "        #axs[0, j].hist(mean_cams[cls].flatten(), bins= 'auto', color='blue', edgecolor='black')\n",
    "        \n",
    "        '''MODIFICA PER FREQUENZA FINO A 45Hz'''\n",
    "        axs[0, j].hist(mean_cams[cls][:46, :].flatten(), bins= 'auto', color='blue', edgecolor='black')\n",
    "        \n",
    "        \n",
    "        #axs[0, j].set_title(f\"Histogram of Mean Grad-CAM values (Raw) - Class {condition_names[cls]}\", fontsize=12)\n",
    "        axs[0, j].set_title(f\"Histogram of Mean Heatmap Activation Values (Raw) - Class {condition_names[cls]}\", fontsize=12)\n",
    "        axs[0, j].set_xlabel(\"Grad-CAM value\", fontsize=10)\n",
    "        axs[0, j].set_ylabel(\"Frequency\", fontsize=10)\n",
    "        \n",
    "        \n",
    "    \n",
    "    # PLOT RIGA 2: Visualizzazione dei valori delle heatmap medie delle due classi\n",
    "    # RISPETTO ALLA DISTRIBUZIONE CONGIUNTA, SU CUI VIENE FATTA LA NORMALIZZAZIONE\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    Questi valori rappresentano le heatmap medie delle attivazioni di entrambe le classi, \n",
    "    rispetto alla DISTRIBUZIONE CONGIUNTA, SU CUI VIENE FATTA LA NORMALIZZAZIONE\n",
    "    \n",
    "    Quindi si tratta di valori di attivazione della mappa Grad-CAM media rispetto alla distribuzione congiunta NORMALIZZATA\n",
    "\n",
    "    Per chiarire meglio il processo:\n",
    "\n",
    "        1) Valori di attivazione: Quando si calcola la Grad-CAM, ottieni una mappa di attivazione per ciascun pixel. \n",
    "                               Questa mappa mostra quanto ciascun pixel contribuisce alla decisione del modello.\n",
    "                               Questi valori di attivazione sono pesati in base ai gradienti della classe di interesse.\n",
    "\n",
    "        2) Mediati per classe: Nel tuo caso, stai calcolando la media di queste attivazioni per ogni classe (ad esempio, classe 0 e classe 1). \n",
    "                            Questo processo permette di ottenere una rappresentazione complessiva di come la rete percepisce l'importanza di ogni pixel \n",
    "                            rispetto alla classe.\n",
    "\n",
    "        3) Calcolo la distribuzione congiunta dei valori raw medi di ogni classe (su distribuzione congiunta!): \n",
    "        Stai visualizzando un istogramma di questi valori medi, sulla DISTRIBUZIONE CONGIUNTA, ossia\n",
    "                                                           \n",
    "                                                           - prendo i valori (raw)delle heatmap media di entrambe le classi\n",
    "                                                           - calcolare la distribuzione congiunta dei valori (all_vals = ...)\n",
    "                                                           - ottengo quindi la nuova distribuzione congiunta dalle heatmap medie di entrambe le classi\n",
    "                                                           \n",
    "                                                           - calcolo media e deviazione standard delle distribuzione congiunta\n",
    "                                                           - faccio la normalizzazione della distribuzione congiunta\n",
    "                                                           \n",
    "                                                           - calcolo minimo e massimo a seguito della normalizzazione e non prima\n",
    "                                                             della distribuzione congiunta normalizzata\n",
    "                                                           \n",
    "                                                           - faccio i plot di entrambe delle heatmap medie normalizzate,\n",
    "                                                             ma rispetto alla distribuzione congiunta\n",
    "                                                             \n",
    "                                                           \n",
    "                                                           Questo darebbe una visione della distribuzione delle attivazioni,\n",
    "                                                           per capire come i valori siano distribuiti tra le 2 classi (che ora son confrontabili!)\n",
    "                                                           a livello NORMALIZZATO!\n",
    "                                                        \n",
    "    '''\n",
    "    \n",
    "    '''SOPRA ABBIAMO CREATO --> all_vals_raw'''\n",
    "    \n",
    "    # Creo la distribuzione congiunta dei valori di ogni heatmap media RAW delle due classi, srotolando i valori di entrambe\n",
    "    #all_vals_raw = np.concatenate([mean_cams[0].flatten(), mean_cams[1].flatten()])\n",
    "    \n",
    "    #Calcolo media e deviazione standard della distribuzione congiunta dei valori (raw) delle heatmap medie di entrambe le classi \n",
    "    #joint_mean = np.mean(all_vals_raw)\n",
    "    #joint_std = np.std(all_vals_raw)\n",
    "    \n",
    "    # Normalizzazione Z-score della distribuzione congiunta\n",
    "    #normalized_mean_cams = {}\n",
    "    \n",
    "    #for cls in [0, 1]:\n",
    "        #normalized_mean_cams[cls] = (mean_cams[cls] - joint_mean) / joint_std\n",
    "\n",
    "    # Il range minimo e massimo su cui plottare entrambe le heatmap medie normalizzate in base alla distribuzione congiunta (riga 3)\n",
    "    # dovrà essere rispetto alla distribuzione congiunta a seguito della normalizzazione\n",
    "    \n",
    "    #normalized_all_vals = np.concatenate([normalized_mean_cams[0].flatten(), normalized_mean_cams[1].flatten()])\n",
    "    \n",
    "    #vmin_normalized = normalized_all_vals.min()\n",
    "    #vmax_normalized = normalized_all_vals.max()\n",
    "    \n",
    "    vmin_normalized = all_vals_raw.min()\n",
    "    vmax_normalized = all_vals_raw.max()\n",
    "\n",
    "    \n",
    "    '''\n",
    "    # Opzione: normalizzazione robusta con percentili\n",
    "    vmin_normalized, vmax_normalized = np.percentile(all_vals_raw, [5, 95])\n",
    "    '''\n",
    "    \n",
    "    # Seconda riga: Mean heatmap di ogni classe normalizzata a partire dalla distribuzione congiunta ( = di entrambe le classi)\n",
    "    for j, cls in enumerate([0, 1]):\n",
    "        \n",
    "        \n",
    "        im = axs[1, j].imshow(\n",
    "            mean_cams[cls],\n",
    "            #normalized_mean_cams[cls], #QUI LA RENDO IN 2D, NON IN 1D COME PRIMA\n",
    "            #cmap='seismic',\n",
    "            cmap='RdYlBu_r',\n",
    "            vmin= vmin_normalized, vmax= vmax_normalized,\n",
    "            extent=[0, 4000, 0, 81],\n",
    "            aspect='auto',\n",
    "            origin='lower'\n",
    "        )\n",
    "        \n",
    "        \n",
    "        # → calcola 6 tick equi-spaziati\n",
    "        ticks = np.linspace(vmin_normalized, vmax_normalized, 6)  \n",
    "        \n",
    "        cbar = fig.colorbar(\n",
    "            im,\n",
    "            ax=axs[1, j],\n",
    "            orientation='horizontal',\n",
    "            pad=0.12,\n",
    "            ticks=ticks)\n",
    "        \n",
    "        cbar.ax.set_xticklabels([f\"{t:.4f}\" for t in ticks])\n",
    "\n",
    "        \n",
    "        axs[1, j].set_title(f\"Mean Grad-CAM Heatmap (Raw) - Class {condition_names[cls]}\", fontsize=12)\n",
    "        \n",
    "        '''QUESTA NON CONSENTE DEFINIZIONE ASSI!'''\n",
    "        #axs[1, j].axis('off')\n",
    "        \n",
    "        axs[1, j].axis('on') \n",
    "        axs[1,j].set_xlabel(\"Time (mms)\")\n",
    "        axs[1,j].set_ylabel(\"Frequency (Hz)\")\n",
    "        \n",
    "        \n",
    "        '''MODIFICA PER FREQUENZA FINO A 45Hz'''\n",
    "        axs[1, j].set_ylim(0, 45)\n",
    "        \n",
    "        #fig.colorbar(im, ax=axs[3, j], orientation='horizontal', pad=0.05)\n",
    "    \n",
    "    print(f\"\\033[1mRange heatmap raw globale (vmin_raw, vmax_raw): {vmin_normalized}, {vmax_normalized}\\033[0m\")\n",
    "    \n",
    "    # PLOT RIGA 3: Spettrogramma medio (raw) per ciascuna classe log-scaled\n",
    "    \n",
    "    '''\n",
    "    Spiegazione delle modifiche aggiunte:\n",
    "\n",
    "    1) Calcolo dello spettrogramma medio raw:\n",
    "\n",
    "    Dopo aver raccolto i campioni nel dizionario samples, viene creato il dizionario mean_raw_spectrograms.\n",
    "    Per ogni classe, i tensori vengono concatenati lungo la dimensione batch e si calcola la media sul batch (dim=0).\n",
    "    \n",
    "    Poi, però, ogni spettogramma medio deve congiunto in una distribuzione in modo da plottare poi il valore dello spettrogramma  \n",
    "    rispetto al minimo ed al massimo della distribuzione congiunta dello spettrogramma medio di entrambe le classi! \n",
    "    \n",
    "    Il risultato viene convertito in un array NumPy per il plotting.\n",
    "    '''\n",
    "    \n",
    "    # Calcolo della distribuzione congiunta degli spettrogrammi medi delle due classi! \n",
    "    #all_vals_raw_samples = np.concatenate([mean_raw_spectrograms[0].flatten(), mean_raw_spectrograms[1].flatten()])\n",
    "    \n",
    "    '''SE VOLESSI RESTRINGERE TRA 5° e 95° PERCENTILE'''\n",
    "    #low_raw, high_raw = np.percentile(all_vals_raw, [5, 95])\n",
    "    #half_width_raw = max(abs(low_raw), abs(high_raw))   \n",
    "    #vmin_raw, vmax_raw = -half_width_raw, +half_width_raw\n",
    "    \n",
    "    '''ALTRIMENTI, TENGO TUTTO IL RANGE, DAL MINIMO AL MASSIMO'''\n",
    "    \n",
    "    #Ora qui prendo il miimo e massimo a partire dalla distribuzione congiunta!\n",
    "    #vmin_raw_samples, vmax_raw_samples = all_vals_raw_samples.min(), all_vals_raw_samples.max()\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    1) Qual è la differenza tra prima e ora?\n",
    "    \n",
    "    Prima calcolavo, dentro il for cls in [0,1], un nuovo vmin_raw_samples e vmax_raw_samples separatamente per ciascuna classe.\n",
    "    Di conseguenza ogni subplot sulla riga 3 aveva la sua scala di colori, rendendo impossibile un confronto diretto visivo \n",
    "    fra le due condizioni.\n",
    "    \n",
    "    Ora invece calcolerai una sola volta il log-power medio di entrambe le classi, ne ricavi un unico array congiunto,\n",
    "    quindi ne estrai un solo vmin e vmax. Questo ti garantisce che entrambi i subplot della riga 3 useranno la stessa scala di colori.\n",
    "\n",
    "\n",
    "    Per far sì che tutte e due le condizioni usino lo stesso minimo e massimo, sposto la raccolta dei limiti fuori dal ciclo,\n",
    "    usando la distribuzione congiunta dei log-power di entrambe le classi\n",
    "    \n",
    "    vmin_raw_samples e vmax_raw_samples li calcoli una volta sola, su tutti i valori logaritmici concatenati.\n",
    "    Entrambe le mappe usano esattamente lo stesso range, così le barre dei colori saranno allineate.\n",
    "    \n",
    "    Con questa modifica:\n",
    "\n",
    "    log_mean_power contiene già i valori in scala logaritmica.\n",
    "    vmin_raw_samples e vmax_raw_samples sono condivisi fra entrambe le colonne.\n",
    "    Ogni subplot userà la stessa “barretta” di colore, quindi potrai confrontare direttamente “deep blues” e “reds” delle due condizioni.\n",
    "    '''\n",
    "    \n",
    "    # 1. Calcola i log-power medi per ciascuna classe\n",
    "    log_mean_power = {\n",
    "        cls: np.log1p(mean_raw_spectrograms[cls])\n",
    "        for cls in [0,1]\n",
    "    }\n",
    "\n",
    "    # 2. Raccogli TUTTI i valori in un unico array\n",
    "    \n",
    "    '''PRE 45 Hz'''\n",
    "    #all_log_vals = np.concatenate([\n",
    "    #    log_mean_power[0].flatten(),\n",
    "    #    log_mean_power[1].flatten()\n",
    "    #])\n",
    "    \n",
    "    \n",
    "    '''MODIFICA PER FREQUENZA FINO A 45Hz'''\n",
    "    \n",
    "    all_log_vals = np.concatenate([\n",
    "        log_mean_power[0][:46, :].flatten(),\n",
    "        log_mean_power[1][:46, :].flatten()\n",
    "    ])\n",
    "    \n",
    "\n",
    "    # 3. Estrai un unico vmin/vmax condiviso\n",
    "    vmin_raw_samples = all_log_vals.min()\n",
    "    vmax_raw_samples = all_log_vals.max()\n",
    "\n",
    "        \n",
    "    # Se conosci i limiti temporali e di frequenza, puoi usare l'argomento extent\n",
    "    for j, cls in enumerate([0, 1]):\n",
    "        \n",
    "        #if mean_raw_spectrograms[cls] is not None:\n",
    "        if log_mean_power[cls] is not None:    \n",
    "            \n",
    "            #Trasformo in scala logaritmica i miei dati EEG sulla spettro medio di ogni classe\n",
    "            #mean_raw_spectrograms[cls] = np.log1p(mean_raw_spectrograms[cls])\n",
    "        \n",
    "            \n",
    "            # Calcolo della distribuzione congiunta degli spettrogrammi medi delle due classi! \n",
    "            #all_vals_raw_samples = np.concatenate([mean_raw_spectrograms[0].flatten(), mean_raw_spectrograms[1].flatten()])\n",
    "            \n",
    "            #Ora qui prendo il miimo e massimo a partire dalla distribuzione congiunta!\n",
    "            #vmin_raw_samples, vmax_raw_samples = all_vals_raw_samples.min(), all_vals_raw_samples.max()\n",
    "    \n",
    "            im = axs[2, j].imshow(log_mean_power[cls], \n",
    "                                  #mean_raw_spectrograms[cls], \n",
    "                                  extent=[0, 4000, 0, 81],\n",
    "                                  aspect='auto', \n",
    "                                  cmap='jet', \n",
    "                                  vmin = vmin_raw_samples, vmax = vmax_raw_samples,\n",
    "                                  origin='lower')\n",
    "            \n",
    "            axs[2, j].set_title(f\"Log-Scaled Mean Raw Spectrogram - Class {condition_names[cls]}\", fontsize=12)\n",
    "            axs[2, j].set_xlabel(\"Time (mms)\", fontsize=10)\n",
    "            axs[2, j].set_ylabel(\"Frequency (Hz)\", fontsize=10)\n",
    "            \n",
    "        \n",
    "            '''MODIFICA PER FREQUENZA FINO A 45Hz'''\n",
    "            axs[2, j].set_ylim(0, 45)\n",
    "            \n",
    "            '''\n",
    "            \n",
    "            ATTENZIONE QUI CHE C'ERA UN GRAVE ERRORE\n",
    "            \n",
    "            --> fig.colorbar(im, ax=axs[3, j]) \n",
    "            \n",
    "            #Qui la Color Bar Verticale sarebbe \n",
    "            #scala dello spettrogramma raw, finita per sbaglio sul Δ-GradCAM perché hai scritto ax=axs[3,j] invece di ax=axs[4,j].\n",
    "            \n",
    "            \n",
    "            La barra VERTICALE (CHE DOVEVA STAR NELLA 5° RIGA!!!!) della color bar accanto alla heatmap ti sta mostrando\n",
    "            \n",
    "            i VALORI ASSOLUTI della Grad-CAM (nel tuo caso non normalizzati, quindi scala di milioni --> variabile hist_data\n",
    "            ossia l'istogramma dei valori della heatmap media (prima della normalizzazione robusta)\n",
    "            '''\n",
    "            fig.colorbar(im, ax=axs[2, j])\n",
    "            \n",
    "            axs[2, j].axis('on')\n",
    "        else:\n",
    "            axs[2, j].axis(\"off\")\n",
    "            \n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    \n",
    "    \n",
    "    # ------------------------------------------------------------ ------------------------------------------------------------\n",
    "    # ❸ — Ripristino allo stato precedente il modello ottimizzato trovato migliore, che aveva incluso anche layer LSTM\n",
    "    # ------------------------------------------------------------ ------------------------------------------------------------\n",
    "    \n",
    "    if needs_train_mode:\n",
    "        # ➌ ripristino layer singoli (i.e., riporto BN/Dropout dove stavano in eval mode)\n",
    "        for m, old_flag in saved:\n",
    "            m.train(old_flag)\n",
    "        # ➍ ripristino lo stato globale del modello (di nuovo ad .eval())\n",
    "        # i.e.,  come era stato passato in input alla funzione compute_gradcam_figure a partire 'load_best_run_results'!\n",
    "        \n",
    "        #Così simuli l’eval (Dropout off, BN congelato) pur essendo in train() per soddisfare CuDNN‑RNN.\n",
    "        model.train(was_training)\n",
    "        \n",
    "    \n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Passaggio 8: Salvataggio della figura\n",
    "    #Qui la figura viene salvata in un buffer di memoria, pronto per essere salvato o inviato altrove\n",
    "    \n",
    "    # -------------------------------\n",
    "    # Passaggio 8: Salvataggio della figura in un buffer\n",
    "    # -------------\n",
    "\n",
    "    # Salva la figura in un buffer (che potrai poi passare a save_performance_results)\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='png')\n",
    "    buf.seek(0)\n",
    "    fig_image = buf.getvalue()\n",
    "    buf.close()\n",
    "    plt.close(fig)\n",
    "    \n",
    "    return fig_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e152d0e-002e-4be2-9c45-dba5d77daabd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a2900435-6c78-4c92-8bb8-cb1c4eacd0c7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### **MODELLI CNN2D_LSTM_TF, BiLSTM e Transformer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321fa60a-fe56-4745-8694-653222f41fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "DEFINIZIONE DEI MODELLI NEW VERSION PER SPETTROGRAMMI\n",
    "'''\n",
    "\n",
    "\n",
    "'''CNN2D_LSTM_TF\n",
    "\n",
    "Spiegazione dettagliata dei passaggi\n",
    "\n",
    "1) Input\n",
    "\n",
    "Shape Iniziale: (batch_size, 64, 81, 9)\n",
    "64 canali EEG, 81 bin di frequenza, 9 finestre temporali\n",
    "\n",
    "2) Block 1\n",
    "\n",
    "BatchNorm2d(64) normalizza ciascun canale\n",
    "Conv2d(64→32, 3×3, padding=1) produce 32 mappe (B,32,81,9)\n",
    "ReLU mantiene la stessa shape\n",
    "MaxPool2d(2,2) dimezza: frequenza 81→40, time 9→4 → (B,32,40,4)\n",
    "\n",
    "3) Block 2 “residuo”\n",
    "\n",
    "res = x salva skip (B,32,40,4)\n",
    "res_conv 1×1: Conv2d(32→64,k=1) riallinea i canali → (B,64,40,4)\n",
    "res_bn normalizza → (B,64,40,4)\n",
    "\n",
    "    Main path:\n",
    "\n",
    "        BatchNorm2d(32) → (B,32,40,4)\n",
    "        Conv2d(32→64,3×3,pad=1) + ReLU → (B,64,40,4)\n",
    "        BatchNorm2d(64) → (B,64,40,4)\n",
    "        Conv2d(64→64,3×3,pad=1) → (B,64,40,4)\n",
    "\n",
    "    Somma residua: (B,64,40,4) + (B,64,40,4) → (B,64,40,4)\n",
    "    ReLU + Pool: dimezza → (B,64,20,2)\n",
    "\n",
    "4) Block 3\n",
    "\n",
    "    Conv2d(64→128,3×3,pad=1) + BatchNorm + ReLU → (B,128,20,2)\n",
    "    MaxPool2d → frequenza 20→10, time 2→1 → (B,128,10,1)\n",
    "\n",
    "5) Preparazione per LSTM\n",
    "\n",
    "    permute(0,2,1,3): porta freq come sequenza → (B,10,128,1)\n",
    "    reshape(b,10,128*1): collapse canali×time → (B,10,128)\n",
    "\n",
    "6) LSTM + testata finale\n",
    "\n",
    "    Dropout 0.2 su (B,10,128)\n",
    "    LSTM unidirezionale 128→64: produce out = (B,10,64)\n",
    "    Estrai ultimo timestep out[:, -1, :] → (B,64)\n",
    "    Linear(64→2) → logits (B,2)\n",
    "\n",
    "Così hai un modello che parte da 64 canali EEG, mantiene l’architettura a 3 blocchi residui + LSTM del paper, e termina con una classificazione binaria.\n",
    "\n",
    "'''\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN2D_LSTM_TF(nn.Module):\n",
    "\n",
    "    def __init__(self, input_channels=64, num_classes=2, dropout=0.2):\n",
    "        super().__init__()\n",
    "        # --- Block 1 ---\n",
    "        self.bn1   = nn.BatchNorm2d(input_channels)    # normalizza 64 canali\n",
    "        self.conv1 = nn.Conv2d(input_channels, 32, kernel_size=3, padding=1)\n",
    "        self.pool  = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # --- Block 2 (residual) ---\n",
    "        # Proiezione 1×1 per riallineare i canali di skip (32→64)\n",
    "        self.res_conv = nn.Conv2d(32, 64, kernel_size=1, bias=False)\n",
    "        self.res_bn   = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.bn2a   = nn.BatchNorm2d(32)\n",
    "        self.conv2a = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn2b   = nn.BatchNorm2d(64)\n",
    "        self.conv2b = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "\n",
    "        # --- Block 3 ---\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.bn3   = nn.BatchNorm2d(128)\n",
    "\n",
    "        # --- Head: Dropout + LSTM + FC finale ---\n",
    "        self.dropout     = nn.Dropout(dropout)\n",
    "        self.hidden_size = 64\n",
    "        \n",
    "        # dopo 3 pool: freq da 81→10, time da 9→1 → feature per timestep = 128×1\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=128,\n",
    "            hidden_size=self.hidden_size,\n",
    "            num_layers=1,\n",
    "            batch_first=True,\n",
    "            bidirectional=False\n",
    "        )\n",
    "        self.classifier = nn.Linear(self.hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B,64,81,9)\n",
    "\n",
    "        # --- Block 1 ---\n",
    "        x = self.bn1(x)                   # → (B,64,81,9)\n",
    "        x = F.relu(self.conv1(x))         # → (B,32,81,9)\n",
    "        x = self.pool(x)                  # → (B,32,40,4)\n",
    "\n",
    "        # --- Block 2 (residuo) ---\n",
    "        res = x                           # skip: (B,32,40,4)\n",
    "        res = self.res_conv(res)          # progetto: → (B,64,40,4)\n",
    "        res = self.res_bn(res)            # → (B,64,40,4)\n",
    "\n",
    "        # main path\n",
    "        x = self.bn2a(x)                  # → (B,32,40,4)\n",
    "        x = F.relu(self.conv2a(x))        # → (B,64,40,4)\n",
    "        x = self.bn2b(x)                  # → (B,64,40,4)\n",
    "        x = self.conv2b(x)                # → (B,64,40,4)\n",
    "\n",
    "        x = x + res                       # somma residua valida → (B,64,40,4)\n",
    "        x = F.relu(x)                     \n",
    "        x = self.pool(x)                  # → (B,64,20,2)\n",
    "\n",
    "        # --- Block 3 ---\n",
    "        x = F.relu(self.bn3(self.conv3(x)))  # → (B,128,20,2)\n",
    "        x = self.pool(x)                     # → (B,128,10,1)\n",
    "\n",
    "        # --- Prepara per LSTM ---\n",
    "        x = x.permute(0, 2, 1, 3)         # → (B,10,128,1)\n",
    "        b, seq, ch, tw = x.size()        \n",
    "        x = x.reshape(b, seq, ch * tw)    # → (B,10,128)\n",
    "\n",
    "        # --- LSTM + classificazione ---\n",
    "        out, _ = self.lstm(self.dropout(x))  # → out: (B,10,64)\n",
    "        last = out[:, -1, :]                 # prendo l’ultima uscita → (B,64)\n",
    "        logits = self.classifier(last)       # → (B,2)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c213a499-f168-4567-bea2-a506ccd8b740",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "DEFINIZIONE DEI MODELLI NEW VERSION PER SPETTROGRAMMI\n",
    "'''\n",
    "\n",
    "\n",
    "'''CNN2D\n",
    "\n",
    "Una CNN2D si aspetta input in forma (batch, canali, altezza, larghezza). \n",
    "Nel tuo caso, puoi interpretare l’\"altezza\" come i bin di frequenza (38)\n",
    "e la \"larghezza\" come le finestre temporali (6).\n",
    "\n",
    "Quindi, la tua CNN2D lavorerebbe direttamente con:\n",
    "Shape: (batch, canali, frequenze, tempo)\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "class CNN2D(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_channels, num_classes):\n",
    "        \n",
    "        super(CNN2D, self).__init__()\n",
    "        \n",
    "        # Ipotizziamo kernel 3x3 con padding per mantenere le dimensioni (puoi adattare a tuo piacimento)\n",
    "        self.conv1 = nn.Conv2d(input_channels, 16, kernel_size=(2, 2), stride=(1, 1), padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=(2, 2))\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=(2, 2), stride=(1, 1), padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.pool2 = nn.AvgPool2d(kernel_size=(2, 2))\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(32, 48, kernel_size=(2, 2), stride=(1, 1), padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(48)\n",
    "        self.pool3 = nn.AvgPool2d(kernel_size=(2, 2))\n",
    "        \n",
    "        # Utilizzo LazyLinear per evitare di calcolare manualmente la dimensione piatta finale\n",
    "        self.fc1 = nn.LazyLinear(8)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.LazyLinear(num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # x: (batch, canali, frequenze, tempo)\n",
    "        \n",
    "        # Passaggio attraverso il primo strato convoluzionale, BatchNorm e pooling\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)  # Batch Normalization\n",
    "        x = F.elu(x)\n",
    "        #x = torch.tanh(x)  # Sostituito ELU con tanh\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        # Passaggio attraverso il secondo strato convoluzionale, BatchNorm e pooling\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)  # Batch Normalization\n",
    "        x = F.elu(x)\n",
    "        #x = torch.tanh(x)  # Sostituito ELU con tanh\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        # Passaggio attraverso il secondo strato convoluzionale, BatchNorm e pooling\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)  # Batch Normalization\n",
    "        x = F.elu(x)\n",
    "        x = torch.tanh(x)  # Sostituito ELU con tanh\n",
    "        x = self.pool3(x)\n",
    "\n",
    "        # Flatten per preparare i dati per gli strati fully connected\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "\n",
    "        # Passaggio attraverso il primo strato fully connected\n",
    "        x = self.fc1(x)\n",
    "        x = F.elu(x)\n",
    "        #x = torch.tanh(x)  # Sostituito ELU con tanh\n",
    "\n",
    "        # Dropout per evitare overfitting\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # Passaggio attraverso il secondo strato fully connected\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "Gli LSTM si aspettano un input in forma (batch, lunghezza_sequenza, dimensione_feature). \n",
    "Dovrai quindi decidere qual è la dimensione sequenziale.\n",
    "\n",
    "Opzione comune: usare il tempo come sequenza\n",
    "Step 1: Trasponi i dati in modo da avere il tempo come dimensione sequenziale.\n",
    "\n",
    "Dalla forma (batch, canali, frequenze, tempo) puoi fare:\n",
    "\n",
    "\n",
    "x = x.permute(0, 3, 1, 2)  # Diventa (batch, tempo, canali, frequenze)\n",
    "\n",
    "Step 2: Unisci le dimensioni dei canali e dei bin di frequenza in un’unica dimensione di feature:\n",
    "\n",
    "\n",
    "batch, tempo, canali, frequenze = x.shape\n",
    "x = x.reshape(batch, tempo, canali * frequenze)  # Ora: (batch, tempo, canali*frequenze)\n",
    "\n",
    "Nel tuo caso, per 3 canali e 38 bin di frequenza: input_size = 3 * 38 = 114 e lunghezza sequenza = 6.\n",
    "\n",
    "Nota: Se invece preferisci usare i bin di frequenza come sequenza, potresti fare:\n",
    "\n",
    "x = x.permute(0, 2, 1, 3)  # (batch, frequenze, canali, tempo)\n",
    "x = x.reshape(batch, frequenze, canali * tempo)  # Sequence length = 38, feature size = 3*6 = 18\n",
    "La scelta dipende dal tipo di informazione temporale o spettrale che vuoi evidenziare.\n",
    "\n",
    "'''\n",
    "\n",
    "class ReadMEndYou(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_sizes, output_size, dropout=0.5, bidirectional=False):\n",
    "        \"\"\"\n",
    "        input_size: dimensione delle feature per time-step (dovrà essere canali * frequenze)\n",
    "        hidden_sizes: lista con le dimensioni degli hidden state, es. [24, 48, 62]\n",
    "        output_size: numero di classi\n",
    "        \n",
    "        \"\"\"\n",
    "    \n",
    "        super(ReadMEndYou, self).__init__()\n",
    "        \n",
    "        self.bidirectional = bidirectional # Impostazione della bidirezionalità    \n",
    "        \n",
    "        # Adattiamo hidden_size in base alla bidirezionalità\n",
    "        self.hidden_sizes = [\n",
    "            hidden_sizes[0] * 2 if bidirectional else hidden_sizes[0],\n",
    "            hidden_sizes[1] * 2 if bidirectional else hidden_sizes[1],\n",
    "            hidden_sizes[2] * 2 if bidirectional else hidden_sizes[2]\n",
    "        ]\n",
    "        \n",
    "        self.lstm1 = nn.LSTM(input_size=input_size, \n",
    "                             hidden_size=self.hidden_sizes[0], \n",
    "                             num_layers=1, \n",
    "                             batch_first=True, \n",
    "                             dropout=0, \n",
    "                             bidirectional=bidirectional)\n",
    "        self.lstm2 = nn.LSTM(input_size=self.hidden_sizes[0] * 2 if bidirectional else self.hidden_sizes[0],\n",
    "                             hidden_size=self.hidden_sizes[1], \n",
    "                             num_layers=1, \n",
    "                             batch_first=True, \n",
    "                             dropout=0,\n",
    "                             bidirectional=bidirectional)\n",
    "        self.lstm3 = nn.LSTM(input_size=self.hidden_sizes[1] * 2 if bidirectional else self.hidden_sizes[1],\n",
    "                             hidden_size=self.hidden_sizes[2],\n",
    "                             num_layers=1, \n",
    "                             batch_first=True, \n",
    "                             dropout=0,\n",
    "                             bidirectional=bidirectional)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(self.hidden_sizes[2] * 2 if bidirectional else self.hidden_sizes[2], output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # x: (batch, canali, frequenze, tempo)\n",
    "        \n",
    "        # Trasponi per avere il tempo come dimensione sequenziale:\n",
    "        x = x.permute(0, 3, 1, 2)  # -> (batch, tempo, canali, frequenze)\n",
    "        \n",
    "        batch, time, channels, freqs = x.shape\n",
    "        \n",
    "        x = x.reshape(batch, time, channels * freqs)  # -> (batch, tempo, channels*frequencies)\n",
    "        # Ora input_size deve essere channels * freqs (es. 3 * 26 = 78)\n",
    "        # Ora input_size deve essere channels * freqs (es. 64 * 81 = 5184)\n",
    "        \n",
    "        # LSTM 1\n",
    "        out, _ = self.lstm1(x)\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        # LSTM 2\n",
    "        out, _ = self.lstm2(out)\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        # LSTM 3\n",
    "        out, _ = self.lstm3(out)\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        # Estraiamo l'output dell'ultimo time-step\n",
    "        out = out[:, -1, :]\n",
    "        \n",
    "        # Dropout prima del layer fully connected    \n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        # Passaggio attraverso il layer finale per la previsione\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "        \n",
    "\n",
    "\n",
    "'''\n",
    "Il modulo Transformer in PyTorch lavora tipicamente su input di forma (seq_length, batch, embedding_dim).\n",
    "\n",
    "Nel codice attuale, si parte da una forma simile a (batch, canali, seq_length), ma dovrai adattarla alla nuova struttura.\n",
    "\n",
    "Possibili approcci:\n",
    "\n",
    "1) Approccio A: usare il tempo come sequenza\n",
    "\n",
    "Se consideri il tempo (6 time windows) come la sequenza, puoi procedere come segue:\n",
    "\n",
    "A) Unisci canali e frequenze in un’unica dimensione di feature:\n",
    "\n",
    "# Dati originali: (batch, canali, frequenze, tempo)\n",
    "x = x.permute(0, 3, 1, 2)  # (batch, tempo, canali, frequenze)\n",
    "batch, tempo, canali, frequenze = x.shape\n",
    "x = x.reshape(batch, tempo, canali * frequenze)  # (batch, tempo, 3*38 = 114)\n",
    "\n",
    "B) Modifica il layer di embedding:\n",
    "\n",
    "Nel codice attuale, l'embedding è definito come:\n",
    "\n",
    "self.embedding = nn.Linear(seq_length, d_model)\n",
    "Dovrai cambiarlo in modo che mappi le dimensioni delle feature (in questo caso 114) a uno spazio latente:\n",
    "\n",
    "self.embedding = nn.Linear(canali * frequenze, d_model)\n",
    "\n",
    "C) Permuta per il Transformer:\n",
    "\n",
    "Dopo l'embedding, passa l'input alla forma (seq_length, batch, d_model):\n",
    "\n",
    "x = x.permute(1, 0, 2)  # Ora: (tempo, batch, d_model)\n",
    "\n",
    "\n",
    "2) Approccio B: usare i bin di frequenza come sequenza\n",
    "In alternativa, se reputi più rilevante la risoluzione spettrale, puoi considerare i 38 bin come sequenza e combinare canali e tempo:\n",
    "\n",
    "\n",
    "x = x.permute(0, 2, 1, 3)  # (batch, frequenze, canali, tempo)\n",
    "batch, frequenze, canali, tempo = x.shape\n",
    "x = x.reshape(batch, frequenze, canali * tempo)  # (batch, frequenze, 3*6 = 18)\n",
    "\n",
    "E poi procedere con un embedding layer che mappa da 18 a d_model e permutare in (frequenze, batch, d_model).\n",
    "\n",
    "Scelta dell'approccio:\n",
    "Se l'aspetto temporale è più critico, probabilmente è meglio usare l’Approccio A (sequenza di lunghezza 6).\n",
    "Se invece vuoi dare maggior rilievo alla struttura spettrale, l’Approccio B potrebbe essere più indicato.\n",
    "\n",
    "Ricorda che la scelta dipende dalla natura del tuo problema e dalla rilevanza delle informazioni temporali rispetto a quelle spettrali.\n",
    "'''\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "#Scelta: In questa implementazione abbiamo deciso di usare il tempo come sequenza.\n",
    "#In alternativa, potresti scegliere i bin di frequenza come sequenza, ma ciò richiederebbe una diversa riorganizzazione delle dimensioni \n",
    "#(ad esempio, un permute diverso).\n",
    "\n",
    "class ReadMYMind(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, num_heads, num_layers, num_classes, channels=64, freqs=81):\n",
    "        \n",
    "        super(ReadMYMind, self).__init__()\n",
    "\n",
    "        # Il layer di embedding mapperà la feature dimension (channels * freqs) a d_model\n",
    "        self.embedding = nn.Linear(channels * freqs, d_model)\n",
    "        \n",
    "        # Transformer per l'attenzione spaziale (qui si applica direttamente alla sequenza temporale)\n",
    "        self.spatial_transformer = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(d_model=d_model, nhead=num_heads),\n",
    "            num_layers=num_layers\n",
    "        )\n",
    "        # Transformer per l'attenzione temporale (si potrebbe considerare un'iterazione successiva)\n",
    "        self.temporal_transformer = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(d_model=d_model, nhead=num_heads),\n",
    "            num_layers=num_layers\n",
    "        )\n",
    "        # Cross-attention per combinare le rappresentazioni\n",
    "        self.cross_attention = nn.MultiheadAttention(embed_dim=d_model, num_heads=num_heads)\n",
    "        \n",
    "        # Fusione e classificazione finale\n",
    "        self.fc_fusion = nn.Linear(d_model, d_model)\n",
    "        self.fc_classify = nn.Linear(d_model, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x: (batch, canali, frequenze, tempo)\n",
    "        \n",
    "        # Utilizziamo il tempo come sequenza\n",
    "        x = x.permute(0, 3, 1, 2)  # -> (batch, tempo, canali, frequenze)\n",
    "        \n",
    "        batch, time, channels, freqs = x.shape\n",
    "        x = x.reshape(batch, time, channels * freqs)  # -> (batch, tempo, channels*frequencies)\n",
    "        \n",
    "        # Embedding: (batch, tempo, d_model)\n",
    "        x = self.embedding(x)\n",
    "        \n",
    "        # Transformer richiede input di forma (seq_length, batch, embedding_dim)\n",
    "        x = x.permute(1, 0, 2)  # -> (tempo, batch, d_model)\n",
    "        \n",
    "        # Applichiamo il Transformer per l'attenzione spaziale\n",
    "        x_spatial = self.spatial_transformer(x)\n",
    "        \n",
    "        # Applichiamo il Transformer per l'attenzione temporale\n",
    "        x_temporal = self.temporal_transformer(x_spatial)\n",
    "        \n",
    "        # Cross-attention: (tempo, batch, d_model)\n",
    "        x_cross, _ = self.cross_attention(x_spatial, x_temporal, x_temporal)\n",
    "        \n",
    "        # Fusione: per esempio, facciamo una media sul tempo (dimensione 0)\n",
    "        x_fused = self.fc_fusion((x_spatial + x_temporal).mean(dim=0))  # -> (batch, d_model)\n",
    "        \n",
    "        # Classificazione finale\n",
    "        output = self.fc_classify(x_fused)  # -> (batch, num_classes)\n",
    "        \n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d693e769-8dfc-4c7f-a1e3-e600637092d4",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### **NUOVO LOOP PER DATI NON HYPER SU CNN2D_LSTM_TF, BiLSTM e Transformer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e5a98f-b566-41e5-b269-45147359bf13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "import random\n",
    "#perché è importante numpy.random.seed()?\n",
    "#https://www.analyticsvidhya.com/blog/2021/12/what-does-numpy-random-seed-do/#:~:text=The%20numpy%20random%20seed%20is,displays%20the%20same%20random%20numbers.\n",
    "from numpy.random import seed\n",
    "\n",
    "import numpy as np\n",
    "import copy as cp\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, classification_report\n",
    "\n",
    "#importing librerie pytorch\n",
    "import torch \n",
    "import torch.nn as nn #neural network module\n",
    "import torch.optim as optim #ottimizzatore\n",
    "import torch.nn.functional as F \n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "#from sklearn.model_selection import KFold\n",
    "\n",
    "#importing librerie numpy, pandas, scikit-learn e matplotlib\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "99b8c6bb-5770-47ed-86fd-273f23162e5f",
   "metadata": {
    "tags": []
   },
   "source": [
    "#LOOP PER CARICARE I DATI NON HYPER\n",
    "data_dict = {}\n",
    "\n",
    "# Condizioni sperimentali\n",
    "#experimental_conditions = [\"th_resp_vs_pt_resp\", \"th_resp_vs_shared_resp\", \"pt_resp_vs_shared_resp\"]\n",
    "\n",
    "for condition in experimental_conditions:\n",
    "\n",
    "    for data_type in [\"spectrograms\"]:\n",
    "        \n",
    "        #for category in [\"familiar\", \"unfamiliar\"]:\n",
    "        for category in [\"familiar\"]: \n",
    "            \n",
    "            #for subject_type in [\"th\", \"pt\"]:\n",
    "            for subject_type in [\"th\"]:\n",
    "            \n",
    "                # Caricamento e suddivisione dei dati\n",
    "                if data_type == \"wavelet\":\n",
    "                    X, y = load_data(data_type, category, subject_type, wavelet_level=\"delta\")\n",
    "                else:\n",
    "                    X, y = load_data(data_type, category, subject_type)\n",
    "\n",
    "                #key = f\"{condition}/{data_type}_{category}_{subject_type}\"\n",
    "                key = f\"{condition}_{data_type}_{category}_{subject_type}\"\n",
    "                data_dict[key] = (X, y)\n",
    "\n",
    "                # Stampa di conferma\n",
    "                print(f\"Dataset caricato: \\033[1m{key}\\033[0m - Forma X: {X.shape}, Lunghezza y: {len(y)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a484e1-880f-4b83-9bb7-bc7f4474f79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''VERSIONE NUOVA UFFICIALE\n",
    "\n",
    "\n",
    "Ecco come puoi correggere solo il calcolo dell’AUC–ROC sul training set a posteriori, \n",
    "lasciando invariato tutto il resto di load_best_run_results. \n",
    "\n",
    "\n",
    "L’idea è:\n",
    "\n",
    "1) Estrarre la history normale da W&B (che contiene il vecchio train_auc)\n",
    "2) Individuare best_epoch\n",
    "3) Caricare il modello migliore da disco\n",
    "4) Rifare un passaggio solo sullo train_loader per ottenere le vere probabilità e ricalcolare la ROC–AUC\n",
    "5) Sovrascrivere il vecchio valore auc_train_history[best_epoch] e aggiornare best_metrics[\"train_auc\"]\n",
    "\n",
    "\n",
    "\n",
    "Cosa è cambiato\n",
    "\n",
    "1) Ti ho inserito un passaggio 6) in cui ricalcoli l’AUC–ROC vero del train set, usando torch.softmax(…,dim=1)[:,1].\n",
    "2) Sostituisci il vecchio auc_train_history[best_epoch] col valore corretto.\n",
    "3) Ricomponi best_metrics[\"train_auc\"] con true_auc_train.\n",
    "\n",
    "Da qui in poi, puoi chiamare subito dopo la tua testing(...) per ottenere anche tutte le metriche sul test set e salvare la tabella finale in cui:\n",
    "\n",
    "“Train” = best_metrics[\"train_*\"] (ora con AUC corretta)\n",
    "\n",
    "“Test” = test_results[\"test_performances\"]\n",
    "\n",
    "Ecco fatto: nessun re‑training, solo un passaggio aggiuntivo per correggere il calcolo dell’AUC–ROC sul train set.\n",
    "\n",
    "\n",
    "\n",
    "Quindi il punto 6\n",
    "\n",
    "# --- 6) Ricalcolo vero train AUC–ROC sul train_loader ---\n",
    "\n",
    "serve per ri-calcolarsi correttamente l'auc roc al train set nell'epoca in cui sul val set ho ottenuto la migliore validation accuracy, \n",
    "che corrisponde quindi al modello salvato dentro il best_model che io ri-prelevo quando poi lo do in pasto al test set?\n",
    "\n",
    "\n",
    "Esattamente: quel passaggio 6):\n",
    "\n",
    "Riprende il modello caricato dal file .pkl (che è proprio il best_model scelto sull’epoca di miglior val_accuracy),\n",
    "\n",
    "Lo mette in eval() e senza gradienti scorre tutto il train_loader,\n",
    "\n",
    "Calcola le probabilità (softmax(:,1)) e da quelle ricava la vera ROC–AUC per il train set,\n",
    "\n",
    "Infine sovrascrive auc_train_history[best_epoch] e aggiorna best_metrics[\"train_auc\"] con questo valore corretto.\n",
    "\n",
    "In questo modo la tua colonna “Train” nella tabella conterrà davvero l’AUC–ROC calcolata sulle probabilità del modello nella stessa epoca \n",
    "in cui hai ottenuto la migliore validazione, cioè esattamente quei pesi che poi passerai al test set.\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "from wandb import Api\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, roc_auc_score, confusion_matrix, classification_report\n",
    ")\n",
    "import io\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "import re\n",
    "\n",
    "\n",
    "    \n",
    "'''\n",
    "1) questa serve per plottare le metriche di loss e accuracy in ogni modello e condizione sperimentale\n",
    "per salvarla dentro al dizionario 'training_plot' come buffer di memoria\n",
    "'''\n",
    "\n",
    "\n",
    "def plot_training_results(loss_train_history, loss_val_history, accuracy_train_history, accuracy_val_history):\n",
    "    \n",
    "    '''\n",
    "    # Creazione di una figura con 2 subplot\n",
    "    '''\n",
    "    fig, ax = plt.subplots(2, 1, figsize=(10, 8))  # 2 righe, 1 colonna, dimensione figura\n",
    "\n",
    "    #Plot della loss\n",
    "    ax[0].plot(loss_train_history, label='Train Loss', color='blue')\n",
    "    ax[0].plot(loss_val_history, label='Validation Loss', color='orange')\n",
    "    #ax[0].set_title(f'Loss during Training: {exp_cond_1} vs {exp_cond_2}', fontsize=16)  # Titolo più grande\n",
    "    ax[0].set_title(f'Loss during Training: ', fontsize=12)  # Titolo più grande\n",
    "    ax[0].set_xlabel('Epochs', fontsize=12)  # Dimensione font asse x\n",
    "    ax[0].set_ylabel('Loss', fontsize=12)    # Dimensione font asse y\n",
    "    ax[0].legend(fontsize=12)  # Dimensione font legenda\n",
    "    ax[0].grid(True)\n",
    "\n",
    "    # Plot dell'accuracy\n",
    "    ax[1].plot(accuracy_train_history, label='Train Accuracy', color='blue')\n",
    "    ax[1].plot(accuracy_val_history, label='Validation Accuracy', color='orange')\n",
    "    #ax[1].set_title(f'Accuracy during Training: {exp_cond_1} vs {exp_cond_2}', fontsize=16)  # Titolo più grande\n",
    "    ax[1].set_title(f'Accuracy during Training: ', fontsize=12)  # Titolo più grande\n",
    "    ax[1].set_xlabel('Epochs', fontsize=12)  # Dimensione font asse x\n",
    "    ax[1].set_ylabel('Accuracy', fontsize=12)  # Dimensione font asse y\n",
    "    ax[1].legend(fontsize=12)  # Dimensione font legenda\n",
    "    ax[1].grid(True)\n",
    "    \n",
    "    # Regolare la spaziatura tra i subplot\n",
    "    plt.tight_layout()  # Alternativa: fig.subplots_adjust(hspace=0.3)\n",
    "    \n",
    "    #plt.close(fig)\n",
    "    \n",
    "    '''\n",
    "    # Salvare il plot in un buffer di memoria\n",
    "    '''\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='png')  # Salviamo il plot in formato PNG\n",
    "    buf.seek(0)  # Torniamo all'inizio del buffer\n",
    "\n",
    "    # Convertire il buffer in un'immagine PIL (opzionale, per visualizzarla)\n",
    "    img = Image.open(buf)\n",
    "\n",
    "    # Aggiungere i dati dell'immagine nel dizionario\n",
    "    plot_image_data = buf.getvalue()  # Otteniamo i dati binari dell'immagine\n",
    "    buf.close()\n",
    "    \n",
    "    # Ritorniamo i dati dell'immagine da salvare nel dizionario\n",
    "    return plot_image_data\n",
    "\n",
    "\n",
    "'''\n",
    "2) questa serve per estrarmi le stringhe per ricostruire il nome del progetto su W&B per \n",
    "poi estrarmi le metriche ottenute sul training e validation \n",
    "da salvare sempre dentro al dizionario 'training_plot' \n",
    "'''\n",
    "\n",
    "# Funzione per parsare la chiave\n",
    "def parse_combination_key(combination_key):\n",
    "    \"\"\"\n",
    "    Estrae (exp_cond, data_type, category_subject) da combination_key.\n",
    "    Il formato atteso è:\n",
    "    \"th_resp_vs_pt_resp|pt_resp_vs_shared_resp|th_resp_vs_shared_resp\" _ \n",
    "    \"1_20|1_45|wavelet\" _ \n",
    "    \"familiar_th|familiar_pt|unfamiliar_th|unfamiliar_pt\"\n",
    "    \"\"\"\n",
    "    match = re.match(\n",
    "        r\"^(rest_vs_left_fist|rest_vs_right_fist|left_fist_vs_right_fist)_(spectrograms)_(familiar_th|familiar_pt|unfamiliar_th|unfamiliar_pt)$\",\n",
    "        combination_key\n",
    "    )\n",
    "    if match:\n",
    "        return match.groups()  # (exp_cond, data_type, category_subject)\n",
    "    else:\n",
    "        raise ValueError(f\"Formato non valido: {combination_key}\")\n",
    "        \n",
    "\n",
    "'''CELLA DI ESEMPIO PER VERIFICARE SE QUESTA FUNZIONE FACESSE IL PARSING DELLE STRINGHE DELLE COMBINAZIONI DI FATTORI CORRETTAMENTE'''\n",
    "\n",
    "# Test\n",
    "#combination_key = \"rest_vs_left_fist_spectrograms_familiar_th\"\n",
    "#condition_experiment, data_type, subject_key = parse_combination_key(combination_key)\n",
    "\n",
    "#print(\"Condizione:\", condition_experiment)\n",
    "#print(\"Data Type:\", data_type)\n",
    "#print(\"Soggetto:\", subject_key)\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "Ecco come puoi correggere solo il calcolo dell’AUC–ROC sul training set a posteriori, lasciando invariato tutto il resto di load_best_run_results. \n",
    "\n",
    "\n",
    "L’idea è:\n",
    "\n",
    "1) Estrarre la history normale da W&B (che contiene il vecchio train_auc)\n",
    "2) Individuare best_epoch\n",
    "3) Caricare il modello migliore da disco\n",
    "4) Rifare un passaggio solo sullo train_loader per ottenere le vere probabilità e ricalcolare la ROC–AUC\n",
    "5) Sovrascrivere il vecchio valore auc_train_history[best_epoch] e aggiornare best_metrics[\"train_auc\"]\n",
    "\n",
    "\n",
    "\n",
    "Cosa è cambiato\n",
    "\n",
    "1) Ti ho inserito un passaggio 6) in cui ricalcoli l’AUC–ROC vero del train set, usando torch.softmax(…,dim=1)[:,1].\n",
    "2) Sostituisci il vecchio auc_train_history[best_epoch] col valore corretto.\n",
    "3) Ricomponi best_metrics[\"train_auc\"] con true_auc_train.\n",
    "\n",
    "Da qui in poi, puoi chiamare subito dopo la tua testing(...) per ottenere anche tutte le metriche sul test set e salvare la tabella finale in cui:\n",
    "\n",
    "“Train” = best_metrics[\"train_*\"] (ora con AUC corretta)\n",
    "\n",
    "“Test” = test_results[\"test_performances\"]\n",
    "\n",
    "Ecco fatto: nessun re‑training, solo un passaggio aggiuntivo per correggere il calcolo dell’AUC–ROC sul train set.\n",
    "\n",
    "\n",
    "\n",
    "Quindi il punto 6\n",
    "\n",
    "# --- 6) Ricalcolo vero train AUC–ROC sul train_loader ---\n",
    "\n",
    "serve per ri-calcolarsi correttamente l'auc roc al train set nell'epoca in cui sul val set ho ottenuto la migliore validation accuracy, \n",
    "che corrisponde quindi al modello salvato dentro il best_model che io ri-prelevo quando poi lo do in pasto al test set?\n",
    "\n",
    "\n",
    "Esattamente: quel passaggio 6):\n",
    "\n",
    "Riprende il modello caricato dal file .pkl (che è proprio il best_model scelto sull’epoca di miglior val_accuracy),\n",
    "\n",
    "Lo mette in eval() e senza gradienti scorre tutto il train_loader,\n",
    "\n",
    "Calcola le probabilità (softmax(:,1)) e da quelle ricava la vera ROC–AUC per il train set,\n",
    "\n",
    "Infine sovrascrive auc_train_history[best_epoch] e aggiorna best_metrics[\"train_auc\"] con questo valore corretto.\n",
    "\n",
    "In questo modo la tua colonna “Train” nella tabella conterrà davvero l’AUC–ROC calcolata sulle probabilità del modello nella stessa epoca \n",
    "in cui hai ottenuto la migliore validazione, cioè esattamente quei pesi che poi passerai al test set.\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "'''\n",
    "3) Dopodiché, comincia la funzione di load_best_run_results che, \n",
    "per ogni progetto e sweep del relativo modello,\n",
    "\n",
    "si va ad estrarre le metriche del train (corregge il calcolo del train_auc)\n",
    "e si calcola anche per il validation phase la confusion matrix e classification report\n",
    "\n",
    "\n",
    "4) dopodichè dovrebbe richiamare la funzione di \n",
    "\"plot_training_results\" in modo che poi si salvi i plot di training e validation (sia loss che accuracy)\n",
    "in modo che si salvi tutto in una immagine come buffer che viene spuntato fuori da quella funzione \n",
    "\n",
    "e poi inserito come valore dentro al dizionario training_results che sarà l'output di \"load_best_run_results\" \n",
    "\n",
    "\n",
    "quindi qui sotto mi manca richiamare la funzione \"plot_training_results\" con una variabile tipo training_plot = plot_training_results che avrà come argomenti\n",
    "\n",
    "queste liste qua salvate come colonne del df creato dentro a 'load_best_run_results!'\n",
    "\n",
    "\n",
    "loss_train_history     = df[\"train_loss\"].tolist()\n",
    "loss_val_history       = df[\"val_loss\"].tolist()\n",
    "accuracy_train_history = df[\"train_accuracy\"].tolist()\n",
    "accuracy_val_history   = df[\"val_accuracy\"].tolist()\n",
    "\n",
    "\n",
    "5) dopodiché mi serve caricare tutte queste info dentro al dizionario train_results, che sarà l'output di load_best_run_results... \n",
    "e su questo ho dei dubbi su quali chiavi del dizionario tenere separate oppure se \"unirne\" qualcuna, aggregando tutte le info del sweep_config assieme, \n",
    "sia che siano veri iper-parametri (learning rate etc) o parametri architetturali della rete (anche se avevano valori fissi) il più delle volte se vedi\n",
    "\n",
    "\n",
    "\n",
    "# 2.1 – Sweep config per ciascun modello\n",
    "sweep_config_cnn3d = {\n",
    "    \"method\": \"random\",\n",
    "    \"metric\": {\"name\": \"val_accuracy\", \"goal\": \"maximize\"},\n",
    "    \"parameters\": {\n",
    "        \"lr\": {\"values\": [1e-5, 5e-5, 1e-4, 5e-4, 1e-3, 5e-3, 1e-2]},\n",
    "        \"weight_decay\": {\"values\": [0, 1e-4, 1e-3, 1e-2, 1e-1]},\n",
    "        \"n_epochs\": {\"value\": 100},\n",
    "        \"patience\": {\"value\": 12},\n",
    "        \"model_name\": {\"values\": [\"CNN3D_LSTM_FC\"]},\n",
    "        \"batch_size\": {\"values\": [32, 48, 64, 96]},\n",
    "        \"standardization\": {\"values\": [True, False]},\n",
    "        \"beta1\": {\"values\": [0.9, 0.95]},\n",
    "        \"beta2\": {\"values\": [0.99, 0.995]},\n",
    "        \"eps\": {\"values\": [1e-8, 1e-7]},\n",
    "        \"use_lstm\": {\"values\": [True, False]},\n",
    "        \"lstm_hidden\": {\"values\": [32]},\n",
    "        \"dropout\": {\"values\": [0.5]},\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "sweep_config_cnn_sep = {\n",
    "    \"method\": \"random\",\n",
    "    \"metric\": {\"name\": \"val_accuracy\", \"goal\": \"maximize\"},\n",
    "    \"parameters\": {\n",
    "        \"lr\": {\"values\": [1e-5, 5e-5, 1e-4, 5e-4, 1e-3, 5e-3, 1e-2]},\n",
    "        \"weight_decay\": {\"values\": [0, 1e-4, 1e-3, 1e-2, 1e-1]},\n",
    "        \"n_epochs\": {\"value\": 100},\n",
    "        \"patience\": {\"value\": 12},\n",
    "        \"model_name\": {\"values\": [\"SeparableCNN2D_LSTM_FC\"]},\n",
    "        \"batch_size\": {\"values\": [32, 48, 64, 96]},\n",
    "        \"standardization\": {\"values\": [True, False]},\n",
    "        \"beta1\": {\"values\": [0.9, 0.95]},\n",
    "        \"beta2\": {\"values\": [0.99, 0.995]},\n",
    "        \"eps\": {\"values\": [1e-8, 1e-7]},\n",
    "        \"use_lstm\": {\"values\": [True, False]},\n",
    "        \"lstm_hidden\": {\"values\": [32]},\n",
    "        \"dropout\": {\"values\": [0.5]},\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "def load_best_run_results(\n",
    "    key, # es. \"rest_vs_left_fist_spectrograms_familiar_th\"\n",
    "    model, # # <-- istanza PyTorch già caricata con i pesi best es. \"CNN3D_LSTM_FC\"\n",
    "    \n",
    "    sweep_config,      # <— qui richiamo lo sweep config del modello corrispondente\n",
    "    \n",
    "    data_loaders, # dict con DataLoader per \"train\" e \"val\"\n",
    "    entity = \"my_wb_entity\"): # entity = \"stefano‑bargione‑universit‑di‑roma‑tor‑vergata\"\n",
    "    \n",
    "    \n",
    "    # --- 1) Parse key e ricava project name ---\n",
    "    exp_cond, data_type, category_subject = parse_combination_key(key)\n",
    "    \n",
    "    \n",
    "    '''CAMBIATA PER DATI MOTORI (MOVIMENTO REALE!) IN RAPPRESENTAZIONE TIME X FREQS'''\n",
    "    #project = f\"{exp_cond}_{data_type}_channels_freqs_new_3d_grid_multiband\"\n",
    "    \n",
    "    project = f\"{exp_cond}_{data_type}_time_freqs_new_3d_grid_multiband\"\n",
    "    \n",
    "    '''OLD APPROACH'''\n",
    "    #model_name = type(model).__name__\n",
    "    \n",
    "\n",
    "    '''SE ESTRAGGO SWEEP ID A POSTERIORI DAL PROGETTO\n",
    "\n",
    "    1) Prendo tutte le run del progetto e modello corrispondente\n",
    "    2) Filtro solo quelle con config[\"model_name\"] == model_name.\n",
    "    3) Controllo che ce ne sia almeno una (altrimenti errore).\n",
    "    4) Costruisce un set di tutti gli r.sweep e verifica che sia esattamente uno (altrimenti errore).\n",
    "    5) Estrae quello unico (.pop()) e lo stampa insieme al numero di run.\n",
    "    6) Infine, seleziona la singola best_run sulla base di val_accuracy.\n",
    "\n",
    "    '''\n",
    "    \n",
    "    # 2) Recupero tutte le run del progetto\n",
    "    api  = Api()\n",
    "    runs = api.runs(f\"{entity}/{project}\")\n",
    "    \n",
    "    \n",
    "    '''NEW APPROACH'''\n",
    "    # === PATCH: accetta alias tra nome classe PyTorch e nome usato nello sweep ===\n",
    "    def _get_param_list(cfg, key):\n",
    "        p = cfg[\"parameters\"][key]\n",
    "        vals = p.get(\"values\", p.get(\"value\"))\n",
    "        if isinstance(vals, str): \n",
    "            return [vals]\n",
    "        return list(vals) if isinstance(vals, (list, tuple)) else [vals]\n",
    "\n",
    "    model_class = type(model).__name__          # es. \"ReadMEndYou\"\n",
    "    cfg_names   = _get_param_list(sweep_config, \"model_name\")   # es. [\"BiLSTM\"]\n",
    "    aliases     = set([model_class, *cfg_names])                # {\"ReadMEndYou\",\"BiLSTM\"}\n",
    "    \n",
    "    def matches_aliases(r):\n",
    "        return (\n",
    "            r.config.get(\"model_name\") in aliases or\n",
    "            r.config.get(\"model_class\") in aliases or\n",
    "            bool(set(r.tags or []) & aliases)\n",
    "        )\n",
    "    \n",
    "    # 3) filtro solo quelle del modello giusto\n",
    "    \n",
    "    '''OLD APPROACH'''\n",
    "    #runs_filtered = [r for r in runs if r.config.get(\"model_name\", \"\") == model_name]\n",
    "    #n_runs = len(runs_filtered)\n",
    "    \n",
    "    '''NEW APPROACH'''\n",
    "    runs_filtered = [r for r in runs if matches_aliases(r)]\n",
    "    n_runs = len(runs_filtered)\n",
    "    \n",
    "\n",
    "    if n_runs == 0:\n",
    "        raise RuntimeError(f\"Nessuna run trovata per progetto `{project}` e modello `{model_name}`\")\n",
    "\n",
    "    # 4) controllo che le run filtrate appartengano tutte allo stesso sweep\n",
    "    unique_sweeps = {r.sweep for r in runs_filtered}\n",
    "    if len(unique_sweeps) != 1:\n",
    "        raise RuntimeError(\n",
    "            f\"Trovati più sweep per progetto `{project}` e modello `{model_name}`: {unique_sweeps}\"\n",
    "        )\n",
    "\n",
    "    # 5) estraggo lo sweep_id\n",
    "    sweep_id_unico = unique_sweeps.pop()\n",
    "    #print(f\"✓ Trovate \\033[1m{n_runs}\\033[0m runs in progetto `{project}` e modello `{model_name}`, sweep: `{sweep_id_unico}`\")\n",
    "    print(f\"✓ Trovate \\033[1m{n_runs}\\033[0m runs\\n\")\n",
    "    print(f\"✓ Progetto \\033[1m`{project}`\\033[0m\\n\")\n",
    "    print(f\"✓ Modello \\033[1m`{model_name}`\\033[0m\\n\")\n",
    "    print(f\"✓ Sweep \\033[1m`{sweep_id_unico}`\\033[0m\\n\\n\")\n",
    "\n",
    "    # 6) scelgo la run con val_accuracy massima\n",
    "    best_run = max(runs_filtered, key=lambda r: r.summary.get(\"val_accuracy\", 0.0))\n",
    "\n",
    "    # --- 7) Estraggo tutta la history (compresi i train_auc sbagliati) ---\n",
    "    df = best_run.history(\n",
    "        keys=[\n",
    "          \"train_loss\",\"train_accuracy\",\"train_precision\",\n",
    "          \"train_recall\",\"train_f1\",\"train_auc\",\n",
    "          \"val_loss\",\"val_accuracy\"\n",
    "        ],\n",
    "        pandas=True\n",
    "    )\n",
    "    # converto in liste\n",
    "    loss_train_history     = df[\"train_loss\"].tolist()\n",
    "    loss_val_history       = df[\"val_loss\"].tolist()\n",
    "    accuracy_train_history = df[\"train_accuracy\"].tolist()\n",
    "    accuracy_val_history   = df[\"val_accuracy\"].tolist()\n",
    "    precision_train_history= df[\"train_precision\"].tolist()\n",
    "    recall_train_history   = df[\"train_recall\"].tolist()\n",
    "    f1_train_history       = df[\"train_f1\"].tolist()\n",
    "    auc_train_history      = df[\"train_auc\"].tolist()\n",
    "\n",
    "    # best_epoch (su val_accuracy)\n",
    "    best_epoch = int(df[\"val_accuracy\"].idxmax())\n",
    "\n",
    "    # --- 8) Prendo il modello ottimizzato .pkl corrispondente passato in input ---\n",
    "    device     = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    model.to(device).eval()\n",
    "\n",
    "    # --- 9) Ricalcolo vero train AUC–ROC sul train_loader ---\n",
    "    y_t_train, y_s_train = [], []\n",
    "    with torch.no_grad():\n",
    "        for x,y in data_loaders[\"train\"]:\n",
    "            x = x.to(device)\n",
    "            logits = model(x)\n",
    "            probs  = torch.softmax(logits, dim=1)[:,1].cpu().numpy()\n",
    "            y_s_train.extend(probs)\n",
    "            y_t_train.extend(y.numpy())\n",
    "            \n",
    "    true_auc_train = roc_auc_score(np.array(y_t_train), np.array(y_s_train))\n",
    "\n",
    "    # Sovrascrivo il vecchio valore sbagliato\n",
    "    auc_train_history[best_epoch] = true_auc_train\n",
    "\n",
    "    # Ricostruisco best_metrics\n",
    "    best_metrics = {\n",
    "      \"train_loss\":       [round(loss_train_history[best_epoch],4)],\n",
    "      \"train_accuracy\":   [round(accuracy_train_history[best_epoch],4)],\n",
    "      \"train_precision\":  [round(precision_train_history[best_epoch],4)],\n",
    "      \"train_recall\":     [round(recall_train_history[best_epoch],4)],\n",
    "      \"train_f1_score\":   [round(f1_train_history[best_epoch],4)],\n",
    "      \"train_auc\":        [round(true_auc_train,4)]\n",
    "    }\n",
    "    \n",
    "    #Solo una nota: qui non serve per training che l'auc abbia l'average='weighted' \n",
    "    #perché è binario e stai usando score continui.\n",
    "    #anche se sopra lo avevi messo in \"training_sweep\".\n",
    "    \n",
    "    #Per le altre metriche (precision, recall, f1_score invece) l'average andava bene!\n",
    "    #Anche in binario: average='weighted' = fai la media pesata per supporto delle metriche per ciascuna classe (0 e 1). \n",
    "    #È sensato se hai sbilanciamento e vuoi che le metriche riflettano anche quanto è frequente ciascuna classe. \n",
    "    \n",
    "    #L’unica cosa da essere consapevoli è che non stai riportando “F1 della classe positiva”, \n",
    "    #ma una F1 complessiva pesata sulle due classi. \n",
    "    #Ma va bene, basta essere coerenti e chiari nel testo della tesi/paper.\"\n",
    "    \n",
    "\n",
    "    # --- 10) Ricreo confusion matrix e classification report su val set ---\n",
    "    \n",
    "    #Per il validation set, invece, rifai il calcolo:\n",
    "    \n",
    "    #y_t_val = true labels (0/1).\n",
    "    #y_p_val = predizioni binarie (0/1), usate per accuracy / precision / recall / f1.\n",
    "    #y_s_val = score continui (probabilità o logit della classe 1), usati per il calcolo dell'AUC-ROC:\n",
    "    \n",
    "    #Quindi diventerà ---> val_auc = roc_auc_score(y_t_val, y_s_val)\n",
    "    #Quindi qui \"y_s_val\" è semplicemente la lista di p(y=1) per ogni campione di validation.\n",
    "    \n",
    "    y_t_val, y_p_val, y_s_val = [], [], []\n",
    "    with torch.no_grad():\n",
    "        for x,y in data_loaders[\"val\"]:\n",
    "            x = x.to(device)\n",
    "            logits = model(x)\n",
    "            probs  = torch.softmax(logits, dim=1)[:,1].cpu().numpy()\n",
    "            preds  = (probs >= 0.5).astype(int)\n",
    "            \n",
    "            \n",
    "            y_p_val.extend(preds) # predizioni 0/1\n",
    "            y_s_val.extend(probs) # score continui per AUC\n",
    "            y_t_val.extend(y.numpy()) \n",
    "            \n",
    "    confusion_matrix_val = confusion_matrix(y_t_val, y_p_val)\n",
    "    classification_report_val = classification_report(y_t_val, y_p_val, output_dict=False)\n",
    "    \n",
    "    # Metriche Validation\n",
    "    val_accuracy = accuracy_score(y_t_val, y_p_val)\n",
    "    val_precision = precision_score(y_t_val, y_p_val, average='weighted')\n",
    "    val_recall    = recall_score(y_t_val, y_p_val, average='weighted')\n",
    "    val_f1        = f1_score(y_t_val, y_p_val, average='weighted')\n",
    "    \n",
    "    try:\n",
    "        val_auc = roc_auc_score(y_t_val, y_s_val)   # <-- NOTHING average=... qui\n",
    "    except ValueError:\n",
    "        print(\"⚠️ AUC non calcolabile: nel val set c'è una sola classe.\")\n",
    "        val_auc = np.nan\n",
    "    \n",
    "    # Val performances alla best_epoch\n",
    "    validation_performances = {\n",
    "        # dalla history di W&B (loss/acc per quella epoch)\n",
    "        \"val_loss\":       [round(loss_val_history[best_epoch],4)],\n",
    "        \"val_accuracy\":   [round(accuracy_val_history[best_epoch],4)],\n",
    "        \n",
    "        # dalle metriche ricalcolate con il best_model\n",
    "        \"val_precision\":  [round(val_precision,4)],\n",
    "        \"val_recall\":     [round(val_recall,4)],\n",
    "        \"val_f1_score\":   [round(val_f1,4)],\n",
    "        \"val_auc\":        [round(val_auc,4)],\n",
    "    }\n",
    "    \n",
    "        \n",
    "    # --- 10) Plot delle curve loss/accuracy tra train e test ---\n",
    "    training_plot = plot_training_results(\n",
    "        loss_train_history,\n",
    "        loss_val_history,\n",
    "        accuracy_train_history,\n",
    "        accuracy_val_history\n",
    "    )\n",
    "\n",
    "    # --- 11) Composizione del dict finale identico a `training()` ---\n",
    "    \n",
    "    # Restituire tutti i risultati in un dizionario\n",
    "    train_results = {\n",
    "        \"training_performances\": best_metrics,  # Aggiungi il dizionario delle performance\n",
    "        \n",
    "        \"loss_train_history\": loss_train_history,\n",
    "        \"loss_val_history\": loss_val_history,\n",
    "        \n",
    "        \"accuracy_train_history\": accuracy_train_history,\n",
    "        \"accuracy_val_history\": accuracy_val_history,\n",
    "        \n",
    "        \"best_model\": model,\n",
    "        \n",
    "        # VALIDATION\n",
    "        \"validation_performances\": validation_performances,\n",
    "        \n",
    "        \"confusion_matrix\": confusion_matrix_val,\n",
    "        \"classification_report\": classification_report_val,\n",
    "    \n",
    "        \"hyperparams\" : {k: best_run.config[k] for k in best_run.config.keys() if k in sweep_config[\"parameters\"]},\n",
    "            \n",
    "        \"training_plot\": training_plot  # Salviamo il buffer con il plot\n",
    "    }\n",
    "    \n",
    "    '''\n",
    "    Ho questo errore \"Errore “cudnn RNN backward can only be called in training mode”\" solo con i dati di \n",
    "    left_fist_vs_right_fist, per il modello SeparableCNN2D_LSTM_FC, \n",
    "    mentre con i dati delle altre condizioni sperimentali, ossia:\n",
    "    \n",
    "    rest_vs_left_fist o rest_vs_right_fist, sempre per il modello SeparableCNN2D_LSTM_FC,non succede ... come mai solo con l'ultimo succede? \n",
    "    \n",
    "    cioè dove dovrei aver lasciato il modello caricato in eval.() ?\n",
    "    \n",
    "    probabilmente qui nella funzione load_best_train_results!?\n",
    "    \n",
    "    quindi qui poi alla fine dovrei rimettere il modello in un'altra modalità alla fine della funzione? \n",
    "    perché in sostanza, dovrebbe succedere che in sostanza... non succede nulla per lo stesso modello per  gli altri dati, \n",
    "    perché ogni volta che ne prendo uno lo porto in eval e vabbè.. ma poi il problema succede solo per l'ultimo caso solo, \n",
    "    perché forse l'ultimo proprio, ossia solo SeparableCNN2D_LSTM_FC usa proprio il layer LSTM e quindi da errore là,\n",
    "    perché dentro a load_best_train_results è rimasto in .eval() ed ha il layer LSTM e quindi dà errore?\n",
    "    \n",
    "    \n",
    "    \n",
    "    Perché l’errore appare “solo” con l’ultima combinazione\n",
    "\n",
    "    1. load_best_run_results() termina con:\n",
    "\n",
    "    model.to(device).eval()   # ← il modello rimane in eval()\n",
    "    \n",
    "    2. In compute_gradcam_figure() tu usi il best model che hai messo in train_results[\"best_model\"] (quello appena impostato in eval()), poi esegui:\n",
    "\n",
    "   \n",
    "    output = model(sample_input)\n",
    "    ...\n",
    "    target.backward()         # <-- gradiente attraverso l’LSTM\n",
    "    3. Il kernel CuDNN per gli RNN (LSTM/GRU) rifiuta il backward quando il modulo è in modalità inference (eval()), e solleva:\n",
    "\n",
    "    \n",
    "    RuntimeError: cudnn RNN backward can only be called in training mode\n",
    "    \n",
    "    4. Per le combinazioni precedenti con lo stesso modello “SeparableCNN2D_LSTM_FC” non è esploso perché, con ogni probabilità, \n",
    "    use_lstm=False nelle relative run migliori (quindi l’LSTM non c’è e CuDNN non interviene).\n",
    "    \n",
    "    Nell’ultima combinazione invece la best‑run ha use_lstm=True, quindi compare l’LSTM e l’errore salta fuori.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    return train_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db08fe00-c940-4a6b-ad96-7f47d9a357b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#LOOP PER CARICARE I DATI NON HYPER\n",
    "data_dict = {}\n",
    "\n",
    "# Condizioni sperimentali\n",
    "#experimental_conditions = [\"th_resp_vs_pt_resp\", \"th_resp_vs_shared_resp\", \"pt_resp_vs_shared_resp\"]\n",
    "\n",
    "experimental_conditions = [\"rest_vs_left_fist\", \"rest_vs_right_fist\", \"left_fist_vs_right_fist\"]\n",
    "\n",
    "for condition in experimental_conditions:\n",
    "\n",
    "    for data_type in [\"spectrograms\"]:\n",
    "        \n",
    "        #for category in [\"familiar\", \"unfamiliar\"]:\n",
    "        for category in [\"familiar\"]:\n",
    "            \n",
    "            #for subject_type in [\"th\", \"pt\"]:\n",
    "            for subject_type in [\"th\"]:\n",
    "            \n",
    "                # Caricamento e suddivisione dei dati\n",
    "                if data_type == \"wavelet\":\n",
    "                    X, y = load_data(data_type, category, subject_type, wavelet_level=\"delta\", condition = condition)\n",
    "                else:\n",
    "                    X, y = load_data(data_type, category, subject_type, condition = condition)\n",
    "\n",
    "                #key = f\"{condition}/{data_type}_{category}_{subject_type}\"\n",
    "                key = f\"{condition}_{data_type}_{category}_{subject_type}\"\n",
    "                data_dict[key] = (X, y)\n",
    "\n",
    "                # Stampa di conferma\n",
    "                print(f\"Dataset caricato: \\033[1m{key}\\033[0m - Forma X: {X.shape}, Lunghezza y: {len(y)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47e9065-9cdd-4f3f-a9a2-f5ed8ad5927d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ed90af-c56c-4acf-b2dc-db6b106649d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_dict['rest_vs_left_fist_spectrograms_familiar_th'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b755671f-8ee7-47c5-b5c9-543a8de6aa2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "perfetto ora, siccome ho creato data_dict nel modo di cui sopra, \n",
    "ora dentro ogni chiave, \n",
    "ci sono già tutte le chiavi associate correttamente, per estrarmi i dati e labels corrispondenti di quella combinazione di fattori lì.\n",
    "\n",
    "infatti dentro ogni chiave c'è una tupla, con 2 elementi, il primo è l'array dei dati, il secondo è l'array delle labels\n",
    "'''\n",
    "\n",
    "#data_dict['rest_vs_left_fist']['spectrograms'][0].shape\n",
    "\n",
    "data_dict['rest_vs_left_fist_spectrograms_familiar_th'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e07f4c1-d214-4943-8f6f-957fdff29de0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''NEW VERSION'''\n",
    "\n",
    "# Percorso base per il salvataggio\n",
    "base_folder = \"/home/stefano/Interrogait/spectrograms_best_models_post_WB_GradCAM_Checks_motor_task_1_new\"\n",
    "\n",
    "os.makedirs(base_folder, exist_ok=True)\n",
    "\n",
    "# Condizioni sperimentali\n",
    "#experimental_conditions = [\"th_resp_vs_pt_resp\", \"th_resp_vs_shared_resp\", \"pt_resp_vs_shared_resp\"]\n",
    "\n",
    "experimental_conditions = [\"rest_vs_left_fist\", \"rest_vs_right_fist\", \"left_fist_vs_right_fist\"]\n",
    "\n",
    "# Tipologie di dati\n",
    "data_types = [\"spectrograms\"]\n",
    "\n",
    "# Subfolders per tipologia di soggetto\n",
    "#subfolders = [\"th_fam\", \"th_unfam\", \"pt_fam\", \"pt_unfam\"]\n",
    "subfolders = [\"th_fam\"]\n",
    "\n",
    "# Creazione della struttura delle cartelle\n",
    "for condition in experimental_conditions:\n",
    "    for data_type in data_types:\n",
    "        for subfolder in subfolders:\n",
    "            \n",
    "            path = os.path.join(base_folder, condition, data_type, subfolder)\n",
    "            \n",
    "            if not os.path.exists(path):\n",
    "                os.makedirs(path, exist_ok=True)\n",
    "            \n",
    "            print(f\"Cartella creata: \\033[1m{path}\\033[0m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d76a7d-5bca-4212-afd6-8b62a3823d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "\n",
    "# 2.1 – Sweep config per ciascun modello\n",
    "sweep_config_cnn2d_lstm_tf = {\n",
    "    \"method\": \"random\",\n",
    "    \"metric\": {\"name\": \"val_accuracy\", \"goal\": \"maximize\"},\n",
    "    \"parameters\": {\n",
    "        \"lr\": {\"values\": [1e-5, 5e-5, 1e-4, 5e-4, 1e-3, 5e-3, 1e-2]},\n",
    "        \"weight_decay\": {\"values\": [0, 1e-4, 1e-3, 1e-2, 1e-1]},\n",
    "        \"n_epochs\": {\"value\": 100},\n",
    "        \"patience\": {\"value\": 12},\n",
    "        \"model_name\": {\"values\": [\"CNN2D_LSTM_TF\"]},\n",
    "        \"batch_size\": {\"values\": [32, 48, 64, 96]},\n",
    "        \n",
    "        \"standardization\": {\"values\": [True]}, #        ATTENZIONE QUI IMPOSTIAMO SEMPRE A TRUE\n",
    "        \"beta1\": {\"values\": [0.9, 0.95]},\n",
    "        \"beta2\": {\"values\": [0.99, 0.995]},\n",
    "        \"eps\": {\"values\": [1e-8, 1e-7]},\n",
    "        \n",
    "        # --- specifici del modello ---\n",
    "    \n",
    "        \"dropout\": {\"values\": [0.5]},\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "sweep_config_bilstm = {\n",
    "    \"method\": \"random\",\n",
    "    \"metric\": {\"name\": \"val_accuracy\", \"goal\": \"maximize\"},\n",
    "    \"parameters\": {\n",
    "        \"lr\": {\"values\": [1e-5, 5e-5, 1e-4, 5e-4, 1e-3, 5e-3, 1e-2]},\n",
    "        \"weight_decay\": {\"values\": [0, 1e-4, 1e-3, 1e-2, 1e-1]},\n",
    "        \"n_epochs\": {\"value\": 100},\n",
    "        \"patience\": {\"value\": 12},\n",
    "        \"model_name\": {\"values\": [\"BiLSTM\"]},\n",
    "        \"batch_size\": {\"values\": [32, 48, 64, 96]},\n",
    "        \"standardization\": {\"values\": [True]}, #        ATTENZIONE QUI IMPOSTIAMO SEMPRE A TRUE\n",
    "        \"beta1\": {\"values\": [0.9, 0.95]},\n",
    "        \"beta2\": {\"values\": [0.99, 0.995]},\n",
    "        \"eps\": {\"values\": [1e-8, 1e-7]},\n",
    "        \n",
    "        # --- specifici del modello ---\n",
    "        \"dropout\": {\"values\": [0.5]},\n",
    "        \"bidirectional\": {\"values\": [False, True]},\n",
    "        \n",
    "        #Soluzione 1 per mettere valori agli hidden sizes\n",
    "        #\"hidden1\": {\"values\": [24, 32, 48, 64]},\n",
    "        #\"hidden2\": {\"values\": [48, 64, 96, 128]},\n",
    "        #\"hidden3\": {\"values\": [62, 96, 128, 160]}\n",
    "        # in build del modello: hidden_sizes=[hidden1, hidden2, hidden3]\n",
    "        \n",
    "        #Soluzione 2 per mettere valori agli hidden sizes\n",
    "        \n",
    "        #hidden_sizes = [24, 48, 62]\n",
    "        #lstm_model = ReadMEndYou(input_size=input_channels * num_freqs, hidden_sizes=hidden_sizes, output_size=num_classes)\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "sweep_config_transformer = {\n",
    "    \"method\": \"random\",\n",
    "    \"metric\": {\"name\": \"val_accuracy\", \"goal\": \"maximize\"},\n",
    "    \"parameters\": {\n",
    "        \"lr\": {\"values\": [1e-5, 5e-5, 1e-4, 5e-4, 1e-3, 5e-3, 1e-2]},\n",
    "        \"weight_decay\": {\"values\": [0, 1e-4, 1e-3, 1e-2, 1e-1]},\n",
    "        \"n_epochs\": {\"value\": 100},\n",
    "        \"patience\": {\"value\": 12},\n",
    "        \"model_name\": {\"values\": [\"Transformer\"]},\n",
    "        \"batch_size\": {\"values\": [32, 48, 64, 96]},\n",
    "        \"standardization\": {\"values\": [True]}, #        ATTENZIONE QUI IMPOSTIAMO SEMPRE A TRUE\n",
    "        \"beta1\": {\"values\": [0.9, 0.95]},\n",
    "        \"beta2\": {\"values\": [0.99, 0.995]},\n",
    "        \"eps\": {\"values\": [1e-8, 1e-7]},\n",
    "        \n",
    "        # --- specifici del modello ---\n",
    "        \"d_model\": {\"values\": [32]},\n",
    "        \"num_heads\": {\"values\": [2]},\n",
    "        \"num_layers\": {\"values\": [2]},\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  ....\n",
    "  ....\n",
    "  ....\n",
    "  \n",
    "  \n",
    "  \n",
    "        # ====== MODELLI TIME×FREQ ======\n",
    "    \n",
    "        cnn_model = CNN2D_LSTM_TF(input_channels = input_channels, num_classes =num_classes, dropout = dropout)\n",
    "        hidden_sizes = [24, 48, 62]\n",
    "        lstm_model = ReadMEndYou(input_size=input_channels * num_freqs, hidden_sizes=hidden_sizes, output_size=num_classes)\n",
    "        transformer_model = ReadMYMind(d_model=d_model, num_heads=num_heads, num_layers=num_layers, num_classes=num_classes)\n",
    "\n",
    "        # Creazione di dati fittizi per il test\n",
    "        x = torch.randn(batch_size, input_channels, num_freqs, num_timepoints)  # (batch, canali, frequenze, tempo)\n",
    "        \n",
    "\n",
    "        # ricavo channels e freqs dai dati (shape attesa: N, C, F, T)\n",
    "        channels, freqs = int(X_train.shape[1]), int(X_train.shape[2])\n",
    "\n",
    "        if config.model_name == \"CNN2D_LSTM_TF\":\n",
    "\n",
    "            #OCCHIO QUI ADESSO SAREBBE TEMPO x FREQUENZA\n",
    "\n",
    "            model = CNN2D_LSTM_TF(\n",
    "                input_channels = channels, # qui 64\n",
    "                num_classes = 2,\n",
    "                dropout=config.dropout,\n",
    "            )\n",
    "\n",
    "            print(f\"\\nInizializzazione Modello \\033[1mCNN2D_LSTM_TF\\033[0m\")\n",
    "\n",
    "\n",
    "        elif config.model_name == \"BiLSTM\":\n",
    "            hidden_sizes = [24, 48, 62]\n",
    "            model = ReadMEndYou(\n",
    "                input_size = channels * freqs, #  qui 64*81\n",
    "                hidden_sizes = hidden_sizes,\n",
    "                output_size = 2,\n",
    "                dropout = config.dropout,\n",
    "                bidirectional = config.bidirectional\n",
    "            )\n",
    "            print(f\"\\nInizializzazione Modello \\033[1mReadMEndYou (BiLSTM)\\033[0m\")\n",
    "\n",
    "        elif config.model_name == \"Transformer\":\n",
    "            model = ReadMYMind(\n",
    "                d_model=config.d_model,\n",
    "                num_heads=config.num_heads,\n",
    "                num_layers=config.num_layers,\n",
    "                num_classes=2,\n",
    "                channels = channels,\n",
    "                freqs = freqs\n",
    "            )\n",
    "\n",
    "            print(f\"\\nInizializzazione Modello \\033[1mReadMYMind (Transformer)\\033[0m\")\n",
    "        else:\n",
    "            raise ValueError(f\"Modello sconosciuto: {config.model_name}\")\n",
    "            \n",
    "            \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6780f6d-e8ee-4dfa-9579-51213243a239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1 – Sweep config per ciascun modello\n",
    "sweep_config_cnn2d_lstm_tf = {\n",
    "    \"method\": \"random\",\n",
    "    \"metric\": {\"name\": \"val_accuracy\", \"goal\": \"maximize\"},\n",
    "    \"parameters\": {\n",
    "        \"lr\": {\"values\": [1e-5, 5e-5, 1e-4, 5e-4, 1e-3, 5e-3, 1e-2]},\n",
    "        \"weight_decay\": {\"values\": [0, 1e-4, 1e-3, 1e-2, 1e-1]},\n",
    "        \"n_epochs\": {\"value\": 100},\n",
    "        \"patience\": {\"value\": 12},\n",
    "        \"model_name\": {\"values\": [\"CNN2D_LSTM_TF\"]},\n",
    "        \"batch_size\": {\"values\": [32, 48, 64, 96]},\n",
    "        \n",
    "        \"standardization\": {\"values\": [True]}, #        ATTENZIONE QUI IMPOSTIAMO SEMPRE A TRUE\n",
    "        \"beta1\": {\"values\": [0.9, 0.95]},\n",
    "        \"beta2\": {\"values\": [0.99, 0.995]},\n",
    "        \"eps\": {\"values\": [1e-8, 1e-7]},\n",
    "        \n",
    "        # --- specifici del modello ---\n",
    "    \n",
    "        \"dropout\": {\"values\": [0.5]},\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "sweep_config_bilstm = {\n",
    "    \"method\": \"random\",\n",
    "    \"metric\": {\"name\": \"val_accuracy\", \"goal\": \"maximize\"},\n",
    "    \"parameters\": {\n",
    "        \"lr\": {\"values\": [1e-5, 5e-5, 1e-4, 5e-4, 1e-3, 5e-3, 1e-2]},\n",
    "        \"weight_decay\": {\"values\": [0, 1e-4, 1e-3, 1e-2, 1e-1]},\n",
    "        \"n_epochs\": {\"value\": 100},\n",
    "        \"patience\": {\"value\": 12},\n",
    "        \"model_name\": {\"values\": [\"BiLSTM\"]},\n",
    "        \"batch_size\": {\"values\": [32, 48, 64, 96]},\n",
    "        \"standardization\": {\"values\": [True]}, #        ATTENZIONE QUI IMPOSTIAMO SEMPRE A TRUE\n",
    "        \"beta1\": {\"values\": [0.9, 0.95]},\n",
    "        \"beta2\": {\"values\": [0.99, 0.995]},\n",
    "        \"eps\": {\"values\": [1e-8, 1e-7]},\n",
    "        \n",
    "        # --- specifici del modello ---\n",
    "        \"dropout\": {\"values\": [0.5]},\n",
    "        \"bidirectional\": {\"values\": [False, True]},\n",
    "        \n",
    "        #Soluzione 1 per mettere valori agli hidden sizes\n",
    "        #\"hidden1\": {\"values\": [24, 32, 48, 64]},\n",
    "        #\"hidden2\": {\"values\": [48, 64, 96, 128]},\n",
    "        #\"hidden3\": {\"values\": [62, 96, 128, 160]}\n",
    "        # in build del modello: hidden_sizes=[hidden1, hidden2, hidden3]\n",
    "        \n",
    "        #Soluzione 2 per mettere valori agli hidden sizes\n",
    "        \n",
    "        #hidden_sizes = [24, 48, 62]\n",
    "        #lstm_model = ReadMEndYou(input_size=input_channels * num_freqs, hidden_sizes=hidden_sizes, output_size=num_classes)\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "sweep_config_transformer = {\n",
    "    \"method\": \"random\",\n",
    "    \"metric\": {\"name\": \"val_accuracy\", \"goal\": \"maximize\"},\n",
    "    \"parameters\": {\n",
    "        \"lr\": {\"values\": [1e-5, 5e-5, 1e-4, 5e-4, 1e-3, 5e-3, 1e-2]},\n",
    "        \"weight_decay\": {\"values\": [0, 1e-4, 1e-3, 1e-2, 1e-1]},\n",
    "        \"n_epochs\": {\"value\": 100},\n",
    "        \"patience\": {\"value\": 12},\n",
    "        \"model_name\": {\"values\": [\"Transformer\"]},\n",
    "        \"batch_size\": {\"values\": [32, 48, 64, 96]},\n",
    "        \"standardization\": {\"values\": [True]}, #        ATTENZIONE QUI IMPOSTIAMO SEMPRE A TRUE\n",
    "        \"beta1\": {\"values\": [0.9, 0.95]},\n",
    "        \"beta2\": {\"values\": [0.99, 0.995]},\n",
    "        \"eps\": {\"values\": [1e-8, 1e-7]},\n",
    "        \n",
    "        # --- specifici del modello ---\n",
    "        \"d_model\": {\"values\": [32]},\n",
    "        \"num_heads\": {\"values\": [2]},\n",
    "        \"num_layers\": {\"values\": [2]},\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d62fcb5-3bd7-4839-a79f-9d489863a9ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''                                              *************** CON NUOVE MODIFICHE DEL PAPER ***************\n",
    "\n",
    "\n",
    "Cosa cambia rispetto a prima\n",
    "\n",
    "1) load_config_if_available:\n",
    "\n",
    "    estrae la config (batch_size, lr, β₁, β₂, ε, ecc.)\n",
    "    carica i best_weights salvati in .pkl da W&B\n",
    "\n",
    "2) processed_datasets / processed_models\n",
    "\n",
    "    evitano duplicate runs\n",
    "\n",
    "3) Optimizer & Scheduler & EarlyStopping\n",
    "\n",
    "    sono configurati con i valori estratti da config\n",
    "    scheduler con patience=4 (dimezza lr dopo 4 epoche senza miglioramento di val_loss)\n",
    "    early‐stopping con patience=12 sul val_loss\n",
    "\n",
    "4) Training/testing\n",
    "\n",
    "    la tua funzione training(...) dovrebbe accettare ora anche scheduler e early_stopping\n",
    "\n",
    "5) GradCAM\n",
    "\n",
    "    calcolato e salvato solo per il tuo CNN2D+LSTM\n",
    "\n",
    "Con queste modifiche, il tuo loop:\n",
    "\n",
    "    rispetta fedelmente il setup del paper\n",
    "    mantiene la pipeline di W&B per la logica di sweep e salvataggio dei migliori modelli\n",
    "    aggiunge minimi cambiamenti, lasciando intatte le tue funzioni training(), testing() e save_performance_results()\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "# Imposta il seme per la riproducibilità\n",
    "\n",
    "#Imposta il seme per i generatori casuali di PyTorch (per operazioni sui tensori e inizializzazione dei pesi dei modelli).\n",
    "#Importante se vuoi garantire che l'addestramento del modello produca gli stessi risultati in diverse esecuzioni.\n",
    "torch.manual_seed(32)\n",
    "\n",
    "#Imposta il seme per NumPy, utile se NumPy viene usato per operazioni casuali (ad es. shuffling dei dati, inizializzazione di matrici, ecc.).\n",
    "#Importante se usi NumPy per il preprocessing dei dati e vuoi riproducibilità.\n",
    "\n",
    "np.random.seed(32)\n",
    "\n",
    "#mposta il seme per il modulo random di Python (utile se si usano funzioni di randomizzazione di Python puro).\n",
    "#Importante solo se usi random per operazioni come mescolamento di liste.\n",
    "random.seed(32)\n",
    "\n",
    "#Imposta il seme per i generatori casuali su GPU, se disponibile.\n",
    "#Utile se stai eseguendo il codice su una GPU per garantire riproducibilità anche in quel contesto.\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(32)\n",
    "\n",
    "       \n",
    "'''\n",
    "\n",
    "In questo caso, \n",
    "\n",
    "il set processed_datasets traccia i dataset già elaborati, \n",
    "e il set processed_models tiene traccia delle combinazioni già effettuate (modello + dataset). \n",
    "\n",
    "In questo modo, puoi escludere un dataset dal training se è già stato utilizzato in precedenza, \n",
    "anche se usato con un modello differente.\n",
    "'''\n",
    "\n",
    "# Dizionario per tracciare la standardizzazione usata per ogni combinazione d\n",
    "# Dizionario per salvare informazioni sul modello (es. se i dati sono standardizzati)\n",
    "models_info = {}\n",
    "\n",
    "\n",
    "# Set per tenere traccia dei dataset già elaborati\n",
    "processed_datasets = set()\n",
    "\n",
    "# Set per tenere traccia delle combinazioni già elaborate\n",
    "processed_models = set()\n",
    "\n",
    "\n",
    "# Path delle performance dei modelli ottimizzati con weight and biases\n",
    "# Path per trovare le best performances di ogni modello per ogni combinazione dei dati\n",
    "base_folder = \"/home/stefano/Interrogait/WB_spectrograms_best_results_motor_task_1_new\"\n",
    "                                        #WB_spectrograms_best_results_motor_task_1\n",
    "\n",
    "# Path di salvataggio delle performance dei modelli dopo estrazione best models da base_folder\n",
    "#save_path_folder = \"/home/stefano/Interrogait/spectrograms_best_models_post_WB\"\n",
    "\n",
    "\n",
    "save_path_folder = \"/home/stefano/Interrogait/spectrograms_best_models_post_WB_GradCAM_Checks_motor_task_1_new\"\n",
    "                                              #spectrograms_best_models_post_WB_GradCAM_Checks_motor_task_1_new\n",
    "\n",
    "\n",
    "# --- LOOP PRINCIPALE (con minime modifiche) ---\n",
    "for key, (X_data, y_data) in data_dict.items():\n",
    "    \n",
    "    print(f\"\\n\\nEstrazione Dati per il dataset: \\033[1m{key}\\033[0m, \\tShape X: \\033[1m{X_data.shape}\\033[0m, Shape y: \\033[1m{y_data.shape}\\033[0m\")\n",
    "    \n",
    "    if key in processed_datasets:\n",
    "        print(f\"ATTENZIONE: Il dataset {key} è già stato elaborato! Salto iterazione...\")\n",
    "        continue\n",
    "        \n",
    "    processed_datasets.add(key)\n",
    "    \n",
    "    X_train, X_val, X_test, y_train, y_val, y_test = split_data(X_data, y_data)\n",
    "    print(f\"Dataset Splitting: Train: \\033[1m{X_train.shape}\\033[0m, Val: \\033[1m{X_val.shape}\\033[0m, Test: \\033[1m{X_test.shape}\\033[0m\")\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    CREO COPIA TEST_LOADER_RAW PER I PLOT DEL POWER RAW PER BANDA E CLASSE\n",
    "    '''\n",
    "    # 1) salva una copia RAW dei soli dati di test PRIMA di standardizzare\n",
    "    X_test_raw = X_test.copy()\n",
    "    y_test_raw = y_test.copy()\n",
    "    \n",
    "    # 2) tensori\n",
    "    X_raw_tensor = torch.tensor(X_test_raw, dtype=torch.float32)\n",
    "    y_raw_tensor = torch.tensor(y_test_raw, dtype=torch.long)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #for model_name in [\"CNN2D\", \"BiLSTM\", \"Transformer\"]:\n",
    "    \n",
    "    '''ATTENZIONE MODIFICA QUI'''\n",
    "    \n",
    "    for model_name in [\"CNN2D_LSTM_TF\", \"BiLSTM\", \"Transformer\"]:\n",
    "\n",
    "        model_key = f\"{model_name}_{key}\"\n",
    "        if model_key in processed_models:\n",
    "            print(f\"ATTENZIONE: Il modello {model_name} per il dataset {key} è già stato addestrato! Salto iterazione...\")\n",
    "            continue\n",
    "        processed_models.add(model_key)\n",
    "        \n",
    "        print(f\"\\nPreparazione dati per il dataset \\033[1m{key}\\033[0m e il modello \\033[1m{model_name}\\033[0m...\")\n",
    "        \n",
    "        # Prova a caricare la configurazione e i pesi ottimali dal file .pkl\n",
    "        \n",
    "        '''\n",
    "        load_config_if_available --> prende in input 'key' che è la chiave composita (i.e, th_resp_vs_pt_resp_1_20_familiar_th)\n",
    "        parse_combination_key --> prende in input 'key' che suddivide la chiave composita in stringhe separate\n",
    "        \n",
    "        exp_cond, data_type, category_subject che sfrutto per crearmi la directory path che mi servirà per caricarmi \n",
    "        pesi del modello e i suoi iper-parametri\n",
    "        \n",
    "        Diciamo che in questo caso, sfrutto 'parse_combination_key per qualcosa che serve a 'load_config_if_available' in modo IMPLICITO..\n",
    "        '''\n",
    "        \n",
    "        config, best_weights = load_config_if_available(key, model_name, base_folder)\n",
    "        \n",
    "        if config is None:\n",
    "            raise ValueError(f\"\\033[1mNessun file .pkl trovato per {model_name} su {key}\\033[0m. Non posso procedere senza la configurazione ottimale.\")\n",
    "        \n",
    "        '''\n",
    "        Successivamente, queste variabili vengono invece create in maniera ESPLICITA per fasi successive del loop\n",
    "        MA in questo caso, parsifica la chiave una VOLTA SOLA e memorizza i valori!\n",
    "        '''\n",
    "        \n",
    "        # Parsifica la chiave una volta sola e memorizza i valori\n",
    "        exp_cond, data_type, category_subject = parse_combination_key(key)\n",
    "        \n",
    "        '''\n",
    "        Dpodiché, \n",
    "        \n",
    "        1) si carica i vari valori degli iper-parametri,\n",
    "        2) si esegue la standardizzazione se servisse,\n",
    "        3) prepara il modello per la divisione in train_loader etc.,\n",
    "        4) si carica la configurazione dei pesi del modello, \n",
    "        5) assegna i vari valori degli iper-parametri del modello corrente per la combinazione di dati correntemente iterata \n",
    "        \n",
    "        6) esegue il training e il test e poi\n",
    "        \n",
    "        7) si salva il tutto nella path corrispondente...\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        Ricordati di aggiungere le varie variabili associate alla definizione dinamica dei valori dei parametri model-specific qui!\n",
    "    \n",
    "        \n",
    "        \n",
    "        '''\n",
    "        \n",
    "        '''\n",
    "        PER DARE UNIFORMITÀ AL CODICE, CAMBIO IL NOME DELLE VARIABILI, CHE CONTENGONO I VALORI OTTIMIZZATI \n",
    "        DA FORNIRE IN INPUT ALLE VARIE FUNZIONI CHE SONO RICHIAMATE NEL LOOP'''\n",
    "        \n",
    "        \n",
    "        model_lr = config[\"lr\"]\n",
    "        model_weight_decay = config[\"weight_decay\"]\n",
    "        model_n_epochs = config[\"n_epochs\"]\n",
    "        model_patience = config[\"patience\"]\n",
    "        \n",
    "        \n",
    "        model_batch_size = config[\"batch_size\"]\n",
    "        model_standardization = config[\"standardization\"]\n",
    "        \n",
    "        #model_n_epochs = config[\"n_epochs\"]\n",
    "        #model_patience = config[\"patience\"]\n",
    "        \n",
    "        #model_lr = config[\"lr\"]\n",
    "        \n",
    "        '''NUOVE MODIFICHE'''\n",
    "        model_beta1 =  config[\"beta1\"]\n",
    "        model_beta2 =  config[\"beta2\"]\n",
    "        model_eps = config[\"eps\"]\n",
    "        \n",
    "        \n",
    "        \n",
    "        #model_weight_decay = config[\"weight_decay\"]\n",
    "        #model_standardization = config[\"standardization\"]\n",
    "        \n",
    "        #print(f\"Parametri per \\033[1m{model_name}\\033[0m: batch_size= \\033[1m{model_batch_size}\\033[0m, n_epochs= \\033[1m{model_n_epochs}\\033[0m, patience= \\033[1m{model_patience}\\033[0m, lr= \\033[1m{model_lr}\\033[0m, weight_decay= \\033[1m{model_weight_decay}\\033[0m, standardization= \\033[1m{model_standardization}\\033[0m\")\n",
    "        print(f\"Parametri per \\033[1m{model_name}\\033[0m: batch_size= \\033[1m{model_batch_size}\\033[0m, n_epochs= \\033[1m{model_n_epochs}\\033[0m, patience= \\033[1m{model_patience}\\033[0m, lr= \\033[1m{model_lr}\\033[0m, model_beta1= \\033[1m{model_beta1}\\033[0m,  model_beta2= \\033[1m{model_beta2}\\033[0m,  model_eps= \\033[1m{model_eps}\\033[0m, standardization= \\033[1m{model_standardization}\\033[0m\")\n",
    "        \n",
    "        # Salva nel dizionario se per quella combinazione è stata applicata la standardizzazione ai dati\n",
    "        models_info[model_key] = {\"standardization\": model_standardization}\n",
    "        \n",
    "        \n",
    "        # 3) dataset & loader per test set (per plots power raw) –‑  IMPORTANTISSIMO: shuffle=False\n",
    "        raw_dataset = TensorDataset(X_raw_tensor, y_raw_tensor)\n",
    "        test_loader_raw = DataLoader(raw_dataset,\n",
    "                             batch_size=model_batch_size,\n",
    "                             shuffle=False)\n",
    "        \n",
    "        \n",
    "        \n",
    "        '''PER MANTENERE LA STESSA LOGICA DEL CODICE (ANCHE SE POTREI INSERIRLA DENTRO PREPARE_DATA_FOR_MODEL MODIFICANDO LA FUNZIONE (SI VEDA IN CELLA SOPRA COME)\n",
    "        IMPONGONO LA STANDARDIZZAZIONE PRIMA DI QUESTA FUNZIONE\n",
    "        '''\n",
    "\n",
    "        if model_standardization:\n",
    "            X_train, X_val, X_test = standardize_data(X_train, X_val, X_test)\n",
    "            print(f\"\\033[1mSÌ Standardizzazione Dati!\\033[0m\")\n",
    "        else:\n",
    "            print(f\"\\033[1mNO Standardizzazione Dati!\\033[0m\")\n",
    "        \n",
    "        # Sposta il modello sulla GPU (se disponibile)\n",
    "        device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "        \n",
    "        # Preparazione dei dataloaders\n",
    "        train_loader, val_loader, test_loader, class_weights_tensor = prepare_data_for_model(\n",
    "            X_train, X_val, X_test, y_train, y_val, y_test, model_type = model_name, batch_size = model_batch_size)\n",
    "        \n",
    "        # Inizializzazione del modello\n",
    "        #if model_name == \"CNN2D\":\n",
    "        #    model = CNN2D(input_channels=64, num_classes=2)\n",
    "        \n",
    "        '''\n",
    "        # ====== MODELLI TIME×FREQ ======\n",
    "    \n",
    "        cnn_model = CNN2D_LSTM_TF(input_channels = input_channels, num_classes =num_classes, dropout = dropout)\n",
    "        hidden_sizes = [24, 48, 62]\n",
    "        lstm_model = ReadMEndYou(input_size=input_channels * num_freqs, hidden_sizes=hidden_sizes, output_size=num_classes)\n",
    "        transformer_model = ReadMYMind(d_model=d_model, num_heads=num_heads, num_layers=num_layers, num_classes=num_classes)\n",
    "\n",
    "        # Creazione di dati fittizi per il test\n",
    "        x = torch.randn(batch_size, input_channels, num_freqs, num_timepoints)  # (batch, canali, frequenze, tempo)\n",
    "        \n",
    "\n",
    "        # ricavo channels e freqs dai dati (shape attesa: N, C, F, T)\n",
    "        channels, freqs = int(X_train.shape[1]), int(X_train.shape[2])\n",
    "\n",
    "        if config.model_name == \"CNN2D_LSTM_TF\":\n",
    "\n",
    "            #OCCHIO QUI ADESSO SAREBBE TEMPO x FREQUENZA\n",
    "\n",
    "            model = CNN2D_LSTM_TF(\n",
    "                input_channels = channels, # qui 64\n",
    "                num_classes = 2,\n",
    "                dropout=config.dropout,\n",
    "            )\n",
    "\n",
    "            print(f\"\\nInizializzazione Modello \\033[1mCNN2D_LSTM_TF\\033[0m\")\n",
    "\n",
    "\n",
    "        elif config.model_name == \"BiLSTM\":\n",
    "            hidden_sizes = [24, 48, 62]\n",
    "            model = ReadMEndYou(\n",
    "                input_size = channels * freqs, #  qui 64*81\n",
    "                hidden_sizes = hidden_sizes,\n",
    "                output_size = 2,\n",
    "                dropout = config.dropout,\n",
    "                bidirectional = config.bidirectional\n",
    "            )\n",
    "            print(f\"\\nInizializzazione Modello \\033[1mReadMEndYou (BiLSTM)\\033[0m\")\n",
    "\n",
    "        elif config.model_name == \"Transformer\":\n",
    "            model = ReadMYMind(\n",
    "                d_model=config.d_model,\n",
    "                num_heads=config.num_heads,\n",
    "                num_layers=config.num_layers,\n",
    "                num_classes=2,\n",
    "                channels = channels,\n",
    "                freqs = freqs\n",
    "            )\n",
    "\n",
    "            print(f\"\\nInizializzazione Modello \\033[1mReadMYMind (Transformer)\\033[0m\")\n",
    "        else:\n",
    "            raise ValueError(f\"Modello sconosciuto: {config.model_name}\")\n",
    "            \n",
    "        \n",
    "        '''\n",
    "        \n",
    "        #channels, freqs = int(X_train.shape[1]), int(X_train.shape[2])\n",
    "        \n",
    "        #sweep_config_cnn2d_lstm_tf\n",
    "        #sweep_config_bilstm\n",
    "        #sweep_config_transformer\n",
    "        \n",
    "        '''PARAMETRI MODEL-SPECIFIC DI CNN2D_LSTM_TF, BiLSTM e Transformer, ma richiamati al momenti della inizializzazione deii relativi sweep_config! '''\n",
    "        \n",
    "        #model_dropout = config['dropout']\n",
    "        #model_bidirectional = config['bidirectional']\n",
    "        #model_d_model = config['d_model']\n",
    "        #model_num_heads = config['num_heads']\n",
    "        #model_num_layers  = config['num_layers']\n",
    "        \n",
    "        \n",
    "        channels, freqs = int(X_train.shape[1]), int(X_train.shape[2])\n",
    "        \n",
    "        if model_name == \"CNN2D_LSTM_TF\":\n",
    "            \n",
    "            sweep_config = sweep_config_cnn2d_lstm_tf\n",
    "            \n",
    "            model_dropout = float(config.get('dropout', 0.5))\n",
    "            \n",
    "            \n",
    "            model = CNN2D_LSTM_TF(input_channels = channels, num_classes = 2, dropout = model_dropout) #input_channels = 64\n",
    "            \n",
    "        elif model_name == \"BiLSTM\":\n",
    "            \n",
    "            sweep_config = sweep_config_bilstm\n",
    "            \n",
    "            model_dropout = float(config.get('dropout', 0.5))\n",
    "            model_bidirectional = bool(config.get('bidirectional', False))\n",
    "            \n",
    "            #input_size= 64 * 81\n",
    "            model = ReadMEndYou(input_size= channels * freqs, hidden_sizes=[24, 48, 62], output_size=2, dropout = model_dropout, bidirectional = model_bidirectional)\n",
    "            \n",
    "        elif model_name == \"Transformer\":\n",
    "            \n",
    "            sweep_config = sweep_config_transformer\n",
    "            \n",
    "            model_d_model = int(config.get('d_model', 32))\n",
    "            model_num_heads = int(config.get('num_heads', 2))\n",
    "            model_num_layers  = int(config.get('num_layers', 2))\n",
    "            \n",
    "            model = ReadMYMind(d_model = model_d_model, num_heads = model_num_heads, num_layers = model_num_layers, num_classes=2, channels = channels, freqs= freqs) #channels = 64, freqs=81\n",
    "        else:\n",
    "            raise ValueError(f\"Modello {model_name} non riconosciuto.\")\n",
    "        \n",
    "        # Se abbiamo caricato i pesi ottimali, li carichiamo nel modello\n",
    "        if best_weights is not None:\n",
    "            try:\n",
    "                model.load_state_dict(best_weights)\n",
    "                print(f\"📊 Modello \\033[1m{model_name}\\033[0m inizializzato con \\033[01i pesi ottimizzati\\033[0m tramite hyper-parameter tuning su \\033[1mWeight & Biases\\033[0m\")\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️Errore nel caricamento dei pesi per {model_name} su {key}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        \n",
    "        '''NUOVE MODIFICHE'''\n",
    "        # Definizione del criterio di perdita\n",
    "        criterion = nn.CrossEntropyLoss(weight = class_weights_tensor)\n",
    "        \n",
    "        '''OLD VERSION'''\n",
    "        # Definizione dell'ottimizzatore con i parametri aggiornati\n",
    "        #optimizer = torch.optim.Adam(model.parameters(), lr = model_lr, weight_decay = model_weight_decay)\n",
    "        \n",
    "        '''NUOVE MODIFICHE'''\n",
    "        \n",
    "         # 10) ottimizzatore + scheduler + early stopping\n",
    "        optimizer = torch.optim.Adam(\n",
    "            model.parameters(),\n",
    "            lr    = model_lr,\n",
    "            betas = (model_beta1, model_beta2),\n",
    "            eps   = model_eps,\n",
    "            weight_decay = model_weight_decay\n",
    "            \n",
    "        )\n",
    "            \n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer,\n",
    "            mode     = \"min\",   # monitoriamo val_loss\n",
    "            factor   = 0.1,\n",
    "            patience = 8,\n",
    "            verbose  = True\n",
    "        )\n",
    "        early_stopping = EarlyStopping(patience=model_patience, mode=\"min\")\n",
    "        \n",
    "        \n",
    "        #criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
    "        \n",
    "        \n",
    "        '''OLD VERSION'''\n",
    "        #print(f\"🏋️‍♂️Avvio del training per \\033[1m{model_name}\\033[0m sul dataset \\033[1m{key}\\033[0m...\")\n",
    "        #my_train_results = training(model, train_loader, val_loader, optimizer, criterion, n_epochs = model_n_epochs, patience = model_patience)\n",
    "    \n",
    "        #print(f\"Avvio del testing per \\033[1m{model_name}\\033[0m sul dataset \\033[1m{key}\\033[0m...\")\n",
    "        #my_test_results = testing(my_train_results, test_loader, criterion)\n",
    "        \n",
    "        '''NEW VERSION'''\n",
    "        # --- dopo model.load_state_dict(best_weights) e criterion = nn.CrossEntropyLoss() ---\n",
    "\n",
    "        # 1) prepara i data_loaders per train/val\n",
    "        data_loaders = {\n",
    "            \"train\": train_loader,\n",
    "            \"val\":   val_loader\n",
    "        }\n",
    "        \n",
    "        print(f\"🏋️‍♂️Salvo le metriche del training per \\033[1m{model_name}\\033[0m sul dataset \\033[1m{key}\\033[0m a seguito della ottimizzazione su W&B ...\")\n",
    "        # 2) richiama la funzione che pesca da W&B la best‐run e corregge la train AUC\n",
    "        \n",
    "        #ATTENZIONE al potenziale problema di stringa, non di API: \n",
    "\n",
    "        #i due esempi che hai postato in realtà usano diversi caratteri “‑” (uno è il classico ASCII U+002D, l’altro è un non‑breaking hyphen U+2011 o simili), quindi quando chiami\n",
    "        \n",
    "        #entity = \"stefano‑bargione‑universit‑di‑roma‑tor‑vergata\"\n",
    "        #stai passando un nome che W&B non riconosce (e quindi api.projects(entity=…) torna vuoto), mentre con\n",
    "\n",
    "        #entity = \"stefano-bargione-universit-di-roma-tor-vergata\"\n",
    "        #funziona perché lì usi i semplici - ASCII.\n",
    "\n",
    "        my_train_results = load_best_run_results(\n",
    "            key=key,\n",
    "            model = model,\n",
    "            sweep_config = sweep_config,\n",
    "            data_loaders = data_loaders,\n",
    "            entity = \"stefano-bargione-universit-di-roma-tor-vergata\"\n",
    "        )\n",
    "        \n",
    "        \n",
    "        '''\n",
    "        L’entity che passi a Api().runs(f\"{entity}/{project}\") è semplicemente il tuo account (o l’organizzazione) su W&B,\n",
    "        cioè la parte che compare subito prima del nome del progetto nell’URL.\n",
    "\n",
    "        Per esempio, se quando apri il tuo progetto su W&B vedi un indirizzo del tipo\n",
    "        \n",
    "        -> https://wandb.ai/steclab/some_project_name, allora entity = \"steclab\".\n",
    "        \n",
    "        Se invece lavori sotto un’organizzazione \n",
    "        \n",
    "        -> “cool‑team”, e l’URL è https://wandb.ai/cool-team/some_project_name, allora userai entity = \"cool-team\".\n",
    "\n",
    "        Puoi verificarlo:\n",
    "\n",
    "        Accedi a wandb.ai e vai sul progetto.\n",
    "        Leggi la prima parte dell’URL (tra wandb.ai/ e il /project_name).\n",
    "        Copiala esattamente come stringa in entity.\n",
    "\n",
    "        Così il tuo Api().runs(f\"{entity}/{project}\") andrà a pescare proprio le run che hai lanciato tu.\n",
    "\n",
    "        my_train_results = load_best_run_results(\n",
    "            key= key,\n",
    "            model = model,\n",
    "            sweep_config = sweep_config,\n",
    "            data_loaders = data_loaders,\n",
    "            entity= \"mio-entity\"\n",
    "        )\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        print(f\"Avvio del testing per \\033[1m{model_name}\\033[0m sul dataset \\033[1m{key}\\033[0m...\")\n",
    "        # 3) usa il best_model caricato dentro `train_results` e chiama il testing\n",
    "        my_test_results = testing(my_train_results, test_loader, criterion)\n",
    "        \n",
    "        \n",
    "        \n",
    "        '''\n",
    "        GRADCAM COMPUTATION PER IL MODELLO CNN2D_LSTM_TF\n",
    "        \n",
    "        La funzione compute_gradcam_figure estrae due campioni (uno per ogni classe) e crea una figura con le due righe richieste.\n",
    "        \n",
    "        Il parametro gradcam_image (un buffer binario o un'immagine) viene passato alla funzione di salvataggio, \n",
    "        'save_performance_results', in modo da essere salvato nella path corretta. \n",
    "        \n",
    "        La funzione 'save_performance_results' è stata modificata \n",
    "        per gestire ANCHE questo nuovo input dell'immagine \n",
    "        \n",
    "        (ossia, per salvare il file con un nome che inizia con 'GradCAM_results_'\n",
    "        seguito da tutte le altre stringhe corrispondenti alla combinazione di fattori che costituiscono il dataset corrente:\n",
    "        \n",
    "        - coppia di condizioni sperimentali da cui provengono i dati (i.e., th_resp_vs_pt_resp )\n",
    "        - tipologia di dato EEG prelevato (i.e., spectrograms) \n",
    "        - provenienza del dato stesso (i.e., familiar_th)\n",
    "        )\n",
    "        \n",
    "        Spiegazione:\n",
    "        \n",
    "        La funzione compute_gradcam_figure eseguire il calcolo di GradCAM (vedi dettagli nella sua funzione)\n",
    "        e alla fine ritornerà in output una variabile \n",
    "        \n",
    "        'fig_image' che sarà poi assegnata alla variabile 'gradcam_image',\n",
    "        che è un oggetto buffer, che contiene i dati binari dell'immagine in formato PNG\n",
    "        (poiché abbiamo usato plt.savefig con format='png'). \n",
    "        \n",
    "        Quindi, quando passi gradcam_image (cioè fig_image) alla funzione 'save_performance_results',\n",
    "        viene scritto direttamente su disco come file PNG.\n",
    "        \n",
    "        Non c'è bisogno di ri-aprire o convertire ulteriormente, a meno che tu non voglia manipolare l'immagine in seguito.\n",
    "        Quindi, la soluzione è corretta così com'è:\n",
    "        il buffer viene salvato come file PNG nella directory specificata, \n",
    "        e successivamente potrai aprirlo con una libreria come cv2 o PIL se necessario.        \n",
    "        \n",
    "        Quindi, gradcam_image (i.e., fig_image) viene quindi passato correttamente dentro al loop di training e test, \n",
    "        tramite 'save_performance_results', come input, \n",
    "        che salverà quindi poi l'immagine nella path corrispondente \n",
    "\n",
    "        '''\n",
    "        \n",
    "        # Se il modello è CNN2D, calcola anche GradCAM per la visualizzazione\n",
    "        gradcam_image = None\n",
    "        \n",
    "        #if model_name == \"CNN2D\":\n",
    "        \n",
    "        '''ATTENZIONE MODIFICA QUI'''\n",
    "        \n",
    "        if model_name == \"CNN2D_LSTM_TF\":\n",
    "            \n",
    "            '''\n",
    "            ATTENZIONE! Qui ho aggiunto alla nuova versione di \"compute_gradcam_figure\" (versione del 17/09/2025)\n",
    "            il test_loader_raw tra gli argomenti della funzione!\n",
    "            '''\n",
    "            gradcam_image = compute_gradcam_figure(model, test_loader, test_loader_raw, exp_cond, data_type, category_subject, device)\n",
    "            if gradcam_image is not None:\n",
    "                print(f\"Creazione di \\033[1mGradCAM Image\\033[0m per il modello \\033[1m{model_name}\\033[0m.\")\n",
    "                \n",
    "        print(f\"Salvataggio dei risultati per \\033[1m{model_name}\\033[0m sul dataset \\033[1m{key}\\033[0m...\")\n",
    "        save_performance_results(model_name,\n",
    "                                 my_train_results,\n",
    "                                 my_test_results,\n",
    "                                 key,\n",
    "                                 exp_cond,\n",
    "                                 model_standardization,\n",
    "                                 base_folder = save_path_folder,\n",
    "                                 gradcam_image = gradcam_image)\n",
    "        \n",
    "        \n",
    "        '''\n",
    "        N.B\n",
    "        \n",
    "        gradcam_image = None avverrà solo all'inizio cioè per il primo modello CNN2D, che verrà testato con una certa combinazione di dati mi sa.. \n",
    "        ma servirebbe tracciare in qualche modo \n",
    "\n",
    "        1) o che la gradcam_image di ogni combinazione venga ri-azzerata alla fine loop\n",
    "        2) o che venga monitorato che gradcam_image di una combinazione di dati già analizzata venga esclusa poi\n",
    "        (o messa in un set) in modo che rivenga per errore sovrascritta più volte.. \n",
    "        \n",
    "        Forse la strada più veloce potrebbe essere la soluzione 1)\n",
    "        \n",
    "        La soluzione più veloce e semplice è reimpostare la variabile gradcam_image a None alla fine dell'iterazione per ogni combinazione di dati\n",
    "        (cioè, all'interno del ciclo esterno che itera su key). \n",
    "         \n",
    "        In questo modo, per ogni nuovo dataset la variabile viene \"azzera\" e viene calcolata l'immagine GradCAM solo per quella combinazione, \n",
    "        evitando di sovrascrivere accidentalmente i risultati già calcolati per combinazioni precedenti.\n",
    "         \n",
    "        Un'altra possibilità sarebbe tenere traccia delle chiavi (o combinazioni) per cui hai già calcolato la GradCAM,\n",
    "        ad esempio usando un set, e saltare il calcolo se la combinazione è già presente. \n",
    "        \n",
    "        Tuttavia, se ogni combinazione deve avere la sua immagine, \n",
    "        la soluzione più semplice è quella di reimpostare gradcam_image = None alla fine dell'iterazione.\n",
    "        \n",
    "        Quindi, per esempio, alla fine del ciclo per ogni dataset (key) potresti fare:\n",
    "        (VEDI SOTTO)\n",
    "        \n",
    "        In questo modo, ti assicuri che per ogni nuova combinazione la variabile sia pulita e pronta per essere ricalcolata, \n",
    "        senza rischio di sovrascrivere o confondere i risultati\n",
    "        '''\n",
    "        \n",
    "        # Reimposta gradcam_image a None per la prossima combinazione di dati\n",
    "        gradcam_image = None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230dbfd1-e48b-4384-8526-1fbb9cabb7d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"finito\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89734ab8-5e46-4287-acd1-8a030e55e08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(models_info.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac03018-c1e2-45bc-8b0b-5e5ad6aee9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/stefano/Interrogait/spectrograms_best_models_post_WB_GradCAM_Checks_motor_task_1_new.pkl', 'wb') as f:\n",
    "    pickle.dump(models_info, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2080a3c-1b0e-43c4-8d94-1160a9948a79",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### **CREAZIONE DELLE TABLES CON INTEGRAZIONE DELLE PERFORMANCE TRAINING & TEST DEI MODELLI DENTRO DATAFRAME**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6d2065-f9dd-4ac2-a6b9-13ccba964341",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### **Integrazioni in Tabella delle Performance Training e Test del Modello dentro DataFrame - NEW APPROACH**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3a9728-0b81-4f22-ba9e-be6d38776373",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Spiegazione"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27171b6c-84af-45a8-8ab9-e7f093e820dd",
   "metadata": {},
   "source": [
    "Ok in questo modo, model_standardization_dict dovrebbe andare a salvarsi se, i dati per quella combinazione di fattori, rispetto ad uno specifico modello, siano stati standardizzati o meno.\n",
    "\n",
    "Di conseguenza, dentro questo loop\n",
    "\n",
    "    import os\n",
    "    import pickle\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    from pandas.plotting import table\n",
    "\n",
    "    # Base folder\n",
    "    base_folder = \"/home/stefano/Interrogait/time_domain_best_models_post_WB\"\n",
    "\n",
    "    # Condizioni sperimentali\n",
    "    experimental_conditions = [\"th_resp_vs_pt_resp\", \"th_resp_vs_shared_resp\", \"pt_resp_vs_shared_resp\"]\n",
    "\n",
    "    # Tipologie di dati\n",
    "    data_types = [\"1_20\", \"1_45\", \"wavelet_delta\"]\n",
    "\n",
    "    # Subfolders per tipologia di soggetto\n",
    "    subfolders = [\"th_fam\", \"th_unfam\", \"pt_fam\", \"pt_unfam\"]\n",
    "\n",
    "    # Dizionario per salvare tutti i modelli\n",
    "    all_models = {}\n",
    "\n",
    "    # Caricamento dei modelli\n",
    "    for condition in experimental_conditions:\n",
    "        for data_type in data_types:\n",
    "            for subfolder in subfolders:\n",
    "\n",
    "                path = os.path.join(base_folder, condition, data_type, subfolder)\n",
    "\n",
    "                if not os.path.exists(path):\n",
    "                    print(f\"Directory non trovata: {path}\")\n",
    "                    continue\n",
    "\n",
    "                # Creiamo la chiave per questa combinazione\n",
    "                key = f\"{condition}_{data_type}_{subfolder}\"\n",
    "                all_models[key] = {}\n",
    "\n",
    "                # Otteniamo la lista di file nella directory\n",
    "                files = os.listdir(path)\n",
    "\n",
    "                # Filtriamo e carichiamo i file .pkl\n",
    "                for file in files:\n",
    "                    if file.endswith(\".pkl\"):  # Controlliamo se è un file modello\n",
    "                        file_path = os.path.join(path, file)\n",
    "                        try:\n",
    "                            with open(file_path, \"rb\") as f:\n",
    "                                all_models[key][file] = pickle.load(f)\n",
    "                        except Exception as e:\n",
    "                            print(f\"Errore nel caricamento di {file}: {e}\")\n",
    "\n",
    "    # Creazione delle tabelle di performance\n",
    "    for key, models_dict in all_models.items():\n",
    "\n",
    "        # Otteniamo le informazioni dalla chiave\n",
    "        #condition, data_type, subfolder = key.split(\"_\", 2)\n",
    "        condition, data_type, subfolder = parse_combination_models_keys(key)\n",
    "\n",
    "        print(f\"\\nProcessing: \\033[1m{condition}\\033[0m - \\033[1m{data_type}\\033[0m - \\033[1m{subfolder}\\033[0m\\n\")\n",
    "\n",
    "        # Creazione della tabella\n",
    "        df_data = {\"Metriche\": [\"Accuracy\", \"Loss\", \"Precision\", \"Recall\", \"F1-Score\", \"AUC-ROC\"]}\n",
    "\n",
    "        # Iteriamo sui modelli caricati\n",
    "        for model_name, model_data in models_dict.items():\n",
    "            name_model = model_name.split(\"_\")[0]  # Nome modello\n",
    "            print(f\"    Processing model: \\033[1m{name_model}\\033[0m\")\n",
    "\n",
    "            try:\n",
    "                # Recupera i risultati di training e testing\n",
    "                train_scores = model_data.get('my_train_results', {}).get('training_performances', {})\n",
    "                test_scores = model_data.get('my_test_results', {}).get('test_performances', {})\n",
    "\n",
    "                # Converti i valori in float\n",
    "                train_scores = {key: float(value[0]) for key, value in train_scores.items()}\n",
    "                test_scores = {key: float(value[0]) for key, value in test_scores.items()}\n",
    "\n",
    "\n",
    "                # Aggiungi le metriche di training\n",
    "                df_data[f\"{name_model} (Training)\"] = [\n",
    "                    train_scores[\"train_accuracy\"],\n",
    "                    train_scores[\"train_loss\"],\n",
    "                    train_scores[\"train_precision\"],\n",
    "                    train_scores[\"train_recall\"],\n",
    "                    train_scores[\"train_f1_score\"],\n",
    "                    train_scores[\"train_auc\"],\n",
    "                ]\n",
    "\n",
    "                # Aggiungi le metriche di test\n",
    "                df_data[f\"{name_model} (Testing)\"] = [\n",
    "                    test_scores[\"test_accuracy\"],\n",
    "                    test_scores[\"test_loss\"],\n",
    "                    test_scores[\"test_precision\"],\n",
    "                    test_scores[\"test_recall\"],\n",
    "                    test_scores[\"test_f1_score\"],\n",
    "                    test_scores[\"test_auc\"],\n",
    "                ]\n",
    "\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"    Errore nell'elaborazione di {model_name}: {e}\")\n",
    "\n",
    "        # Creazione del DataFrame\n",
    "        #df_performances = pd.DataFrame(df_data)\n",
    "\n",
    "        # Crea un'immagine della tabella\n",
    "        #fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        #ax.axis('off')\n",
    "        #tabla = table(ax, df_performances, loc='center', colWidths=[0.2] * len(df_performances.columns))\n",
    "        #tabla.auto_set_font_size(True)\n",
    "        #tabla.set_fontsize(10)\n",
    "        #tabla.scale(2, 2)\n",
    "\n",
    "        # Evidenzia i nomi delle colonne\n",
    "        #for key, cell in tabla.get_celld().items():\n",
    "        #    if key[0] == 0:\n",
    "        #        cell.set_text_props(weight='bold')\n",
    "\n",
    "        # Salva l'immagine della tabella\n",
    "        path = os.path.join(base_folder, condition, data_type, subfolder)\n",
    "        file_name = f\"models_performances_{condition}_{data_type}_{subfolder}.png\"\n",
    "        img_file_path = os.path.join(path, file_name)\n",
    "        #fig.savefig(img_file_path, bbox_inches='tight', dpi=300)\n",
    "        #plt.close(fig)\n",
    "\n",
    "        print(f\"\\nTabella dei dati di \\033[1m{key}\\033[0m salvati in: \\n\\033[1m{img_file_path}\\033[0m\")\n",
    "\n",
    "\n",
    "vorrei provare ad iterare con \"zip\", sia all_models che su model_standardization_dict ...? (che forse dovrebbero avere la stessa struttura, che renderebbe possibile questa cosa...?)\n",
    "\n",
    "E, nel momento in cui si aggiungono le metriche del training e test del relativo modello, controllare rispetto a model_standardization_dict (di cui si ha la chiave per accedere all' informazione su se quel modello, per quella combinazioni di fattori che compongono quel dato) se il dato sia stato standardizzato... \n",
    "\n",
    "Se questo è VERO, allora nella colonna del dataframe che si riferisce al modello... vorrei che ci mettessi accanto, alla stringa che si riferisce al nome del modello (name_model) un asterisco, SOLO SE, per quel modello, allenato con quella combinazioni di fattori che compongono quel dato, i dati siano stati standardizzati...\n",
    "\n",
    "chiaro?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de272833-7493-485b-b243-8b56af4cf443",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Implementazione "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239247af-02a3-458b-b389-8a23ddcba9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "path = '/home/stefano/Interrogait/'\n",
    "\n",
    "with open(f\"{path}spectrograms_best_models_post_WB_GradCAM_Checks_motor_task_1_new.pkl\", \"rb\") as f:\n",
    "    models_info = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19611c9-56a3-4981-b9c4-90d6ac379379",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "In questo codice:\n",
    "\n",
    "model_info.get('standardization', False) cerca la chiave 'standardization' all'interno di ogni sottodizionario. \n",
    "Se non esiste, restituirà False come valore di default.\n",
    "Se standardization è True, stampa la chiave associata.\n",
    "'''\n",
    "\n",
    "# Ciclo attraverso le chiavi di 'models_info'\n",
    "for key, model_info in models_info.items():\n",
    "    # Controllo se 'standardization' è True\n",
    "    if model_info.get('standardization', False):  # Default a False nel caso in cui non esista la chiave\n",
    "        print(key)  # Stampa la chiave\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d384f7c7-d111-4063-b1d6-4b9d800a890f",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b61a41d-aa17-437e-92cc-8a9077d0b2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for key, model_info in all_models.items():\n",
    "#    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e3c8e2-8c4f-439d-bba0-4fda22320ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Siccome la stringa associata alla category subject è diversa tra i due.. \n",
    "\n",
    "familiar_th  familiar_pt unfamiliar_pt unfamiliar_pt  da un lato (models_info)\n",
    "th_fam, pt_fam, th_unfam, pt_unfam  dall'altro (all_models)\n",
    "\n",
    "la corrispondenza non avverrà mai... per cui, si deve fare il mapping corrispondente tra \n",
    "le stringhe di uno e dell'altro, in modo che models_info cambi come parte della stringa della sua chiave da queste \n",
    "\n",
    "familiar_th  familiar_pt unfamiliar_pt unfamiliar_pt\n",
    "a queste\n",
    "th_fam, pt_fam, th_unfam, pt_unfam \n",
    "\n",
    "'''\n",
    "\n",
    "mapping_subject = {\n",
    "    \"familiar_th\": \"th_fam\",\n",
    "    \"familiar_pt\": \"pt_fam\",\n",
    "    \"unfamiliar_th\": \"th_unfam\",\n",
    "    \"unfamiliar_pt\": \"pt_unfam\"\n",
    "}\n",
    "\n",
    "# Creiamo un nuovo dizionario con le chiavi corrette\n",
    "updated_models_info = {}\n",
    "\n",
    "for key, value in models_info.items():\n",
    "    for old_suffix, new_suffix in mapping_subject.items():\n",
    "        if key.endswith(old_suffix):\n",
    "            new_key = key.replace(old_suffix, new_suffix)\n",
    "            updated_models_info[new_key] = value\n",
    "            break  # Evita sostituzioni multiple se una è già stata fatta\n",
    "    else:\n",
    "        # Se nessuna sostituzione è stata fatta, mantieni la chiave originale\n",
    "        updated_models_info[key] = value\n",
    "\n",
    "# Sostituisci il vecchio dizionario con quello aggiornato\n",
    "models_info = updated_models_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2a69ac-2db4-4487-8349-2412ebee7e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_info.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe35486-b430-4fc9-84f5-b806a96c9e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Ciclo attraverso le chiavi di 'models_info' AGGIORNATO!'''\n",
    "\n",
    "for key, model_info in models_info.items():\n",
    "    # Controllo se 'standardization' è True\n",
    "    if model_info.get('standardization', False):  # Default a False nel caso in cui non esista la chiave\n",
    "        print(key)  # Stampa la chiavi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced9833f-fd78-4fe8-aa31-0e10b2e335c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Parsing della chiave e costruzione del path:\n",
    "Usando la funzione parse_combination_key si estraggono \n",
    "\n",
    "exp_cond, data_type e category_subject dalla chiave del dataset. \n",
    "\n",
    "Questi vengono usati per costruire il percorso in cui cercare i file .pkl.\n",
    "'''\n",
    "\n",
    "# Funzione per parsare la chiave\n",
    "def parse_combination_models_keys(combination_key):\n",
    "    \"\"\"\n",
    "    Estrae (exp_cond, data_type, category_subject) da combination_key.\n",
    "    \n",
    "    Il formato atteso PRIMA è:\n",
    "    \n",
    "    \"th_resp_vs_pt_resp|pt_resp_vs_shared_resp|th_resp_vs_shared_resp\" _ spectrograms\" _ \"familiar_th|familiar_pt|unfamiliar_th|unfamiliar_pt\"\n",
    "    \n",
    "    Il formato atteso ORA è:\n",
    "    \n",
    "     \"th_resp_vs_pt_resp|pt_resp_vs_shared_resp|th_resp_vs_shared_resp\" _ spectrograms\" _ \"th_fam|th_unfam|pt_fam|pt_unfam\"\n",
    "     \n",
    "    \"\"\"\n",
    "    #r\"^(th_resp_vs_pt_resp|pt_resp_vs_shared_resp|th_resp_vs_shared_resp)_(spectrograms)_(th_fam|th_unfam|pt_fam|pt_unfam)$\", \n",
    "    \n",
    "    match = re.match(\n",
    "        r\"^(rest_vs_left_fist|rest_vs_right_fist|left_fist_vs_right_fist)_(spectrograms)_(th_fam|th_unfam|pt_fam|pt_unfam)$\",\n",
    "        combination_key\n",
    "    )\n",
    "    if match:\n",
    "        return match.groups()  # (exp_cond, data_type, category_subject)\n",
    "    else:\n",
    "        raise ValueError(f\"Formato non valido: {combination_key}\")\n",
    "        \n",
    "    return exp_cond, data_type, category_subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b82fd6-88b0-457a-998f-f9efe913ff09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "NEW APPROACH \n",
    "\n",
    "Adesso replichiamo l'approccio usato prima, ma stavolta integrado tutte le combinazioni di dati. \n",
    "Andiamo a\n",
    "\n",
    "1) iterare sulla struttura delle directory a partire da base_folder, \n",
    "2) caricare i modelli .pkl per ogni combinazione di fattori che compongono i dati\n",
    "3) creare un DataFrame che raccolga le metriche di tutti i modelli relativi alla stessa combinazione di dati. \n",
    "\n",
    "Infine, salviamo questa tabella come immagine all'interno della cartella corrispondente\n",
    "'''\n",
    "\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import table\n",
    "\n",
    "\n",
    "\n",
    "# Base folder\n",
    "#base_folder = \"/home/stefano/Interrogait/spectrograms_best_models_post_WB\"\n",
    "\n",
    "base_folder = \"/home/stefano/Interrogait/spectrograms_best_models_post_WB_GradCAM_Checks_motor_task_1_new\"\n",
    "                                        #spectrograms_best_models_post_WB_GradCAM_Checks_motor_task_1_new\n",
    "\n",
    "# Condizioni sperimentali\n",
    "#experimental_conditions = [\"th_resp_vs_pt_resp\", \"th_resp_vs_shared_resp\", \"pt_resp_vs_shared_resp\"]\n",
    "\n",
    "experimental_conditions = [\"rest_vs_left_fist\", \"rest_vs_right_fist\", \"left_fist_vs_right_fist\"]\n",
    "\n",
    "\n",
    "# Tipologie di dati\n",
    "data_types = [\"spectrograms\"]\n",
    "\n",
    "# Subfolders per tipologia di soggetto\n",
    "#subfolders = [\"th_fam\", \"th_unfam\", \"pt_fam\", \"pt_unfam\"]\n",
    "\n",
    "subfolders = [\"th_fam\"]\n",
    "\n",
    "# Dizionario per salvare tutti i modelli\n",
    "all_models = {}\n",
    "\n",
    "# Caricamento dei modelli\n",
    "for condition in experimental_conditions:\n",
    "    for data_type in data_types:\n",
    "        for subfolder in subfolders:\n",
    "            \n",
    "            path = os.path.join(base_folder, condition, data_type, subfolder)\n",
    "            \n",
    "            if not os.path.exists(path):\n",
    "                print(f\"Directory non trovata: {path}\")\n",
    "                continue\n",
    "            \n",
    "            # Creiamo la chiave per questa combinazione\n",
    "            key = f\"{condition}_{data_type}_{subfolder}\"\n",
    "            all_models[key] = {}\n",
    "\n",
    "            # Otteniamo la lista di file nella directory\n",
    "            files = os.listdir(path)\n",
    "            \n",
    "            # Filtriamo e carichiamo i file .pkl\n",
    "            for file in files:\n",
    "                if file.endswith(\".pkl\"):  # Controlliamo se è un file modello\n",
    "                    file_path = os.path.join(path, file)\n",
    "                    try:\n",
    "                        with open(file_path, \"rb\") as f:\n",
    "                            all_models[key][file] = pickle.load(f)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Errore nel caricamento di {file}: {e}\")\n",
    "\n",
    "# Creazione delle tabelle di performance\n",
    "for key, models_dict in all_models.items():\n",
    "    \n",
    "    # Otteniamo le informazioni dalla chiave\n",
    "    condition, data_type, subfolder = parse_combination_models_keys(key)\n",
    "    \n",
    "    print(f\"\\nProcessing: \\033[1m{condition}\\033[0m - \\033[1m{data_type}\\033[0m - \\033[1m{subfolder}\\033[0m\\n\")\n",
    "    \n",
    "    # Creazione della tabella\n",
    "    df_data = {\"Metriche\": [\"Accuracy\", \"Loss\", \"Precision\", \"Recall\", \"F1-Score\", \"AUC-ROC\"]}\n",
    "\n",
    "    # Iteriamo sui modelli caricati\n",
    "    for model_name, model_data in models_dict.items():\n",
    "        \n",
    "        # Estrai il nome del modello dal file (ad esempio, \"CNN1D\" da \"CNN1D_performances_...pkl\")\n",
    "        #name_model = model_name.split(\"_\")[0]\n",
    "        \n",
    "        if model_name.startswith((\"CNN2D_LSTM\")):\n",
    "            \n",
    "            # es. “CNN3D_LSTM_FC”  →  split → [“CNN3D”, “LSTM”, “FC”] → prendi i primi 2 elementi\n",
    "            parts = model_name.split(\"_\")\n",
    "            name_model = \"_\".join(parts[:2])      # “CNN3D_LSTM” o “SeparableCNN2D_LSTM”\n",
    "        else:\n",
    "            name_model = model_name.split(\"_\")[0]  # Prende solo CNN1D, CNN2D\n",
    "        \n",
    "        print(f\"    Processing model: \\033[1m{name_model}\\033[0m\")\n",
    "        \n",
    "        # Costruisci la chiave utilizzata nel dizionario models_info\n",
    "        \n",
    "        '''\n",
    "        Nota: occorrerà che il formato della chiave sia consistente tra i due loop.\n",
    "        \n",
    "        Ad esempio, se nel primo loop era f\"{key}_{model_name}\", qui potresti dover fare:\n",
    "        model_key = f\"{key}_{name_model}\"\n",
    "        \n",
    "        Oppure, se nel primo loop era f\"{model_name}_{key}\", qui potresti dover fare:\n",
    "        model_key = f\"{name_model}_{key}\"\n",
    "        \n",
    "        '''\n",
    "        model_key = f\"{name_model}_{key}\"\n",
    "        \n",
    "        # Controlla se i dati sono stati standardizzati per questo modello\n",
    "        standardization_flag = models_info.get(model_key, {}).get(\"standardization\", False)\n",
    "        \n",
    "        if standardization_flag:\n",
    "            #suffix = \"*\" \n",
    "            suffix = \"\" \n",
    "        else:\n",
    "            suffix = \"\" \n",
    "        \n",
    "        try:\n",
    "            # Recupera i risultati di training e testing\n",
    "            train_scores = model_data.get('my_train_results', {}).get('training_performances', {})\n",
    "            \n",
    "            val_scores = model_data.get('my_train_results', {}).get('validation_performances', {})\n",
    "            \n",
    "            test_scores = model_data.get('my_test_results', {}).get('test_performances', {})\n",
    "            \n",
    "            # Converti i valori in float\n",
    "            train_scores = {key: float(value[0]) for key, value in train_scores.items()}\n",
    "            \n",
    "            val_scores = {key: float(value[0]) for key, value in val_scores.items()}\n",
    "            \n",
    "            \n",
    "            test_scores = {key: float(value[0]) for key, value in test_scores.items()}\n",
    "            \n",
    "            \n",
    "            # Aggiunge le metriche di training, modificando il nome della colonna se è vera la condizione\n",
    "            col_train = f\"{name_model} (Training){suffix}\"  # Usa suffix qui per il nome\n",
    "            \n",
    "            df_data[f\"{col_train}\"] = [\n",
    "                train_scores[\"train_accuracy\"],\n",
    "                train_scores[\"train_loss\"],\n",
    "                train_scores[\"train_precision\"],\n",
    "                train_scores[\"train_recall\"],\n",
    "                train_scores[\"train_f1_score\"],\n",
    "                train_scores[\"train_auc\"],\n",
    "            ]\n",
    "            \n",
    "            col_val = f\"{name_model} (Validation){suffix}\"  # Usa suffix qui per il nome\n",
    "            \n",
    "            \n",
    "            df_data[f\"{col_val}\"] = [\n",
    "                val_scores[\"val_accuracy\"],\n",
    "                val_scores[\"val_loss\"],\n",
    "                val_scores[\"val_precision\"],\n",
    "                val_scores[\"val_recall\"],\n",
    "                val_scores[\"val_f1_score\"],\n",
    "                val_scores[\"val_auc\"],\n",
    "            ]\n",
    "\n",
    "            # Aggiunge le metriche di training, modificando il nome della colonna se è vera la condizione\n",
    "            col_test = f\"{name_model} (Test){suffix}\"  # Usa suffix qui per il nome\n",
    "            \n",
    "            df_data[f\"{col_test}\"] = [\n",
    "                test_scores[\"test_accuracy\"],\n",
    "                test_scores[\"test_loss\"],\n",
    "                test_scores[\"test_precision\"],\n",
    "                test_scores[\"test_recall\"],\n",
    "                test_scores[\"test_f1_score\"],\n",
    "                test_scores[\"test_auc\"],\n",
    "            ]\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"    Errore nell'elaborazione di {model_name}: {e}\")\n",
    "\n",
    "    # Creazione del DataFrame\n",
    "    df_performances = pd.DataFrame(df_data)\n",
    "\n",
    "    # Crea un'immagine della tabella\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    ax.axis('off')\n",
    "    \n",
    "    # Aggiunta del titolo\n",
    "    #title = f\"DL Models performances for Exp Conditions: {condition}, EEG data: {data_type}, Subject: {subfolder}\"\n",
    "    title = f\"DL Models performances for Exp Conditions: {condition}, EEG data: {data_type}\"\n",
    "    ax.set_title(title, fontsize=12, fontweight=\"bold\", pad=20)\n",
    "\n",
    "    tabla = table(ax, df_performances, loc='center', colWidths=[0.2] * len(df_performances.columns))\n",
    "    tabla.auto_set_font_size(True)\n",
    "    tabla.set_fontsize(10)\n",
    "    tabla.scale(2, 2)\n",
    "\n",
    "    # Evidenzia i nomi delle colonne\n",
    "    for key, cell in tabla.get_celld().items():\n",
    "        if key[0] == 0:\n",
    "            cell.set_text_props(weight='bold')\n",
    "\n",
    "    # Salva l'immagine della tabella\n",
    "    path = os.path.join(base_folder, condition, data_type, subfolder)\n",
    "    file_name = f\"models_performances_{condition}_{data_type}_{subfolder}.png\"\n",
    "    img_file_path = os.path.join(path, file_name)\n",
    "    fig.savefig(img_file_path, bbox_inches='tight', dpi=300)\n",
    "    plt.close(fig)\n",
    "\n",
    "    print(f\"\\nTabella dei dati di \\033[1m{condition}_{data_type}_{subfolder}\\033[0m salvati in: \\n\\033[1m{img_file_path}\\033[0m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17976f1c-3932-4192-8c47-b4eea521ae2f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Impostazione **Weight & Biases DL Training** con **Rappresentazione Frequenza-Elettrodi dei miei dati EEG** a seconda del Dataset del Task scelto\n",
    "\n",
    "\n",
    "Notebook **\"Optimization Weight and Biases Time Domain EEG Spectrograms\"**\n",
    "\n",
    "- Task 1: Motor Execution (Open and close right or left fist) - Unilateral - Runs 3, 7, 11 \n",
    "- Task 2: Motor Imagery (Imagine opening and closing right and left fists) - Unilateral - Runs 4, 8, 12 \n",
    "- Task 3: Motor Execution (Open and close both fists and feet) - Bilateral - Runs 5, 9, 13 \n",
    "- Task 4: Motor Imagery (Imagine opening and closing both fists and feet) - Bilateral - Runs 6, 10, 14 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1805cd4b-daf6-4deb-982a-075504e60604",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Optimization Weight and Biases - EEG Spectrograms - Electrodes x Frequencies - CNN2D_LSTM\n",
    "\n",
    "### (**Solo Iper-parametri Dinamici**)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af03aa8-05d2-4eab-acce-880a5a49a811",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### **Weight & Biases Login & REMOTE CHECKS - EEG Spectrograms - Electrodes x Frequencies**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c78b6f3-9f2e-4ca1-a2c6-6d1044eb3f28",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### **Weight & Biases Login PRECEDURA CORRETTA ✅ (CANCELLAZIONE RUNS e NON SWEEPS!) - EEG Spectrograms - Electrodes x Frequencies V1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afecd078-29cf-4a63-8e3c-48376cddc0e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Puoi usare l’API Python di W&B per elencare da remoto tutti i progetti di una certa entity (tuo utente o organizzazione).\n",
    "\n",
    "Ad esempio:\n",
    "\n",
    "'''\n",
    "\n",
    "import wandb\n",
    "\n",
    "# 1) autenticati (se non l’hai già fatto con wandb.login())\n",
    "# wandb.login()\n",
    "\n",
    "# 2) crea un’istanza dell’API\n",
    "api = wandb.Api()\n",
    "\n",
    "# 3) scegli la tua entity (nome utente o org). \n",
    "#    Se omesso, prende la tua entity di default.\n",
    "\n",
    "entity = 'stefano-bargione-universit-di-roma-tor-vergata'\n",
    "\n",
    "# 4) prendi la lista dei progetti\n",
    "projects = api.projects(entity=entity)\n",
    "\n",
    "# 5) stampa i nomi\n",
    "for proj in projects:\n",
    "    print(proj.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a77297-f866-44f8-9fa7-ff83b3201f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "###TUTTE ASSIEME\n",
    "\n",
    "\n",
    "import wandb\n",
    "\n",
    "# Nomi dei progetti\n",
    "project_names = [\n",
    "    #'left_fist_vs_right_fist_spectrograms_channels_freqs_new_2d_grid_multiband',\n",
    "    #'rest_vs_right_fist_spectrograms_channels_freqs_new_2d_grid_multiband',\n",
    "    #'rest_vs_left_fist_spectrograms_channels_freqs_new_2d_grid_multiband',\n",
    "    \n",
    "    #'left_fist_vs_right_fist_spectrograms_channels_freqs_new_imagery_2d_grid_multiband'\n",
    "    #'rest_vs_right_fist_spectrograms_channels_freqs_new_imagery_2d_grid_multiband',\n",
    "    #'rest_vs_left_fist_spectrograms_channels_freqs_new_imagery_2d_grid_multiband',\n",
    "    \n",
    "    #'both_feet_vs_both_fists_spectrograms_channels_freqs_new_imagery_2d_grid_multiband',\n",
    "    #'rest_vs_both_fists_spectrograms_channels_freqs_new_imagery_2d_grid_multiband',\n",
    "    #'rest_vs_both_feet_spectrograms_channels_freqs_new_imagery_2d_grid_multiband',\n",
    "    \n",
    "    #'both_feet_vs_both_fists_spectrograms_channels_freqs_new_2d_grid_multiband',\n",
    "    #'rest_vs_both_fists_spectrograms_channels_freqs_new_2d_grid_multiband',\n",
    "    #'rest_vs_both_feet_spectrograms_channels_freqs_new_2d_grid_multiband'\n",
    "\n",
    "]\n",
    "\n",
    "user_name = 'stefano-bargione-universit-di-roma-tor-vergata'\n",
    "\n",
    "# Connessione all'API di W&B\n",
    "api = wandb.Api()\n",
    "\n",
    "# Itera su tutti i progetti\n",
    "for project_name in project_names:\n",
    "    print(f\"\\nSelezione delle run per il progetto: \\033[1m{project_name}\\033[0m\")\n",
    "    \n",
    "    # Recupera tutte le run del progetto\n",
    "    runs = api.runs(f\"{user_name}/{project_name}\")\n",
    "    \n",
    "    # Salva gli ID delle run da eliminare\n",
    "    run_ids_to_delete = []\n",
    "    \n",
    "    for run in runs:\n",
    "        #print(f\"Estrazione run ID: {run.id} - Run Name: {run.name}\")\n",
    "        run_ids_to_delete.append(run.id)  # Aggiungi l'ID della run alla lista\n",
    "    \n",
    "    print(f\"\\nTotale runs da eliminare: \\033[1m{len(run_ids_to_delete)}\\033[0m\")\n",
    "    \n",
    "    # Elimina le run\n",
    "    for run_id in run_ids_to_delete:\n",
    "        run = api.run(f\"{user_name}/{project_name}/{run_id}\")\n",
    "        run.delete()  # Elimina la run\n",
    "        #print(f\"Eliminata la run con ID: {run_id}\")\n",
    "    print(f\"Eliminazione runs completata\")\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7d24ae-7de0-4d5d-a352-aa94a1acfaee",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### **Weight & Biases Login PRECEDURA CORRETTA ✅ (CANCELLAZIONE RUNS e SWEEPS!) - EEG Spectrograms - Electrodes x Frequencies** V2"
   ]
  },
  {
   "cell_type": "raw",
   "id": "953dd86d-4cae-42d2-ac58-586f6b938821",
   "metadata": {
    "tags": []
   },
   "source": [
    "'''\n",
    "\n",
    "Sì, è perfettamente normale: in W&B un progetto è semplicemente un contenitore di run e di sweep, \n",
    "e rimane visibile (anche se vuoto) fintanto che non lo archivi o lo cancelli esplicitamente. \n",
    "\n",
    "Cancellare tutte le run e tutti i sweep in un progetto non elimina il progetto stesso — lascia solo un progetto “vuoto” con zero run/sweep.\n",
    "\n",
    "\n",
    "Come rimuovere (o archiviare) anche i progetti\n",
    "\n",
    "\n",
    "1) Dal web UI\n",
    "\n",
    "Vai nella pagina del progetto che vuoi rimuovere.\n",
    "\n",
    "Clicca sui tre puntini (⋯) accanto al nome del progetto.\n",
    "Scegli “Archive project” (per nasconderlo) o, se disponibile, “Delete project” per eliminarlo definitivamente.\n",
    "\n",
    "\n",
    "2) Da CLI\n",
    "Se hai una versione recente del wandb CLI, puoi usare (da terminale):\n",
    "\n",
    "\n",
    "wandb project delete <ENTITY>/<PROJECT_NAME>\n",
    "\n",
    "Esempio:\n",
    "\n",
    "wandb project delete stefano-bargione-universit-di-roma-tor-vergata/th_resp_vs_pt_resp_1_20_familiar_th\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Programmaticamente\n",
    "Attualmente W&B non espone un’API Python ufficiale per cancellare progetti; l’opzione più rapida resta il CLI o la UI.\n",
    "\n",
    "In sintesi\n",
    "Cancellare run/sweep → lascia il progetto “vuoto” (0 run, 0 sweep).\n",
    "\n",
    "Progetto visibile → finché non lo archivi o elimini esplicitamente, lo vedrai nella lista.\n",
    "\n",
    "Per toglierlo di mezzo → archivia o cancella il progetto tramite i tre puntini in UI, oppure con wandb project delete da CLI.\n",
    "\n",
    "\n",
    "\n",
    "IO:\n",
    "ok ma quindi se ricreo il progetto con lo stesso nome semplicemente ripopola quel progetto ma con sweeps e runs nuovi giusto?\n",
    "\n",
    "\n",
    "ChatGPT:\n",
    "\n",
    "Esatto. In W&B il progetto è identificato dal solo nome (più l’entity) e non ha uno “stato” permanente di esistenza: se tu:\n",
    "\n",
    "Elimini o archivi totalmente il progetto (tramite UI o wandb project delete),\n",
    "\n",
    "E poi lanci di nuovo uno wandb.init(..., project=\"quel_nome\"),\n",
    "\n",
    "W&B creerà un nuovo progetto con lo stesso nome, vuoto all’inizio, in cui andranno a confluire i tuoi nuovi sweep e run.\n",
    "\n",
    "Quindi:\n",
    "\n",
    "Se archivi il vecchio progetto, è solo nascosto ma rimane là;\n",
    "\n",
    "Se lo cancelli definitivamente, sparisce e puoi ricrearlo identico per nome, e in quel momento sarà “pulito” (0 sweep, 0 run)\n",
    "pronto a riempirsi con i tuoi esperimenti successivi.\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "import sys\n",
    "import subprocess\n",
    "from itertools import product\n",
    "import wandb\n",
    "\n",
    "# 1) Parti delle stringhe da combinare\n",
    "prefixes = [\n",
    "    \"th_resp_vs_pt_resp\",\n",
    "    \"th_resp_vs_shared_resp\",\n",
    "    \"pt_resp_vs_shared_resp\",\n",
    "]\n",
    "middles = [\n",
    "    \"1_20\",\n",
    "    \"1_45\",\n",
    "    \"wavelet\",\n",
    "]\n",
    "suffixes = [\n",
    "    \"familiar_th\",\n",
    "    \"familiar_pt\",\n",
    "    \"unfamiliar_th\",\n",
    "    \"unfamiliar_pt\",\n",
    "]\n",
    "\n",
    "# 2) Genera tutti i nomi di progetto\n",
    "projects = [\n",
    "    f\"{p}_{m}_{s}\"\n",
    "    for p, m, s in product(prefixes, middles, suffixes)\n",
    "]\n",
    "\n",
    "# 3) Configura l’API e l’entity\n",
    "entity = \"stefano-bargione-universit-di-roma-tor-vergata\"\n",
    "api = wandb.Api()\n",
    "\n",
    "# 4) Itera su ogni progetto: svuota le run e poi cancella gli sweep\n",
    "for proj in projects:\n",
    "    project_path = f\"{entity}/{proj}\"\n",
    "    print(f\"\\n→ Progetto: {project_path}\")\n",
    "\n",
    "    # 4.1 Cancella tutte le run via Python API\n",
    "    try:\n",
    "        runs = api.runs(project_path)\n",
    "        if runs:\n",
    "            print(f\"   • Eliminando {len(runs)} run…\")\n",
    "            for run in runs:\n",
    "                try:\n",
    "                    run.delete()\n",
    "                except Exception as e:\n",
    "                    print(f\"     – Errore cancellando run {run.id}: {e}\")\n",
    "                else:\n",
    "                    print(f\"     – run {run.id} eliminata\")\n",
    "        else:\n",
    "            print(\"   (nessuna run trovata)\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ⚠️ Impossibile caricare le run: {e}\")\n",
    "\n",
    "    # 4.2 Cancella tutti gli sweep via CLI Python module\n",
    "    #    Evitiamo di chiamare un eseguibile esterno, usiamo `python -m wandb`\n",
    "    #    Lo stesso interprete che esegue questo script è in sys.executable\n",
    "    cmd_list = [\n",
    "        sys.executable, \"-m\", \"wandb\", \"sweep\",\n",
    "        \"--project\", project_path, \"--list\"\n",
    "    ]\n",
    "    res = subprocess.run(cmd_list, capture_output=True, text=True)\n",
    "\n",
    "    if res.returncode != 0 or not res.stdout.strip():\n",
    "        print(\"   • Nessuno sweep trovato o progetto inesistente\")\n",
    "        continue\n",
    "\n",
    "    # Ogni riga di res.stdout ha uno sweep_id come primo token\n",
    "    for line in res.stdout.splitlines():\n",
    "        sweep_id = line.split()[0]\n",
    "        print(f\"   • Cancello sweep {sweep_id}\")\n",
    "        cmd_delete = [\n",
    "            sys.executable, \"-m\", \"wandb\", \"sweep\",\n",
    "            \"--delete\", f\"{project_path}/{sweep_id}\"\n",
    "        ]\n",
    "        subprocess.run(cmd_delete, check=False)\n",
    "\n",
    "    print(f\"  ✅ Run e sweep eliminati per {project_path}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ee1d99bd-2d3a-49d2-a2aa-61faa2b47d84",
   "metadata": {
    "tags": []
   },
   "source": [
    "'''SPECIFICO SWEEP DI UNA CERTA CONDIZIONE SPERIMENTALE'''\n",
    "\n",
    "import sys\n",
    "import subprocess\n",
    "from itertools import product\n",
    "import wandb\n",
    "\n",
    "entity   = \"stefano-bargione-universit-di-roma-tor-vergata\"\n",
    "api      = wandb.Api()\n",
    "\n",
    "# il solo progetto di cui voglio ripulire sweep+run\n",
    "target = \"th_resp_vs_pt_resp_1_45_familiar_pt\"\n",
    "project_path = f\"{entity}/{target}\"\n",
    "\n",
    "print(f\"\\n→ Progetto: {project_path}\")\n",
    "\n",
    "# 4.1 Cancella tutte le run via Python API\n",
    "try:\n",
    "    runs = api.runs(project_path)\n",
    "    if runs:\n",
    "        print(f\"   • Eliminando {len(runs)} run…\")\n",
    "        for run in runs:\n",
    "            try:\n",
    "                run.delete()\n",
    "            except Exception as e:\n",
    "                print(f\"     – Errore cancellando run {run.id}: {e}\")\n",
    "            else:\n",
    "                print(f\"     – run {run.id} eliminata\")\n",
    "    else:\n",
    "        print(\"   (nessuna run trovata)\")\n",
    "except Exception as e:\n",
    "    print(f\"   ⚠️ Impossibile caricare le run: {e}\")\n",
    "\n",
    "# 4.2 Cancella tutti gli sweep via CLI (usando python -m wandb)\n",
    "cmd_list = [\n",
    "    sys.executable, \"-m\", \"wandb\", \"sweep\",\n",
    "    \"--project\", project_path, \"--list\"\n",
    "]\n",
    "res = subprocess.run(cmd_list, capture_output=True, text=True)\n",
    "\n",
    "if res.returncode != 0 or not res.stdout.strip():\n",
    "    print(\"   • Nessuno sweep trovato o progetto inesistente\")\n",
    "else:\n",
    "    for line in res.stdout.splitlines():\n",
    "        sweep_id = line.split()[0]\n",
    "        print(f\"   • Cancello sweep {sweep_id}\")\n",
    "        cmd_delete = [\n",
    "            sys.executable, \"-m\", \"wandb\", \"sweep\",\n",
    "            \"--delete\", f\"{project_path}/{sweep_id}\"\n",
    "        ]\n",
    "        subprocess.run(cmd_delete, check=False)\n",
    "\n",
    "print(f\"  ✅ Run e sweep eliminati per {project_path}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d5fded46-3cfe-4744-b38d-459741e80eae",
   "metadata": {
    "tags": []
   },
   "source": [
    "import sys\n",
    "import subprocess\n",
    "import wandb\n",
    "\n",
    "# Configurazione API e entity\n",
    "entity = \"stefano-bargione-universit-di-roma-tor-vergata\"\n",
    "api    = wandb.Api()\n",
    "\n",
    "# 1) Pattern da cercare nel nome dei progetti\n",
    "patterns = [\n",
    "    \"_spectrograms_channels_freqs_new_3d_grid_multiband\",\n",
    "    \"_spectrograms_channels_freqs_new_imagery_3d_grid_multiband\",\n",
    "]\n",
    "\n",
    "# 2) Prendi tutti i progetti e filtra\n",
    "print(\"Recupero tutti i progetti dell'entity…\")\n",
    "all_projects    = api.projects(entity=entity)\n",
    "target_projects = [p for p in all_projects if any(pat in p.name for pat in patterns)]\n",
    "\n",
    "if not target_projects:\n",
    "    print(\"Nessun progetto corrispondente ai pattern trovati.\")\n",
    "    sys.exit(0)\n",
    "\n",
    "# 3) Cicla sui progetti selezionati\n",
    "for proj in target_projects:\n",
    "    name = proj.name\n",
    "    path = f\"{entity}/{name}\"\n",
    "    print(f\"\\n→ Progetto: {path}\")\n",
    "\n",
    "    # 3.1) Elimina tutte le run (per_page=None fa paging automatico)\n",
    "    try:\n",
    "        runs = api.runs(path, per_page=None)\n",
    "        runs = list(runs)  # forza il fetch di tutte le pagine\n",
    "        if runs:\n",
    "            print(f\"   • Eliminando {len(runs)} run…\")\n",
    "            for run in runs:\n",
    "                try:\n",
    "                    run.delete()\n",
    "                    print(f\"     – Run {run.id} eliminata\")\n",
    "                except Exception as e:\n",
    "                    print(f\"     – Errore eliminando run {run.id}: {e}\")\n",
    "        else:\n",
    "            print(\"   (nessuna run trovata)\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ⚠️ Impossibile caricare le run: {e}\")\n",
    "\n",
    "    # 3.2) Ferma (cancel) tutti gli sweep via CLI\n",
    "    try:\n",
    "        sweeps = proj.sweeps()\n",
    "        if sweeps:\n",
    "            for sweep in sweeps:\n",
    "                sid = sweep.id\n",
    "                print(f\"   • Cancello (cancel) sweep {sid}\")\n",
    "                res = subprocess.run(\n",
    "                    [sys.executable, \"-m\", \"wandb\", \"sweep\",\n",
    "                     \"--cancel\", f\"{path}/{sid}\"],\n",
    "                    capture_output=True, text=True\n",
    "                )\n",
    "                if res.returncode == 0:\n",
    "                    print(f\"     – Sweep {sid} cancellato\")\n",
    "                else:\n",
    "                    err = res.stderr.strip().splitlines()[0]\n",
    "                    print(f\"     – Errore cancel sweep {sid}: {err}\")\n",
    "        else:\n",
    "            print(\"   (nessuno sweep trovato)\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ⚠️ Errore caricando gli sweep: {e}\")\n",
    "\n",
    "    print(f\"  ✅ Run e sweep fermati per {path}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "aea459d2-6396-44e4-ba47-dd1734803966",
   "metadata": {
    "tags": []
   },
   "source": [
    "import sys\n",
    "import subprocess\n",
    "import wandb\n",
    "\n",
    "# Configurazione API e entity\n",
    "entity = \"stefano-bargione-universit-di-roma-tor-vergata\"\n",
    "api    = wandb.Api()\n",
    "\n",
    "# 1) Pattern da cercare nel nome dei progetti\n",
    "patterns = [\n",
    "    \"_spectrograms_channels_freqs_new_3d_grid_multiband\",\n",
    "    \"_spectrograms_channels_freqs_new_imagery_3d_grid_multiband\",\n",
    "]\n",
    "\n",
    "# 2) Prendi tutti i progetti e filtra\n",
    "print(\"Recupero tutti i progetti dell'entity…\")\n",
    "all_projects    = api.projects(entity=entity)\n",
    "target_projects = [p for p in all_projects if any(pat in p.name for pat in patterns)]\n",
    "\n",
    "if not target_projects:\n",
    "    print(\"Nessun progetto corrispondente ai pattern trovati.\")\n",
    "    sys.exit(0)\n",
    "\n",
    "# 3) Cicla sui progetti selezionati\n",
    "for proj in target_projects:\n",
    "    name = proj.name\n",
    "    path = f\"{entity}/{name}\"\n",
    "    print(f\"\\n→ Progetto: {path}\")\n",
    "\n",
    "    # 3.1) Elimina tutte le run (per_page=None fa paging automatico)\n",
    "    try:\n",
    "        runs = api.runs(path, per_page=None)\n",
    "        runs = list(runs)  # forza il fetch di tutte le pagine\n",
    "        if runs:\n",
    "            print(f\"   • Eliminando {len(runs)} run…\")\n",
    "            for run in runs:\n",
    "                try:\n",
    "                    run.delete()\n",
    "                    print(f\"     – Run {run.id} eliminata\")\n",
    "                except Exception as e:\n",
    "                    print(f\"     – Errore eliminando run {run.id}: {e}\")\n",
    "        else:\n",
    "            print(\"   (nessuna run trovata)\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ⚠️ Impossibile caricare le run: {e}\")\n",
    "\n",
    "    # 3.2) Ferma (cancel) tutti gli sweep via CLI\n",
    "    try:\n",
    "        sweeps = proj.sweeps()\n",
    "        if sweeps:\n",
    "            for sweep in sweeps:\n",
    "                sid = sweep.id\n",
    "                print(f\"   • Cancello (cancel) sweep {sid}\")\n",
    "                res = subprocess.run(\n",
    "                    [sys.executable, \"-m\", \"wandb\", \"sweep\",\n",
    "                     \"--cancel\", f\"{path}/{sid}\"],\n",
    "                    capture_output=True, text=True\n",
    "                )\n",
    "                if res.returncode == 0:\n",
    "                    print(f\"     – Sweep {sid} cancellato\")\n",
    "                else:\n",
    "                    err = res.stderr.strip().splitlines()[0]\n",
    "                    print(f\"     – Errore cancel sweep {sid}: {err}\")\n",
    "        else:\n",
    "            print(\"   (nessuno sweep trovato)\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ⚠️ Errore caricando gli sweep: {e}\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Verifica che gli sweep siano stati cancellati\n",
    "    print(\"Verifica sweep attivi dopo cancellazione...\")\n",
    "    sweeps = proj.sweeps()  # Riprova a ottenere gli sweep\n",
    "    if not sweeps:\n",
    "        print(\"   ✅ Nessuno sweep attivo trovato.\")\n",
    "    else:\n",
    "        print(f\"   ⚠️ Sweep ancora attivo: {sweeps}\")\n",
    "\n",
    "    print(f\"  ✅ Run e sweep fermati per {path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415f0536-0fc5-417e-ab2b-b09790375b2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''UFFICIALE 19 LUGLIO\n",
    "\n",
    "Spiegazione delle modifiche:\n",
    "Comando per ottenere la lista degli sweep:\n",
    "\n",
    "\n",
    "cmd_list = [\n",
    "    sys.executable, \"-m\", \"wandb\", \"sweep\",\n",
    "    \"--project\", path, \"--list\"\n",
    "]\n",
    "Qui usiamo --list per ottenere la lista di tutti gli sweep per il progetto.\n",
    "\n",
    "Comando per cancellare uno sweep:\n",
    "\n",
    "\n",
    "cmd_delete = [\n",
    "    sys.executable, \"-m\", \"wandb\", \"sweep\",\n",
    "    \"--delete\", f\"{path}/{sweep_id}\"\n",
    "]\n",
    "Qui usiamo --delete per eliminare ogni sweep individuato.\n",
    "\n",
    "Verifica degli sweep dopo la cancellazione:\n",
    "\n",
    "Una volta che abbiamo cancellato gli sweep, facciamo una seconda chiamata proj.sweeps() \n",
    "per verificare se ci sono ancora sweep attivi.\n",
    "\n",
    "Come funziona:\n",
    "Il codice esegue una lista di tutti i progetti che corrispondono ai pattern.\n",
    "\n",
    "Per ogni progetto, le run vengono cancellate prima.\n",
    "\n",
    "Poi, per ogni sweep associato al progetto, il comando wandb sweep --delete viene eseguito per eliminarlo.\n",
    "\n",
    "Infine, viene effettuata una verifica se gli sweep sono stati effettivamente cancellati.\n",
    "\n",
    "Con queste modifiche, dovresti essere in grado di eliminare completamente gli sweep oltre a fermarli.\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "import sys\n",
    "import subprocess\n",
    "import wandb\n",
    "\n",
    "# Configurazione API e entity\n",
    "entity = \"stefano-bargione-universit-di-roma-tor-vergata\"\n",
    "api = wandb.Api()\n",
    "\n",
    "# 1) Pattern da cercare nel nome dei progetti\n",
    "patterns = [\n",
    "    \"_spectrograms_channels_freqs_new_3d_grid_multiband\",\n",
    "    \"_spectrograms_channels_freqs_new_imagery_3d_grid_multiband\",\n",
    "]\n",
    "\n",
    "# 2) Prendi tutti i progetti e filtra\n",
    "print(\"Recupero tutti i progetti dell'entity…\")\n",
    "all_projects = api.projects(entity=entity)\n",
    "target_projects = [p for p in all_projects if any(pat in p.name for pat in patterns)]\n",
    "\n",
    "if not target_projects:\n",
    "    print(\"Nessun progetto corrispondente ai pattern trovati.\")\n",
    "    sys.exit(0)\n",
    "\n",
    "# 3) Cicla sui progetti selezionati\n",
    "for proj in target_projects:\n",
    "    name = proj.name\n",
    "    path = f\"{entity}/{name}\"\n",
    "    print(f\"\\n→ Progetto: {path}\")\n",
    "\n",
    "    # 3.1) Elimina tutte le run (per_page=None fa paging automatico)\n",
    "    try:\n",
    "        runs = api.runs(path, per_page=None)\n",
    "        runs = list(runs)  # forza il fetch di tutte le pagine\n",
    "        if runs:\n",
    "            print(f\"   • Eliminando {len(runs)} run…\")\n",
    "            for run in runs:\n",
    "                try:\n",
    "                    run.delete()\n",
    "                    print(f\"     – Run {run.id} eliminata\")\n",
    "                except Exception as e:\n",
    "                    print(f\"     – Errore eliminando run {run.id}: {e}\")\n",
    "        else:\n",
    "            print(\"   (nessuna run trovata)\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ⚠️ Impossibile caricare le run: {e}\")\n",
    "\n",
    "    # 3.2) Cancella tutti gli sweep via CLI Python module\n",
    "    # Evitiamo di chiamare un eseguibile esterno, usiamo `python -m wandb`\n",
    "    # Lo stesso interprete che esegue questo script è in sys.executable\n",
    "    \n",
    "    cmd_list = [\n",
    "        sys.executable, \"-m\", \"wandb\", \"sweep\",\n",
    "        \"--project\", path, \"--list\"\n",
    "    ]\n",
    "    res = subprocess.run(cmd_list, capture_output=True, text=True)\n",
    "\n",
    "    if res.returncode != 0 or not res.stdout.strip():\n",
    "        print(\"   • Nessuno sweep trovato o progetto inesistente\")\n",
    "        continue\n",
    "\n",
    "    # Ogni riga di res.stdout ha uno sweep_id come primo token\n",
    "    for line in res.stdout.splitlines():\n",
    "        sweep_id = line.split()[0]\n",
    "        print(f\"   • Cancello sweep {sweep_id}\")\n",
    "        cmd_delete = [\n",
    "            sys.executable, \"-m\", \"wandb\", \"sweep\",\n",
    "            \"--delete\", f\"{path}/{sweep_id}\"\n",
    "        ]\n",
    "        subprocess.run(cmd_delete, check=False)\n",
    "\n",
    "    # Verifica che gli sweep siano stati cancellati\n",
    "    print(\"Verifica sweep attivi dopo cancellazione...\")\n",
    "    sweeps = proj.sweeps()  # Riprova a ottenere gli sweep\n",
    "    if not sweeps:\n",
    "        print(\"   ✅ Nessuno sweep attivo trovato.\")\n",
    "    else:\n",
    "        print(f\"   ⚠️ Sweep ancora attivo: {sweeps}\")\n",
    "\n",
    "    print(f\"  ✅ Run e sweep eliminati per {path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7275be73-2d4b-47e6-9e58-92a27027e5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('finito')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63698e90-8980-491f-a335-9f4be13aaf67",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### **IO**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e541ebc6-8305-43d4-9d3a-7aadf15483af",
   "metadata": {},
   "source": [
    "Prima avevo avviata una ricerca di iper-parametri con API da jupyter e avevo impostato la creazione di cartelle per ogni combinazione di dati...\n",
    "\n",
    "tuttavia, ora quando andava ho notato che le cartelle non so state create alle fine.. come mai? è dovuto ad un overload di sovraccarica o è semplicemente un ritardo dovuto all'esecuzione di grande mole di dati da remoto tra l'altro con l'api che ritarda la sincronizzazione delle operazioni del codice su quello che dovrei vedere su jupyter? \n",
    "\n",
    "è fondamentale che le cartelle ed i vari files .pkl del mio codice si salvino, perché poi io le richiamo successivamente per estrarmi gli iper-parametri migliori di ogni ottimizzazione fatta.. devo gestire le risorse di calcolo in modo più equilibrato, affinché le operazioni di salvataggio vengano eseguite correttamente?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf9d314-c6d2-4ca8-928f-afd2f8117fd4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### **CHATGPT**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbec73a-3fde-4b0e-87f5-913efd7501e1",
   "metadata": {},
   "source": [
    "È molto più probabile che la cartella ci sia già, ma:\n",
    "\n",
    "Non si trovi sotto la radice che Jupyter ti mostra (di solito /mnt/data), bensì in /home/stefano/..., per cui il file‑browser non la “vede” fino a quando non navighi esplicitamente lì.\n",
    "\n",
    "O che tu abbia settato WANDB_DIR dopo l’import wandb, quindi wandb abbia già inizializzato il suo percorso di default.\n",
    "\n",
    "In ogni caso non è un problema di “troppa mole di dati che rallenta” o di W&B che perde file, bensì di:\n",
    "\n",
    "percorso sbagliato in cui guardi\n",
    "\n",
    "sincronizzazione asincrona di wandb (che salva localmente in run.dir e lo invia al cloud in background)\n",
    "\n",
    "Controlla davvero se la cartella esiste\n",
    "Nella cella del notebook, esegui:\n",
    "\n",
    "bash\n",
    "Copia\n",
    "Modifica\n",
    "!ls -l /home/stefano/Interrogait/WB_spectrograms_analyses_motor_task_1\n",
    "o più genericamente\n",
    "\n",
    "bash\n",
    "Copia\n",
    "Modifica\n",
    "!find /home/stefano/Interrogait -maxdepth 2 -type d\n",
    "Se la cartella esiste veramente, basta che la navighi nel file‑browser (“…” in alto a sinistra → “Change directory” → incolli quel path) o che tu salvi direttamente in /mnt/data/... così la vedi subito.\n",
    "\n",
    "Come forzare wandb a usare la cartella che vuoi\n",
    "Metti prima di ogni import wandb queste due righe:\n",
    "\n",
    "python\n",
    "Copia\n",
    "Modifica\n",
    "import os\n",
    "WB_dir = \"/mnt/data/WB_spectrograms_analyses_motor_task_1\"\n",
    "os.makedirs(WB_dir, exist_ok=True)\n",
    "os.environ[\"WANDB_DIR\"] = WB_dir\n",
    "Poi:\n",
    "\n",
    "python\n",
    "Copia\n",
    "Modifica\n",
    "import wandb\n",
    "wandb.login()\n",
    "run = wandb.init(\n",
    "    project=\"spectrograms-analyses-motor-task-1\",\n",
    "    dir=WB_dir,         # <–– anche qui puoi sovrascrivere il path\n",
    "    resume=\"allow\"      # <–– se fai sweep/runs multipli\n",
    ")\n",
    "In questo modo:\n",
    "\n",
    "Wandb salverà localmente tutti i log e i file di run in WB_dir.\n",
    "\n",
    "Il file‑browser di Jupyter (che punta su /mnt/data) li vedrà immediatamente.\n",
    "\n",
    "Wandb poi sincronizzerà tutto in cloud, ma tu puoi lavorare “in locale” senza perdere nulla.\n",
    "\n",
    "Salvare i .pkl\n",
    "Quando salvi i tuoi .pkl all’interno della loop di hyperopt fai:\n",
    "\n",
    "python\n",
    "Copia\n",
    "Modifica\n",
    "out_path = os.path.join(WB_dir, f\"{run.id}__{combo_name}.pkl\")\n",
    "with open(out_path, \"wb\") as f:\n",
    "    pickle.dump(my_results, f)\n",
    "wandb.save(out_path)   # <–– forza wandb ad aggiungere questo file allo snapshot del run\n",
    "In questo modo:\n",
    "\n",
    "Il file viene scritto subito in WB_dir\n",
    "\n",
    "Viene collegato al run W&B (utile se poi fai wandb.restore)\n",
    "\n",
    "Verifica “a freddo”\n",
    "Dopo aver fatto partire i tuoi esperimenti, in un’altra cella puoi lanciare:\n",
    "\n",
    "bash\n",
    "Copia\n",
    "Modifica\n",
    "!ls -R /mnt/data/WB_spectrograms_analyses_motor_task_1\n",
    "oppure – da CLI –\n",
    "\n",
    "bash\n",
    "Copia\n",
    "Modifica\n",
    "wandb files <ENTITY>/<PROJECT>/<RUN_ID>\n",
    "per vedere l’elenco dei file che sono stati salvati/sincronizzati.\n",
    "\n",
    "Se invece proprio non trovi nulla, controlla:\n",
    "\n",
    "che non ci siano errori silenziosi (un try/except: pass che assorbe i problemi di I/O)\n",
    "\n",
    "che tu stia eseguendo la cella di creazione delle cartelle prima di qualunque wandb.init\n",
    "\n",
    "che non stia scrivendo in un container o in un filesystem ephemeral diverso da quello mostrato dal file‑browser\n",
    "\n",
    "Con questa configurazione dovresti avere:\n",
    "\n",
    "Cartelle create sotto /mnt/data/WB_spectrograms_analyses_motor_task_1\n",
    "\n",
    "I tuoi .pkl visibili subito in Jupyter\n",
    "\n",
    "Wandb che continua a fare upload in background senza perderli\n",
    "\n",
    "Fammi sapere se così riesci a trovarli ed evitare di perdere i risultati dei tuoi sweep!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8e2091-93ac-49d3-beb6-2ff072547953",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### **Weight & Biases Procedure FINAL SEQUENCE OF STEPS - EEG Spectrograms - Electrodes x Frequencies ONLY HYPER-PARAMS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d1d33d-d516-4925-a416-57a7e4d9515c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Library Importing \n",
    "    \n",
    "import os\n",
    "import math\n",
    "import copy as cp \n",
    "\n",
    "import tqdm\n",
    "from tqdm import tqdm\n",
    "\n",
    "import random\n",
    "\n",
    "#import mne \n",
    "import scipy\n",
    "\n",
    "import numpy as np  # NumPy per operazioni numeriche\n",
    "import matplotlib.pyplot as plt  # Matplotlib per la visualizzazione dei dati\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import random\n",
    "\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f506297e-e8c0-42d2-a3c4-3e17bcdd2413",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '/home/stefano/Interrogait/all_datas/Spectrograms_channels_frequencies_motor_tasks/'\n",
    "\n",
    "# Controlla se la cartella esiste, altrimenti la crea\n",
    "if not os.path.exists(base_path):\n",
    "    os.makedirs(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad892c8-26eb-4be0-9108-b52193d0ec51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Caricare l'intero dizionario annidato con pickle\n",
    "with open(f'{base_path}new_all_th_concat_spectrograms_coupled_exp_task_1_2d_grid_multiband.pkl', 'rb') as f:\n",
    "    new_all_th_concat_spectrograms_coupled_exp_task_1 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6225a258-b3bf-4f28-ae50-14eb46a32b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_all_th_concat_spectrograms_coupled_exp_task_1.keys() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f7ee91-e66f-4040-a9f3-c29d864e708b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_all_th_concat_spectrograms_coupled_exp_task_1['rest_vs_left_fist'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39efb605-ed73-4db7-9bc4-203dd130f86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new_all_th_concat_spectrograms_coupled_exp_task_1['rest_vs_left_fist']['data'].shape)\n",
    "print()\n",
    "print(new_all_th_concat_spectrograms_coupled_exp_task_1['rest_vs_right_fist']['data'].shape)\n",
    "print()\n",
    "print(new_all_th_concat_spectrograms_coupled_exp_task_1['left_fist_vs_right_fist']['data'].shape)\n",
    "print()\n",
    "print(np.unique(new_all_th_concat_spectrograms_coupled_exp_task_1['rest_vs_left_fist']['labels'], return_counts = True))\n",
    "print()\n",
    "print(np.unique(new_all_th_concat_spectrograms_coupled_exp_task_1['rest_vs_right_fist']['labels'], return_counts = True))\n",
    "print()\n",
    "print(np.unique(new_all_th_concat_spectrograms_coupled_exp_task_1['left_fist_vs_right_fist']['labels'], return_counts = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f721063-983a-4208-a395-f8213ce32a84",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### **Utils Functions - EEG Spectrograms - Electrodes x Frequencies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b9eb7f-4102-4e8d-9b9d-2829543a0534",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "QUI DENTRO HO CONFIGURATO \n",
    "LE FUNZIONI DI CONTROLLO DELLE STRINGHE \n",
    "PER IL SALVATAGGIO DELLE PERFORMANCE DEL MODELLO\n",
    "NELLE RELATIVE SUBFOLDERS\n",
    "\n",
    "(I.E., get_subfolder_from_key, get_subfolder_from_key_hyper)\n",
    "\n",
    "IN MODO CHE SI LEGHINO ALLA CHIAVE 'STANDARDIZATION' DELL'OGGETTO SWEEP_CONFIG\n",
    "'''\n",
    "\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def load_data(data_type, category, subject_type, condition = \"th_resp_vs_pt_resp\"):\n",
    "    \"\"\"\n",
    "    Carica i dati EEG dalla directory appropriata, già salvati con la finestra temporale (0°-640° punto)\n",
    "\n",
    "    Parameters:\n",
    "    - data_type: str, \"spectrograms\",\n",
    "    - category: str, \"task_1\"\n",
    "    - subject_type: str, \"th\" (terapisti)\n",
    "    - condition: str, condizione sperimentale da selezionare\n",
    "    \n",
    "\n",
    "    Returns:\n",
    "    - X: Dati EEG sotto-selezionati (50°-300° punto e canali selezionati se applicabile)\n",
    "    - y: Etichette corrispondenti\n",
    "    \"\"\"\n",
    "\n",
    "    # Definizione dei percorsi base\n",
    "    base_paths = {\n",
    "        \"spectrograms\": {\n",
    "            \"familiar\": \"/home/stefano/Interrogait/all_datas/Spectrograms_channels_frequencies_motor_tasks/\"\n",
    "            #\"unfamiliar\": \"/home/stefano/Interrogait/all_datas/Unfamiliar_Spectrograms/\"\n",
    "        },\n",
    "    }\n",
    "\n",
    "    # Seleziona il path corretto\n",
    "    base_path = base_paths[data_type][category]\n",
    "\n",
    "    # Determina il nome del file corretto\n",
    "    if data_type in [\"spectrograms\"]:\n",
    "        filename = f\"new_all_{subject_type}_concat_spectrograms_coupled_exp_task_1_2d_grid_multiband.pkl\"\n",
    "    else:\n",
    "        raise ValueError(\"data_type non valido!\")\n",
    "        \n",
    "    # Caricamento del file\n",
    "    filepath = base_path + filename\n",
    "    \n",
    "    with open(filepath, \"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "    \n",
    "    '''\n",
    "    Per i dati spectrogram, la funzione seleziona la condizione desiderata (i.e., condition = \"th_resp_vs_pt_resp\") \n",
    "    e preleva i dati e le etichette associati a quella condizione.\n",
    "    '''\n",
    "    \n",
    "    # Selezione della finestra temporale e delle etichette\n",
    "    X = data[condition][\"data\"]\n",
    "    y = data[condition][\"labels\"]\n",
    "\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "\n",
    "def select_channels(data, channels=[12, 30, 48]):\n",
    "    \"\"\"\n",
    "    Seleziona i canali EEG specificati SOLO per i dati 1-20 e 1-45.\n",
    "\n",
    "    Parameters:\n",
    "    - data: array NumPy, dati EEG con shape (n_trials, n_channels, n_timepoints)\n",
    "    - channels: list, indici dei canali da selezionare\n",
    "\n",
    "    Returns:\n",
    "    - data filtrato sui canali specificati\n",
    "    \"\"\"\n",
    "    return data[:, channels, :]\n",
    "\n",
    "\n",
    "# Funzione per train-test split\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "\n",
    "def split_data(X, y, test_size=0.2, val_size=0.2):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=val_size, random_state=42)\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test\n",
    "\n",
    "\n",
    "'''ATTENZIONE MODIFICATA FUNZIONE DI STANDARDIZZAZIONE'''\n",
    "# Funzione per standardizzare i dati\n",
    "# Con questa modifica eviti che std==0 produca NaN e i tuoi loss torneranno numeri sensati.\n",
    "def standardize_data(X_train, X_val, X_test, eps = 1e-8):\n",
    "    \n",
    "    mean = X_train.mean(axis=0, keepdims=True)\n",
    "    std = X_train.std(axis=0, keepdims=True)\n",
    "    \n",
    "    #aggiungo eps per evitare divisione per zero\n",
    "    X_train = (X_train - mean) / (std + eps)\n",
    "    X_val = (X_val - mean) / (std + eps)\n",
    "    X_test = (X_test - mean) / (std + eps)\n",
    "    \n",
    "    return X_train, X_val, X_test\n",
    "\n",
    "\n",
    "# Import modelli (definisci le classi CNN1D, ReadMEndYou, ReadMYMind)\n",
    "#from models import CNN1D, ReadMEndYou, ReadMYMind  # Assicurati di avere i modelli definiti in 'models.py'\n",
    "\n",
    "# Funzione per inizializzare i modelli\n",
    "def initialize_models():\n",
    "    #model = CNN1D(input_channels=3, num_classes=2)\n",
    "    model_CNN = CNN2D(input_channels = 61, num_classes=2)\n",
    "    #model_LSTM = ReadMEndYou(input_size=3, hidden_sizes=[24, 48, 62], output_size=2, bidirectional=True)\n",
    "    model_LSTM = ReadMEndYou(input_size=61 * 26, hidden_sizes=[24, 48, 62], output_size=2, bidirectional=True)\n",
    "    #model_Transformer = ReadMYMind(num_channels=3, seq_length=250, d_model=16, num_heads=4, num_layers=2, num_classes=2)\n",
    "    model_Transformer = ReadMYMind(d_model=16, num_heads=4, num_layers=2, num_classes=2, channels=61, freqs=26)\n",
    "    \n",
    "    return model_CNN, model_LSTM, model_Transformer\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "\n",
    "'''\n",
    "Questa funzione prende in input i dati di training, validation e test, \n",
    "il tipo di modello scelto e la dimensione del batch. Si occupa di:\n",
    "\n",
    "Calcolare i pesi delle classi.\n",
    "Convertire i dati in tensori PyTorch, con le opportune trasformazioni per CNN, LSTM o Transformer.\n",
    "Creare i dataset e i dataloader per il training.\n",
    "'''\n",
    "\n",
    "\n",
    "def prepare_data_for_model(X_train, X_val, X_test, y_train, y_val, y_test, model_type, batch_size=48):\n",
    "    \n",
    "    # Calcolo dei pesi delle classi\n",
    "    class_weights = compute_class_weight(class_weight='balanced', \n",
    "                                         classes=np.unique(y_train), \n",
    "                                         y=y_train)\n",
    "    \n",
    "    class_weights_tensor = torch.tensor(class_weights, dtype=torch.float32)\n",
    "    class_weights_tensor = class_weights_tensor.to(dtype=torch.float32, device=device)\n",
    "    \n",
    "    # Conversione delle etichette in interi\n",
    "    y_train = y_train.astype(int)\n",
    "    y_val = y_val.astype(int)\n",
    "    y_test = y_test.astype(int)\n",
    "    \n",
    "    # Conversione dei dati in tensori PyTorch con permutazione se necessario\n",
    "    \n",
    "    '''OCCHIO QUI CAMBIATO'''\n",
    "    #if model_type == \"CNN2D\":\n",
    "    \n",
    "    if model_type == \"CNN2D_LSTM_FC\":\n",
    "        \n",
    "    #if model_type == \"CNN2D\":\n",
    "        X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "        X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "        X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "    \n",
    "    #BiLSTM (ReadMEndYou):\n",
    "    #Ora il modello si aspetta l’input con shape (batch, canali, frequenze, tempo) \n",
    "    #e, al suo interno, \n",
    "    #esegue la permutazione per avere il tempo come dimensione sequenziale. \n",
    "    #Non serve quindi applicare una permutazione anche qui.\n",
    "    \n",
    "    elif model_type == \"CNN3D_LSTM_FC\":\n",
    "        X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "        X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "        X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "    \n",
    "    elif model_type == \"SeparableCNN2D_LSTM_FC\":\n",
    "        X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "        X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "        X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "        \n",
    "    elif model_type == \"BiLSTM\":\n",
    "            \n",
    "        X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "        X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "        X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "    \n",
    "    #Transformer (ReadMYMind):\n",
    "    #Analogamente, il modello gestisce internamente la riorganizzazione dell’input, quindi lasciamo i dati nella loro forma originale.\n",
    "    elif model_type == \"Transformer\":\n",
    "        X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "        X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "        X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(\"Modello non riconosciuto. Scegli tra 'CNN', 'LSTM' o 'Transformer'.\")\n",
    "    \n",
    "    # Conversione delle etichette in tensori\n",
    "    y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "    y_val_tensor = torch.tensor(y_val, dtype=torch.long)\n",
    "    y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "    \n",
    "    # Creazione dei dataset\n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "    test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "    \n",
    "    # Creazione dei dataloader\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    return train_loader, val_loader, test_loader, class_weights_tensor\n",
    "\n",
    "\n",
    "'''\n",
    "# Funzione per determinare a quale subfolder appartiene la chiave\n",
    "def get_subfolder_from_key(key, sweep_config):\n",
    "    \n",
    "    \n",
    "    #Mi richiamo la chiave 'standardization' che ho impostato nella configurazione dell'oggetto weight and biases\n",
    "    #(i.e., sweep_config['standardization']) e eseguo una procedura condizionale \n",
    "    \n",
    "    ossia che, se risulta o True o False, lui cambi le condizioni di gestione \n",
    "    della costruzione delle path di salvataggio \n",
    "    \n",
    "    \n",
    "    # Controlla se i dati sono standardizzati\n",
    "    if sweep_config['standardization']:\n",
    "    \n",
    "        #PER I DATI SCALED\n",
    "        if '_familiar_th' in key:\n",
    "            return 'TH_FAM'\n",
    "        elif '_unfamiliar_th' in key:\n",
    "            return 'TH_UNFAM'\n",
    "        elif '_familiar_pt' in key:\n",
    "            return 'PT_FAM'\n",
    "        elif '_unfamiliar_pt' in key:\n",
    "            return 'PT_UNFAM'\n",
    "        else:\n",
    "            return None\n",
    "    else: \n",
    "        #PER I DATI UNSCALED\n",
    "\n",
    "        if '_familiar_th' in key:\n",
    "            return 'TH_FAM_UNSCALED'\n",
    "        elif '_unfamiliar_th' in key:\n",
    "            return 'TH_UNFAM_UNSCALED'\n",
    "        elif '_familiar_pt' in key:\n",
    "            return 'PT_FAM_UNSCALED'\n",
    "        elif '_unfamiliar_pt' in key:\n",
    "            return 'PT_UNFAM_UNSCALED'\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "     \n",
    "   \n",
    "    \n",
    "# Funzione per salvare i risultati\n",
    "def save_performance_results(model_name, my_train_results, my_test_results, key, data_type, sweep_config, condition = \"th_resp_vs_pt_resp\"):\n",
    "    \"\"\"\n",
    "    Funzione che salva i risultati del modello in base alla combinazione di 'key' e 'model_name'.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Identificazione del subfolder in base alla chiave\n",
    "    subfolder = get_subfolder_from_key(key, sweep_config)\n",
    "    \n",
    "    # Debug: controllo sulla subfolder\n",
    "    print(f\"\\nDEBUG - Chiave: \\033[1m{key}\\033[0m, Subfolder ottenuto: \\033[1m{subfolder}\\033[0m\")\n",
    "    \n",
    "    if subfolder is None:\n",
    "        print(f\"Errore: La chiave \\033[1m{key}\\033[0m non corrisponde a nessun subfolder valido.\\n\")\n",
    "        return\n",
    "    \n",
    "    # Determinazione del tipo di dato direttamente dalla chiave\n",
    "    if \"wavelet\" in key:\n",
    "        data_type_str = \"wavelet_delta\"\n",
    "    elif \"1_20\" in key:\n",
    "        data_type_str = \"1_20\"\n",
    "    elif \"1_45\" in key:\n",
    "        data_type_str = \"1_45\"\n",
    "    else:\n",
    "        print(f\"Errore: Tipo di dato non riconosciuto nella chiave '{key}'.\")\n",
    "        return\n",
    "\n",
    "    # Creazione del nome del file con l'inclusione della combinazione key + model_name\n",
    "    file_name = f\"{model_name}_performances_{condition}_{subfolder}_{data_type_str}.pkl\"\n",
    "    folder_path = os.path.join(base_folder, subfolder)\n",
    "    \n",
    "    # Verifica se la cartella di destinazione esiste, altrimenti creala\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "    \n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "    # Creazione del dizionario con i risultati\n",
    "    results_dict = {\n",
    "        'my_train_results': my_train_results,\n",
    "        'my_test_results': my_test_results\n",
    "    }\n",
    "\n",
    "    # Salvataggio del dizionario con i risultati\n",
    "    try:\n",
    "        with open(file_path, 'wb') as f:\n",
    "            pickle.dump(results_dict, f)\n",
    "        print(f\"\\nRisultati salvati con successo ✅ in: \\n\\033[1m{file_path}\\033[0m\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"Errore durante il salvataggio dei risultati: {e}\")\n",
    "        \n",
    "'''\n",
    "\n",
    "\n",
    "# Funzione per determinare a quale subfolder appartiene la chiave\n",
    "def get_subfolder_from_key(key, model_standardization):\n",
    "    \n",
    "    #DEFINIZIONE DELLA PATH DOVE VIENE SALVATO IL FILE\n",
    "    if '_familiar_th' in key:\n",
    "        return 'th_fam'\n",
    "    elif '_unfamiliar_th' in key:\n",
    "        return 'th_unfam'\n",
    "    elif '_familiar_pt' in key:\n",
    "        return 'pt_fam'\n",
    "    elif '_unfamiliar_pt' in key:\n",
    "        return 'pt_unfam'\n",
    "    else:\n",
    "        return None\n",
    "     \n",
    "   \n",
    "    \n",
    "# Funzione per salvare i risultati\n",
    "def save_performance_results(model_name, my_train_results, my_test_results, key, data_type, sweep_config, condition = \"th_resp_vs_pt_resp\"):\n",
    "    \"\"\"\n",
    "    Funzione che salva i risultati del modello in base alla combinazione di 'key' e 'model_name'.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Identificazione del subfolder in base alla chiave\n",
    "    subfolder = get_subfolder_from_key(key, sweep_config)\n",
    "    \n",
    "    # Debug: controllo sulla subfolder\n",
    "    print(f\"\\nDEBUG - Chiave: \\033[1m{key}\\033[0m, Subfolder ottenuto: \\033[1m{subfolder}\\033[0m\")\n",
    "    \n",
    "    if subfolder is None:\n",
    "        print(f\"Errore: La chiave \\033[1m{key}\\033[0m non corrisponde a nessun subfolder valido.\\n\")\n",
    "        return\n",
    "    \n",
    "     # Determinazione del tipo di dato direttamente dalla chiave\n",
    "    if \"spectrograms\" in key:\n",
    "        data_type_str = \"spectrograms\"\n",
    "    else:\n",
    "        print(f\"Errore: Tipo di dato non riconosciuto nella chiave '{key}'.\")\n",
    "        return\n",
    "\n",
    "    # Creazione del nome del file con l'inclusione della combinazione key + model_name\n",
    "    file_name = f\"{model_name}_performances_{condition}_{subfolder}_{data_type_str}.pkl\"\n",
    "    folder_path = os.path.join(base_folder, subfolder)\n",
    "    \n",
    "    # Verifica se la cartella di destinazione esiste, altrimenti creala\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "    \n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "    # Creazione del dizionario con i risultati\n",
    "    results_dict = {\n",
    "        'my_train_results': my_train_results,\n",
    "        'my_test_results': my_test_results\n",
    "    }\n",
    "\n",
    "    # Salvataggio del dizionario con i risultati\n",
    "    try:\n",
    "        with open(file_path, 'wb') as f:\n",
    "            pickle.dump(results_dict, f)\n",
    "        print(f\"\\nRisultati salvati con successo ✅ in: \\n\\033[1m{file_path}\\033[0m\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"Errore durante il salvataggio dei risultati: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e248dfe-4ed0-4e2e-b918-76e4ff92b117",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### **DL Models - EEG Spectrograms - Electrodes x Frequencies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218a8501-de68-4de6-95f8-ea24e2bb895a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "VERSIONE CONVOLUZIONE 3D PURA e CONVOLUZIONI SEPARABILI 19 LUGLIO 2025\n",
    "\n",
    "\n",
    "Due versioni dell’architettura:\n",
    "\n",
    "CNN3D_LSTM_FC: usa nn.Conv3d per eseguire una vera convoluzione 3D sui cinque depth (bande di frequenza), \n",
    "mantenendo il resto del flusso identico.\n",
    "\n",
    "SeparableCNN2D_LSTM_FC: applica in sequenza una convoluzione depthwise (gruppi = canali) e una pointwise (1×1) \n",
    "per fondere i cinque canali in modo efficiente.\n",
    "\n",
    "Entrambe le classi si integrano con il tuo blocco LSTM e il classificatore come nella versione originale.\n",
    "\n",
    "\n",
    "\n",
    "******** PROBLEMA SUL GRADCAM NELLE ANALISI PRE 19 LUGLIO ********\n",
    "\n",
    "\n",
    "Per ottenere un Grad‑CAM “3D” su ciascuna delle 5 bande (cioè un volume 9×9×5) \n",
    "invece di schiacciare tutto in una mappa 9×9, bisogna:\n",
    "\n",
    "Non appiattire la dimensione di profondità (“depth” = bande) con cam.mean(dim=1).\n",
    "\n",
    "Calcolare i pesi medi dei gradienti solo su altezza e larghezza, non su depth, in modo da preservare D=5.\n",
    "\n",
    "Upsample (solo) le due dimensioni spaziali H×W, lasciando inalterata la profondità D.\n",
    "\n",
    "(Opzionale) \n",
    "\n",
    "Se il tuo primo Conv3d usa un kernel di profondità pari all’intera profondità d’ingresso, \n",
    "quella informazione viene compressa in D=1!\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "******** PROBLEMA SUL CONV3D NELLE ANALISI PRE 19 LUGLIO ********\n",
    "\n",
    "\n",
    "Se il tuo primo Conv3d usa un kernel di profondità pari all’intera profondità d’ingresso, \n",
    "quella informazione viene compressa in D=1!\n",
    "\n",
    "\n",
    "Se vuoi davvero avere D=5 in uscita, devi cambiare conv1 in:\n",
    "\n",
    "\n",
    "# ❌ kernel_size=(5,3,3), padding=(0,1,1) → D_out = 1\n",
    "\n",
    "self.conv1 = nn.Conv3d(1, 32, kernel_size=(3,3,3), padding=(1,1,1))\n",
    "così la profondità si conserva da 5→5.\n",
    "\n",
    "\n",
    "\n",
    "1) Perché in conv1 useremo padding=(1,1,1) e negli altri layer padding=(0,1,1)\n",
    "Obiettivo: mantenere la profondità (numero di bande, D = 5) costante lungo tutta la rete.\n",
    "\n",
    "In conv1, abbiamo scelto kernel_size=(3,3,3) perché vogliamo che il filtro “scorra” su tutti e tre gli assi (D,H,W).\n",
    "\n",
    "Con kernel_depth=3, per avere\n",
    "\n",
    "𝐷out = (𝐷in + 2⋅𝑃 depth − 𝐾 depth)/ 𝑆 + 1 = 5\n",
    "\n",
    "Da qui (1,1,1) per (depth, height, width).\n",
    "\n",
    "Negli altri layer 3D (conv2a, conv2b, conv3) il kernel depth = 1 (kernel_size=(1,3,3)), \n",
    "quindi la profondità non cambia se mettiamo padding_depth=0 con padding (0,1,1) nel layer conv2 e conv3\n",
    "\n",
    "In altre parole, su quell’asse non serve alcun padding:\n",
    "\n",
    "se P dept = 0 allora diventa infatti\n",
    "\n",
    "𝐷out = (𝐷in + 2⋅0 − 𝐾 depth)/ 𝑆 + 1 = 5\n",
    "\n",
    "2⋅0\n",
    "\n",
    "\n",
    "Non è che la tua rete “CNN3D_LSTM_FC” sia sbagliata in senso assoluto, \n",
    "ma — proprio a causa di quel primo Conv3d con kernel_size=(5,3,3) e padding=(0,1,1) — \n",
    "\n",
    "stai automaticamente comprimendo tutte e 5 le bande nella singola fetta di profondità:\n",
    "\n",
    "\n",
    "self.conv1 = nn.Conv3d(\n",
    "    in_channels=1, out_channels=32,\n",
    "    kernel_size=(5, 3, 3),  # → D_out = (5 − 5 + 2·0)/1 + 1 = 1\n",
    "    padding=(0, 1, 1)\n",
    ")\n",
    "Quindi il tuo tensore (B, 1, 5, 9, 9) diventa (B, 32, 1, 9, 9): la dimensione depth (5) si riduce a 1 subito.\n",
    "\n",
    "Se invece vuoi davvero preservare le 5 “fette” come vera terza dimensione spaziale, hai due possibili correzioni:\n",
    "\n",
    "Usare un kernel 3×3×3 (o 1×3×3) in conv1, in modo da non “abbracciare” tutta la profondità d’ingresso:\n",
    "\n",
    "\n",
    "- self.conv1 = nn.Conv3d(1, 32, kernel_size=(5, 3, 3), padding=(0, 1, 1))\n",
    "+ # preserva D: depth out = depth in = 5\n",
    "+ self.conv1 = nn.Conv3d(1, 32, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
    "\n",
    "Oppure, se vuoi mantenere le bande completamente indipendenti in questo layer,\n",
    "\n",
    "\n",
    "self.conv1 = nn.Conv3d(1, 32, kernel_size=(1, 3, 3), padding=(0, 1, 1))\n",
    "che trasforma (B,1,5,9,9) → (B,32,5,9,9).\n",
    "\n",
    "Lasciare com’è, sapendo però che la rete “fonderà” le 5 bande in un’unica mappa di profondità: \n",
    "non è un bug, è una scelta architetturale.\n",
    "\n",
    "\n",
    "\n",
    "La SeparableCNN2D_LSTM_FC\n",
    "Quella architettura non comprime mai le bande all’interno di un’unica fetta, perché:\n",
    "\n",
    "Le bande diventano canali di un Conv2d depth‑wise:\n",
    "\n",
    "\n",
    "x = x.permute(0, 3, 1, 2)  # (B,5,9,9)\n",
    "self.dw_conv1 = nn.Conv2d(5, 5, kernel_size=3, padding=1, groups=5)\n",
    "Ogni “fetta” (banda) resta separata fino al pointwise e agli strati successivi.\n",
    "\n",
    "Quindi se il tuo obiettivo è avere un’uscita per banda (e poi poter plottare un Grad‑CAM 2D per ciascuna),\n",
    "la SeparableCNN2D è già configurata correttamente.\n",
    "\n",
    "Se invece vuoi un Grad‑CAM “volumetrico” 3D (5×9×9) direttamente dal modello 3D puro,\n",
    "la vera modifica necessaria è solo sul primo Conv3d, come mostrato sopra.\n",
    "\n",
    "Fammi sapere quale dei due setup stai usando e ti aiuto a integrare il Grad‑CAM 3D di conseguenza!\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "Ecco l’implementazione completa di CNN3D_LSTM_FC (“approccio sequenza di profondità”) in cui:\n",
    "\n",
    "mantieni il tuo primo blocco 3D con kernel (3,3,3) e padding (1,1,1), quindi D rimane 5 fino alla fine;\n",
    "\n",
    "riduci le spatial singleton dims (H=1,W=1) e trasformi la depth D=5 in una sequenza di lunghezza 5;\n",
    "\n",
    "imposti l’input_size=128 nell’LSTM (feature per time‑step = 128);\n",
    "\n",
    "\n",
    "Con questa versione:\n",
    "\n",
    "la sequenza per l’LSTM ha lunghezza D=5;\n",
    "\n",
    "ogni passo ha 128 feature, esattamente input_size=128;\n",
    "\n",
    "non servono trucchi di reshape su scala globale.\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN3D_LSTM_FC(nn.Module):\n",
    "    \"\"\"\n",
    "    Version with pure 3D convolutions treating the 5 frequency bands\n",
    "    as a sequence (depth) for the LSTM.\n",
    "    Input: Tensor of shape (B, 9, 9, 5) --> reshaped to (B, 1, 5, 9, 9)\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=2, dropout=0.5, hidden_size=64, use_lstm=True):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.hidden_size = hidden_size\n",
    "        self.use_lstm = use_lstm\n",
    "\n",
    "        # --- Block 1 (3D) ---\n",
    "        self.conv1   = nn.Conv3d(1,  32, kernel_size=(3,3,3), padding=(1,1,1))\n",
    "        self.bn1     = nn.BatchNorm3d(32)\n",
    "        self.pool3d  = nn.MaxPool3d((1,2,2))  # non tocca D\n",
    "\n",
    "        # --- Block 2 (3D Residual) ---\n",
    "        self.res_conv3d = nn.Conv3d(32, 64, kernel_size=1, bias=False)\n",
    "        self.res_bn3d   = nn.BatchNorm3d(64)\n",
    "        self.conv2a     = nn.Conv3d(32, 64, kernel_size=(1,3,3), padding=(0,1,1))\n",
    "        self.bn2a       = nn.BatchNorm3d(64)\n",
    "        self.conv2b     = nn.Conv3d(64, 64, kernel_size=(1,3,3), padding=(0,1,1))\n",
    "        self.bn2b       = nn.BatchNorm3d(64)\n",
    "\n",
    "        # --- Block 3 (3D) ---\n",
    "        self.conv3 = nn.Conv3d(64, 128, kernel_size=(1,3,3), padding=(0,1,1))\n",
    "        self.bn3   = nn.BatchNorm3d(128)\n",
    "\n",
    "        # LSTM o FC finale\n",
    "        if self.use_lstm:\n",
    "            # input_size = feature_dim per time‑step = 128\n",
    "            self.lstm       = nn.LSTM(input_size=128,\n",
    "                                      hidden_size=self.hidden_size,\n",
    "                                      num_layers=1,\n",
    "                                      batch_first=True)\n",
    "            self.classifier = nn.LazyLinear(num_classes)\n",
    "        else:\n",
    "            self.classifier = nn.LazyLinear(num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, 9, 9, 5)\n",
    "        if x.ndim == 4:\n",
    "            # -> (B,1,D=5,H=9,W=9)\n",
    "            x = x.permute(0, 3, 1, 2).unsqueeze(1)\n",
    "\n",
    "        # --- Block 1 ---\n",
    "        x = F.relu(self.bn1(self.conv1(x)))  # (B,32,5,9,9)\n",
    "        x = self.pool3d(x)                   # (B,32,5,4,4)\n",
    "\n",
    "        # --- Block 2 (Residual) ---\n",
    "        res = self.res_bn3d(self.res_conv3d(x))  # (B,64,5,4,4)\n",
    "        x   = F.relu(self.conv2a(x))             # (B,64,5,4,4)\n",
    "        x   = self.bn2b(self.conv2b(x))          # (B,64,5,4,4)\n",
    "        x   = F.relu(x + res)                    # (B,64,5,4,4)\n",
    "        x   = self.pool3d(x)                     # (B,64,5,2,2)\n",
    "\n",
    "        # --- Block 3 ---\n",
    "        x = F.relu(self.bn3(self.conv3(x)))      # (B,128,5,2,2)\n",
    "        x = self.pool3d(x)                       # (B,128,5,1,1)\n",
    "\n",
    "        # Stampa delle dimensioni prima di passare al classifier\n",
    "        #print(f\"Dimensioni prima del classifier: {x.shape}\")\n",
    "\n",
    "        if self.use_lstm:\n",
    "            # x: (B,128,5,1,1)\n",
    "            # -> squeeze spatial dims → (B,128,5)\n",
    "            x = x.squeeze(-1).squeeze(-1)\n",
    "            # -> permute per batch_first → (B, seq_len=5, feat=128)\n",
    "            x = x.permute(0, 2, 1)\n",
    "            x = self.dropout(x)\n",
    "            out, _ = self.lstm(x)               # out: (B,5,hidden_size)\n",
    "            last    = out[:, -1, :]             # prendo l’ultimo time-step\n",
    "            logits  = self.classifier(last)     # (B, num_classes)\n",
    "        else:\n",
    "            # x: (B,128,5,1,1) → flatten → (B,128)\n",
    "            x = x.view(x.size(0), -1)\n",
    "            logits = self.classifier(self.dropout(x))\n",
    "\n",
    "        return logits\n",
    "\n",
    "    \n",
    "\n",
    "class SeparableCNN2D_LSTM_FC(nn.Module):\n",
    "    \"\"\"\n",
    "    Version with depthwise + pointwise separable convolutions\n",
    "    across the 5 channels.\n",
    "    Input: Tensor of shape (B, 9, 9, 5) -> (B,5,9,9)\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=2, dropout=0.5, hidden_size=64, use_lstm=True):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.hidden_size = hidden_size\n",
    "        self.use_lstm = use_lstm\n",
    "\n",
    "        # --- Block 1 separabile ---\n",
    "        self.dw_conv1 = nn.Conv2d(5, 5, kernel_size=3, padding=1, groups=5)\n",
    "        self.pw_conv1 = nn.Conv2d(5, 32, kernel_size=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # --- Block 2 (residuo) ---\n",
    "        self.res_conv = nn.Conv2d(32, 64, kernel_size=1, bias=False)\n",
    "        self.res_bn = nn.BatchNorm2d(64)\n",
    "        self.bn2a = nn.BatchNorm2d(32)\n",
    "        self.conv2a = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn2b = nn.BatchNorm2d(64)\n",
    "        self.conv2b = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "\n",
    "        # --- Block 3 ---\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size=128 * 5, hidden_size=self.hidden_size, num_layers=1, batch_first=True)\n",
    "\n",
    "        if self.use_lstm:\n",
    "            self.lstm = nn.LSTM(\n",
    "                input_size=128 * 1,\n",
    "                hidden_size=self.hidden_size,\n",
    "                num_layers=1,\n",
    "                batch_first=True\n",
    "            )\n",
    "            self.classifier = nn.Linear(self.hidden_size, num_classes)\n",
    "        else:\n",
    "            self.classifier = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 3, 1, 2)  # -> (B,5,9,9)\n",
    "\n",
    "        x = F.relu(self.dw_conv1(x))\n",
    "        x = F.relu(self.bn1(self.pw_conv1(x)))\n",
    "        x = self.pool(x)\n",
    "\n",
    "        res = self.res_bn(self.res_conv(x))\n",
    "        x = F.relu(self.conv2a(self.bn2a(x)))\n",
    "        x = self.bn2b(self.conv2b(x))\n",
    "        x = F.relu(x + res)\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.pool(x)  # (B,128,1,1)\n",
    "\n",
    "        if self.use_lstm:\n",
    "            x = x.permute(0, 2, 1, 3).reshape(x.size(0), 1, -1)  # (B,1,128)\n",
    "            out, _ = self.lstm(self.dropout(x))\n",
    "            last = out[:, -1, :]\n",
    "            logits = self.classifier(last)\n",
    "        else:\n",
    "            x = x.view(x.size(0), -1)\n",
    "            logits = self.classifier(self.dropout(x))\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d889ef-c0f6-40f8-9042-ce6b1eaba938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick test\n",
    "if __name__ == \"__main__\":\n",
    "    cnn = CNN3D_LSTM_FC()\n",
    "    sep_conv = SeparableCNN2D_LSTM_FC()\n",
    "    \n",
    "    # Test both input orders\n",
    "    x2 = torch.randn(8, 9, 9, 5)\n",
    "    print(cnn(x2).shape)   # -> (8,2)\n",
    "    print(sep_conv(x2).shape)  # -> (8,2)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f4e1a43a-29ec-4006-8af1-fb009b667e57",
   "metadata": {
    "tags": []
   },
   "source": [
    "'''\n",
    "DEFINIZIONE DEI MODELLI NEW VERSION PER SPETTROGRAMMI 4D\n",
    "'''    \n",
    "    \n",
    "\n",
    "'''CNN2D\n",
    "\n",
    "Una CNN2D si aspetta input in forma (batch, canali, altezza, larghezza). \n",
    "Nel tuo caso, puoi interpretare l’\"altezza\" come i bin di frequenza (38)\n",
    "e la \"larghezza\" come le finestre temporali (6).\n",
    "\n",
    "Quindi, la tua CNN2D lavorerebbe direttamente con:\n",
    "Shape: (batch, canali, frequenze, tempo)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class CNN2D(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_channels, num_classes):\n",
    "        \n",
    "        super(CNN2D, self).__init__()\n",
    "        \n",
    "        # Ipotizziamo kernel 3x3 con padding per mantenere le dimensioni (puoi adattare a tuo piacimento)\n",
    "        self.conv1 = nn.Conv2d(input_channels, 16, kernel_size=(2, 2), stride=(1, 1), padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=(2, 2))\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=(2, 2), stride=(1, 1), padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.pool2 = nn.AvgPool2d(kernel_size=(2, 2))\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(32, 48, kernel_size=(2, 2), stride=(1, 1), padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(48)\n",
    "        self.pool3 = nn.AvgPool2d(kernel_size=(2, 2))\n",
    "        \n",
    "        # Utilizzo LazyLinear per evitare di calcolare manualmente la dimensione piatta finale\n",
    "        self.fc1 = nn.LazyLinear(8)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.LazyLinear(num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # x: (batch, canali, frequenze, tempo)\n",
    "        \n",
    "        # Passaggio attraverso il primo strato convoluzionale, BatchNorm e pooling\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)  # Batch Normalization\n",
    "        x = F.elu(x)\n",
    "        #x = torch.tanh(x)  # Sostituito ELU con tanh\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        # Passaggio attraverso il secondo strato convoluzionale, BatchNorm e pooling\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)  # Batch Normalization\n",
    "        x = F.elu(x)\n",
    "        #x = torch.tanh(x)  # Sostituito ELU con tanh\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        # Passaggio attraverso il secondo strato convoluzionale, BatchNorm e pooling\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)  # Batch Normalization\n",
    "        x = F.elu(x)\n",
    "        x = torch.tanh(x)  # Sostituito ELU con tanh\n",
    "        x = self.pool3(x)\n",
    "\n",
    "        # Flatten per preparare i dati per gli strati fully connected\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "\n",
    "        # Passaggio attraverso il primo strato fully connected\n",
    "        x = self.fc1(x)\n",
    "        x = F.elu(x)\n",
    "        #x = torch.tanh(x)  # Sostituito ELU con tanh\n",
    "\n",
    "        # Dropout per evitare overfitting\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # Passaggio attraverso il secondo strato fully connected\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n",
    "'''\n",
    "\n",
    "\n",
    "'''\n",
    "Gli LSTM si aspettano un input in forma (batch, lunghezza_sequenza, dimensione_feature). \n",
    "Dovrai quindi decidere qual è la dimensione sequenziale.\n",
    "\n",
    "Opzione comune: usare il tempo come sequenza\n",
    "Step 1: Trasponi i dati in modo da avere il tempo come dimensione sequenziale.\n",
    "\n",
    "Dalla forma (batch, canali, frequenze, tempo) puoi fare:\n",
    "\n",
    "\n",
    "x = x.permute(0, 3, 1, 2)  # Diventa (batch, tempo, canali, frequenze)\n",
    "\n",
    "Step 2: Unisci le dimensioni dei canali e dei bin di frequenza in un’unica dimensione di feature:\n",
    "\n",
    "\n",
    "batch, tempo, canali, frequenze = x.shape\n",
    "x = x.reshape(batch, tempo, canali * frequenze)  # Ora: (batch, tempo, canali*frequenze)\n",
    "\n",
    "Nel tuo caso, per 3 canali e 38 bin di frequenza: input_size = 3 * 38 = 114 e lunghezza sequenza = 6.\n",
    "\n",
    "Nota: Se invece preferisci usare i bin di frequenza come sequenza, potresti fare:\n",
    "\n",
    "x = x.permute(0, 2, 1, 3)  # (batch, frequenze, canali, tempo)\n",
    "x = x.reshape(batch, frequenze, canali * tempo)  # Sequence length = 38, feature size = 3*6 = 18\n",
    "La scelta dipende dal tipo di informazione temporale o spettrale che vuoi evidenziare.\n",
    "\n",
    "'''\n",
    "\n",
    "class ReadMEndYou(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_sizes, output_size, dropout=0.5, bidirectional=False):\n",
    "        \"\"\"\n",
    "        input_size: dimensione delle feature per time-step (dovrà essere canali * frequenze)\n",
    "        hidden_sizes: lista con le dimensioni degli hidden state, es. [24, 48, 62]\n",
    "        output_size: numero di classi\n",
    "        \n",
    "        \"\"\"\n",
    "    \n",
    "        super(ReadMEndYou, self).__init__()\n",
    "        \n",
    "        self.bidirectional = bidirectional # Impostazione della bidirezionalità    \n",
    "        \n",
    "        # Adattiamo hidden_size in base alla bidirezionalità\n",
    "        self.hidden_sizes = [\n",
    "            hidden_sizes[0] * 2 if bidirectional else hidden_sizes[0],\n",
    "            hidden_sizes[1] * 2 if bidirectional else hidden_sizes[1],\n",
    "            hidden_sizes[2] * 2 if bidirectional else hidden_sizes[2]\n",
    "        ]\n",
    "        \n",
    "        self.lstm1 = nn.LSTM(input_size=input_size, \n",
    "                             hidden_size=self.hidden_sizes[0], \n",
    "                             num_layers=1, \n",
    "                             batch_first=True, \n",
    "                             dropout=0, \n",
    "                             bidirectional=bidirectional)\n",
    "        self.lstm2 = nn.LSTM(input_size=self.hidden_sizes[0] * 2 if bidirectional else self.hidden_sizes[0],\n",
    "                             hidden_size=self.hidden_sizes[1], \n",
    "                             num_layers=1, \n",
    "                             batch_first=True, \n",
    "                             dropout=0,\n",
    "                             bidirectional=bidirectional)\n",
    "        self.lstm3 = nn.LSTM(input_size=self.hidden_sizes[1] * 2 if bidirectional else self.hidden_sizes[1],\n",
    "                             hidden_size=self.hidden_sizes[2],\n",
    "                             num_layers=1, \n",
    "                             batch_first=True, \n",
    "                             dropout=0,\n",
    "                             bidirectional=bidirectional)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(self.hidden_sizes[2] * 2 if bidirectional else self.hidden_sizes[2], output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # x: (batch, canali, frequenze, tempo)\n",
    "        \n",
    "        # Trasponi per avere il tempo come dimensione sequenziale:\n",
    "        x = x.permute(0, 3, 1, 2)  # -> (batch, tempo, canali, frequenze)\n",
    "        \n",
    "        batch, time, channels, freqs = x.shape\n",
    "        \n",
    "        x = x.reshape(batch, time, channels * freqs)  # -> (batch, tempo, channels*frequencies)\n",
    "        # Ora input_size deve essere channels * freqs (es. 64 * 81 = 7471)\n",
    "        \n",
    "        # LSTM 1\n",
    "        out, _ = self.lstm1(x)\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        # LSTM 2\n",
    "        out, _ = self.lstm2(out)\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        # LSTM 3\n",
    "        out, _ = self.lstm3(out)\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        # Estraiamo l'output dell'ultimo time-step\n",
    "        out = out[:, -1, :]\n",
    "        \n",
    "        # Dropout prima del layer fully connected    \n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        # Passaggio attraverso il layer finale per la previsione\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "        \n",
    "\n",
    "\n",
    "'''\n",
    "Il modulo Transformer in PyTorch lavora tipicamente su input di forma (seq_length, batch, embedding_dim).\n",
    "\n",
    "Nel codice attuale, si parte da una forma simile a (batch, canali, seq_length), ma dovrai adattarla alla nuova struttura.\n",
    "\n",
    "Possibili approcci:\n",
    "\n",
    "1) Approccio A: usare il tempo come sequenza\n",
    "\n",
    "Se consideri il tempo (6 time windows) come la sequenza, puoi procedere come segue:\n",
    "\n",
    "A) Unisci canali e frequenze in un’unica dimensione di feature:\n",
    "\n",
    "# Dati originali: (batch, canali, frequenze, tempo)\n",
    "x = x.permute(0, 3, 1, 2)  # (batch, tempo, canali, frequenze)\n",
    "batch, tempo, canali, frequenze = x.shape\n",
    "x = x.reshape(batch, tempo, canali * frequenze)  # (batch, tempo, 3*38 = 114)\n",
    "\n",
    "B) Modifica il layer di embedding:\n",
    "\n",
    "Nel codice attuale, l'embedding è definito come:\n",
    "\n",
    "self.embedding = nn.Linear(seq_length, d_model)\n",
    "Dovrai cambiarlo in modo che mappi le dimensioni delle feature (in questo caso 114) a uno spazio latente:\n",
    "\n",
    "self.embedding = nn.Linear(canali * frequenze, d_model)\n",
    "\n",
    "C) Permuta per il Transformer:\n",
    "\n",
    "Dopo l'embedding, passa l'input alla forma (seq_length, batch, d_model):\n",
    "\n",
    "x = x.permute(1, 0, 2)  # Ora: (tempo, batch, d_model)\n",
    "\n",
    "\n",
    "2) Approccio B: usare i bin di frequenza come sequenza\n",
    "In alternativa, se reputi più rilevante la risoluzione spettrale, puoi considerare i 38 bin come sequenza e combinare canali e tempo:\n",
    "\n",
    "\n",
    "x = x.permute(0, 2, 1, 3)  # (batch, frequenze, canali, tempo)\n",
    "batch, frequenze, canali, tempo = x.shape\n",
    "x = x.reshape(batch, frequenze, canali * tempo)  # (batch, frequenze, 3*6 = 18)\n",
    "\n",
    "E poi procedere con un embedding layer che mappa da 18 a d_model e permutare in (frequenze, batch, d_model).\n",
    "\n",
    "Scelta dell'approccio:\n",
    "Se l'aspetto temporale è più critico, probabilmente è meglio usare l’Approccio A (sequenza di lunghezza 6).\n",
    "Se invece vuoi dare maggior rilievo alla struttura spettrale, l’Approccio B potrebbe essere più indicato.\n",
    "\n",
    "Ricorda che la scelta dipende dalla natura del tuo problema e dalla rilevanza delle informazioni temporali rispetto a quelle spettrali.\n",
    "'''\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "#Scelta: In questa implementazione abbiamo deciso di usare il tempo come sequenza.\n",
    "#In alternativa, potresti scegliere i bin di frequenza come sequenza, ma ciò richiederebbe una diversa riorganizzazione delle dimensioni \n",
    "#(ad esempio, un permute diverso).\n",
    "\n",
    "class ReadMYMind(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, num_heads, num_layers, num_classes, channels=64, freqs=81):\n",
    "        \n",
    "        super(ReadMYMind, self).__init__()\n",
    "\n",
    "        # Il layer di embedding mapperà la feature dimension (channels * freqs) a d_model\n",
    "        self.embedding = nn.Linear(channels * freqs, d_model)\n",
    "        \n",
    "        # Transformer per l'attenzione spaziale (qui si applica direttamente alla sequenza temporale)\n",
    "        self.spatial_transformer = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(d_model=d_model, nhead=num_heads),\n",
    "            num_layers=num_layers\n",
    "        )\n",
    "        # Transformer per l'attenzione temporale (si potrebbe considerare un'iterazione successiva)\n",
    "        self.temporal_transformer = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(d_model=d_model, nhead=num_heads),\n",
    "            num_layers=num_layers\n",
    "        )\n",
    "        # Cross-attention per combinare le rappresentazioni\n",
    "        self.cross_attention = nn.MultiheadAttention(embed_dim=d_model, num_heads=num_heads)\n",
    "        \n",
    "        # Fusione e classificazione finale\n",
    "        self.fc_fusion = nn.Linear(d_model, d_model)\n",
    "        self.fc_classify = nn.Linear(d_model, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x: (batch, canali, frequenze, tempo)\n",
    "        \n",
    "        # Utilizziamo il tempo come sequenza\n",
    "        x = x.permute(0, 3, 1, 2)  # -> (batch, tempo, canali, frequenze)\n",
    "        \n",
    "        batch, time, channels, freqs = x.shape\n",
    "        x = x.reshape(batch, time, channels * freqs)  # -> (batch, tempo, channels*frequencies)\n",
    "        \n",
    "        # Embedding: (batch, tempo, d_model)\n",
    "        x = self.embedding(x)\n",
    "        \n",
    "        # Transformer richiede input di forma (seq_length, batch, embedding_dim)\n",
    "        x = x.permute(1, 0, 2)  # -> (tempo, batch, d_model)\n",
    "        \n",
    "        # Applichiamo il Transformer per l'attenzione spaziale\n",
    "        x_spatial = self.spatial_transformer(x)\n",
    "        # Applichiamo il Transformer per l'attenzione temporale\n",
    "        x_temporal = self.temporal_transformer(x_spatial)\n",
    "        \n",
    "        # Cross-attention: (tempo, batch, d_model)\n",
    "        x_cross, _ = self.cross_attention(x_spatial, x_temporal, x_temporal)\n",
    "        \n",
    "        # Fusione: per esempio, facciamo una media sul tempo (dimensione 0)\n",
    "        x_fused = self.fc_fusion((x_spatial + x_temporal).mean(dim=0))  # -> (batch, d_model)\n",
    "        \n",
    "        # Classificazione finale\n",
    "        output = self.fc_classify(x_fused)  # -> (batch, num_classes)\n",
    "        \n",
    "        return output\n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "id": "251cf624-5956-457e-8dc6-848c34171e39",
   "metadata": {
    "tags": []
   },
   "source": [
    "'''\n",
    "DEFINIZIONE DEI MODELLI NEW VERSION PER SPETTROGRAMMI 3D ...?\n",
    "'''    \n",
    "    \n",
    "\n",
    "\n",
    "'''\n",
    "Gli LSTM si aspettano un input in forma (batch, lunghezza_sequenza, dimensione_feature). \n",
    "Dovrai quindi decidere qual è la dimensione sequenziale.\n",
    "\n",
    "Opzione comune: usare il tempo come sequenza\n",
    "Step 1: Trasponi i dati in modo da avere il tempo come dimensione sequenziale.\n",
    "\n",
    "Dalla forma (batch, canali, frequenze, tempo) puoi fare:\n",
    "\n",
    "\n",
    "x = x.permute(0, 3, 1, 2)  # Diventa (batch, tempo, canali, frequenze)\n",
    "\n",
    "Step 2: Unisci le dimensioni dei canali e dei bin di frequenza in un’unica dimensione di feature:\n",
    "\n",
    "\n",
    "batch, tempo, canali, frequenze = x.shape\n",
    "x = x.reshape(batch, tempo, canali * frequenze)  # Ora: (batch, tempo, canali*frequenze)\n",
    "\n",
    "Nel tuo caso, per 3 canali e 38 bin di frequenza: input_size = 3 * 38 = 114 e lunghezza sequenza = 6.\n",
    "\n",
    "Nota: Se invece preferisci usare i bin di frequenza come sequenza, potresti fare:\n",
    "\n",
    "x = x.permute(0, 2, 1, 3)  # (batch, frequenze, canali, tempo)\n",
    "x = x.reshape(batch, frequenze, canali * tempo)  # Sequence length = 38, feature size = 3*6 = 18\n",
    "La scelta dipende dal tipo di informazione temporale o spettrale che vuoi evidenziare.\n",
    "\n",
    "\n",
    "************** ************** ************** ************** ************** ************** ************** **************\n",
    "\n",
    "Ecco le modifiche minime per adattare entrambe le classi al nuovo input x: (batch, frequenze, canali).\n",
    "\n",
    "1) LSTM multi-layer (ReadMEndYou)\n",
    "Prima:**\n",
    "\n",
    "python\n",
    "Copia\n",
    "Modifica\n",
    "# x: (batch, canali, frequenze, tempo)\n",
    "x = x.permute(0, 3, 1, 2)    # → (batch, tempo, canali, frequenze)\n",
    "x = x.reshape(batch, time, channels * freqs)\n",
    "Ora:**\n",
    "\n",
    "non hai più la dimensione “tempo”,\n",
    "\n",
    "frequenze diventa la lunghezza di sequenza,\n",
    "\n",
    "canali è la feature size.\n",
    "\n",
    "\n",
    "Parametri:\n",
    "\n",
    "input_size ora deve essere il numero di canali.\n",
    "\n",
    "Se avevi prima input_size = 64*81, ora sarà semplicemente 64 (numero di canali).\n",
    "\n",
    "************** ************** ************** ************** ************** ************** ************** **************\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "class ReadMEndYou(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_sizes, output_size, dropout=0.5, bidirectional=False):\n",
    "        \"\"\"\n",
    "        input_size: dimensione delle feature per time-step (dovrà essere canali * frequenze)\n",
    "        hidden_sizes: lista con le dimensioni degli hidden state, es. [24, 48, 62]\n",
    "        output_size: numero di classi\n",
    "        \n",
    "        \"\"\"\n",
    "    \n",
    "        super(ReadMEndYou, self).__init__()\n",
    "        \n",
    "        self.bidirectional = bidirectional # Impostazione della bidirezionalità    \n",
    "        \n",
    "        # Adattiamo hidden_size in base alla bidirezionalità\n",
    "        self.hidden_sizes = [\n",
    "            hidden_sizes[0] * 2 if bidirectional else hidden_sizes[0],\n",
    "            hidden_sizes[1] * 2 if bidirectional else hidden_sizes[1],\n",
    "            hidden_sizes[2] * 2 if bidirectional else hidden_sizes[2]\n",
    "        ]\n",
    "        \n",
    "        self.lstm1 = nn.LSTM(input_size=input_size, \n",
    "                             hidden_size=self.hidden_sizes[0], \n",
    "                             num_layers=1, \n",
    "                             batch_first=True, \n",
    "                             dropout=0, \n",
    "                             bidirectional=bidirectional)\n",
    "        self.lstm2 = nn.LSTM(input_size=self.hidden_sizes[0] * 2 if bidirectional else self.hidden_sizes[0],\n",
    "                             hidden_size=self.hidden_sizes[1], \n",
    "                             num_layers=1, \n",
    "                             batch_first=True, \n",
    "                             dropout=0,\n",
    "                             bidirectional=bidirectional)\n",
    "        self.lstm3 = nn.LSTM(input_size=self.hidden_sizes[1] * 2 if bidirectional else self.hidden_sizes[1],\n",
    "                             hidden_size=self.hidden_sizes[2],\n",
    "                             num_layers=1, \n",
    "                             batch_first=True, \n",
    "                             dropout=0,\n",
    "                             bidirectional=bidirectional)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(self.hidden_sizes[2] * 2 if bidirectional else self.hidden_sizes[2], output_size)\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x: (batch, frequenze, canali)\n",
    "        \n",
    "        # qui: seq_len = frequenze, feat = canali\n",
    "        \n",
    "        # No permute/reshape necessario oltre alla LSTM\n",
    "        \n",
    "        # LSTM 1\n",
    "        out, _ = self.lstm1(x)    # → (batch, frequenze, hidden_sizes[0])\n",
    "        \n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        # LSTM 2\n",
    "        out, _ = self.lstm2(out)  # → (batch, frequenze, hidden_sizes[1])\n",
    "        \n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        # LSTM 3\n",
    "        out, _ = self.lstm3(out)  # → (batch, frequenze, hidden_sizes[2])\n",
    "        \n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        # Estraiamo l'output dell'ultimo time-step\n",
    "       \n",
    "        out = out[:, -1, :]       # → (batch, hidden_sizes[2])\n",
    "        \n",
    "       # Dropout prima del layer fully connected    Z\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        # Passaggio attraverso il layer finale per la previsione\n",
    "        return self.fc(out)       # → (batch, output_size)\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    PRIMA ERA \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # x: (batch, canali, frequenze, tempo)\n",
    "        \n",
    "        # Trasponi per avere il tempo come dimensione sequenziale:\n",
    "        x = x.permute(0, 3, 1, 2)  # -> (batch, tempo, canali, frequenze)\n",
    "        \n",
    "        batch, time, channels, freqs = x.shape\n",
    "        \n",
    "        x = x.reshape(batch, time, channels * freqs)  # -> (batch, tempo, channels*frequencies)\n",
    "        # Ora input_size deve essere channels * freqs (es. 64 * 81 = 7471)\n",
    "        \n",
    "        # LSTM 1\n",
    "        out, _ = self.lstm1(x)\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        # LSTM 2\n",
    "        out, _ = self.lstm2(out)\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        # LSTM 3\n",
    "        out, _ = self.lstm3(out)\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        # Estraiamo l'output dell'ultimo time-step\n",
    "        out = out[:, -1, :]\n",
    "        \n",
    "        # Dropout prima del layer fully connected    \n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        # Passaggio attraverso il layer finale per la previsione\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "        \n",
    "    '''\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "'''\n",
    "Il modulo Transformer in PyTorch lavora tipicamente su input di forma (seq_length, batch, embedding_dim).\n",
    "\n",
    "Nel codice attuale, si parte da una forma simile a (batch, canali, seq_length), ma dovrai adattarla alla nuova struttura.\n",
    "\n",
    "Possibili approcci:\n",
    "\n",
    "1) Approccio A: usare il tempo come sequenza\n",
    "\n",
    "Se consideri il tempo (6 time windows) come la sequenza, puoi procedere come segue:\n",
    "\n",
    "A) Unisci canali e frequenze in un’unica dimensione di feature:\n",
    "\n",
    "# Dati originali: (batch, canali, frequenze, tempo)\n",
    "x = x.permute(0, 3, 1, 2)  # (batch, tempo, canali, frequenze)\n",
    "batch, tempo, canali, frequenze = x.shape\n",
    "x = x.reshape(batch, tempo, canali * frequenze)  # (batch, tempo, 3*38 = 114)\n",
    "\n",
    "B) Modifica il layer di embedding:\n",
    "\n",
    "Nel codice attuale, l'embedding è definito come:\n",
    "\n",
    "self.embedding = nn.Linear(seq_length, d_model)\n",
    "Dovrai cambiarlo in modo che mappi le dimensioni delle feature (in questo caso 114) a uno spazio latente:\n",
    "\n",
    "self.embedding = nn.Linear(canali * frequenze, d_model)\n",
    "\n",
    "C) Permuta per il Transformer:\n",
    "\n",
    "Dopo l'embedding, passa l'input alla forma (seq_length, batch, d_model):\n",
    "\n",
    "x = x.permute(1, 0, 2)  # Ora: (tempo, batch, d_model)\n",
    "\n",
    "\n",
    "2) Approccio B: usare i bin di frequenza come sequenza\n",
    "In alternativa, se reputi più rilevante la risoluzione spettrale, puoi considerare i 38 bin come sequenza e combinare canali e tempo:\n",
    "\n",
    "\n",
    "x = x.permute(0, 2, 1, 3)  # (batch, frequenze, canali, tempo)\n",
    "batch, frequenze, canali, tempo = x.shape\n",
    "x = x.reshape(batch, frequenze, canali * tempo)  # (batch, frequenze, 3*6 = 18)\n",
    "\n",
    "E poi procedere con un embedding layer che mappa da 18 a d_model e permutare in (frequenze, batch, d_model).\n",
    "\n",
    "Scelta dell'approccio:\n",
    "Se l'aspetto temporale è più critico, probabilmente è meglio usare l’Approccio A (sequenza di lunghezza 6).\n",
    "Se invece vuoi dare maggior rilievo alla struttura spettrale, l’Approccio B potrebbe essere più indicato.\n",
    "\n",
    "Ricorda che la scelta dipende dalla natura del tuo problema e dalla rilevanza delle informazioni temporali rispetto a quelle spettrali.\n",
    "\n",
    "\n",
    "************** ************** ************** ************** ************** ************** ************** **************\n",
    "\n",
    "2) Transformer (ReadMYMind)\n",
    "Prima:**\n",
    "\n",
    "\n",
    "# x: (batch, canali, frequenze, tempo)\n",
    "x = x.permute(0, 3, 1, 2)      # → (batch, tempo, canali, frequenze)\n",
    "x = x.reshape(batch, tempo, channels * freqs)\n",
    "self.embedding = nn.Linear(channels * freqs, d_model)\n",
    "\n",
    "\n",
    "Ora:**\n",
    "\n",
    "frequenze è la sequenza,\n",
    "\n",
    "canali è la feature dim → embedding lin(C → d_model).\n",
    "\n",
    "\n",
    "\n",
    "Nota:\n",
    "\n",
    "Non c’è più la reshape(batch, time, channels*freqs),\n",
    "\n",
    "l’embedding lavora su canali → d_model,\n",
    "\n",
    "la “sequenza” è già la dimensione delle frequenze.\n",
    "\n",
    "\n",
    "Con queste due modifiche:\n",
    "\n",
    "mantieni intatta la struttura logica di LSTM e Transformer\n",
    "\n",
    "adatti solo le linee di permute/reshape ed il Linear(...) iniziale\n",
    "\n",
    "riduci l’input_size per la LSTM a (n_canali) e l’embedding del Transformer a channels→d_model\n",
    "\n",
    "************** ************** ************** ************** ************** ************** ************** **************\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class ReadMYMind(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, num_heads, num_layers, num_classes, channels=64, freqs=None):\n",
    "        \n",
    "        super(ReadMYMind, self).__init__()\n",
    "        \n",
    "        # freqs non serve più, ma lasciamolo per compatibilità\n",
    "        \n",
    "        # Il layer di embedding mapperà la feature dimension (channels) a d_model\n",
    "        self.embedding = nn.Linear(channels,  d_model)\n",
    "        \n",
    "        # Transformer per l'attenzione spaziale (qui si applica direttamente alla sequenza -dimensione canali-)\n",
    "        self.spatial_transformer = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(d_model=d_model, nhead=num_heads),\n",
    "            num_layers=num_layers\n",
    "        )\n",
    "        # Transformer per l'attenzione temporale (si potrebbe considerare un'iterazione successiva)\n",
    "        self.temporal_transformer = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(d_model=d_model, nhead=num_heads),\n",
    "            num_layers=num_layers\n",
    "        )\n",
    "        # Cross-attention per combinare le rappresentazioni\n",
    "        self.cross_attention = nn.MultiheadAttention(embed_dim=d_model, num_heads=num_heads)\n",
    "        \n",
    "        # Fusione e classificazione finale\n",
    "        self.fc_fusion = nn.Linear(d_model, d_model)\n",
    "        self.fc_classify = nn.Linear(d_model, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x: (batch, frequenze, canali)\n",
    "        \n",
    "        # seq_len = frequenze, feat = canali\n",
    "        \n",
    "        # Embedding: (batch, frequenze, d_model)\n",
    "        x = self.embedding(x) # → (batch, frequenze, d_model)\n",
    "            \n",
    "        # Transformer richiede input di forma (seq_length, batch, embedding_dim)\n",
    "        x = x.permute(1, 0, 2)  # -> (frequenze, batch, d_model)\n",
    "        \n",
    "        # Applichiamo il Transformer per l'attenzione spaziale\n",
    "        x_spatial = self.spatial_transformer(x)\n",
    "        \n",
    "        # Applichiamo il Transformer per l'attenzione temporale\n",
    "        x_temporal = self.temporal_transformer(x_spatial)\n",
    "        \n",
    "        # Cross-attention: (tempo, batch, d_model)\n",
    "        x_cross, _ = self.cross_attention(x_spatial, x_temporal, x_temporal)\n",
    "        \n",
    "        # fusione (qui media sul tempo)\n",
    "        \n",
    "        '''\n",
    "        Con “# fusione (qui media sul tempo)” intendo che, una volta ottenute due rappresentazioni parallele:\n",
    "\n",
    "        x_spatial → attenzione “spaziale” sulle frequenze\n",
    "\n",
    "        x_temporal → attenzione “temporale” (sul medesimo input, dopo la spaziale)\n",
    "\n",
    "        le combiniamo sommando element-wise quei due tensori e poi ne facciamo la media sulla dimensione della sequenza (qui le frequenze)\n",
    "        per ottenere un unico vettore di lunghezza d_model per ciascun batch.\n",
    "\n",
    "        In pratica:\n",
    "\n",
    "        # x_spatial e x_temporal: shape = (seq_len, batch, d_model)\n",
    "        # seq_len = numero di frequenze\n",
    "\n",
    "        # 1) sommiamo le due mappe\n",
    "        combined = x_spatial + x_temporal         # → (seq_len, batch, d_model)\n",
    "\n",
    "        # 2) media su `dim=0`, cioè sul seq_len:\n",
    "        fused = combined.mean(dim=0)              # → (batch, d_model)\n",
    "        Così “fondere” le due attenzioni significa:\n",
    "\n",
    "        sommare le loro informazioni in ogni posizione di frequenza,\n",
    "\n",
    "        ridurre tutta la serie di frequenze a un singolo vettore di feature (la media),\n",
    "\n",
    "        ottenendo infine una rappresentazione compatta (batch, d_model) pronta per il classificatore.\n",
    "        \n",
    "        Ha senso farla, ed è in effetti una delle strategie più semplici ed efficaci per “riassumere”\n",
    "        lungo la dimensione di sequenza (le frequenze, nel tuo caso) una rappresentazione che ha già subito più livelli di attenzione. \n",
    "       \n",
    "        In particolare:\n",
    "\n",
    "        Pooling globale (average‐pooling)\n",
    "        Riduce la dipendenza da una particolare frequenza “focus” e cattura un segnale mediato su tutto lo spettro.\n",
    "\n",
    "        È parametricamente leggero (non introduce pesi aggiuntivi) ed è robusto al rumore su singole bande.\n",
    "\n",
    "        Perché funziona nel tuo modello\n",
    "\n",
    "        Hai già applicato due TransformerEncoder (spaziale e temporale) e una cross‐attention, \n",
    "        quindi ogni posizione di frequenza ha visto sia contesto locale che globale. \n",
    "        \n",
    "        Prendere la media di quelle posizioni ti dà un vettore compatto che incorpora tutte le interazioni.\n",
    "\n",
    "        Alternative più “learned” al semplice mean\n",
    "        Se però vuoi che il modello decida dove guardare meglio, puoi sostituire la media con:\n",
    "\n",
    "        Attention pooling (un piccolo MLP che calcola un peso per ciascuna frequenza e poi fa la somma pesata anziché la media semplice).\n",
    "        [CLS] token (su modelli Transformer, inserire un token di classificazione in testa alla sequenza e usare la sua rappresentazione finale).\n",
    "        Max‐pooling (se cerchi di catturare caratteristiche “picco” su qualche banda).\n",
    "\n",
    "        Per esempio, un semplice attention pooling sul tuo fused tensor potrebbe diventare:\n",
    "        \n",
    "        # dopo x_cross: shape = (seq_len, batch, d_model)\n",
    "        alpha = torch.softmax(self.attn_fc(x_cross).permute(1,2,0), dim=-1)  # -> (batch, d_model, seq_len)\n",
    "        pooled = (alpha @ x_cross.permute(1,0,2))                           # -> (batch, d_model)\n",
    "        dove self.attn_fc = nn.Linear(d_model, 1) imparerebbe un peso per ogni frequenza.\n",
    "\n",
    "        In sintesi: la media sul tempo (frequenze) è un’ottima baseline: stabile, veloce e priva di parametri aggiuntivi. \n",
    "        Se però vuoi dare al tuo modello la flessibilità di “decidere” quali bande sono più informative, \n",
    "        puoi sperimentare con un semplice attention pooling o con un token [CLS].\n",
    "\n",
    "        '''\n",
    "        \n",
    "        # Fusione: per esempio, facciamo una media sul tempo (dimensione 0)\n",
    "        x_fused = self.fc_fusion((x_spatial + x_temporal).mean(dim=0))  # -> (batch, d_model)\n",
    "        \n",
    "        # Classificazione finale\n",
    "        output = self.fc_classify(x_fused)  # -> (batch, num_classes)\n",
    "        \n",
    "        return output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1497eed-8070-4cd2-a2e0-31d47427aafb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(new_all_th_concat_spectrograms_coupled_exp_task_1['rest_vs_left_fist']['data'].shape)\n",
    "print()\n",
    "print(new_all_th_concat_spectrograms_coupled_exp_task_1['rest_vs_right_fist']['data'].shape)\n",
    "print()\n",
    "print(new_all_th_concat_spectrograms_coupled_exp_task_1['left_fist_vs_right_fist']['data'].shape)\n",
    "print()\n",
    "print(np.unique(new_all_th_concat_spectrograms_coupled_exp_task_1['rest_vs_left_fist']['labels'], return_counts = True))\n",
    "print()\n",
    "print(np.unique(new_all_th_concat_spectrograms_coupled_exp_task_1['rest_vs_right_fist']['labels'], return_counts = True))\n",
    "print()\n",
    "print(np.unique(new_all_th_concat_spectrograms_coupled_exp_task_1['left_fist_vs_right_fist']['labels'], return_counts = True))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e70bc0ba-513d-4d96-b976-a2642cdf0ae4",
   "metadata": {
    "tags": []
   },
   "source": [
    "'''\n",
    "Ecco un codice che fornisce dati di input fittizi a ciascuna rete neurale, \n",
    "stampa le dimensioni a ogni passaggio e verifica che gli output abbiano le forme attese.\n",
    "\n",
    "Ho mantenuto le forme coerenti con i tuoi parametri:\n",
    "\n",
    "\n",
    "Batch size: 8\n",
    "Numero di canali EEG: 3\n",
    "Numero di frequenze: 38\n",
    "Numero di timepoints (campioni temporali): 100\n",
    "Numero di classi: 2\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Parametri\n",
    "batch_size = 45\n",
    "input_channels = 64   # Canali EEG\n",
    "num_freqs = 81       # Numero di frequenze\n",
    "num_timepoints = 9  # Numero di campioni temporali\n",
    "\n",
    "num_classes = 2       # Numero di classi\n",
    "\n",
    "dropout = 0.2\n",
    "\n",
    "# Creazione di dati fittizi per il test\n",
    "x = torch.randn(batch_size, input_channels, num_freqs, num_timepoints)  # (batch, canali, frequenze, tempo)\n",
    "print(f\"Input iniziale: {x.shape}\\n\")\n",
    "\n",
    "# ---- CNN2D ----\n",
    "#cnn_model = CNN2D(input_channels=input_channels, num_classes=num_classes)\n",
    "\n",
    "cnn_model = CNN2D_LSTM_TF(input_channels = input_channels, n_classes =num_classes, dropout = dropout)\n",
    "cnn_output = cnn_model(x)\n",
    "print(f\"Output CNN2D: {cnn_output.shape}\\n\")  # Atteso: (batch_size, num_classes)\n",
    "\n",
    "\n",
    "# ---- ReadMEndYou (LSTM) ----\n",
    "hidden_sizes = [24, 48, 62]\n",
    "lstm_model = ReadMEndYou(input_size=input_channels * num_freqs, hidden_sizes=hidden_sizes, output_size=num_classes)\n",
    "lstm_output = lstm_model(x)\n",
    "print(f\"Output ReadMEndYou (LSTM): {lstm_output.shape}\\n\")  # Atteso: (batch_size, num_classes)\n",
    "\n",
    "# ---- ReadMYMind (Transformer) ----\n",
    "d_model = 64   # Dimensione embedding\n",
    "num_heads = 8   # Numero di teste di attenzione\n",
    "num_layers = 3  # Numero di strati Transformer\n",
    "\n",
    "transformer_model = ReadMYMind(d_model=d_model, num_heads=num_heads, num_layers=num_layers, num_classes=num_classes)\n",
    "transformer_output = transformer_model(x)\n",
    "print(f\"Output ReadMYMind (Transformer): {transformer_output.shape}\\n\")  # Atteso: (batch_size, num_classes)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "eee3ae26-4347-401f-8996-5cd985d22251",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Test della rete GRID 2D\n",
    "batch_size = 45\n",
    "grid_size = 9\n",
    "x_test = torch.randn(batch_size, grid_size, grid_size)\n",
    "\n",
    "model = CNN2D_LSTM_FC(input_channels = 1, num_classes=2, dropout=0.2)\n",
    "output = model(x_test)\n",
    "print(\"Output shape:\", output.shape)  # → torch.Size([32, 2])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b1565e9d-1804-4eb2-b95b-182479bf8747",
   "metadata": {},
   "source": [
    "# Test della rete GRID 2D MULTI-BAND\n",
    "\n",
    "input_tensor = torch.randn(6922, 9, 9, 5)  # (B,H,W,C)\n",
    "model = CNN2D_LSTM_FC(input_channels=5)\n",
    "output = model(input_tensor)  # → (6922, 2)\n",
    "\n",
    "\n",
    "model = CNN2D_LSTM_FC(input_channels = 5, num_classes=2, dropout=0.2)\n",
    "output = model(input_tensor)\n",
    "print(\"Output shape:\", output.shape)  # → torch.Size([32, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35fe219-77bb-41a8-9a67-477b177ffc8c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### **Early Stopping - EEG Spectrograms - Electrodes x Frequencies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45efccea-1289-42fe-aca6-1c55ad70cc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "DEFINIZIONE EARLY STOPPING\n",
    "'''\n",
    "\n",
    "import io\n",
    "from PIL import Image\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience = 10, min_delta = 0.001, mode = 'max'):\n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "        :param patience: Numero di epoche da attendere prima di interrompere il training se non c'è miglioramento\n",
    "        \n",
    "        Esempio: il training si interromperà se non si osserva un miglioramento per (N = 5) epoche consecutive.\n",
    "        \n",
    "        :param min_delta: Variazione minima richiesta per considerare un miglioramento\n",
    "        \n",
    "        definisce il miglioramento minimo richiesto per essere considerato significativo. \n",
    "        Se il miglioramento è inferiore a min_delta, non viene considerato un vero miglioramento.\n",
    "        \n",
    "        Il parametro min_delta in una configurazione di early stopping indica \n",
    "        la minima variazione del valore di una metrica \n",
    "        (ad esempio, la perdita o l'accuratezza) \n",
    "        che deve verificarsi tra un'epoca e la successiva \n",
    "        per continuare l'allenamento. \n",
    "        \n",
    "        In genere, il valore di min_delta dipende dal tipo di modello e dai dati specifici, \n",
    "        ma di solito si trova in un intervallo tra 0.001 e 0.01.\n",
    "    \n",
    "            - Se stai cercando di evitare che l'allenamento si fermi troppo presto,\n",
    "            puoi impostare un valore più basso per min_delta (come 0.001), \n",
    "            - Se vuoi essere più conservativo e permettere fluttuazioni nei valori della metrica,\n",
    "            un valore più alto (come 0.01) potrebbe essere appropriato.\n",
    "\n",
    "        Un buon punto di partenza potrebbe essere 0.001, e poi fare dei test per capire quale valore funziona meglio\n",
    "        nel tuo caso specifico!\n",
    "        \n",
    "        :param mode: 'min' per monitorare la loss (minimizzazione), 'max' per l'accuracy (massimizzazione)\n",
    "        \n",
    "        'max' → ottimizza metriche da massimizzare (es. accuracy, F1-score, AUC).\n",
    "        'min' → ottimizza metriche da minimizzare (es. loss).\n",
    "        \n",
    "        \"\"\"\n",
    "            \n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.mode = mode\n",
    "        self.best_score = None # Tiene traccia del miglior punteggio osservato\n",
    "        self.counter = 0 # Conta quante epoche consecutive non migliorano\n",
    "        self.early_stop = False # Flag che indica se attivare l'early stopping\n",
    "        \n",
    "        #Ogni volta che si chiama la classe con early_stopping(current_score), controlla se il modello sta migliorando o meno.\n",
    "\n",
    "    def __call__(self, current_score):\n",
    "        \n",
    "        #Caso 1: Prima iterazione (best_score ancora None)\n",
    "        #→ Se non esiste ancora un miglior punteggio, lo inizializza con il primo valore ricevuto.\n",
    "        \n",
    "        if self.best_score is None:\n",
    "            self.best_score = current_score\n",
    "            \n",
    "        #Caso 2: Il modello migliora\n",
    "        #→ Se il valore migliora di almeno min_delta, aggiorna best_score e resetta il contatore.\n",
    "\n",
    "        elif (self.mode == 'min' and current_score < self.best_score - self.min_delta) or \\\n",
    "             (self.mode == 'max' and current_score > self.best_score + self.min_delta):\n",
    "            self.best_score = current_score\n",
    "            self.counter = 0  # Reset contatore se migliora\n",
    "            \n",
    "        #Caso 3: Il modello NON migliora\n",
    "        \n",
    "        #→ Se il valore non migliora, incrementa il contatore.\n",
    "        #→ Se il contatore raggiunge patience, imposta early_stop = True, segnalando che il training deve essere interrotto.\n",
    "        \n",
    "        else:\n",
    "            self.counter += 1  # Incrementa se non migliora\n",
    "            if self.counter >= self.patience:\n",
    "                print(f\"🛑 Early stopping attivato! Nessun miglioramento per {self.patience} epoche consecutive.\")\n",
    "                self.early_stop = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ed0c34-ebc4-4d3d-a51c-633de5d5ca6e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### **Weight & Biases Login - EEG Spectrograms - Electrodes x Frequencies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f5ebda-2244-4786-9e4d-c15007f7731e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "WEIGHT AND BIASES LOGIN\n",
    "\n",
    "Il messaggio che stai ricevendo indica \n",
    "che sei già connesso al tuo account Weights & Biases (wandb).\n",
    "\n",
    "Se vuoi forzare il login, puoi usare il comando suggerito:\n",
    "\n",
    "wandb login --relogin\n",
    "\n",
    "Questo comando ti permetterà di reinserire le credenziali e riconnetterti al tuo account.\n",
    "Se non hai bisogno di disconnetterti o di cambiare l'account,\n",
    "puoi semplicemente continuare a usare wandb senza ulteriori passaggi. \n",
    "Hai bisogno di ulteriore assistenza con wandb o con il tuo progetto?\n",
    "'''\n",
    "\n",
    "\n",
    "import wandb\n",
    "wandb.login()\n",
    "print(\"✅ Weights & Biases login effettuato con successo!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27afa84a-cac4-4154-a0ef-5ccb6e5f2cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Per modificare il percorso in cui W&B salva i dati localmente,\n",
    "puoi configurare la variabile di ambiente WANDB_DIR.\n",
    "\n",
    "Questo ti permette di specificare una directory personalizzata in cui W&B salva tutti i file associati al tuo run, inclusi i dati e i log.\n",
    "'''\n",
    "\n",
    "import os\n",
    "\n",
    "# Imposta la directory per i dati W&B:\n",
    "# Questo cambierà la cartella in cui W&B salva i dati per quella sessione di esecuzione\n",
    "\n",
    "# Definisci la cartella principale\n",
    "#WB_dir = \"/home/stefano/Interrogait/WB_spectrograms_analyses_channels_frequencies_params_hyperparams_motor_task_1\"\n",
    "\n",
    "WB_dir = \"/home/stefano/Interrogait/WB_spectrograms_analyses_channels_frequencies_params_motor_task_1_new_3d_grid_multiband\"\n",
    "os.makedirs(WB_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "os.environ[\"WANDB_DIR\"] = WB_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bc892a-7f16-41d7-a6d7-3f5b61dc1d0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy\n",
    "\n",
    "# Apri il file in modalità lettura binaria ('rb')\n",
    "\n",
    "#path = '/home/stefano/Interrogait/all_datas/Unfamiliar_Spectrograms/'\n",
    "\n",
    "#path = '/home/stefano/Interrogait/all_datas/Familiar_Spectrograms_channels_frequencies/'\n",
    "\n",
    "path = '/home/stefano/Interrogait/all_datas/Spectrograms_channels_frequencies_motor_tasks/'\n",
    "\n",
    "with open(f\"{path}new_all_th_concat_spectrograms_coupled_exp_task_1_2d_grid_multiband.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3cd156-88bd-46e3-b047-f0842adbdddf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Itera sulle chiavi del dizionario principale\n",
    "for condition, values in data.items():\n",
    "    if isinstance(values, dict) and \"data\" in values and \"labels\" in values:\n",
    "        X_shape = values[\"data\"].shape\n",
    "        y_length = len(values[\"labels\"])\n",
    "        print(f\"🔹 Condizione: {condition}\")\n",
    "        print(f\"   ➡ Shape dati: {X_shape}\")\n",
    "        print(f\"   ➡ Lunghezza labels: {y_length}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce91395-e41b-4391-89da-67a3fd2988c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_all_th_concat_spectrograms_coupled_exp_task_1.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac71feb6-aef4-4717-88b7-130bee156585",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### **Datasets Loading - EEG Spectrograms - Electrodes x Frequencies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb25019-2498-466e-bd5f-1fb73adac7a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##################### CODICE UFFICIALE DEL 04/03/2025 ORE 9:30 #####################\n",
    "                                 ##################### SENZA DETTAGLI SCRITTI V°3 #####################\n",
    "        \n",
    "'''ATTENZIONE: \n",
    "\n",
    "HO SOSTITUITO LE VARIABILI DI \n",
    "\n",
    "    1) DATASET_TRAIN_LOADER -->  TRAIN_LOADER\n",
    "    2) DATASET_VAL_LOADER -->  VAL_LOADER\n",
    "\n",
    "    VEDI FUNZIONE 'PREPARE_DATA_FOR_MODEL --> NOMI DELLE VARIABILI DEI TORCH TENSOR DATASET LOADER SON  'TRAIN_LOADER' E VAL_LOADER!!!  \n",
    "\n",
    "'''\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import wandb\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "import copy as cp\n",
    "import numpy as np\n",
    "\n",
    "import wandb\n",
    "import random\n",
    "import copy as cp\n",
    "\n",
    "\n",
    "# Definisci le lista delle coppie di condizioni sperimentali\n",
    "#experimental_conditions = [\"th_resp_vs_pt_resp\", \"th_resp_vs_shared_resp\", \"pt_resp_vs_shared_resp\"]\n",
    "\n",
    "experimental_conditions = [\"rest_vs_left_fist\", \"rest_vs_right_fist\", \"left_fist_vs_right_fist\"]\n",
    "\n",
    "\n",
    "# Inizializza il dizionario per caricare i dati\n",
    "data_dict = {}\n",
    "\n",
    "#Definisci la cartella principale\n",
    "\n",
    "#base_dir = \"/home/stefano/Interrogait/WB_spectrograms_best_results\"\n",
    "\n",
    "#base_dir = \"/home/stefano/Interrogait/WB_spectrograms_best_results_channels_frequencies\"\n",
    "\n",
    "#base_dir = \"/home/stefano/Interrogait/WB_spectrograms_best_results_channels_frequencies_params_hyperparams\"\n",
    "\n",
    "\n",
    "'''HO AGGIUNTO NEW QUI PER CREARE CARTELLA CON SWEEP NUOVI, CONFRONTANDO BILSTM & TRANSFORMER CON CNN2D_LSTM!'''\n",
    "\n",
    "base_dir = \"/home/stefano/Interrogait/WB_spectrograms_best_results_channels_frequencies_params_motor_task_1_new_3d_grid_multiband\"\n",
    "\n",
    "\n",
    "os.makedirs(base_dir, exist_ok = True)\n",
    "\n",
    "'''LOOP DI CARICAMENTO DATI'''\n",
    "\n",
    "for condition in experimental_conditions:\n",
    "    # Crea la cartella per la condizione sperimentale\n",
    "    condition_dir = os.path.join(base_dir, condition)\n",
    "    os.makedirs(condition_dir, exist_ok=True)\n",
    "    \n",
    "    # Aggiungi un livello di annidamento per ogni condizione\n",
    "    data_dict[condition] = {}\n",
    "    \n",
    "    for data_type in [\"spectrograms\"]:\n",
    "        \n",
    "        # Crea la cartella per il tipo di dato\n",
    "        data_dir = os.path.join(condition_dir, data_type)\n",
    "        os.makedirs(data_dir, exist_ok=True)\n",
    "        \n",
    "        #for category in [\"familiar\", \"unfamiliar\"]:\n",
    "        for category in [\"familiar\"]:\n",
    "            \n",
    "            # Crea la cartella per la categoria\n",
    "            #category_dir = os.path.join(data_dir, category)\n",
    "            #os.makedirs(category_dir, exist_ok=True)\n",
    "            \n",
    "            #for subject_type in [\"th\", \"pt\"]:\n",
    "            for subject_type in [\"th\"]:\n",
    "                # Caricamento e suddivisione dei dati\n",
    "                \n",
    "                #if data_type == \"spectrograms\":\n",
    "                    \n",
    "                print(f\"Caricamento dati per: {condition} - {data_type} - {category}_{subject_type}\")\n",
    "                X, y = load_data(data_type, category, subject_type, condition=condition)\n",
    "                \n",
    "                \n",
    "                # Creazione della chiave per il dizionario annidato\n",
    "                data_dict[condition][data_type] = data_dict[condition].get(data_type, {})\n",
    "                data_dict[condition][data_type][f\"{category}_{subject_type}\"] = (X, y)\n",
    "                \n",
    "                # Stampa di conferma\n",
    "                print(f\"Dataset caricato: \\033[1m{condition}\\033[0m_\\033[1m{data_type}\\033[0m_\\033[1m{category}_{subject_type}\\033[0m - Shape X: \\033[1m{X.shape}\\033[0m, Shape y: \\033[1m{len(y)}\\033[0m\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e44aeeb-d0e4-4262-841c-2c7bd05b4474",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### **Datasets Loading - EEG Spectrograms - Electrodes x Frequencies** \n",
    "\n",
    "#### **CHECK PER ASSENZA DI VALORI NEGATIVI NELLA POTENZA SPETTRALE DEI DATI EEG** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c882c35e-a5dd-4377-b40e-7d3baaae3ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Caricare l'intero dizionario annidato con pickle\n",
    "path = '/home/stefano/EEGMMIDB_Analyses/'\n",
    "\n",
    "# Caricare l'intero dizionario annidato con pickle\n",
    "#with open(f'{path_channels}ordered_electrodes.pkl', 'rb') as f:\n",
    "\n",
    "with open(f'{path}electrode_grid_map.pkl', 'rb') as f:\n",
    "    EEG_channels_names = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f1ac5c-94e2-4611-a9cc-268f87e09fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for condition in data_dict.keys():\n",
    "    for data_type in data_dict[condition].keys():\n",
    "        for group_key in data_dict[condition][data_type].keys():\n",
    "            \n",
    "            # Estrai i dati\n",
    "            X, y = data_dict[condition][data_type][group_key]\n",
    "\n",
    "            # Controlli di validità\n",
    "            min_val = X.min()\n",
    "            has_neg = (X < 0).any()\n",
    "            has_nan = np.isnan(X).any()\n",
    "            has_inf = np.isinf(X).any()\n",
    "\n",
    "            # Stampa risultato\n",
    "            print(f\"\\n🧪 Check: {condition} → {data_type} → {group_key}\")\n",
    "            print(f\"  ➤ Shape X: {X.shape}, Shape y: {y.shape}\")\n",
    "            print(f\"  ➤ Valore minimo assoluto: {min_val}\")\n",
    "            print(f\"  ➤ Contiene negativi? {'✅ SÌ' if has_neg else '❌ NO'}\")\n",
    "            print(f\"  ➤ Contiene NaN? {'✅ SÌ' if has_nan else '❌ NO'}\")\n",
    "            print(f\"  ➤ Contiene Inf? {'✅ SÌ' if has_inf else '❌ NO'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576d1494-2323-41d4-87ad-37fb76c94a10",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### **Datasets Loading - EEG Spectrograms - Electrodes x Frequencies**\n",
    "\n",
    "#### **CHECK VALORI POTENZA SPETTRALE PER BANDA** \n",
    "#### **VISUALIZZAZIONE POTENZA MEDIA PER BANDA A LIVELLO TOPOGRAFICO, TRA LE DUE CONDIZIONI SPERIMENTALI**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68085a6e-17d1-4bdc-90c2-2d616b1e7695",
   "metadata": {},
   "source": [
    "| Oggetto              | Contenuto                      | Uso nello script                                                                          |\n",
    "| -------------------- | ------------------------------ | ----------------------------------------------------------------------------------------- |\n",
    "| `electrode_grid_map` | `{ 'Fz': (y,x), … }`           | serve a posizionare il testo con `ax.text(x,y,label,…)`.                                  |\n",
    "| `grand_X`            | tutti i trial → `(N, 9, 9, 5)` | da cui ricavi: <br>• `mean_power_per_band` (bar plot) <br>• `mean_maps` (heat‑map 9×9×5). |\n",
    "\n",
    "\n",
    "Così vedrai:\n",
    "\n",
    "Bar‑plot delle bande dominate (Delta, Theta, Alpha, …).\n",
    "\n",
    "Heat‑map della distribuzione spaziale media per ciascuna banda, con il nome di ogni elettrodo sovra‑impresso nella sua cella 9 × 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b79eef2-bbeb-484d-8313-11c2999a601f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# funzione d’aiuto: dalla stringa condition → lista [name0, name1]\n",
    "def split_condition(cond_str: str):\n",
    "    if \"_vs_\" in cond_str:\n",
    "        return cond_str.split(\"_vs_\", maxsplit=1)\n",
    "    else:\n",
    "        return [f\"{cond_str}_0\", f\"{cond_str}_1\"]     # fallback\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 1.  Riepilogo min/max (dataset  ➜ banda  ➜ label 0/1 con nome)\n",
    "# ------------------------------------------------------------------\n",
    "band_names = ['Delta', 'Theta', 'Alpha', 'Beta', 'Gamma']\n",
    "\n",
    "for condition in data_dict:                      # es. 'rest_vs_left_fist'\n",
    "    cls_names = split_condition(condition)       # ['rest', 'left_fist']\n",
    "    for data_type in data_dict[condition]:\n",
    "        for group_key in data_dict[condition][data_type]:\n",
    "            \n",
    "            X, y = data_dict[condition][data_type][group_key]\n",
    "\n",
    "            print(f\"\\n🧪  \\033[1m{condition} → {data_type} → {group_key}\\033[0m\\n\")\n",
    "            print(f\"    Shape X: {X.shape},  Shape y: {y.shape}\")\n",
    "            print(f\"    Min assoluto dataset : {X.min():.3e}\")\n",
    "            print(f\"    Negativi presenti?   {'✅ SÌ' if (X < 0).any() else '❌ NO'}\\n\")\n",
    "            \n",
    "            print(f\" \\033[1mValori di potenza spettrale per banda (tra i dati di tutte e due le classi)\\033[0m\")\n",
    "            # range banda – tutti i trial insieme\n",
    "            for b, name in enumerate(band_names):\n",
    "                mm = X[..., b]\n",
    "                print(f\"       • {name:<6} tot : min={mm.min():.3e}   max={mm.max():.3e}\")\n",
    "\n",
    "            # range banda – separato per label 0 / 1  (con nome condizione)\n",
    "            for lbl in [0, 1]:\n",
    "                mask = (y == lbl)\n",
    "                if not mask.any():\n",
    "                    continue\n",
    "                X_lbl = X[mask]\n",
    "                print(f\"\\n       ▼ Label \\033[1m{lbl}\\033[0m  (\\033[1m{cls_names[lbl]}\\033[0m)\")\n",
    "                for b, name in enumerate(band_names):\n",
    "                    mm = X_lbl[..., b]\n",
    "                    print(f\"         {name:<6}: min={mm.min():.3e}   max={mm.max():.3e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59eee62-200f-401b-9f0f-3e721e228361",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "                                                    UNITA' MISURA IN VOLT, CON SCALA COLORI GLOBALE PER TUTTE LE BANDE\n",
    "\n",
    "\n",
    "Ho preparato uno snippet che, per ogni dataset:\n",
    "\n",
    "1) Prende tutti i trial di ognuna delle 2 condizioni sperimentali per dataset e calcola:\n",
    "\n",
    "2) la potenza media per banda (bar‑plot) e la visualizza rispetto a quella per le altre \n",
    "\n",
    "3) la mappa 9 × 9 della potenza media per ogni banda (un’heat‑map per banda), mettendo i relativi plot della relativa banda uno accanto all'altro \n",
    "per le 2 condizioni sperimentali \n",
    "\n",
    "'''\n",
    "\n",
    "import pickle, numpy as np, matplotlib.pyplot as plt\n",
    "\n",
    "# ---------- mappa elettrodo → (y,x) ----------\n",
    "with open('/home/stefano/EEGMMIDB_Analyses/electrode_grid_map.pkl', 'rb') as f:\n",
    "    electrode_grid_map = pickle.load(f)          # {'Fz':(0,4), 'Cz':(4,4), ...}\n",
    "\n",
    "band_names = ['Delta', 'Theta', 'Alpha', 'Beta', 'Gamma']\n",
    "\n",
    "def split_condition(cond_str):\n",
    "    return cond_str.split(\"_vs_\", 1) if \"_vs_\" in cond_str else [f\"{cond_str}_0\",\n",
    "                                                                 f\"{cond_str}_1\"]\n",
    "\n",
    "# ============================================================\n",
    "# LOOP su ogni dataset (= coppia di condizioni sperimentali)\n",
    "# ============================================================\n",
    "for condition in data_dict:                             # es. 'rest_vs_left_fist'\n",
    "    cls_names = split_condition(condition)              # ['rest', 'left_fist']\n",
    "    \n",
    "    for dtype in data_dict[condition]:\n",
    "        for gk in data_dict[condition][dtype]:\n",
    "            \n",
    "            X, y = data_dict[condition][dtype][gk]      # X:(N,9,9,5)\n",
    "            print(f\"\\n👀  Figura   {condition}  /  {gk}   (shape X={X.shape})\")\n",
    "\n",
    "            # ---------- pre‑calcola medie ----------\n",
    "            mean_bar   = []      # (2, 5)\n",
    "            mean_maps  = []      # (2, 9,9,5)\n",
    "            for lbl in (0,1):\n",
    "                mask = (y == lbl)\n",
    "                if not mask.any():               # se manca una classe, riempi di NaN\n",
    "                    mean_bar.append(np.full(5, np.nan))\n",
    "                    mean_maps.append(np.full((9,9,5), np.nan))\n",
    "                else:\n",
    "                    Xlbl = X[mask]\n",
    "                    mean_bar.append(Xlbl.mean(axis=(0,1,2)))\n",
    "                    mean_maps.append(Xlbl.mean(axis=0))\n",
    "            \n",
    "            \n",
    "            '''MODIFICA PER TROVARE MINIMO E MASSIMO PER OGNI SCALA'''\n",
    "            # ---------- calcola scala cromatica comune per le heatmap ----------\n",
    "            vmin = np.nanmin([np.nanmin(mean_maps[0]), np.nanmin(mean_maps[1])])\n",
    "            vmax = np.nanmax([np.nanmax(mean_maps[0]), np.nanmax(mean_maps[1])])\n",
    "\n",
    "            # ---------- layout figure ----------\n",
    "            n_rows, n_cols = 1 + len(band_names), 2       # 6 × 2\n",
    "            \n",
    "            fig, axs = plt.subplots(n_rows, n_cols,\n",
    "                                    figsize=(10, 18),\n",
    "                                    constrained_layout=False)\n",
    "            \n",
    "            fig.suptitle(f\"{condition}  –  {dtype} / {gk}\",\n",
    "                         fontsize=10, \n",
    "                         y=0.97)      # ⬅︎ 0.97 invece di 0.995\n",
    "            \n",
    "            '''più vai verso 0.99 e più sovrapposizione ci sarà tra il fig.suptitle e i titoli delle varie righe'''\n",
    "            fig.subplots_adjust(top=0.95)          # ⬅︎ spinge giù l’intera griglia\n",
    "\n",
    "            # --- riga‑0: bar‑plot ---\n",
    "            for col, lbl in enumerate((0,1)):\n",
    "                ax = axs[0, col]\n",
    "                ax.bar(band_names, mean_bar[lbl])\n",
    "                ax.set_title(f\"{cls_names[lbl]}  (label {lbl})\")\n",
    "                ax.set_ylabel(\"Mean power\")\n",
    "                ax.set_ylim(0, np.nanmax(mean_bar))       # scala comune\n",
    "                if col == 1: ax.set_ylabel(\"\")            # evita doppio testo\n",
    "\n",
    "            # --- righe 1‑5: heat‑map per banda ---\n",
    "            for r, band in enumerate(band_names, start=1):\n",
    "                for col, lbl in enumerate((0,1)):\n",
    "                    ax = axs[r, col]\n",
    "                    \n",
    "                    '''Tutte le heatmap ora useranno la stessa scala di colori, \n",
    "                    rendendo comparabili le potenze tra bande e tra classi.'''\n",
    "                    \n",
    "                    im = ax.imshow(mean_maps[lbl][:,:,r-1],\n",
    "                       cmap='jet', origin='upper', aspect='equal',\n",
    "                       vmin=vmin, vmax=vmax)  # ⬅️ scala colori comune\n",
    "                    \n",
    "                    #im = ax.imshow(mean_maps[lbl][:,:,r-1],\n",
    "                                   #cmap='jet', origin='upper', aspect='equal')\n",
    "                    # etichette elettrodo\n",
    "                    for lab,(yy,xx) in electrode_grid_map.items():\n",
    "                        ax.text(xx, yy, lab,\n",
    "                                ha='center', va='center',\n",
    "                                fontsize=5.5, color='black', weight='bold')\n",
    "                    ax.set_xticks([]); ax.set_yticks([])\n",
    "                    if col == 0:\n",
    "                        ax.set_ylabel(band, rotation=90, labelpad=6,\n",
    "                                      fontsize=9, weight='bold')\n",
    "                    # color‑bar SOLO a destra\n",
    "                    if col == 1:\n",
    "                        fig.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "\n",
    "            fig.suptitle(f\"{condition}  –  {dtype} / {gk}\", fontsize=14, y=0.995)\n",
    "            plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fda0902-e8fd-454d-aa4b-e0e39bbbb9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Due punti veloci prima del codice:\n",
    "\n",
    "Ampiezza vs Potenza. L’EEG “grezzo” è in ampiezza (Volt). Quando fai FFT e sommi i bin di una banda, stai calcolando (a fattori di scala vicini)\n",
    "la potenza nella banda: la potenza è proporzionale al quadrato dell’ampiezza → unità V² (oppure V²/Hz se usi PSD e poi integri).\n",
    "\n",
    "Unità nei plot. Se lasci in Volt, la potenza risulta in V²; per resa “da neuroscienze” conviene convertire a µV² (moltiplicando per 1e12) \n",
    "prima di plottare e scrivere le unità su assi e colorbar.\n",
    "\n",
    "Quando usare scala colore “globale” vs “per banda”\n",
    "\n",
    "Globale (tutte le bande insieme): mantiene il confronto assoluto tra bande (es. Delta ≫ Gamma). Rischia di “appiattire” le bande più deboli.\n",
    "\n",
    "Per banda (comune alle due condizioni): ogni riga/banda ha la stessa scala tra le 2 condizioni, così vedi meglio le differenze topografiche all’interno della banda,\n",
    "senza che Delta domini tutto.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Come provarlo subito\n",
    "\n",
    "1) Potenza in µV² + scala globale\n",
    "\n",
    "plot_band_power(data_dict, scale_mode=\"global\", unit_mode=\"uV2\", use_sem=False)\n",
    "\n",
    "\n",
    "2) Potenza in µV² + scala per banda (comune alle 2 condizioni)\n",
    "\n",
    "plot_band_power(data_dict, scale_mode=\"per_band\", unit_mode=\"uV2\", use_sem=False)\n",
    "\n",
    "\n",
    "3) dB re: 1 µV² + scala per banda\n",
    "\n",
    "plot_band_power(data_dict, scale_mode=\"per_band\", unit_mode=\"dB\", use_sem=False)\n",
    "\n",
    "\n",
    "4) Potenza relativa per banda (%), scala per banda con range [0,100]\n",
    "\n",
    "plot_band_power(data_dict, scale_mode=\"per_band\", unit_mode=\"relative\",\n",
    "                use_sem=False, relative_pct=True)\n",
    "\n",
    "\n",
    "\n",
    "Quando preferire ciascuna\n",
    "\n",
    "a) µV²: valori assoluti; utile per magnitudini reali (attenzione: Delta tende a dominare).\n",
    "\n",
    "b) dB: confronti più “compressi” e leggibili, differenze proporzionali diventano additive.\n",
    "\n",
    "c) Relativa % (per elettrodo): evidenzia come si ridistribuisce lo spettro tra bande nello stesso elettrodo, indipendente dall’ampiezza assoluta\n",
    "(ottimo per topografie comparative).\n",
    "\n",
    "Se vuoi aggiungere un’opzione “per Hz” (µV²/Hz, cioè normalizzare per larghezza di banda) o “delta vs baseline” in dB, dimmelo e la integro con 2–3 righe.\n",
    "\n",
    "                                                            \n",
    "                                                            \n",
    "                                                        UNITA' MISURA IN MICROVOLT, CON OPZIONE PER SCALA COLORI\n",
    "                                                        \n",
    "                                                        GLOBALE PER TUTTE LE BANDE (in MICROVOLT PERO'!)\n",
    "                                                        PER BANDA ((in MICROVOLT PERO'!)\n",
    "                                                        LOGARITMICA (dB)\n",
    "                                                        \n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import pickle, numpy as np, matplotlib.pyplot as plt\n",
    "\n",
    "# ---------- mappa elettrodo → (y,x) ----------\n",
    "with open('/home/stefano/EEGMMIDB_Analyses/electrode_grid_map.pkl', 'rb') as f:\n",
    "    electrode_grid_map = pickle.load(f)  # {'Fz':(0,4), 'Cz':(4,4), ...}\n",
    "\n",
    "band_names = ['Delta', 'Theta', 'Alpha', 'Beta', 'Gamma']\n",
    "\n",
    "def split_condition(cond_str):\n",
    "    return cond_str.split(\"_vs_\", 1) if \"_vs_\" in cond_str else [f\"{cond_str}_0\", f\"{cond_str}_1\"]\n",
    "\n",
    "def _to_units(X_v2, unit_mode=\"uV2\", relative_pct=True, eps=1e-30):\n",
    "    \"\"\"\n",
    "    X_v2: array (N, 9, 9, 5) in V² (potenza per banda).\n",
    "    Ritorna (X_plot, unit_label).\n",
    "    \"\"\"\n",
    "    if unit_mode == \"uV2\":\n",
    "        return X_v2 * 1e12, \"µV²\"\n",
    "    elif unit_mode == \"dB\":\n",
    "        return 10 * np.log10(np.maximum(X_v2 * 1e12, eps)), \"dB (re: 1 µV²)\"\n",
    "    elif unit_mode == \"relative\":\n",
    "        # per trial & elettrodo: normalizza per somma sulle 5 bande\n",
    "        denom = np.sum(X_v2, axis=-1, keepdims=True)  # (N,9,9,1) in V²\n",
    "        frac = np.divide(X_v2, np.maximum(denom, eps), where=denom>0)  # 0..1\n",
    "        if relative_pct:\n",
    "            return frac * 100.0, \"%\"\n",
    "        else:\n",
    "            return frac, \"rel\"\n",
    "    else:\n",
    "        raise ValueError(\"unit_mode deve essere 'uV2', 'dB' o 'relative'.\")\n",
    "\n",
    "def plot_band_power(\n",
    "    data_dict,\n",
    "    scale_mode=\"global\",      # \"global\" oppure \"per_band\"\n",
    "    unit_mode=\"uV2\",          # \"uV2\", \"dB\", \"relative\"\n",
    "    use_sem=False,            # True per barre d'errore\n",
    "    cmap=\"viridis\",\n",
    "    relative_pct=True\n",
    "):\n",
    "    for condition in data_dict:                             # es. 'rest_vs_left_fist'\n",
    "        cls_names = split_condition(condition)              # ['rest', 'left_fist']\n",
    "\n",
    "        for dtype in data_dict[condition]:\n",
    "            for gk in data_dict[condition][dtype]:\n",
    "\n",
    "                X_v2, y = data_dict[condition][dtype][gk]   # X_v2:(N,9,9,5) in V²\n",
    "                print(f\"\\n👀  Figura   {condition}  /  {gk}   (shape X={X_v2.shape})\")\n",
    "\n",
    "                # ---------- CONVERSIONE UNITÀ ----------\n",
    "                X_plot, unit_label = _to_units(X_v2, unit_mode=unit_mode, relative_pct=relative_pct)\n",
    "\n",
    "                # ---------- pre-calcola medie ----------\n",
    "                mean_bar   = []      # (2, 5): media sui trial della media spaziale\n",
    "                sem_bar    = []      # (2, 5): SEM sui trial (se richiesto)\n",
    "                mean_maps  = []      # (2, 9,9,5): media su trial (per heatmap)\n",
    "\n",
    "                for lbl in (0,1):\n",
    "                    mask = (y == lbl)\n",
    "                    if not mask.any():\n",
    "                        mean_bar.append(np.full(5, np.nan))\n",
    "                        if use_sem:\n",
    "                            sem_bar.append(np.full(5, np.nan))\n",
    "                        mean_maps.append(np.full((9,9,5), np.nan))\n",
    "                    else:\n",
    "                        Xlbl = X_plot[mask]                     # (n_lbl, 9,9,5)\n",
    "                        mean_maps.append(Xlbl.mean(axis=0))     # (9,9,5)\n",
    "\n",
    "                        # bar: media per banda dopo media spaziale per trial\n",
    "                        trial_means = Xlbl.mean(axis=(1,2))     # (n_lbl, 5)\n",
    "                        mean_bar.append(trial_means.mean(axis=0))\n",
    "                        if use_sem:\n",
    "                            sem_bar.append(trial_means.std(axis=0, ddof=1) / np.sqrt(trial_means.shape[0]))\n",
    "\n",
    "                # ---------- scale cromatiche ----------\n",
    "                if scale_mode == \"global\":\n",
    "                    # un’unica scala per tutte le bande/condizioni\n",
    "                    both = np.stack([mean_maps[0], mean_maps[1]], axis=0)   # (2,9,9,5)\n",
    "                    vmin_global = np.nanmin(both)\n",
    "                    vmax_global = np.nanmax(both)\n",
    "                    band_vmin = [vmin_global]*len(band_names)\n",
    "                    band_vmax = [vmax_global]*len(band_names)\n",
    "                else:\n",
    "                    # \"per_band\": una scala per riga/banda, comune alle due condizioni\n",
    "                    band_vmin, band_vmax = [], []\n",
    "                    for b in range(len(band_names)):\n",
    "                        both_b = np.stack([mean_maps[0][:,:,b], mean_maps[1][:,:,b]], axis=0)  # (2,9,9)\n",
    "                        band_vmin.append(np.nanmin(both_b))\n",
    "                        band_vmax.append(np.nanmax(both_b))\n",
    "\n",
    "                    # Facoltativo: per \"relative %\" puoi forzare [0,100] per confronti immediati\n",
    "                    if unit_mode == \"relative\" and relative_pct:\n",
    "                        band_vmin = [0.0]*len(band_names)\n",
    "                        band_vmax = [100.0]*len(band_names)\n",
    "\n",
    "                # ---------- layout figure ----------\n",
    "                n_rows, n_cols = 1 + len(band_names), 2   # 6 × 2\n",
    "                fig, axs = plt.subplots(n_rows, n_cols, figsize=(10, 18), constrained_layout=False)\n",
    "                fig.suptitle(f\"{condition}  –  {dtype} / {gk}\", fontsize=12, y=0.97)\n",
    "                \n",
    "                #fig.subplots_adjust(top=0.95, hspace=0.35)\n",
    "                fig.subplots_adjust(top=0.92) \n",
    "                \n",
    "                # --- riga-0: bar-plot (con o senza SEM) ---\n",
    "                if use_sem:\n",
    "                    ymax = np.nanmax(np.vstack([\n",
    "                        (mean_bar[0] + sem_bar[0]),\n",
    "                        (mean_bar[1] + sem_bar[1])\n",
    "                    ]))\n",
    "                else:\n",
    "                    ymax = np.nanmax(np.vstack([mean_bar[0], mean_bar[1]]))\n",
    "                ymax = (ymax * 1.05) if np.isfinite(ymax) else 1.0\n",
    "\n",
    "                for col, lbl in enumerate((0,1)):\n",
    "                    ax = axs[0, col]\n",
    "                    if use_sem:\n",
    "                        ax.bar(band_names, mean_bar[lbl], yerr=sem_bar[lbl], capsize=3)\n",
    "                    else:\n",
    "                        ax.bar(band_names, mean_bar[lbl])\n",
    "                    ax.set_title(f\"{cls_names[lbl]}  (label {lbl})\")\n",
    "                    ax.set_ylabel(f\"Mean power [{unit_label}]\")\n",
    "                    ax.set_ylim(0, ymax)\n",
    "                    if col == 1:\n",
    "                        ax.set_ylabel(\"\")\n",
    "\n",
    "                # --- righe 1-5: heat-map per banda ---\n",
    "                for r, band in enumerate(band_names, start=1):\n",
    "                    for col, lbl in enumerate((0,1)):\n",
    "                        ax = axs[r, col]\n",
    "                        im = ax.imshow(\n",
    "                            mean_maps[lbl][:,:,r-1],\n",
    "                            cmap=cmap, origin='upper', aspect='equal',\n",
    "                            vmin=band_vmin[r-1], vmax=band_vmax[r-1]\n",
    "                        )\n",
    "                        # etichette elettrodo\n",
    "                        for lab,(yy,xx) in electrode_grid_map.items():\n",
    "                            ax.text(xx, yy, lab, ha='center', va='center',\n",
    "                                    fontsize=5.5, color='black', weight='bold')\n",
    "                        ax.set_xticks([]); ax.set_yticks([])\n",
    "                        if col == 0:\n",
    "                            ax.set_ylabel(band, rotation=90, labelpad=6,\n",
    "                                          fontsize=9, weight='bold')\n",
    "                    # colorbar UNA per banda (colonna destra)\n",
    "                    cbar = fig.colorbar(im, ax=axs[r, 1], fraction=0.046, pad=0.04)\n",
    "                    cbar.set_label(unit_label)\n",
    "\n",
    "                plt.show()\n",
    "                plt.close(fig)\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f953fbf-f99b-4159-91f1-f486aef37403",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_band_power(data_dict, scale_mode=\"global\", unit_mode=\"uV2\", use_sem=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d38036-1c33-4d01-a423-9baec7461190",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "-- IO:\n",
    "Qui sopra la potenza media in alpha tra le due condizioni ti sembra sensato con l'attivaizone motoria per il movimento di mano sn rispetto a baseline (fermo)?\n",
    "\n",
    "\n",
    "\n",
    "-- CHATGPT:\n",
    "Sì—se in alpha (8–12 Hz) vedi potenza più alta a rest e più bassa in left_fist, è coerente: durante l’attivazione motoria (o immaginazione)\n",
    "ci si aspetta desincronizzazione mu/alpha (ERD) rispetto alla baseline. Per mano sinistra l’ERD dovrebbe essere più marcata controlateralmente, \n",
    "quindi su elettrodi centrali destro-emisferici (≈ C4/FC4/CP4), mentre l’emisfero sinistro (C3…) funge da confronto.\n",
    "\n",
    "Detto questo, due accortezze per capire se l’effetto è davvero “motorio” e non solo attenzione/arousal:\n",
    "\n",
    "Topografia\n",
    "Controlla che il calo in alpha sia focalizzato su area sensori-motoria destra più che occipitale. Se vedi un calo molto diffuso/occipitale,\n",
    "può riflettere attenzione/occhi/vision più che motricità.\n",
    "\n",
    "Metodica di misura\n",
    "\n",
    "Usa un indice ERD% = (power_task − power_rest) / power_rest × 100 per banda/elettrodo.\n",
    "\n",
    "Focalizzati su una ROI: ROI_contra = {FC4, C4, CP4} vs ROI_ipsi = {FC3, C3, CP3}; atteso ERD% più negativo nella ROI controlaterale.\n",
    "\n",
    "Prova anche beta (13–30 Hz): in movimento/MI tipicamente ERD beta e, se c’è movimento reale, rebound post-movimento.\n",
    "\n",
    "Se vuoi calcolarlo col tuo schema dati (N,9,9,5):\n",
    "\n",
    "# alpha = indice 2 nelle tue band\n",
    "alpha = 2\n",
    "mask_rest = (y==0)\n",
    "mask_left = (y==1)\n",
    "rest_map  = X_v2[mask_rest].mean(axis=0)[:,:,alpha]\n",
    "left_map  = X_v2[mask_left].mean(axis=0)[:,:,alpha]\n",
    "erd_alpha = (left_map - rest_map) / (rest_map + 1e-30) * 100  # ERD% (negativo = desync)\n",
    "\n",
    "# media su ROI (coordinate da electrode_grid_map)\n",
    "roi_contra = {'FC4','C4','CP4'}\n",
    "roi_ipsi   = {'FC3','C3','CP3'}\n",
    "def roi_mean(m):\n",
    "    idx = [electrode_grid_map[ch] for ch in roi_contra]  # (y,x)\n",
    "    contra = np.mean([m[y,x] for y,x in idx])\n",
    "    idx = [electrode_grid_map[ch] for ch in roi_ipsi]\n",
    "    ipsi = np.mean([m[y,x] for y,x in idx])\n",
    "    return contra, ipsi\n",
    "\n",
    "contra_erd, ipsi_erd = roi_mean(erd_alpha)\n",
    "print('ERD% alpha – contra:', contra_erd, 'ipsi:', ipsi_erd)\n",
    "\n",
    "\n",
    "Interpretazione attesa: ERD% alpha più negativo su C4-FC4-CP4 rispetto a C3-FC3-CP3. Se questo pattern c’è, \n",
    "i tuoi plot sono perfettamente sensati per “left_fist vs rest”. Se non c’è, prova: unità relative (%) nel tuo plot_band_power,\n",
    "montaggio Laplacian/CSD, e controlla eventuale alpha occipitale (occhi/attenzione).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "-- IO:\n",
    "\n",
    "ok tu mi hai detto infatti \"Controlla che il calo in alpha sia focalizzato su area sensori-motoria destra più che occipitale\" \n",
    "con: Usa un indice ERD% = (power_task − power_rest) / power_rest × 100 per banda/elettrodo. Focalizzati su una ROI: ROI_contra = {FC4, C4, CP4} \n",
    "vs ROI_ipsi = {FC3, C3, CP3}; atteso ERD% più negativo nella ROI controlaterale allora mi concentrei su tutta la corteccia motoria per la mia ROI, \n",
    "ossia ossia tra FC5 fino a scendere a CP5 e tra FC6 fino a scendere a CP6, tutti quegli elettrodi lì se vedi. \n",
    "\n",
    "riesci a correggermi allora il codice per fare questa verifica, e dirmi che stiamo facendo e cosa ci aspettiamo? \"\n",
    "\n",
    "\n",
    "Se vuoi calcolarlo col tuo schema dati (N,9,9,5):\n",
    "\n",
    "# alpha = indice 2 nelle tue band\n",
    "alpha = 2\n",
    "mask_rest = (y==0)\n",
    "mask_left = (y==1)\n",
    "rest_map  = X_v2[mask_rest].mean(axis=0)[:,:,alpha]\n",
    "left_map  = X_v2[mask_left].mean(axis=0)[:,:,alpha]\n",
    "erd_alpha = (left_map - rest_map) / (rest_map + 1e-30) * 100  # ERD% (negativo = desync)\n",
    "\n",
    "# media su ROI (coordinate da electrode_grid_map)\n",
    "roi_contra = {'FC4','C4','CP4'}\n",
    "roi_ipsi   = {'FC3','C3','CP3'}\n",
    "def roi_mean(m):\n",
    "    idx = [electrode_grid_map[ch] for ch in roi_contra]  # (y,x)\n",
    "    contra = np.mean([m[y,x] for y,x in idx])\n",
    "    idx = [electrode_grid_map[ch] for ch in roi_ipsi]\n",
    "    ipsi = np.mean([m[y,x] for y,x in idx])\n",
    "    return contra, ipsi\n",
    "\n",
    "contra_erd, ipsi_erd = roi_mean(erd_alpha)\n",
    "print('ERD% alpha – contra:', contra_erd, 'ipsi:', ipsi_erd)\n",
    "\n",
    "\n",
    "-- CHATGPT:\n",
    "\n",
    "Assolutamente sì — se vuoi testare l’ipotesi “ERD α (8–12 Hz) controlaterale più forte sulla cintura motoria”, prendiamo proprio le strisce FC6–C6–CP6 \n",
    "\n",
    "(controlaterale per mano sinistra) vs FC5–C5–CP5 (ipsilaterale) e calcoliamo l’ERD%:\n",
    "\n",
    "Cosa facciamo:\n",
    "\n",
    "stimiamo la mappa media di potenza in alpha per rest (label 0) e left_fist (label 1);\n",
    "\n",
    "calcoliamo l’ERD% per elettrodo: \n",
    "(task−rest)/rest×100  → più negativo = maggiore desincronizzazione;\n",
    "\n",
    "mediamo l’ERD% sulla ROI controlaterale {FC6, C6, CP6} e sulla ROI ipsilaterale {FC5, C5, CP5};\n",
    "\n",
    "verifichiamo che la ROI controlaterale sia più negativa.\n",
    "\n",
    "Cosa ci aspettiamo (left_fist):\n",
    "ERD%_contra (FC6–C6–CP6) < ERD%_ipsi (FC5–C5–CP5) ≤ 0.\n",
    "Se l’effetto è motorio, la differenza contra - ipsi dovrebbe essere < 0 (più desync a destra).\n",
    "\n",
    "\n",
    "\n",
    "Codice pronto da incollare\n",
    "\n",
    "Usa questo “drop-in” sul tuo (X_v2, y) e la tua electrode_grid_map (nessun altro cambiamento necessario). È robusto a etichette mancanti.\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# --- parametri ---\n",
    "BAND_NAMES = ['Delta','Theta','Alpha','Beta','Gamma']\n",
    "ALPHA_IDX = BAND_NAMES.index('Alpha')     # = 2\n",
    "REST_LABEL = 0\n",
    "LEFTFIST_LABEL = 1\n",
    "EPS = 1e-30\n",
    "\n",
    "# ROI per test \"left_fist vs rest\" (controlaterale = emisfero destro)\n",
    "ROI_CONTRA = {'FC6','C6','CP6'}  # destra\n",
    "ROI_IPSI   = {'FC5','C5','CP5'}  # sinistra\n",
    "\n",
    "def compute_erd_map(X_v2, y, band_idx=ALPHA_IDX, task_label=LEFTFIST_LABEL, rest_label=REST_LABEL):\n",
    "    \"\"\"\n",
    "    X_v2: (N, 9, 9, 5) in V^2\n",
    "    y   : (N,) con 0=rest, 1=left_fist (qui)\n",
    "    ritorna: (erd_map, rest_mean, task_mean) per la banda richiesta\n",
    "    \"\"\"\n",
    "    rest = X_v2[y == rest_label, :, :, band_idx]   # (n_r, 9, 9)\n",
    "    task = X_v2[y == task_label, :, :, band_idx]   # (n_t, 9, 9)\n",
    "    if rest.size == 0 or task.size == 0:\n",
    "        raise ValueError(\"Mancano trial per rest o task nella selezione corrente.\")\n",
    "    rest_mean = rest.mean(axis=0)                  # (9, 9)\n",
    "    task_mean = task.mean(axis=0)                  # (9, 9)\n",
    "    erd_map = (task_mean - rest_mean) / (rest_mean + EPS) * 100.0\n",
    "    return erd_map, rest_mean, task_mean\n",
    "\n",
    "def roi_mean_from_map(m2d, roi_set, electrode_grid_map):\n",
    "    \"\"\"\n",
    "    m2d: (9,9) mappa (es. ERD%)\n",
    "    roi_set: set di etichette canali (es. {'FC6','C6','CP6'})\n",
    "    electrode_grid_map: dict {'Cz': (y,x), ...}\n",
    "    \"\"\"\n",
    "    coords = [(lab, electrode_grid_map[lab]) for lab in roi_set if lab in electrode_grid_map]\n",
    "    if not coords:\n",
    "        raise ValueError(f\"Nessun canale della ROI trovato nella mappa: {sorted(list(roi_set))}\")\n",
    "    vals = [m2d[y, x] for _, (y, x) in coords]\n",
    "    # info su eventuali canali mancanti (non blocca)\n",
    "    missing = sorted(list(roi_set - set(lab for lab, _ in coords)))\n",
    "    if missing:\n",
    "        print(f\"[WARN] Canali ROI assenti nella mappa: {missing}\")\n",
    "    return float(np.mean(vals))\n",
    "\n",
    "# ----------------- ESECUZIONE -----------------\n",
    "# supponendo che tu abbia: X_v2, y, electrode_grid_map già in scope\n",
    "erd_alpha, rest_alpha, task_alpha = compute_erd_map(X_v2, y, band_idx=ALPHA_IDX)\n",
    "\n",
    "contra_erd = roi_mean_from_map(erd_alpha, ROI_CONTRA, electrode_grid_map)\n",
    "ipsi_erd   = roi_mean_from_map(erd_alpha, ROI_IPSI,   electrode_grid_map)\n",
    "delta_roi  = contra_erd - ipsi_erd\n",
    "\n",
    "print(f\"ERD% α (left_fist vs rest):\")\n",
    "print(f\"  ROI controlaterale (FC6,C6,CP6): {contra_erd:.2f} %\")\n",
    "print(f\"  ROI ipsilaterale   (FC5,C5,CP5): {ipsi_erd:.2f} %\")\n",
    "print(f\"  Differenza contra - ipsi        : {delta_roi:.2f} %  (atteso < 0)\")\n",
    "\n",
    "# opzionale: verifica che l'ERD occipitale non domini (attenzione/occhi)\n",
    "ROI_OCCIP = {'O1','Oz','O2'}\n",
    "try:\n",
    "    occip_erd = roi_mean_from_map(erd_alpha, ROI_OCCIP, electrode_grid_map)\n",
    "    print(f\"  Controllo occipitale (O1,Oz,O2): {occip_erd:.2f} %  (atteso vicino a 0 per effetto motorio puro)\")\n",
    "except ValueError:\n",
    "    pass\n",
    "\n",
    "\n",
    "\n",
    "Nota: il calcolo è fatto direttamente su V²; il rapporto con la baseline annulla qualsiasi fattore di scala (µV², dB, ecc.), \n",
    "quindi non serve convertire unità prima dell’ERD%.\n",
    "\n",
    "Se vuoi integrarlo nel tuo data_dict, basta infilare le ultime 10 righe dentro il loop dove già stampi shape X=..., usando l’X_v2, y di quel blocco.\n",
    "\n",
    "\n",
    "\n",
    "IO: ok quindi come dovrei integrare questo pezzo di codice qui sopra a quellod del plotting?\n",
    "'''\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "350755b8-a4a7-41c5-b4d3-ea86b55d9f41",
   "metadata": {
    "tags": []
   },
   "source": [
    "'''\n",
    "\n",
    "QUI LA ERD% SAREBBE ANCHE PER CONFRONTO TRA LE DUE MANI, NON CORRETTO (TEORICAMENTE)\n",
    "\n",
    "\n",
    "perfetto — ti lascio una versione “drop-in” che integra il calcolo dell’ERD% in alpha dentro al tuo plot_band_power.\n",
    "Fa tre cose in più:\n",
    "\n",
    "calcola la mappa ERD% alpha su V² (indipendente dalle unità del plotting);\n",
    "\n",
    "stampa le medie ERD% su ROI controlaterale {FC6,C6,CP6} e ipsilaterale {FC5,C5,CP5} + la differenza;\n",
    "\n",
    "aggiunge in fondo alla figura una riga extra con la heatmap ERD% (Alpha), scala simmetrica (negativo = desync).\n",
    "\n",
    "Cosa ci aspettiamo (left_fist vs rest)\n",
    "\n",
    "ROI controlaterale (destra: FC6–C6–CP6) con ERD% più negativa dell’ipsilaterale → contra - ipsi < 0.\n",
    "\n",
    "Occipitale idealmente vicino a 0 (se vuoi puoi aggiungere anche quel check).\n",
    "'''\n",
    "\n",
    "\n",
    "# --- costanti/ROI per l'ERD ---\n",
    "BAND_NAMES = ['Delta','Theta','Alpha','Beta','Gamma']\n",
    "ALPHA_IDX = BAND_NAMES.index('Alpha')     # = 2\n",
    "REST_LABEL = 0\n",
    "LEFTFIST_LABEL = 1\n",
    "EPS = 1e-30\n",
    "\n",
    "# ROI motorie: colonne laterali della \"cintura\" sensori-motoria\n",
    "ROI_CONTRA = {'FC6','C6','CP6'}  # emisfero destro (controlaterale per mano sinistra)\n",
    "ROI_IPSI   = {'FC5','C5','CP5'}  # emisfero sinistro\n",
    "\n",
    "def compute_erd_map(X_v2, y, band_idx=ALPHA_IDX,\n",
    "                    task_label=LEFTFIST_LABEL, rest_label=REST_LABEL):\n",
    "    \"\"\"\n",
    "    X_v2: (N, 9, 9, 5) in V^2; y: (N,)\n",
    "    Ritorna ERD% = (task - rest)/rest*100 per la banda 'band_idx'\n",
    "    + mappe di potenza medie rest/task (in V^2).\n",
    "    \"\"\"\n",
    "    rest = X_v2[y == rest_label, :, :, band_idx]   # (n_r, 9, 9)\n",
    "    task = X_v2[y == task_label, :, :, band_idx]   # (n_t, 9, 9)\n",
    "    if rest.size == 0 or task.size == 0:\n",
    "        raise ValueError(\"Mancano trial per rest o task nella selezione corrente.\")\n",
    "    rest_mean = rest.mean(axis=0)                  # (9, 9)\n",
    "    task_mean = task.mean(axis=0)                  # (9, 9)\n",
    "    erd_map = (task_mean - rest_mean) / (rest_mean + EPS) * 100.0\n",
    "    return erd_map, rest_mean, task_mean\n",
    "\n",
    "def roi_mean_from_map(m2d, roi_set, electrode_grid_map):\n",
    "    \"\"\"\n",
    "    Media della mappa 'm2d' su una ROI definita da etichette canali (es. {'FC6','C6','CP6'}).\n",
    "    \"\"\"\n",
    "    coords = [(lab, electrode_grid_map[lab]) for lab in roi_set if lab in electrode_grid_map]\n",
    "    if not coords:\n",
    "        raise ValueError(f\"Nessun canale della ROI trovato nella mappa: {sorted(list(roi_set))}\")\n",
    "    vals = [m2d[y, x] for _, (y, x) in coords]\n",
    "    missing = sorted(list(roi_set - set(lab for lab, _ in coords)))\n",
    "    if missing:\n",
    "        print(f\"[WARN] Canali ROI assenti nella mappa: {missing}\")\n",
    "    return float(np.mean(vals))\n",
    "\n",
    "\n",
    "\n",
    "#Sostituisci la tua plot_band_power con questa (integra l’ERD in coda alla figura)\n",
    "\n",
    "def plot_band_power(\n",
    "    data_dict,\n",
    "    scale_mode=\"global\",      # \"global\" oppure \"per_band\"\n",
    "    unit_mode=\"uV2\",          # \"uV2\", \"dB\", \"relative\"\n",
    "    use_sem=False,            # True per barre d'errore\n",
    "    cmap=\"viridis\",\n",
    "    relative_pct=True,\n",
    "    show_alpha_erd=True,      # <— NUOVO: aggiunge riga con ERD% Alpha\n",
    "    cmap_erd=\"RdBu_r\"         # colormap divergente per ERD (negativo/positivo)\n",
    "):\n",
    "    for condition in data_dict:                             # es. 'rest_vs_left_fist'\n",
    "        cls_names = split_condition(condition)              # ['rest', 'left_fist']\n",
    "\n",
    "        for dtype in data_dict[condition]:\n",
    "            for gk in data_dict[condition][dtype]:\n",
    "\n",
    "                X_v2, y = data_dict[condition][dtype][gk]   # X_v2:(N,9,9,5) in V²\n",
    "                print(f\"\\n👀  Figura   {condition}  /  {gk}   (shape X={X_v2.shape})\")\n",
    "\n",
    "                # ---------- ERD% Alpha su V^2 (prima di qualsiasi conversione) ----------\n",
    "                erd_alpha, rest_alpha, task_alpha = compute_erd_map(\n",
    "                    X_v2, y, band_idx=ALPHA_IDX,\n",
    "                    task_label=LEFTFIST_LABEL, rest_label=REST_LABEL\n",
    "                )\n",
    "                contra_erd = roi_mean_from_map(erd_alpha, ROI_CONTRA, electrode_grid_map)\n",
    "                ipsi_erd   = roi_mean_from_map(erd_alpha, ROI_IPSI,   electrode_grid_map)\n",
    "                delta_roi  = contra_erd - ipsi_erd\n",
    "                print(f\"ERD% α (left_fist vs rest): \"\n",
    "                      f\"contra={contra_erd:.2f}%  ipsi={ipsi_erd:.2f}%  \"\n",
    "                      f\"Δ(contra-ipsi)={delta_roi:.2f}%  [atteso < 0]\")\n",
    "\n",
    "                # scala simmetrica per la mappa ERD\n",
    "                vmax_erd = float(np.nanmax(np.abs(erd_alpha)))\n",
    "                vmin_erd = -vmax_erd\n",
    "\n",
    "                # ---------- CONVERSIONE UNITÀ per i plot di potenza ----------\n",
    "                X_plot, unit_label = _to_units(X_v2, unit_mode=unit_mode, relative_pct=relative_pct)\n",
    "\n",
    "                # ---------- pre-calcola medie ----------\n",
    "                mean_bar   = []      # (2, 5): media sui trial della media spaziale\n",
    "                sem_bar    = []      # (2, 5): SEM sui trial (se richiesto)\n",
    "                mean_maps  = []      # (2, 9,9,5): media su trial (per heatmap)\n",
    "\n",
    "                for lbl in (0,1):\n",
    "                    mask = (y == lbl)\n",
    "                    if not mask.any():\n",
    "                        mean_bar.append(np.full(5, np.nan))\n",
    "                        if use_sem:\n",
    "                            sem_bar.append(np.full(5, np.nan))\n",
    "                        mean_maps.append(np.full((9,9,5), np.nan))\n",
    "                    else:\n",
    "                        Xlbl = X_plot[mask]                     # (n_lbl, 9,9,5)\n",
    "                        mean_maps.append(Xlbl.mean(axis=0))     # (9,9,5)\n",
    "\n",
    "                        # bar: media per banda dopo media spaziale per trial\n",
    "                        trial_means = Xlbl.mean(axis=(1,2))     # (n_lbl, 5)\n",
    "                        mean_bar.append(trial_means.mean(axis=0))\n",
    "                        if use_sem:\n",
    "                            sem_bar.append(trial_means.std(axis=0, ddof=1) / np.sqrt(trial_means.shape[0]))\n",
    "\n",
    "                # ---------- scale cromatiche ----------\n",
    "                if scale_mode == \"global\":\n",
    "                    both = np.stack([mean_maps[0], mean_maps[1]], axis=0)   # (2,9,9,5)\n",
    "                    vmin_global = np.nanmin(both); vmax_global = np.nanmax(both)\n",
    "                    band_vmin = [vmin_global]*len(band_names)\n",
    "                    band_vmax = [vmax_global]*len(band_names)\n",
    "                else:\n",
    "                    band_vmin, band_vmax = [], []\n",
    "                    for b in range(len(band_names)):\n",
    "                        both_b = np.stack([mean_maps[0][:,:,b], mean_maps[1][:,:,b]], axis=0)  # (2,9,9)\n",
    "                        band_vmin.append(np.nanmin(both_b))\n",
    "                        band_vmax.append(np.nanmax(both_b))\n",
    "                    if unit_mode == \"relative\" and relative_pct:\n",
    "                        band_vmin = [0.0]*len(band_names)\n",
    "                        band_vmax = [100.0]*len(band_names)\n",
    "\n",
    "                # ---------- layout figure ----------\n",
    "                extra_rows = 1 if show_alpha_erd else 0\n",
    "                n_rows, n_cols = 1 + len(band_names) + extra_rows, 2\n",
    "                fig, axs = plt.subplots(n_rows, n_cols, figsize=(10, 20 if show_alpha_erd else 18),\n",
    "                                        constrained_layout=False)\n",
    "                fig.suptitle(f\"{condition}  –  {dtype} / {gk}\", fontsize=12, y=0.97)\n",
    "                fig.subplots_adjust(top=0.94)\n",
    "\n",
    "                # --- riga-0: bar-plot (con o senza SEM) ---\n",
    "                if use_sem:\n",
    "                    ymax = np.nanmax(np.vstack([\n",
    "                        (mean_bar[0] + sem_bar[0]),\n",
    "                        (mean_bar[1] + sem_bar[1])\n",
    "                    ]))\n",
    "                else:\n",
    "                    ymax = np.nanmax(np.vstack([mean_bar[0], mean_bar[1]]))\n",
    "                ymax = (ymax * 1.05) if np.isfinite(ymax) else 1.0\n",
    "\n",
    "                for col, lbl in enumerate((0,1)):\n",
    "                    ax = axs[0, col]\n",
    "                    if use_sem:\n",
    "                        ax.bar(band_names, mean_bar[lbl], yerr=sem_bar[lbl], capsize=3)\n",
    "                    else:\n",
    "                        ax.bar(band_names, mean_bar[lbl])\n",
    "                    ax.set_title(f\"{cls_names[lbl]}  (label {lbl})\")\n",
    "                    ax.set_ylabel(f\"Mean power [{unit_label}]\")\n",
    "                    ax.set_ylim(0, ymax)\n",
    "                    if col == 1:\n",
    "                        ax.set_ylabel(\"\")\n",
    "\n",
    "                # --- righe 1-5: heat-map per banda ---\n",
    "                for r, band in enumerate(band_names, start=1):\n",
    "                    for col, lbl in enumerate((0,1)):\n",
    "                        ax = axs[r, col]\n",
    "                        im = ax.imshow(\n",
    "                            mean_maps[lbl][:,:,r-1],\n",
    "                            cmap=cmap, origin='upper', aspect='equal',\n",
    "                            vmin=band_vmin[r-1], vmax=band_vmax[r-1]\n",
    "                        )\n",
    "                        for lab,(yy,xx) in electrode_grid_map.items():\n",
    "                            ax.text(xx, yy, lab, ha='center', va='center',\n",
    "                                    fontsize=5.5, color='black', weight='bold')\n",
    "                        ax.set_xticks([]); ax.set_yticks([])\n",
    "                        if col == 0:\n",
    "                            ax.set_ylabel(band, rotation=90, labelpad=6,\n",
    "                                          fontsize=9, weight='bold')\n",
    "                    cbar = fig.colorbar(im, ax=axs[r, 1], fraction=0.046, pad=0.04)\n",
    "                    cbar.set_label(unit_label)\n",
    "\n",
    "                # --- riga finale opzionale: ERD% Alpha ---\n",
    "                if show_alpha_erd:\n",
    "                    r = 1 + len(band_names)\n",
    "                    for col in (0, 1):\n",
    "                        ax = axs[r, col]\n",
    "                        im_erd = ax.imshow(\n",
    "                            erd_alpha, cmap=cmap_erd, origin='upper', aspect='equal',\n",
    "                            vmin=vmin_erd, vmax=vmax_erd\n",
    "                        )\n",
    "                        for lab,(yy,xx) in electrode_grid_map.items():\n",
    "                            ax.text(xx, yy, lab, ha='center', va='center',\n",
    "                                    fontsize=5.5, color='black', weight='bold')\n",
    "                        ax.set_xticks([]); ax.set_yticks([])\n",
    "                    # titoli / colorbar ERD\n",
    "                    axs[r, 0].set_ylabel(\"Alpha ERD% (task−rest)/rest\", rotation=90,\n",
    "                                         labelpad=6, fontsize=9, weight='bold')\n",
    "                    axs[r, 1].set_title(f\"ROI: contra={contra_erd:.1f}%  ipsi={ipsi_erd:.1f}%  Δ={delta_roi:.1f}% (atteso<0)\")\n",
    "                    cbar = fig.colorbar(im_erd, ax=axs[r, 1], fraction=0.046, pad=0.04)\n",
    "                    cbar.set_label(\"ERD% (Alpha)\")\n",
    "\n",
    "                plt.show()\n",
    "                plt.close(fig)\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "raw",
   "id": "f7baf646-7157-4f3c-86f4-13ac1269d4b7",
   "metadata": {
    "tags": []
   },
   "source": [
    "plot_band_power(data_dict, \n",
    "                scale_mode=\"per_band\", \n",
    "                unit_mode=\"uV2\",\n",
    "                use_sem=False,\n",
    "                relative_pct=True,\n",
    "                show_alpha_erd=True,      # <— NUOVO: aggiunge riga con ERD% Alpha\n",
    "                cmap_erd=\"RdBu_r\")         # colormap divergente per ERD (negativo/positivo)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee6fec2-194b-493c-a22c-536e17ae72d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Sotto trovi il patch pronto-incolla che fa esattamente tre cose:\n",
    "\n",
    "capisce in automatico quale mano è il task (dalla coppia di classi nella condizione);\n",
    "\n",
    "inverte le ROI (controlaterale/ipsilaterale) in base alla mano;\n",
    "\n",
    "salta l’ERD quando la condizione non contiene rest (es. left_fist_vs_right_fist).\n",
    "\n",
    "\n",
    "Con queste tre modifiche:\n",
    "\n",
    "rest_vs_left_fist → ROI controlaterale = destra;\n",
    "\n",
    "rest_vs_right_fist → ROI controlaterale = sinistra;\n",
    "\n",
    "left_fist_vs_right_fist → nessuna riga ERD (niente baseline), oppure Lateralization Index!\n",
    "\n",
    "1) posso mettere un parametro aggiuntivo 'lateralization_index' come booleno per cui: \n",
    "\n",
    "se è false allora mantiene ERD disabilitata per confronto 'mano vs mano', \n",
    "mentre se è true allora mi mostra il lateralization index normalizzato di cui mi hai accennato\n",
    "\n",
    "\n",
    "il valore Δ è sempre “contra − ipsi” e ci aspettiamo Δ < 0 quando la lateralizzazione è corretta.\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "# ============================================================\n",
    "# Plot potenza per banda + ERD% Alpha con ROI auto-invertite\n",
    "# ============================================================\n",
    "\n",
    "import pickle, numpy as np, matplotlib.pyplot as plt\n",
    "\n",
    "# ---------- mappa elettrodo → (y,x) ----------\n",
    "with open('/home/stefano/EEGMMIDB_Analyses/electrode_grid_map.pkl', 'rb') as f:\n",
    "    electrode_grid_map = pickle.load(f)  # {'Fz':(0,4), 'Cz':(4,4), ...}\n",
    "\n",
    "# ---------- bande ----------\n",
    "BAND_NAMES = ['Delta', 'Theta', 'Alpha', 'Beta', 'Gamma']\n",
    "band_names = BAND_NAMES[:]  # alias usato nei plot\n",
    "ALPHA_IDX = BAND_NAMES.index('Alpha')     # = 2\n",
    "\n",
    "# ---------- utility ----------\n",
    "def split_condition(cond_str):\n",
    "    \"\"\"'rest_vs_left_fist' -> ['rest','left_fist'].\"\"\"\n",
    "    return cond_str.split(\"_vs_\", 1) if \"_vs_\" in cond_str else [f\"{cond_str}_0\", f\"{cond_str}_1\"]\n",
    "\n",
    "def _to_units(X_v2, unit_mode=\"uV2\", relative_pct=True, eps=1e-30):\n",
    "    \"\"\"\n",
    "    X_v2: array (N, 9, 9, 5) in V² (potenza per banda).\n",
    "    Ritorna (X_plot, unit_label).\n",
    "    \"\"\"\n",
    "    if unit_mode == \"uV2\":\n",
    "        return X_v2 * 1e12, \"µV²\"\n",
    "    \n",
    "    elif unit_mode == \"dB\":\n",
    "        return 10 * np.log10(np.maximum(X_v2 * 1e12, eps)), \"dB (re: 1 µV²)\"\n",
    "    \n",
    "    elif unit_mode == \"relative\":\n",
    "        # per trial & elettrodo: normalizza per somma sulle 5 bande\n",
    "        denom = np.sum(X_v2, axis=-1, keepdims=True)  # (N,9,9,1) in V²\n",
    "        frac = np.divide(X_v2, np.maximum(denom, eps), where=denom>0)  # 0..1\n",
    "        return (frac * 100.0, \"%\") if relative_pct else (frac, \"rel\")\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(\"unit_mode deve essere 'uV2', 'dB' o 'relative'.\")\n",
    "\n",
    "# ---------- costanti ERD ----------\n",
    "EPS = 1e-30\n",
    "\n",
    "\n",
    "#1) Aggiungere il “lateralization_index” (anche per mano vs mano)\n",
    "\n",
    "#Di seguito ti passo patch minimali da copiare nel tuo file.\n",
    "#A) metti queste funzioni helper vicino a compute_erd_map:\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "1) Cosa significano “LI_power α (left/right)” e la riga ERD?\n",
    "\n",
    "ERD% α – ROI contra/ipsi, Δ\n",
    "Misura la desincronizzazione in alpha/mu (8–12 Hz) del task rispetto a rest:\n",
    "\n",
    "ERD % = (task − rest/rest) × 100\n",
    "\n",
    "\n",
    "più negativa ⇒ maggiore desincronizzazione (effetto motorio).\n",
    "• Δ = contra − ipsi: atteso < 0 nel movimento (controlateralità).\n",
    "\n",
    "LI_power α (left/right)\n",
    "Quando non c’è rest (mano vs mano) mostriamo l’indice di lateralizzazione su potenza:\n",
    "\n",
    "\n",
    "LI= (Pow contra + Pow ipsi)/ (Pow contra − Pow ipsi)\n",
    "\n",
    "→ range [−1,1]\n",
    "\n",
    "• LI > 0: la potenza alpha è maggiore nell’emisfero controlaterale (per quella mano).\n",
    "• LI < 0: maggiore nell’ipsilaterale.\n",
    "\n",
    "È utile per mano vs mano; con il rest conviene usare l’ERD (più interpretabile fisiologicamente).\n",
    "\n",
    "\n",
    "Posso farne un plot?\n",
    "\n",
    "Sì. Sotto trovi una patch che:\n",
    "\n",
    "in mano vs mano disegna una barra/marker orizzontale su [−1,1] con il valore LI_power α per left e right;\n",
    "mantiene la mappa ERD% quando è presente rest.\n",
    "\n",
    "\n",
    "\n",
    "2) Letteratura su “lateralization index” (EEG mu/alpha)\n",
    "\n",
    "Sì, l’indice di lateralizzazione è usato sia su potenza (contra vs ipsi) sia su ERD:\n",
    "\n",
    "Forme su potenza (tipico α somatosensoriale/attenzione): molti lavori calcolano contra − ipsi o \n",
    "(contra−ipsi)/(contra+ipsi) per la banda α --> ad esempio vedi \n",
    "\n",
    "Haegens et al., J Neurosci 2011 (α-lateralization index definito su canali selezionati) \n",
    "https://www.jneurosci.org/content/31/14/5197?utm_source=chatgpt.com\n",
    "\n",
    "Bacigalupo & Luck 2019 (lateralized α = contra − ipsi). \n",
    "https://pmc.ncbi.nlm.nih.gov/articles/PMC6382983/?utm_source=chatgpt.com\n",
    "\n",
    "\n",
    "\n",
    "Forme su ERD (mu/β motorie): nelle SMR motorie è comune calcolare l’ERD controlaterale e confrontarla con l’ipsilaterale; \n",
    "alcuni studi e applicazioni di neurofeedback definiscono un LI basato su ERD\n",
    "\n",
    "(es. LI= (ERD contra − ERD ipsi) /(∣ERD contra∣ + ∣ERD ipsi∣). \n",
    "\n",
    "Vedi Hayashi et al., NeuroImage 2020 (formula esplicita del LI), insieme alla letteratura classica di Pfurtschellera su ERD/ERS e dominanza controlaterale. \n",
    "\n",
    "https://www.sciencedirect.com/science/article/pii/S1053811920307849?utm_source=chatgpt.com\n",
    "https://doc.ml.tu-berlin.de/bbci/teaching/PfuSil99.pdf?utm_source=chatgpt.com\n",
    "https://pubmed.ncbi.nlm.nih.gov/11322970/\n",
    "\n",
    "\n",
    "Evidenza di dominanza controlaterale in mu-ERD durante esecuzione/MI: review e case-studies storici (Pfurtscheller et al.) \n",
    "e lavori più recenti confermano il pattern atteso. \n",
    "\n",
    "\n",
    "https://doc.ml.tu-berlin.de/bbci/teaching/PfuSil99.pdf?utm_source=chatgpt.com\n",
    "https://pmc.ncbi.nlm.nih.gov/articles/PMC6261430/?utm_source=chatgpt.com\n",
    "https://pub.ista.ac.at/~schloegl/publications/pfurtscheller2006.pdf?utm_source=chatgpt.com\n",
    "\n",
    "\n",
    "\n",
    "In breve: il tuo LI normalizzato è sensato; su “mano vs mano” puoi usare la versione su potenza, mentre su “mano vs rest” preferisci la versione su ERD.\n",
    "\n",
    "\n",
    "Forse non conviene estendere ad altri elettrodi per estendere la ROI su anche\n",
    "\n",
    "FC3, FC1,C5,C3,C1 e CP3 e CP1 per lato sinistro e \n",
    "FC2, FC4,C6,C2,C4 e CP4 e CP2 per lato destro?\n",
    "\n",
    "\n",
    "2) ROI “wide motor strip”\n",
    "\n",
    "Aggiungo un parametro roi_variant:\n",
    "\n",
    "\"narrow\" (attuale: {FC6,C6,CP6} vs {FC5,C5,CP5})\n",
    "\n",
    "\"wide\" (estesa come richiesto):\n",
    "\n",
    "sinistra: {FC5,FC3,FC1, C5,C3,C1, CP5,CP3,CP1}\n",
    "\n",
    "destra: {FC6,FC4,FC2, C6,C4,C2, CP6,CP4,CP2}\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "#Aggiunge:\n",
    "\n",
    "#import per gli inset\n",
    "#funzioni per bootstrap CI e permutation test\n",
    "#calcolo trial-wise per ERD e LI\n",
    "#rendering degli inset con barre/CI e p-value\n",
    "\n",
    "\n",
    "'''\n",
    "Qui sotto c’è una patch diff minimale che:\n",
    "\n",
    "allarga la figura quando c’è la riga ERD/LI;\n",
    "\n",
    "invece di sovrapporre l’inset lo mette a destra della mappa ERD con make_axes_locatable;\n",
    "\n",
    "sposta anche la colorbar ancora più a destra, così non si schiaccia nulla\n",
    "\n",
    "'''\n",
    "\n",
    "import pickle, numpy as np, matplotlib.pyplot as plt\n",
    "\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "#from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "\n",
    "\n",
    "# ---------- statistiche & CI (no SciPy) ----------\n",
    "def _bootstrap_ci_mean(x, n_boot=5000, alpha=0.05, rng=None):\n",
    "    x = np.asarray(x, float)\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng()\n",
    "    idx = rng.integers(0, len(x), size=(n_boot, len(x)))\n",
    "    m = x[idx].mean(axis=1)\n",
    "    lo, hi = np.percentile(m, [100*alpha/2, 100*(1-alpha/2)])\n",
    "    return lo, hi\n",
    "\n",
    "\n",
    "def _perm_test_signed(d, n_perm=10000, rng=None):\n",
    "    \"\"\"\n",
    "    Test a 0 media per differenze appaiate: d = contra - ipsi (per trial).\n",
    "    Ritorna p-value a due code.\n",
    "    \"\"\"\n",
    "    d = np.asarray(d, float)\n",
    "    obs = np.mean(d)\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng()\n",
    "    signs = rng.choice([-1.0, 1.0], size=(n_perm, len(d)))\n",
    "    perm_means = (signs * d).mean(axis=1)\n",
    "    p = (np.sum(np.abs(perm_means) >= np.abs(obs)) + 1) / (n_perm + 1)\n",
    "    return float(p), obs\n",
    "\n",
    "def _perm_test_onesample(x, n_perm=10000, rng=None):\n",
    "    \"\"\"\n",
    "    One-sample vs 0 (per LI): flip di segno. Ritorna p-value a due code.\n",
    "    \"\"\"\n",
    "    x = np.asarray(x, float)\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng()\n",
    "    obs = np.mean(x)\n",
    "    signs = rng.choice([-1.0, 1.0], size=(n_perm, len(x)))\n",
    "    perm_means = (signs * x).mean(axis=1)\n",
    "    p = (np.sum(np.abs(perm_means) >= np.abs(obs)) + 1) / (n_perm + 1)\n",
    "    return float(p), obs\n",
    "\n",
    "def _roi_mean_trial(m2d, roi_set, electrode_grid_map):\n",
    "    coords = [electrode_grid_map[lab] for lab in roi_set if lab in electrode_grid_map]\n",
    "    return float(np.mean([m2d[y, x] for (y, x) in coords]))\n",
    "\n",
    "\n",
    "\n",
    "def compute_erd_trials(X_v2, y, band_idx, task_label, rest_label, roi_contra, roi_ipsi):\n",
    "    \"\"\"\n",
    "    ERD% per trial di TASK rispetto alla media REST, poi media ROI -> due vettori trial-wise.\n",
    "    \"\"\"\n",
    "    rest_mean = X_v2[y==rest_label, :, :, band_idx].mean(axis=0)  # (9,9)\n",
    "    task_trials = X_v2[y==task_label, :, :, band_idx]             # (T,9,9)\n",
    "    erd_trials_maps = (task_trials - rest_mean) / (rest_mean + EPS) * 100.0\n",
    "    contra = [ _roi_mean_trial(m, roi_contra, electrode_grid_map) for m in erd_trials_maps ]\n",
    "    ipsi   = [ _roi_mean_trial(m, roi_ipsi,   electrode_grid_map) for m in erd_trials_maps ]\n",
    "    return np.array(contra), np.array(ipsi)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def compute_li_erd(erd_map, roi_contra, roi_ipsi, eps=EPS):\n",
    "    ec = roi_mean_from_map(erd_map, roi_contra, electrode_grid_map)\n",
    "    ei = roi_mean_from_map(erd_map, roi_ipsi,   electrode_grid_map)\n",
    "    li = (ec - ei) / (abs(ec) + abs(ei) + eps)   # LI normalizzato su ERD\n",
    "    return li, ec, ei\n",
    "\n",
    "def compute_li_power(power_map, roi_contra, roi_ipsi, eps=EPS):\n",
    "    pc = roi_mean_from_map(power_map, roi_contra, electrode_grid_map)\n",
    "    pi = roi_mean_from_map(power_map, roi_ipsi,   electrode_grid_map)\n",
    "    li = (pc - pi) / (pc + pi + eps)             # LI normalizzato su potenza\n",
    "    return li, pc, pi\n",
    "\n",
    "\n",
    "def compute_erd_map(X_v2, y, band_idx=ALPHA_IDX, task_label=None, rest_label=None):\n",
    "    \"\"\"\n",
    "    Calcola ERD% = (task - rest) / rest * 100 per la banda richiesta.\n",
    "    X_v2: (N, 9, 9, 5) in V^2; y: (N,)\n",
    "    Ritorna: (erd_map, rest_mean, task_mean) con shape (9,9) per mappa.\n",
    "    \"\"\"\n",
    "    if task_label is None or rest_label is None:\n",
    "        raise ValueError(\"task_label e rest_label devono essere forniti.\")\n",
    "    rest = X_v2[y == rest_label, :, :, band_idx]   # (n_r, 9, 9)\n",
    "    task = X_v2[y == task_label, :, :, band_idx]   # (n_t, 9, 9)\n",
    "    if rest.size == 0 or task.size == 0:\n",
    "        raise ValueError(\"Mancano trial per rest o task nella selezione corrente.\")\n",
    "    rest_mean = rest.mean(axis=0)                  # (9, 9)\n",
    "    task_mean = task.mean(axis=0)                  # (9, 9)\n",
    "    erd_map = (task_mean - rest_mean) / (rest_mean + EPS) * 100.0\n",
    "    return erd_map, rest_mean, task_mean\n",
    "\n",
    "def roi_mean_from_map(m2d, roi_set, electrode_grid_map):\n",
    "    \"\"\"\n",
    "    Media della mappa 'm2d' su una ROI definita da etichette canali (es. {'FC6','C6','CP6'}).\n",
    "    \"\"\"\n",
    "    coords = [(lab, electrode_grid_map[lab]) for lab in roi_set if lab in electrode_grid_map]\n",
    "    if not coords:\n",
    "        raise ValueError(f\"Nessun canale della ROI trovato nella mappa: {sorted(list(roi_set))}\")\n",
    "    vals = [m2d[y, x] for _, (y, x) in coords]\n",
    "    missing = sorted(list(roi_set - set(lab for lab, _ in coords)))\n",
    "    if missing:\n",
    "        print(f\"[WARN] Canali ROI assenti nella mappa: {missing}\")\n",
    "    return float(np.mean(vals))\n",
    "\n",
    "def _label_of(y_label_names, target):\n",
    "    \"\"\"Ricava l'id (0/1) dato il nome classe; y_label_names: {0:'rest',1:'left_fist'}.\"\"\"\n",
    "    for k, v in y_label_names.items():\n",
    "        if v == target:\n",
    "            return k\n",
    "    return None\n",
    "\n",
    "# ---------- funzione principale ----------\n",
    "def plot_band_power(\n",
    "    data_dict,\n",
    "    scale_mode=\"global\",\n",
    "    unit_mode=\"uV2\",\n",
    "    use_sem=False,\n",
    "    cmap=\"viridis\",\n",
    "    relative_pct=True,\n",
    "    show_alpha_erd=True,\n",
    "    cmap_erd=\"RdBu_r\",\n",
    "    lateralization_index=False,\n",
    "    roi_variant=\"narrow\",\n",
    "    erd_stats_layout=\"side\"   # \"side\" | \"center\"\n",
    "):\n",
    "    for condition in data_dict:\n",
    "        cls_names = split_condition(condition)\n",
    "\n",
    "        for dtype in data_dict[condition]:\n",
    "            for gk in data_dict[condition][dtype]:\n",
    "\n",
    "                X_v2, y = data_dict[condition][dtype][gk]\n",
    "                print(f\"\\n👀  Figura   {condition}  /  {gk}   (shape X={X_v2.shape})\")\n",
    "\n",
    "                # ---------- ERD% Alpha (solo se c'è 'rest' + una mano) ----------\n",
    "                y_label_names = {0: cls_names[0], 1: cls_names[1]}\n",
    "                has_rest = ('rest' in cls_names)\n",
    "                erd_alpha = None\n",
    "                roi_title = \"\"\n",
    "\n",
    "                li_power_left = None\n",
    "                li_power_right = None\n",
    "\n",
    "                erd_contra_trials = erd_ipsi_trials = None\n",
    "                p_erd = None\n",
    "                ci_contra = ci_ipsi = None\n",
    "                li_left_trials = li_right_trials = None\n",
    "                p_li_left = p_li_right = None\n",
    "\n",
    "                if has_rest:\n",
    "                    if 'left_fist' in cls_names:\n",
    "                        hand = 'left_fist'\n",
    "                        task_label = _label_of(y_label_names, 'left_fist')\n",
    "                        rest_label = _label_of(y_label_names, 'rest')\n",
    "                        if roi_variant == \"wide\":\n",
    "                            ROI_contra = {'FC6','FC4','FC2','C6','C4','C2','CP6','CP4','CP2'}\n",
    "                            ROI_ipsi   = {'FC5','FC3','FC1','C5','C3','C1','CP5','CP3','CP1'}\n",
    "                        else:\n",
    "                            ROI_contra = {'FC6','C6','CP6'}\n",
    "                            ROI_ipsi   = {'FC5','C5','CP5'}\n",
    "                    elif 'right_fist' in cls_names:\n",
    "                        hand = 'right_fist'\n",
    "                        task_label = _label_of(y_label_names, 'right_fist')\n",
    "                        rest_label = _label_of(y_label_names, 'rest')\n",
    "                        if roi_variant == \"wide\":\n",
    "                            ROI_contra = {'FC5','FC3','FC1','C5','C3','C1','CP5','CP3','CP1'}\n",
    "                            ROI_ipsi   = {'FC6','FC4','FC2','C6','C4','C2','CP6','CP4','CP2'}\n",
    "                        else:\n",
    "                            ROI_contra = {'FC5','C5','CP5'}\n",
    "                            ROI_ipsi   = {'FC6','C6','CP6'}\n",
    "                    else:\n",
    "                        hand = None\n",
    "                        task_label = None\n",
    "                        rest_label = _label_of(y_label_names, 'rest')\n",
    "\n",
    "                    if hand is not None and task_label is not None:\n",
    "                        erd_alpha, rest_alpha, task_alpha = compute_erd_map(\n",
    "                            X_v2, y, band_idx=ALPHA_IDX, task_label=task_label, rest_label=rest_label\n",
    "                        )\n",
    "                        erd_contra_trials, erd_ipsi_trials = compute_erd_trials(\n",
    "                            X_v2, y, ALPHA_IDX, task_label, rest_label, ROI_contra, ROI_ipsi\n",
    "                        )\n",
    "                        ci_contra = _bootstrap_ci_mean(erd_contra_trials)\n",
    "                        ci_ipsi   = _bootstrap_ci_mean(erd_ipsi_trials)\n",
    "                        p_erd, _  = _perm_test_signed(erd_contra_trials - erd_ipsi_trials)\n",
    "\n",
    "                        contra_erd = roi_mean_from_map(erd_alpha, ROI_contra, electrode_grid_map)\n",
    "                        ipsi_erd   = roi_mean_from_map(erd_alpha, ROI_ipsi,   electrode_grid_map)\n",
    "                        delta_roi  = contra_erd - ipsi_erd\n",
    "\n",
    "                        print(f\"ERD% α ({hand} vs rest): contra={contra_erd:.2f}%  ipsi={ipsi_erd:.2f}%  \"\n",
    "                              f\"Δ={delta_roi:.2f}%  [atteso Δ<0]  p_paired={p_erd:.4f}\")\n",
    "\n",
    "                        vmax_erd = float(np.nanmax(np.abs(erd_alpha)))\n",
    "                        vmin_erd = -vmax_erd\n",
    "                        roi_title = (f\"ROI: contra={contra_erd:.1f}%  ipsi={ipsi_erd:.1f}%  \"\n",
    "                                     f\"Δ={delta_roi:.1f}% (atteso<0)\")\n",
    "                else:\n",
    "                    print(\"ERD% α non mostrata: condizione senza 'rest'.\")\n",
    "                    if lateralization_index and ('left_fist' in cls_names) and ('right_fist' in cls_names):\n",
    "                        lbl_left  = 0 if y_label_names[0]=='left_fist'  else 1\n",
    "                        lbl_right = 0 if y_label_names[0]=='right_fist' else 1\n",
    "                        ROI_R = {'FC6','FC4','FC2','C6','C4','C2','CP6','CP4','CP2'} if roi_variant==\"wide\" else {'FC6','C6','CP6'}\n",
    "                        ROI_L = {'FC5','FC3','FC1','C5','C3','C1','CP5','CP3','CP1'} if roi_variant==\"wide\" else {'FC5','C5','CP5'}\n",
    "                        left_trials  = X_v2[y==lbl_left , :, :, ALPHA_IDX]\n",
    "                        right_trials = X_v2[y==lbl_right, :, :, ALPHA_IDX]\n",
    "                        li_left_trials = []\n",
    "                        for m in left_trials:\n",
    "                            pc = _roi_mean_trial(m, ROI_R, electrode_grid_map)\n",
    "                            pi = _roi_mean_trial(m, ROI_L, electrode_grid_map)\n",
    "                            li_left_trials.append( (pc - pi) / (pc + pi + EPS) )\n",
    "                        li_right_trials = []\n",
    "                        for m in right_trials:\n",
    "                            pc = _roi_mean_trial(m, ROI_L, electrode_grid_map)\n",
    "                            pi = _roi_mean_trial(m, ROI_R, electrode_grid_map)\n",
    "                            li_right_trials.append( (pc - pi) / (pc + pi + EPS) )\n",
    "                        li_left_trials  = np.asarray(li_left_trials)\n",
    "                        li_right_trials = np.asarray(li_right_trials)\n",
    "                        li_power_left  = float(np.mean(li_left_trials))\n",
    "                        li_power_right = float(np.mean(li_right_trials))\n",
    "                        p_li_left,  _ = _perm_test_onesample(li_left_trials)\n",
    "                        p_li_right, _ = _perm_test_onesample(li_right_trials)\n",
    "                        print(f\"LI_power α: left={li_power_left:+.2f} (p={p_li_left:.4f})  \"\n",
    "                              f\"right={li_power_right:+.2f} (p={p_li_right:.4f})\")\n",
    "\n",
    "                # ---------- CONVERSIONE UNITÀ ----------\n",
    "                X_plot, unit_label = _to_units(X_v2, unit_mode=unit_mode, relative_pct=relative_pct)\n",
    "\n",
    "                # ---------- pre-calcola medie ----------\n",
    "                mean_bar, sem_bar, mean_maps = [], [], []\n",
    "                for lbl in (0,1):\n",
    "                    mask = (y == lbl)\n",
    "                    if not mask.any():\n",
    "                        mean_bar.append(np.full(5, np.nan))\n",
    "                        if use_sem: sem_bar.append(np.full(5, np.nan))\n",
    "                        mean_maps.append(np.full((9,9,5), np.nan))\n",
    "                    else:\n",
    "                        Xlbl = X_plot[mask]\n",
    "                        mean_maps.append(Xlbl.mean(axis=0))\n",
    "                        trial_means = Xlbl.mean(axis=(1,2))\n",
    "                        mean_bar.append(trial_means.mean(axis=0))\n",
    "                        if use_sem:\n",
    "                            sem_bar.append(trial_means.std(axis=0, ddof=1) / np.sqrt(trial_means.shape[0]))\n",
    "\n",
    "                # ---------- scale cromatiche ----------\n",
    "                if scale_mode == \"global\":\n",
    "                    both = np.stack([mean_maps[0], mean_maps[1]], axis=0)\n",
    "                    vmin_global = np.nanmin(both); vmax_global = np.nanmax(both)\n",
    "                    band_vmin = [vmin_global]*len(band_names)\n",
    "                    band_vmax = [vmax_global]*len(band_names)\n",
    "                else:\n",
    "                    band_vmin, band_vmax = [], []\n",
    "                    for b in range(len(band_names)):\n",
    "                        both_b = np.stack([mean_maps[0][:,:,b], mean_maps[1][:,:,b]], axis=0)\n",
    "                        band_vmin.append(np.nanmin(both_b))\n",
    "                        band_vmax.append(np.nanmax(both_b))\n",
    "                    if unit_mode == \"relative\" and relative_pct:\n",
    "                        band_vmin = [0.0]*len(band_names)\n",
    "                        band_vmax = [100.0]*len(band_names)\n",
    "\n",
    "                # ---------- layout figure ----------\n",
    "                extra_rows = 1 if ((show_alpha_erd and (erd_alpha is not None)) \\\n",
    "                                   or (lateralization_index and (li_power_left is not None))) else 0\n",
    "\n",
    "                n_rows, n_cols = 1 + len(band_names) + extra_rows, 2\n",
    "                fig_w = 16 if extra_rows else 10\n",
    "                fig, axs = plt.subplots(n_rows, n_cols, figsize=(fig_w, 20 if extra_rows else 18),\n",
    "                                        constrained_layout=False)\n",
    "\n",
    "                fig.suptitle(f\"{condition}  –  {dtype} / {gk}\", fontsize=12, y=0.97)\n",
    "                # quando il pannello ERD è a destra, lasciamo più aria sul bordo destro\n",
    "                if extra_rows and erd_stats_layout == \"side\":\n",
    "                    fig.subplots_adjust(top=0.94, right=0.72)\n",
    "                else:\n",
    "                    fig.subplots_adjust(top=0.94, right=0.94)\n",
    "\n",
    "                # --- riga-0: bar-plot ---\n",
    "                if use_sem:\n",
    "                    ymax = np.nanmax(np.vstack([(mean_bar[0] + sem_bar[0]), (mean_bar[1] + sem_bar[1])]))\n",
    "                else:\n",
    "                    ymax = np.nanmax(np.vstack([mean_bar[0], mean_bar[1]]))\n",
    "                ymax = (ymax * 1.05) if np.isfinite(ymax) else 1.0\n",
    "\n",
    "                for col, lbl in enumerate((0,1)):\n",
    "                    ax = axs[0, col]\n",
    "                    if use_sem:\n",
    "                        ax.bar(band_names, mean_bar[lbl], yerr=sem_bar[lbl], capsize=3)\n",
    "                    else:\n",
    "                        ax.bar(band_names, mean_bar[lbl])\n",
    "                    ax.set_title(f\"{cls_names[lbl]}  (label {lbl})\")\n",
    "                    ax.set_ylabel(f\"Mean power [{unit_label}]\")\n",
    "                    ax.set_ylim(0, ymax)\n",
    "                    if col == 1:\n",
    "                        ax.set_ylabel(\"\")\n",
    "\n",
    "                # --- righe 1-5: heat-map per banda ---\n",
    "                for r, band in enumerate(band_names, start=1):\n",
    "                    for col, lbl in enumerate((0,1)):\n",
    "                        ax = axs[r, col]\n",
    "                        im = ax.imshow(\n",
    "                            mean_maps[lbl][:,:,r-1],\n",
    "                            cmap=cmap, origin='upper', aspect='equal',\n",
    "                            vmin=band_vmin[r-1], vmax=band_vmax[r-1]\n",
    "                        )\n",
    "                        for lab,(yy,xx) in electrode_grid_map.items():\n",
    "                            ax.text(xx, yy, lab, ha='center', va='center',\n",
    "                                    fontsize=5.5, color='black', weight='bold')\n",
    "                        ax.set_xticks([]); ax.set_yticks([])\n",
    "                        if col == 0:\n",
    "                            ax.set_ylabel(band, rotation=90, labelpad=6, fontsize=9, weight='bold')\n",
    "                    # colorbar UNA per banda (sottile)\n",
    "                    cbar = fig.colorbar(im, ax=axs[r, 1], fraction=0.030, pad=0.018)\n",
    "                    cbar.set_label(unit_label)\n",
    "\n",
    "                # --- riga finale opzionale: ERD% Alpha ---\n",
    "                if show_alpha_erd and (erd_alpha is not None):\n",
    "                    r = 1 + len(band_names)\n",
    "                    for col in (0, 1):\n",
    "                        ax = axs[r, col]\n",
    "                        im_erd = ax.imshow(\n",
    "                            erd_alpha, cmap=cmap_erd, origin='upper', aspect='equal',\n",
    "                            vmin=vmin_erd, vmax=vmax_erd\n",
    "                        )\n",
    "                        for lab,(yy,xx) in electrode_grid_map.items():\n",
    "                            ax.text(xx, yy, lab, ha='center', va='center',\n",
    "                                    fontsize=5.5, color='black', weight='bold')\n",
    "                        ax.set_xticks([]); ax.set_yticks([])\n",
    "\n",
    "                    # etichetta sinistra\n",
    "                    axs[r, 0].set_ylabel(\"Alpha ERD% (task−rest)/rest\", rotation=90,\n",
    "                                         labelpad=6, fontsize=9, weight='bold')\n",
    "\n",
    "                    # titolo centrato leggermente più basso\n",
    "                    fig.canvas.draw()\n",
    "                    bboxL = axs[r, 0].get_position()\n",
    "                    bboxR = axs[r, 1].get_position()\n",
    "                    x_center = 0.5 * (bboxL.x0 + bboxR.x1)\n",
    "                    y_top    = max(bboxL.y1, bboxR.y1) + 0.008\n",
    "                    fig.text(x_center, y_top, roi_title, ha='center', va='bottom',\n",
    "                             fontsize=12, weight='bold')\n",
    "\n",
    "                    # pannello statistico SOLO qui (ERD Alpha)\n",
    "                    y0     = bboxR.y0\n",
    "                    h      = bboxR.height\n",
    "                    means  = [np.mean(erd_contra_trials), np.mean(erd_ipsi_trials)]\n",
    "                    ci_con = ci_contra; ci_ips = ci_ipsi\n",
    "                    cis    = np.array([[means[0]-ci_con[0], ci_con[1]-means[0]],\n",
    "                                       [means[1]-ci_ips[0],  ci_ips[1]-means[1]]])\n",
    "\n",
    "                    if erd_stats_layout == \"side\":\n",
    "                        # ancoriamo la colorbar al bordo destro della figura (più a destra di così non si può)\n",
    "                        right_edge = 0.010   # margine dal bordo destro della figura\n",
    "                        gap        = 0.012   # spazio tra bar e colorbar\n",
    "                        cb_w       = 0.022   # colorbar sottile ma leggibile\n",
    "                        # bar_w occupa il resto utile ma tenuto sottile\n",
    "                        bar_w_max  = 0.12\n",
    "                        bar_w_min  = 0.06\n",
    "                        # calcoliamo una larghezza che non sfori\n",
    "                        avail_for_bar = 1.0 - right_edge - cb_w - gap - (bboxR.x1 + gap)\n",
    "                        bar_w = max(bar_w_min, min(bar_w_max, avail_for_bar))\n",
    "                        # posizioni: cb tutto a destra, bar subito a sinistra\n",
    "                        x_cb  = 1.0 - right_edge - cb_w\n",
    "                        x_bar = x_cb - gap - bar_w\n",
    "                        ax_bar = fig.add_axes([x_bar, y0 + 0.12*h, bar_w, 0.76*h])\n",
    "                        ax_cb  = fig.add_axes([x_cb,  y0 + 0.06*h, cb_w,  0.88*h])\n",
    "                        cbar   = fig.colorbar(im_erd, cax=ax_cb)\n",
    "                        cbar.set_label(\"ERD% (Alpha)\")\n",
    "                        ax_bar.bar([0,1], means, yerr=cis.T, capsize=3)\n",
    "                        ax_bar.set_xticks([0,1]); ax_bar.set_xticklabels(['contra','ipsi'])\n",
    "                        ax_bar.set_ylabel('ERD% α')\n",
    "                        ax_bar.set_title(f\"paired p={p_erd:.3f}\", fontsize=9)\n",
    "\n",
    "                    else:\n",
    "                        # pannello in mezzo (sempre e solo in ultima riga)\n",
    "                        gap   = max(0.02, bboxR.x0 - bboxL.x1)\n",
    "                        mid_w = gap * 0.68\n",
    "                        x_mid = bboxL.x1 + (gap - mid_w)/2\n",
    "                        ax_mid = fig.add_axes([x_mid, y0 + 0.10*h, mid_w, 0.80*h])\n",
    "                        ax_mid.bar([0,1], means, yerr=cis.T, capsize=3)\n",
    "                        ax_mid.set_xticks([0,1]); ax_mid.set_xticklabels(['contra','ipsi'])\n",
    "                        ax_mid.set_ylabel('ERD% α')\n",
    "                        ax_mid.set_title(f\"paired p={p_erd:.3f}\", fontsize=9)\n",
    "                        cax = inset_axes(ax_mid, width=\"8%\", height=\"78%\", loc=\"center right\", borderpad=1.0)\n",
    "                        cbar = fig.colorbar(im_erd, cax=cax)\n",
    "                        cbar.set_label(\"ERD% (Alpha)\")\n",
    "\n",
    "                elif lateralization_index and (li_power_left is not None):\n",
    "                    r = 1 + len(band_names)\n",
    "                    axL, axR = axs[r, 0], axs[r, 1]\n",
    "                    axL.axis('off'); axR.axis('off')\n",
    "                    axL.text(0.5, 0.55, f\"LI_power α (left)  = {li_power_left:+.2f}\",\n",
    "                             ha='center', va='center', fontsize=11, weight='bold')\n",
    "                    axR.text(0.5, 0.55, f\"LI_power α (right) = {li_power_right:+.2f}\",\n",
    "                             ha='center', va='center', fontsize=11, weight='bold')\n",
    "\n",
    "                plt.show()\n",
    "                plt.close(fig)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c78c0c-7244-4568-9e82-1e7ff657ffd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "La riga ERD% Alpha apparirà per le condizioni con rest (p.es. rest_vs_left_fist, rest_vs_right_fist),\n",
    "con ROI auto-invertite in base alla mano. Per condizioni “mano vs mano” non verrà mostrata.\n",
    "\n",
    "\n",
    "Con condizioni rest_vs_left_fist / rest_vs_right_fist → vedrai la mappa ERD% α e, nel titolo della colonna destra, anche i valori ROI (come già fai).\n",
    "\n",
    "Con left_fist_vs_right_fist (senza rest) → niente ERD; in fondo comparirà la riga con LI_power α (left/right).\n",
    "\n",
    "\n",
    "# ---------- funzione principale ----------\n",
    "def plot_band_power(\n",
    "    data_dict,\n",
    "    scale_mode=\"global\",      # \"global\" oppure \"per_band\"\n",
    "    unit_mode=\"uV2\",          # \"uV2\", \"dB\", \"relative\"\n",
    "    use_sem=False,            # True per barre d'errore\n",
    "    cmap=\"viridis\",\n",
    "    relative_pct=True,\n",
    "    show_alpha_erd=True,      # aggiunge riga con ERD% Alpha se presente 'rest'\n",
    "    cmap_erd=\"RdBu_r\",         # colormap divergente per ERD (negativo/positivo)\n",
    "    lateralization_index=False,\n",
    "    roi_variant=\"narrow\"      # \"narrow\" | \"wide\"\n",
    "):\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "plot_band_power(\n",
    "    data_dict,\n",
    "    scale_mode=\"per_band\",\n",
    "    unit_mode=\"uV2\",\n",
    "    use_sem=False,\n",
    "    relative_pct=True,\n",
    "    show_alpha_erd=True,\n",
    "    cmap_erd=\"RdBu_r\",\n",
    "    lateralization_index=False,   # abilita LI\n",
    "    roi_variant=\"narrow\",\n",
    "    erd_stats_layout = \"center\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042e06d7-bf51-4d18-a13c-418ceede87b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93958732-dbe0-4938-a8c8-04b573b638cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict['rest_vs_left_fist'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee385eb-f7a5-4971-8f54-ea6da9e5eef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict['rest_vs_left_fist']['spectrograms'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d93af7-0d1e-4eb3-b865-67d34c0226d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_dict['rest_vs_left_fist']['spectrograms']['familiar_th'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778d0ee8-3749-426a-8912-dff4be6793af",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict['rest_vs_left_fist']['spectrograms']['familiar_th'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cb555d-6dd3-476b-9997-810bbe3d330c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict['rest_vs_left_fist']['spectrograms']['familiar_th'][1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de68738-c1b7-4180-83ab-ea3f6a25f4de",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### **Sweep Configuration - EEG Spectrograms - Electrodes x Frequencies ONLY HYPER-PARAMS**\n",
    "\n",
    "\n",
    "#### **Sweep separati per ciascuno dei modelli CNN3D e CNN Sep**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2bb70a-8ffa-40c8-9486-a1cb97657938",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "N.B. \n",
    "\n",
    "PER SAPERE A QUALE COMBINAZIONE DI FATTORI CORRISPONDONO I DATI (i.e, X_train, X_val, X_test, y_train, y_val, y_test)\n",
    "\n",
    "MI CREO UN DIZIONARIO ULTERIORE, 'DATA_DICT_PREPROCESSED' CHE CONTIENE PER OGNI COMBINAZIONE DI FATTORI I DATI SPLITTATI\n",
    "\n",
    "IN QUESTO MODO, QUANDO FORNISCO ALLA FUNZIONE 'TRAINING_SWEEP' LA TUPLA CON I VARI DATI ((TRAIN, VAL E TEST))\n",
    "IO POSSO CAPIRE A QUALE COMBINAZIONI DI FATTORI CORRISPONDE QUELLA TUPLA DI DATI (TRAIN, VAL E TEST)\n",
    "\n",
    "\n",
    "INOLTRE,\n",
    "MI CREO ANCHE UNA LISTA DI TUPLE DI STRINGHE, DOVE OGNI TUPLA CONTIENE LE STRINGHE DELLE CHIAVI USATE \n",
    "PER LA GENERAZIONE DI DATA_DICT_PREPROCESSED.\n",
    "\n",
    "IN QUESTO MODO, MI ASSICURO CHE SIA UNA COERENZA TRA LA CREAZIONE DEI 'NAME' E 'TAG' DELLA RUN\n",
    "E\n",
    "LA CORRETTA ESTRAZIONE DEI DATI (OSSIA I DATI DI QUALE CONDIZIONE SPERIMENTALE, QUALI EEG INPUT, E DA CHI PROVENGONO!)  \n",
    "\n",
    "\n",
    "Questo approccio permette di garantire la corrispondenza tra \n",
    "\n",
    "1) le chiavi dei dati pre‐processati e \n",
    "2) la configurazione delle runs su W&B\n",
    "\n",
    "andando a creare due strutture in parallelo:\n",
    "\n",
    "- data_dict_preprocessed – che contiene, per ogni combinazione (condition, data_type, category_subject), \n",
    "                            la tupla dei dati già suddivisi (X_train, X_val, X_test, y_train, y_val, y_test);\n",
    "                            \n",
    "- sweeps_id – che contiene, per ogni combinazione (condition, data_type, category_subject), \n",
    "              sia la stringa univoca dello sweep ID, che l'insieme delle stringhe che formano la combinazione (condition, data_type, category_subject)\n",
    "\n",
    "\n",
    "\n",
    "LOOP DI PREPARAZIONE DATI (FINO A DATASET SPLITTING)\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#A QUESTO PUNTO PER OGNI DATASET, FACCIO STEP PRIMA DELLO SWEEP\n",
    "\n",
    "# Set per tenere traccia dei dataset già elaborati\n",
    "processed_datasets = set()\n",
    "\n",
    "# Seleziona il dispositivo (GPU o CPU)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "# Modelli che useremo nei sweep\n",
    "MODEL_LIST = [\"CNN3D_LSTM_FC\", \"SeparableCNN2D_LSTM_FC\"]\n",
    "\n",
    "\n",
    "# Dizionario per salvare gli sweep ID associati a ogni condizione sperimentale\n",
    "\n",
    "'''sweep_ids_for_models contiene la struttura che mi serve da copiare per best_models''' \n",
    "sweep_ids_for_models = {}\n",
    "\n",
    "'''sweep_ids contiene la struttura che mi serve da copiare per iterare sui singoli swweps di ogni combinazione di fattori'''\n",
    "sweep_ids = {}  \n",
    "\n",
    "'''DIZIONARIO CHE VIENE FORNITO IN INGRESSO A TRAINING_SWEEP'''\n",
    "# Dizionario per salvare la tupla di dati già preprocessati\n",
    "data_dict_preprocessed = {}\n",
    "\n",
    "\n",
    "# Loop di addestramento e test per ogni condizione sperimentale\n",
    "for condition, data_types in data_dict.items():  # Itera sulle condizioni sperimentali\n",
    "    \n",
    "    data_dict_preprocessed[condition] = {}\n",
    "    \n",
    "    # Aggiungi al dizionario sweep_ids\n",
    "    if condition not in sweep_ids:\n",
    "        sweep_ids[condition] = {}\n",
    "        \n",
    "        '''sweep_ids_for_models'''\n",
    "        sweep_ids_for_models[condition] = {}\n",
    "        \n",
    "    for data_type, categories in data_types.items():  # Itera sui tipi di dati (1_20, 1_45, wavelet)\n",
    "        \n",
    "        data_dict_preprocessed[condition][data_type] = {}\n",
    "        \n",
    "        if data_type not in sweep_ids[condition]:\n",
    "            sweep_ids[condition][data_type] = {}\n",
    "            \n",
    "            '''sweep_ids_for_models'''\n",
    "            sweep_ids_for_models[condition][data_type] = {}\n",
    "            \n",
    "        for category_subject, (X_data, y_data) in categories.items():  # Itera sulle coppie category_subject\n",
    "            \n",
    "            # 1. Prepara spazio nei dizionari: sotto category_subject, un dict per ogni modello\n",
    "            \n",
    "            data_dict_preprocessed[condition][data_type][category_subject] = None\n",
    "            \n",
    "            if category_subject not in sweep_ids[condition][data_type]:\n",
    "                \n",
    "                sweep_ids[condition][data_type][category_subject] = {}\n",
    "                \n",
    "                '''NUOVA MODIFICA'''\n",
    "                sweep_ids[condition][data_type][category_subject] = {\n",
    "                model: [] for model in MODEL_LIST\n",
    "                }\n",
    "\n",
    "                '''sweep_ids_for_models'''\n",
    "                sweep_ids_for_models[condition][data_type][category_subject] = {}\n",
    "                \n",
    "                '''NUOVA MODIFICA'''\n",
    "                sweep_ids_for_models[condition][data_type][category_subject] = {\n",
    "                model: [] for model in MODEL_LIST\n",
    "                }\n",
    "                \n",
    "            print(f\"\\n\\n\\033[1mEstrazione Dati\\033[0m della Chiave \\033[1m{condition}_{data_type}_{category_subject}\\033[0m\")\n",
    "            \n",
    "            # Controlla se il dataset è già stato elaborato (se la chiave è già nel set)\n",
    "            if (condition, data_type, category_subject) in processed_datasets:\n",
    "                print(f\"⚠️ ATTENZIONE: Il dataset {condition} - {data_type} - {category_subject} è già stato elaborato! Salto iterazione...\")\n",
    "                continue  # Salta se il dataset è già stato processato\n",
    "\n",
    "            # Aggiungi il dataset al set\n",
    "            processed_datasets.add((condition, data_type, category_subject))\n",
    "\n",
    "            X_train, X_val, X_test, y_train, y_val, y_test = split_data(X_data, y_data)\n",
    "            \n",
    "            data_dict_preprocessed[condition][data_type][category_subject] = (X_train, X_val, X_test, y_train, y_val, y_test)\n",
    "            \n",
    "            # Puoi anche aggiungere altri print per verificare la dimensione dei set\n",
    "            print(f\"\\033[1mDataset Splitting\\033[0m: Train Set Shape: {X_train.shape}, Validation Set Shape: {X_val.shape}, Test Set Shape: {X_test.shape}\")\n",
    "\n",
    "            \n",
    "print(f\"\\nCreato \\033[1mdata_dict_preprocessed\\033[0m\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61941516-644e-4626-b2ff-06bff06c896f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict['rest_vs_left_fist'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b598c4bd-d131-46f1-8473-27aaee0d5f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_dict_preprocessed.keys())\n",
    "print(data_dict_preprocessed['rest_vs_left_fist'].keys())\n",
    "print(data_dict_preprocessed['rest_vs_left_fist']['spectrograms'].keys())\n",
    "print(type(data_dict_preprocessed['rest_vs_left_fist']['spectrograms'].keys()))\n",
    "\n",
    "#All'interno, c'è una tupla, di 6 elementi!\n",
    "print(type(data_dict_preprocessed['rest_vs_left_fist']['spectrograms']['familiar_th']))\n",
    "\n",
    "#I 6 elementi della tupla sono X_train, X_val, X_test, y_train, y_val, y_test !\n",
    "print(len(data_dict_preprocessed['rest_vs_left_fist']['spectrograms']['familiar_th']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1d8a36-704e-4d87-800d-7b3e23287357",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sweep_ids_for_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63eb001-bee0-499a-ab36-646f43dfa950",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sweep_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b78c4a4-9f6c-4233-bc3c-41f24889f273",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sweep_ids_for_models)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "21c4502d-f4a6-4b4f-b4fc-727974c18fa2",
   "metadata": {
    "tags": []
   },
   "source": [
    "#Tutti gli sweep saranno organizzati sotto lo stesso progetto,\n",
    "#che corrisponde alla coppia di condizioni sperimentali corrente (i.e., exp_cond).\n",
    "\n",
    "#Questo significa che tutte le runs che verranno lanciate con quello sweep, \n",
    "#saranno associate a quella specifica coppia di condizioni sperimentali corrente.\n",
    "\n",
    "#Dato che sto iterando su ogni coppia di condizioni sperimentali, \n",
    "#ogni sweep verrà automaticamente salvato all'interno del progetto corrispondente \n",
    "#della specifica condizione sperimentale (exp_cond).\n",
    "\n",
    "#In pratica, se hai più condizioni sperimentali \n",
    "#(ad esempio, \"Condizione_A\", \"Condizione_B\", ecc.),\n",
    "#WandB creerà automaticamente sweep separati all'interno dei rispettivi progetti\n",
    "\n",
    "\n",
    "#Creo la configurazione dello sweep e la eseguo\n",
    "sweep_config = {\n",
    "    \"method\": \"random\",\n",
    "    \"metric\": {\"name\": \"val_accuracy\", \"goal\": \"maximize\"},\n",
    "    \"parameters\": {\n",
    "        \n",
    "        #\"lr\": {\"values\": [0.01, 0.001, 0.0005, 0.0001]},\n",
    "        \n",
    "        \"lr\": {\"values\": [1e-3]}, # fissato al valore di default del paper\n",
    "        \n",
    "        #\"weight_decay\": {\"values\": [0, 0.01, 0.001, 0.0001]},\n",
    "        \n",
    "        \"n_epochs\": {\"value\": 100},\n",
    "        \"patience\": {\"value\": 12},\n",
    "        \n",
    "        #\"model_name\":{\"values\": ['CNN2D', 'BiLSTM', 'Transformer']},\n",
    "        \n",
    "        #\"model_name\":{\"values\": ['CNN2D_LSTM_FC', 'BiLSTM', 'Transformer']},\n",
    "        \"model_name\":{\"values\": ['CNN2D_LSTM_FC']},\n",
    "        \n",
    "        #\"batch_size\": {\"values\": [32, 48, 64, 96]},\n",
    "        #\"batch_size\": {\"values\": [32, 48, 64, 72, 84, 96]},\n",
    "        #\"batch_size\": {\"values\": [32, 48, 64, 72, 84]},\n",
    "        \n",
    "        \"batch_size\": {\"values\": [32, 48, 64, 72, 84, 96]},\n",
    "        #\"batch_size\": {\"values\": [16, 24, 32, 48, 64]},\n",
    "        \"standardization\":{\"values\": [True, False]},\n",
    "        \n",
    "        \"beta1\": {\"value\": 0.9},\n",
    "        \"beta2\": {\"value\": 0.999},\n",
    "        \"eps\": {\"value\": 1e-8},\n",
    "        \n",
    "    }\n",
    "}\n",
    "    \n",
    "'''SWEEP_IDS_FOR_MODELS'''\n",
    "\n",
    "#Preparazione del dizionario sweep_ids_for_models (lo aggiorno inserendo il livello delle chiavi dei modelli, per copiare poi la struttura per creare best_models)\n",
    "\n",
    "for condition in sweep_ids_for_models:\n",
    "    for data_type in sweep_ids_for_models[condition]:\n",
    "        for category_subject in sweep_ids_for_models[condition][data_type]:\n",
    "            for model_name in sweep_config[\"parameters\"][\"model_name\"][\"values\"]:\n",
    "                \n",
    "                # Aggiungi il modello al dizionario, se non esiste già\n",
    "                if model_name not in sweep_ids_for_models[condition][data_type][category_subject]:\n",
    "                    sweep_ids_for_models[condition][data_type][category_subject][model_name] = []\n",
    "\n",
    "                    \n",
    "print(f\"\\nAggiornato \\033[1msweep_ids_for_models\\033[0m\")\n",
    "\n",
    "\n",
    "#Preparazione del dizionario best_models (facendo una copia della struttura di 'sweep_ids_for_models')\n",
    "\n",
    "#In questo modo potrò, per ogni condizione sperimentale, tipo di dato EEG e combinazione di ruolo/gruppo,\n",
    "#accedere facilmente al miglior modello (cioè ai suoi pesi e bias) e gestirlo in maniera separata!\n",
    "\n",
    "import copy\n",
    "best_models = copy.deepcopy(sweep_ids_for_models)\n",
    "\n",
    "# Inizializzo il dizionario che contiene il migliori modello tra quelli degli sweep testati, \n",
    "# relativi ad una certa combinazione di fattori,\n",
    "#per ogni condizione sperimentale\n",
    "#tipo di dato EEG \n",
    "#combinazione di ruolo/gruppo\n",
    "\n",
    "for condition in best_models:\n",
    "    for data_type in best_models[condition]:\n",
    "        for category_subject in best_models[condition][data_type]:\n",
    "            for model_name in best_models[condition][data_type][category_subject]:\n",
    "                best_models[condition][data_type][category_subject][model_name] = {\n",
    "                    \"model\": None,\n",
    "                    \"max_val_acc\": -float('inf'),\n",
    "                    \"best_epoch\": None,\n",
    "                    \n",
    "                    #ATTENZIONE! CREATA ALTRA CHIAVE PER SALVARE \n",
    "                    #LA MIGLIORE CONFIGURAZIONE DI IPER-PARAMETRI DI OGNI MODELLO!\n",
    "                    \"config\": None}\n",
    "                \n",
    "print(f\"\\nCreato \\033[1mbest_models\\033[0m\")\n",
    "\n",
    "\n",
    "'''SWEEP_IDS'''\n",
    "\n",
    "#Preparazione del dizionario sweep_ids (lo aggiorno inserendo solo una lista all'ultimo livello)\n",
    "\n",
    "# Itera su sweep_ids e crea le chiavi per category_subject con liste vuote\n",
    "for condition in sweep_ids:\n",
    "    for data_type in sweep_ids[condition]:\n",
    "        for category_subject in sweep_ids[condition][data_type]:\n",
    "            # Inizializza una lista vuota se non esiste già\n",
    "            if not isinstance(sweep_ids[condition][data_type][category_subject], list):\n",
    "                sweep_ids[condition][data_type][category_subject] = []\n",
    "                    \n",
    "print(f\"\\nAggiornato \\033[1msweep_ids\\033[0m\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af31b0a5-08ef-4551-9acd-da1030b91d96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "''' \n",
    "\n",
    "                                                                    AGGIORNATA AL 19 LUGLIO\n",
    "                                                                    \n",
    "                                                                    \n",
    "#\"learning rate : {\"value\"[1e-5, 5e-5, 1e-4, 5e-4, 1e-3, 5e-3, 1e-2]\"}\n",
    "#\"n_epochs\": {\"value\": 100},\n",
    "# \"patience\": {\"value\": 12},\n",
    "#\"batch_size\": {\"values\": [16, 24, 32, 48, 64, 72, 84, 96]}\n",
    "#\"standardization\": {\"values\": [True, False]}, \n",
    "# \"beta1\": {\"values\": [0.8, 0.85, 0.9, 0.95]},\n",
    "#  \"beta2\": {\"values\": [0.98, 0.99, 0.995, 0.999]},\n",
    "#  \"eps\": {\"value\": [1e-8, 1e-7, 1e-6, 1e-5]}                                                                                                                            \n",
    "\n",
    "\n",
    "\n",
    "sweep_config = {\n",
    "    \"method\": \"random\",\n",
    "    \"metric\": {\"name\": \"val_accuracy\", \"goal\": \"maximize\"},\n",
    "    \"parameters\": {\n",
    "        \n",
    "        \"lr\": {\"values\": [1e-5, 5e-5, 1e-4, 5e-4, 1e-3, 5e-3, 1e-2]}, # fissato al valore di default del paper\n",
    "\n",
    "        \"weight_decay\":  {\"values\": [0, 1e-4, 1e-3, 1e-2, 1e-1]},\n",
    "        \n",
    "        \"n_epochs\": {\"value\": 100},\n",
    "        \"patience\": {\"value\": 12},\n",
    "        \n",
    "        \n",
    "        \"model_name\":{\"values\": ['CNN3D_LSTM_FC']},\n",
    "\n",
    "        \"batch_size\": {\"values\": [32, 48, 64, 96]},\n",
    "\n",
    "        \"standardization\":{\"values\": [True, False]},\n",
    "\n",
    "        \"beta1\": {\"values\": [0.9, 0.95]},\n",
    "\n",
    "        \"beta2\": {\"values\": [0.99, 0.995]},\n",
    "        \n",
    "        \"eps\": {\"values\": [1e-8, 1e-7]},\n",
    "        \n",
    "        #In questo modo:\n",
    "        \n",
    "        \"use_lstm\":      {\"values\":[True, False]},\n",
    "        \"lstm_hidden\":   {\"values\":[32]},\n",
    "        \"dropout\":       {\"values\":[0.5]},\n",
    "        \n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "#Tutti gli sweep saranno organizzati sotto lo stesso progetto,\n",
    "#che corrisponde alla coppia di condizioni sperimentali corrente (i.e., exp_cond).\n",
    "\n",
    "#Questo significa che tutte le runs che verranno lanciate con quello sweep, \n",
    "#saranno associate a quella specifica coppia di condizioni sperimentali corrente.\n",
    "\n",
    "#Dato che sto iterando su ogni coppia di condizioni sperimentali, \n",
    "#ogni sweep verrà automaticamente salvato all'interno del progetto corrispondente \n",
    "#della specifica condizione sperimentale (exp_cond).\n",
    "\n",
    "#In pratica, se hai più condizioni sperimentali \n",
    "#(ad esempio, \"Condizione_A\", \"Condizione_B\", ecc.),\n",
    "#WandB creerà automaticamente sweep separati all'interno dei rispettivi progetti\n",
    "\n",
    "\n",
    "#Creo la configurazione dello sweep e la eseguo:\n",
    "\n",
    "#uno per il modello CNN3D_LSTM_FC, uno oer \n",
    "\n",
    "\n",
    "# 2.1 – Sweep config per ciascun modello\n",
    "sweep_config_cnn3d = {\n",
    "    \"method\": \"random\",\n",
    "    \"metric\": {\"name\": \"val_accuracy\", \"goal\": \"maximize\"},\n",
    "    \"parameters\": {\n",
    "        \"lr\": {\"values\": [1e-5, 5e-5, 1e-4, 5e-4, 1e-3, 5e-3, 1e-2]},\n",
    "        \"weight_decay\": {\"values\": [0, 1e-4, 1e-3, 1e-2, 1e-1]},\n",
    "        \"n_epochs\": {\"value\": 100},\n",
    "        \"patience\": {\"value\": 12},\n",
    "        \"model_name\": {\"values\": [\"CNN3D_LSTM_FC\"]},\n",
    "        \"batch_size\": {\"values\": [32, 48, 64, 96]},\n",
    "        \n",
    "        \"standardization\": {\"values\": [True]}, #        '''ATTENZIONE QUI IMPOSTIAMO SEMPRE A TRUE'''\n",
    "        \n",
    "        \"beta1\": {\"values\": [0.9, 0.95]},\n",
    "        \"beta2\": {\"values\": [0.99, 0.995]},\n",
    "        \"eps\": {\"values\": [1e-8, 1e-7]},\n",
    "        \"use_lstm\": {\"values\": [True, False]},\n",
    "        \"lstm_hidden\": {\"values\": [32]},\n",
    "        \"dropout\": {\"values\": [0.5]},\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "sweep_config_cnn_sep = {\n",
    "    \"method\": \"random\",\n",
    "    \"metric\": {\"name\": \"val_accuracy\", \"goal\": \"maximize\"},\n",
    "    \"parameters\": {\n",
    "        \"lr\": {\"values\": [1e-5, 5e-5, 1e-4, 5e-4, 1e-3, 5e-3, 1e-2]},\n",
    "        \"weight_decay\": {\"values\": [0, 1e-4, 1e-3, 1e-2, 1e-1]},\n",
    "        \"n_epochs\": {\"value\": 100},\n",
    "        \"patience\": {\"value\": 12},\n",
    "        \"model_name\": {\"values\": [\"SeparableCNN2D_LSTM_FC\"]},\n",
    "        \"batch_size\": {\"values\": [32, 48, 64, 96]},\n",
    "        \n",
    "        \"standardization\": {\"values\": [True]}, #        '''ATTENZIONE QUI IMPOSTIAMO SEMPRE A TRUE'''\n",
    "        \n",
    "        \"beta1\": {\"values\": [0.9, 0.95]},\n",
    "        \"beta2\": {\"values\": [0.99, 0.995]},\n",
    "        \"eps\": {\"values\": [1e-8, 1e-7]},\n",
    "        \"use_lstm\": {\"values\": [True, False]},\n",
    "        \"lstm_hidden\": {\"values\": [32]},\n",
    "        \"dropout\": {\"values\": [0.5]},\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "'''SWEEP_IDS_FOR_MODELS\n",
    "\n",
    "# 2) Popolo sweep_ids_for_models in base a MODEL_LIST (già inizializzato nella prima cella)\n",
    "'''\n",
    "\n",
    "#Preparazione del dizionario sweep_ids_for_models (lo aggiorno inserendo il livello delle chiavi dei modelli, per copiare poi la struttura per creare best_models)\n",
    "\n",
    "#for condition in sweep_ids_for_models:\n",
    "    #for data_type in sweep_ids_for_models[condition]:\n",
    "        #for category_subject in sweep_ids_for_models[condition][data_type]:\n",
    "            #for model_name in sweep_config[\"parameters\"][\"model_name\"][\"values\"]:\n",
    "                \n",
    "                # Aggiungi il modello al dizionario, se non esiste già\n",
    "                #if model_name not in sweep_ids_for_models[condition][data_type][category_subject]:\n",
    "                    #sweep_ids_for_models[condition][data_type][category_subject][model_name] = []\n",
    "\n",
    "                    \n",
    "print(f\"\\nAggiornato \\033[1msweep_ids_for_models\\033[0m\")\n",
    "\n",
    "\n",
    "'''BEST_MODELS\n",
    "\n",
    "# 3) Creo best_models da sweep_ids_for_models\n",
    "'''\n",
    "\n",
    "#Preparazione del dizionario best_models (facendo una copia della struttura di 'sweep_ids_for_models')\n",
    "\n",
    "#In questo modo potrò, per ogni condizione sperimentale, tipo di dato EEG e combinazione di ruolo/gruppo,\n",
    "#accedere facilmente al miglior modello (cioè ai suoi pesi e bias) e gestirlo in maniera separata!\n",
    "\n",
    "import copy\n",
    "best_models = copy.deepcopy(sweep_ids_for_models)\n",
    "\n",
    "# Inizializzo il dizionario che contiene il migliori modello tra quelli degli sweep testati, \n",
    "# relativi ad una certa combinazione di fattori,\n",
    "#per ogni condizione sperimentale\n",
    "#tipo di dato EEG \n",
    "#combinazione di ruolo/gruppo\n",
    "\n",
    "for condition in best_models:\n",
    "    for data_type in best_models[condition]:\n",
    "        for category_subject in best_models[condition][data_type]:\n",
    "            for model_name in best_models[condition][data_type][category_subject]:\n",
    "                best_models[condition][data_type][category_subject][model_name] = {\n",
    "                    \"model\": None,\n",
    "                    \"max_val_acc\": -float('inf'),\n",
    "                    \"best_epoch\": None,\n",
    "                    \n",
    "                    #ATTENZIONE! CREATA ALTRA CHIAVE PER SALVARE \n",
    "                    #LA MIGLIORE CONFIGURAZIONE DI IPER-PARAMETRI DI OGNI MODELLO!\n",
    "                    \"config\": None}\n",
    "                \n",
    "print(f\"\\nCreato \\033[1mbest_models\\033[0m\")\n",
    "\n",
    "\n",
    "#'''SWEEP_IDS'''\n",
    "\n",
    "#Preparazione del dizionario sweep_ids (lo aggiorno inserendo solo una lista all'ultimo livello)\n",
    "\n",
    "# Itera su sweep_ids e crea le chiavi per category_subject con liste vuote\n",
    "#for condition in sweep_ids:\n",
    "    #for data_type in sweep_ids[condition]:\n",
    "        #for category_subject in sweep_ids[condition][data_type]:\n",
    "            # Inizializza una lista vuota se non esiste già\n",
    "            #if not isinstance(sweep_ids[condition][data_type][category_subject], list):\n",
    "                #sweep_ids[condition][data_type][category_subject] = []\n",
    "                    \n",
    "#print(f\"\\nAggiornato \\033[1msweep_ids\\033[0m\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d52315-66ca-400a-ad31-c522a62b4032",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#print(best_models)\n",
    "#print(sweep_ids_for_models)\n",
    "#print(sweep_ids)\n",
    "#print(data_dict_preprocessed['th_resp_vs_pt_resp']['1_20']['familiar_th'][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e04c8d2-4d59-4442-abeb-f59793e8e761",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e59eba-fb2a-4842-813a-26926d9a2428",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sweep_ids_for_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba131d3-ec40-4cde-9637-b6c085acdc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sweep_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4df920b-a160-4be3-ae16-590ac617ba6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_dict_preprocessed['th_resp_vs_pt_resp']['1_20']['familiar_th'][5].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709802b9-f8a0-4bec-9700-cfd5a4ab7f3c",
   "metadata": {
    "tags": []
   },
   "source": [
    "**NOTA BENE**\n",
    "\n",
    "Come output, io otterrò **quando crei gli sweeps** una cosa come questa, ad esempio:\n",
    "\n",
    "        Create sweep with ID: y73iajvw\n",
    "        Sweep URL: https://wandb.ai/stefano-bargione-universit-di-roma-tor-vergata/th_resp_vs_pt_resp/sweeps/y73iajvw\n",
    "        Sweep ID creato per th_resp_vs_pt_resp - 1_20 - familiar_th - CNN1D: n° sweep y73iajvw\n",
    "        Create sweep with ID: 3b6o28jt\n",
    "        Sweep URL: https://wandb.ai/stefano-bargione-universit-di-roma-tor-vergata/th_resp_vs_pt_resp/sweeps/3b6o28jt\n",
    "        Sweep ID creato per th_resp_vs_pt_resp - 1_20 - familiar_th - BiLSTM: n° sweep 3b6o28jt\n",
    "        Create sweep with ID: q6yp4fas\n",
    "\n",
    "        .....\n",
    "\n",
    "Vedendole bene, per **ogni condizione sperimentale (3)**, **per ogni dato EEG (3)** e **per ogni provenienza del dato EEG (4)**, \n",
    "Io **DOVREI OTTENERE** in totale = **3x3x4 = 36 sweeps** per **OGNI CONDIZIONE SPERIMENTALE**\n",
    "\n",
    "\n",
    "Per **ognuna di queste sweeps**, io se ho capito bene creerò **15 esperimenti** (le mie runs), che corrispondo alle **diverse configurazioni di iper-parametri testati per lo stesso specifico sweep**!\n",
    "\n",
    "(ad esempio, solo questo \n",
    "\n",
    "<br> \n",
    "\n",
    "        Create sweep with ID: y73iajvw\n",
    "        Sweep URL: https://wandb.ai/stefano-bargione-universit-di-roma-tor-vergata/th_resp_vs_pt_resp/sweeps/y73iajvw\n",
    "        Sweep ID creato per th_resp_vs_pt_resp - 1_20 - familiar_th - CNN1D: n° sweep y73iajvw)\n",
    "\n",
    "Dove, le diverse configurazioni, son determinate randomicamente a partire dai valori dentro la variabile \"**sweep_config**\"  che è questa \n",
    "\n",
    "\n",
    "    #Creo la configurazione dello sweep e la eseguo\n",
    "    sweep_config = {\n",
    "        \"method\": \"random\",\n",
    "        \"metric\": {\"name\": \"val_accuracy\", \"goal\": \"maximize\"},\n",
    "        \"parameters\": {\n",
    "            \"lr\": {\"values\": [0.01, 0.001, 0.0005, 0.0001]},\n",
    "            \"weight_decay\": {\"values\": [0, 0.01, 0.001, 0.0001]},\n",
    "            \"n_epochs\": {\"value\": 100},\n",
    "            \"patience\": {\"value\": 10},\n",
    "            \"model_name\":{\"values\": ['CNN1D', 'BiLSTM', 'Transformer']},\n",
    "            \"batch_size\": {\"values\": [32, 48, 64, 96]},\n",
    "            \"standardization\":{\"values\": [True, False]},\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ac6576-e71e-487c-b1a8-15234b7b2c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "ATTENZIONE CHE A QUESTO PUNTO\n",
    "\n",
    "\n",
    "1) sweep_ids[cond][dtype][cat][model_name] contiene le tuple (sweep_id, combo_key) per ciascun modello, che ancora non esistono perché devo esser create durante la creazione degli sweeps, ma ho solo una lista\n",
    "\n",
    "{'rest_vs_left_fist': {'spectrograms': {'familiar_th': []}}, \n",
    "'rest_vs_right_fist': {'spectrograms': {'familiar_th': []}}, \n",
    "'left_fist_vs_right_fist': {'spectrograms': {'familiar_th': []}}}\n",
    "\n",
    "\n",
    "2) sweep_ids_for_models e best_models sono paralleli a sweep_ids con lo stesso livello model_name\n",
    "\n",
    "ossia \n",
    "\n",
    "sweep_ids_for_models come\n",
    "\n",
    "{'rest_vs_left_fist': {'spectrograms': {'familiar_th': {'CNN3D_LSTM_FC': [], 'SeparableCNN2D_LSTM_FC': []}}},\n",
    "'rest_vs_right_fist': {'spectrograms': {'familiar_th': {'CNN3D_LSTM_FC': [], 'SeparableCNN2D_LSTM_FC': []}}},\n",
    "'left_fist_vs_right_fist': {'spectrograms': {'familiar_th': {'CNN3D_LSTM_FC': [], 'SeparableCNN2D_LSTM_FC': []}}}}\n",
    "\n",
    "best_models come\n",
    "\n",
    "{'rest_vs_left_fist': {'spectrograms': {'familiar_th': \n",
    "{'CNN3D_LSTM_FC': {'model': None, 'max_val_acc': -inf, 'best_epoch': None, 'config': None}, \n",
    "'SeparableCNN2D_LSTM_FC': {'model': None, 'max_val_acc': -inf, 'best_epoch': None, 'config': None}}}},\n",
    "\n",
    "'rest_vs_right_fist': {'spectrograms': {'familiar_th': \n",
    "{'CNN3D_LSTM_FC': {'model': None, 'max_val_acc': -inf, 'best_epoch': None, 'config': None}, \n",
    "'SeparableCNN2D_LSTM_FC': {'model': None, 'max_val_acc': -inf, 'best_epoch': None, 'config': None}}}}, \n",
    "\n",
    "'left_fist_vs_right_fist': {'spectrograms': {'familiar_th': \n",
    "{'CNN3D_LSTM_FC': {'model': None, 'max_val_acc': -inf, 'best_epoch': None, 'config': None},\n",
    "'SeparableCNN2D_LSTM_FC': {'model': None, 'max_val_acc': -inf, 'best_epoch': None, 'config': None}}}}}\n",
    "\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd36f8f-865f-45c7-9549-fa97df0d7f27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Popolamento di sweep_ids e lancio degli agenti:\n",
    "\n",
    "Obiettivo: \n",
    "\n",
    "Per ogni combinazione (condition, data_type, category_subject, model_name), \n",
    "Se la lista è vuota, crei uno sweep usando wandb.sweep(sweep_config, project=condition) e lo inserisci nella lista. \n",
    "In seguito, iteri su quella lista (che ora contiene IL TUO SPECIFICO sweep_id) e lanci wandb.agent() per eseguire il training.\n",
    "\n",
    "\n",
    "\n",
    "Nota importante:\n",
    "L'ID restituito da wandb.sweep() è una STRINGA UNIVOCA generata automaticamente da WandB.\n",
    "Non puoi assegnargli direttamente una stringa personalizzata, ma puoi comunque usarlo per mappare nel tuo dizionario la combinazione di fattori! \n",
    "\n",
    "In questo ciclo, il fatto che la lista parta vuota è normale: il codice la popola se necessario e poi lancia l'agente per ogni sweep_id presente.\n",
    "\n",
    "\n",
    "****** ****** ******  ****** ****** ******  ****** ****** ******  ****** ****** ******  ****** ****** ******\n",
    "INOLTRE, BISOGNA CONTROLLARE CHE SI STIA ITERANDO CORRETTAMENTE SOLO SULLA COMBINAZIONE CORRENTE DI \n",
    "\n",
    "                CONDITION, DATA_TYPE, CATEGORY_SUBJECT E MODEL_NAME\n",
    "                \n",
    "QUESTO PERCHÉ SE UN CICLO SI RIPETE PER UNA CONDIZIONE IN PIÙ UNA COMBINAZIONE, POTREBBE GENERARE PIÙ  SWEEP IDS DI QUELLI CHE TI ASPETTI!\n",
    "****** ****** ******  ****** ****** ******  ****** ****** ******  ****** ****** ******  ****** ****** ******\n",
    "\n",
    "\n",
    "\n",
    "SOLUZIONE:\n",
    "\n",
    "Un buon approccio per evitare la creazione ripetuta di Sweep ID \n",
    "per la stessa combinazione di condition, data_type, category_subject e model_name \n",
    "è quello di utilizzare un SET per tenere traccia delle combinazioni già processate.\n",
    "Se una combinazione è già presente nel set, non dovresti creare un nuovo Sweep ID, ma semplicemente saltare quella parte del codice\n",
    "\n",
    "\n",
    "Inoltre, ho avuto una idea ad un certo punto! \n",
    "\n",
    "\n",
    "****************************** ******************************\n",
    "ILLUMINAZIONE DEL POMERIGGIO DEL 04/03/2025: \n",
    "****************************** ******************************\n",
    "\n",
    "\n",
    "Quando creo ogni sweep singolarmente, si genera una stringa univoca di quello sweep, che si riferisce ad un dataset che è il prodotto di diversi fattori:\n",
    "\n",
    "- una certa condizione sperimentale,  \n",
    "- una certo preprocessing sui dati EEG (1_20, 1_45, wavelet)\n",
    "- una certa provenienza del dato proprio (in termini di ruolo e gruppo --> th o pt, familiar o unfamiliar)\n",
    "\n",
    "\n",
    "Di conseguenza, iterando su ogni sweep_ids (che ho fatto in modo avesse la STESSA struttura dei miei dati già splittati i.e, data_dict_preprocessed\n",
    "io posso, \n",
    "\n",
    "1) da un lato eseguire la creazione della stringa univoca associata a quello sweep,\n",
    "2) crearmi una 'combination_key', che sarebbe l'insieme delle stringhe che descrivono quel dataset specifico di data_dict_preprocessed\n",
    "\n",
    "che sarà costituito da\n",
    "\n",
    "- una certa condizione sperimentale,  \n",
    "- una certo preprocessing sui dati EEG (1_20, 1_45, wavelet)\n",
    "- una certa provenienza del dato proprio (in termini di ruolo e gruppo --> th o pt, familiar o unfamiliar)\n",
    "\n",
    "\n",
    "Poiché quindi so già la corrispondenza tra ogni Sweep ID e la sua combinazione di fattori (condition, data_type, category_subject), \n",
    "posso creare un MAPPING, che associ, ad certo Sweep ID e la stringa che descrive i suoi fattori associati!\n",
    "\n",
    "\n",
    "In questo modo, forse, si riesce a risolvere il PROBLEMA 2 NELLA CELLA DI CREAZIONE DELLA FUNZIONE DI TRAINING (VEDI SOTTO!)\n",
    "\n",
    "\n",
    "\n",
    "                                                        ******IMPORTANTE MODIFICA*****\n",
    "                                                        \n",
    "Ora lo sweep_ids non si deve sdoppiare ora, perché sostanzialmente, \n",
    "per ogni modello si creano gli sweeps ids corrispondenti e salvati come valore\n",
    "dentro la chiave del modello corrispondente, sotto forma di tupla...\n",
    "\n",
    "cioè non più così\n",
    "\n",
    "\"sweep_ids[condition][data_type][category_subject].append((new_sweep_id, combination_key))\"\n",
    "\n",
    "ma una cosa del genere\n",
    "\n",
    "\"sweep_ids[condition][data_type][category_subject][model_name].append((new_sweep_id, combination_key))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "COME ERA PRIMA\n",
    "\n",
    "#Inizializza un set per tenere traccia delle combinazioni già elaborate\n",
    "\n",
    "created_combinations = set()\n",
    "\n",
    "for condition in sweep_ids:\n",
    "    for data_type in sweep_ids[condition]:\n",
    "        for category_subject in sweep_ids[condition][data_type]:\n",
    "            \n",
    "            combination_key = f\"{condition}_{data_type}_{category_subject}\"\n",
    "\n",
    "            # Controlla se la combinazione è già stata elaborata\n",
    "            if combination_key not in created_combinations:\n",
    "\n",
    "                if not sweep_ids[condition][data_type][category_subject]:\n",
    "                    #new_sweep_id = wandb.sweep(sweep_config, project=f\"{condition}_spectrograms\")\n",
    "                    new_sweep_id = wandb.sweep(sweep_config, project=f\"{condition}_spectrograms_channels_freqs_new_3d_grid_multiband\")\n",
    "\n",
    "                    #QUI, viene creata la mappatura tra Sweep ID e la descrizione della combinazione (in formato di stringhe)\n",
    "                    #CON LA CREAZIONE DI UNA TUPLA, DENTRO LA LISTA \n",
    "                \n",
    "                    sweep_ids[condition][data_type][category_subject].append((new_sweep_id, combination_key))\n",
    "                    \n",
    "                    print(f\"Sweep ID creato per \\033[1m{combination_key}\\033[0m: n° sweep \\033[1m{new_sweep_id}\\033[0m\")\n",
    "\n",
    "                # Aggiungi la combinazione al set per evitare duplicazioni\n",
    "                created_combinations.add(combination_key)\n",
    "            else:\n",
    "                # Se la combinazione è già stata creata, salta\n",
    "                print(f\"Sweep ID per {combination_key} già esistente.\")\n",
    "                \n",
    "'''\n",
    "\n",
    "\n",
    "'''\n",
    "ADESSO\n",
    "\n",
    "\n",
    "Cosa fa questo snippet\n",
    "\n",
    "Cicla su ogni (condition, data_type, category_subject) una volta sola grazie a created_combinations.\n",
    "\n",
    "All’interno, fa un sottoloop su MODEL_LIST (i tuoi due modelli).\n",
    "\n",
    "In base a model_name, sceglie sweep_config_cnn3d o sweep_config_cnn_sep.\n",
    "\n",
    "Chiama wandb.sweep(...) con il config giusto e salva il risultato in\n",
    "\n",
    "\n",
    "sweep_ids[condition][data_type][category_subject][model_name]\n",
    "anziché nella lista “piatta” che avevi prima.\n",
    "\n",
    "\n",
    "In questo modo:\n",
    "\n",
    "sweep_ids[cond][dtype][cat] resta un dict con due chiavi (\"CNN3D_LSTM_FC\" e \"SeparableCNN2D_LSTM_FC\")\n",
    "\n",
    "Ognuna di quelle chiavi punta a una propria lista di tuple (sweep_id, combo_key)\n",
    "\n",
    "Non serve sdoppiare l’intero sweep_ids, perché tiene già separati gli sweep di ciascun modello\n",
    "\n",
    "Più tardi, quando lancerai gli agent, ti basterà:\n",
    "\n",
    "\n",
    "for model_name, sweeps in sweep_ids[cond][dtype][cat].items():\n",
    "    for sweep_id, combo_key in sweeps:\n",
    "        # qui scegli il train_fn in base a model_name\n",
    "        wandb.agent(sweep_id, function=train_fn_map[model_name], count=200)\n",
    "e ogni modello girerà solo i suoi sweep.\n",
    "\n",
    "\n",
    "\n",
    "Alla fine, sweep_ids avrà la forma:\n",
    "\n",
    "{\n",
    "  'rest_vs_left_fist': {\n",
    "    'spectrograms': {\n",
    "      'familiar_th': {\n",
    "         'CNN3D_LSTM_FC':       [(sweep_id_1, 'rest_vs_left_fist_spectrograms_familiar_th')],\n",
    "         'SeparableCNN2D_LSTM_FC': [(sweep_id_2, 'rest_vs_left_fist_spectrograms_familiar_th')]\n",
    "      }\n",
    "    }\n",
    "  },\n",
    "  …\n",
    "}\n",
    "'''\n",
    "\n",
    "\n",
    "#Ecco come puoi riscrivere solo la TERZA CELLA (quella in cui crei effettivamente gli sweep) \n",
    "#mantenendo la tua struttura “a celle” e usando per ognuno il sweep_config giusto in base al model_name.\n",
    "\n",
    "#Creazione degli sweep (Terza cella)\n",
    "#Ecco il solo snippet che devi usare per creare gli sweep ripartiti per modello, usando i due sweep_config_*:\n",
    "\n",
    "\n",
    "'''\n",
    "Per mantenere la stessa logica di prima ma tenendo conto che ora stai lavorando con modelli separati, \n",
    "dovresti modificare il controllo in modo che verifichi se una combinazione di condition, data_type, category_subject\n",
    "è già stata processata per ciascun modello.\n",
    "\n",
    "Quindi, il controllo dovrebbe essere fatto separatamente per ogni modello dentro il loop che itera sui modelli (MODEL_LIST).\n",
    "Di seguito ti mostro la versione modificata che tiene conto di questo:\n",
    "\n",
    "\n",
    "\n",
    "#Inizializza un set per tenere traccia delle combinazioni già elaborate\n",
    "\n",
    "created_combinations = set()\n",
    "\n",
    "for condition in sweep_ids:\n",
    "    for data_type in sweep_ids[condition]:\n",
    "        for category_subject in sweep_ids[condition][data_type]:\n",
    "            \n",
    "            combination_key = f\"{condition}_{data_type}_{category_subject}\"\n",
    "\n",
    "            # Controlla se la combinazione è già stata elaborata\n",
    "            if combination_key not in created_combinations:\n",
    "\n",
    "                if not sweep_ids[condition][data_type][category_subject]:\n",
    "                    #new_sweep_id = wandb.sweep(sweep_config, project=f\"{condition}_spectrograms\")\n",
    "                    new_sweep_id = wandb.sweep(sweep_config, project=f\"{condition}_spectrograms_channels_freqs_new_3d_grid_multiband\")\n",
    "\n",
    "                    #QUI, viene creata la mappatura tra Sweep ID e la descrizione della combinazione (in formato di stringhe)\n",
    "                    #CON LA CREAZIONE DI UNA TUPLA, DENTRO LA LISTA \n",
    "                \n",
    "                    sweep_ids[condition][data_type][category_subject].append((new_sweep_id, combination_key))\n",
    "                    \n",
    "                    print(f\"Sweep ID creato per \\033[1m{combination_key}\\033[0m: n° sweep \\033[1m{new_sweep_id}\\033[0m\")\n",
    "\n",
    "                # Aggiungi la combinazione al set per evitare duplicazioni\n",
    "                created_combinations.add(combination_key)\n",
    "            else:\n",
    "                # Se la combinazione è già stata creata, salta\n",
    "                print(f\"Sweep ID per {combination_key} già esistente.\")\n",
    "                \n",
    "                \n",
    "                \n",
    "'''\n",
    "\n",
    "                    \n",
    "'''\n",
    "\n",
    "Cosa è stato cambiato rispetto alla versione precedente?\n",
    "Controllo della combinazione di modello:\n",
    "La logica del controllo della combinazione (combination_key, model_name) nel set created_combinations è corretta, \n",
    "perché vogliamo evitare di creare più volte lo stesso sweep per una combinazione di condition, data_type, category_subject, e model_name.\n",
    "\n",
    "Controllo e creazione dello sweep:\n",
    "Il codice controlla prima se la combinazione con il modello non è stata già processata \n",
    "con il controllo if (combination_key, model_name) not in created_combinations. \n",
    "\n",
    "Se non è stata processata, procede a creare lo sweep corrispondente. \n",
    "Se la combinazione esiste già, salta la creazione dello sweep per quel modello.\n",
    "\n",
    "Aggiunta del nuovo sweep ID:\n",
    "Una volta creato il nuovo sweep per il modello, viene aggiunto correttamente \n",
    "alla lista del modello specifico sotto sweep_ids[condition][data_type][category_subject][model_name].\n",
    "\n",
    "Aggiunta al set delle combinazioni:\n",
    "Dopo aver creato lo sweep, aggiungiamo (combination_key, model_name) al set created_combinations\n",
    "per tenere traccia delle combinazioni già elaborate.\n",
    "\n",
    "Verifica della logica:\n",
    "La combinazione (combination_key, model_name) deve essere unica per ciascun modello, \n",
    "e quindi il controllo che evita duplicazioni nel set è corretto.\n",
    "\n",
    "La creazione dello sweep per ciascun modello separato è mantenuta, \n",
    "e viene applicata solo quando la combinazione specifica non è già stata elaborata per quel modello.\n",
    "\n",
    "In questo modo, la logica funziona come nel codice precedente, ma ora si tiene conto anche dei modelli separati, \n",
    "creando un sweep per ciascuno di essi e mantenendo la traccia delle combinazioni in modo appropriato.\n",
    "\n",
    "'''\n",
    "created_combinations = set()\n",
    "\n",
    "# Per semplicità, tieni MODEL_LIST a portata di mano\n",
    "MODEL_LIST = [\"CNN3D_LSTM_FC\", \"SeparableCNN2D_LSTM_FC\"]\n",
    "\n",
    "for condition in sweep_ids:\n",
    "    for data_type in sweep_ids[condition]:\n",
    "        for category_subject in sweep_ids[condition][data_type]:\n",
    "            \n",
    "            combination_key = f\"{condition}_{data_type}_{category_subject}\"\n",
    "            \n",
    "            # per ciascun modello, creo uno sweep separato\n",
    "            for model_name in MODEL_LIST:\n",
    "\n",
    "                # Controlla se la combinazione di condition, data_type, category_subject + modello è già stata elaborata\n",
    "                if (combination_key, model_name) not in created_combinations:\n",
    "\n",
    "                    # Scegli il config in base al model_name\n",
    "                    if model_name == \"CNN3D_LSTM_FC\":\n",
    "                        sweep_conf = sweep_config_cnn3d\n",
    "                        \n",
    "                    else:  # SeparableCNN2D_LSTM_FC\n",
    "                        sweep_conf = sweep_config_cnn_sep\n",
    "                    \n",
    "                    # Controllo se la lista per il modello specifico è vuota\n",
    "                    if not sweep_ids[condition][data_type][category_subject][model_name]:\n",
    "\n",
    "                        # Crea lo sweep e lo appendo nella lista dedicata a quel modello\n",
    "                        new_sweep_id = wandb.sweep(sweep_conf, project=f\"{condition}_spectrograms_channels_freqs_new_3d_grid_multiband\")\n",
    "                        \n",
    "                        #QUI, viene creata la mappatura tra Sweep ID e la descrizione della combinazione (in formato di stringhe)\n",
    "                        #CON LA CREAZIONE DI UNA TUPLA, DENTRO LA LISTA \n",
    "                        \n",
    "                        sweep_ids[condition][data_type][category_subject][model_name].append((new_sweep_id, combination_key))\n",
    "\n",
    "                    print(f\"▶ Sweep \\033[1m{new_sweep_id}\\033[0m creato per \\033[1m{combination_key}\\033[0m, modello \\033[1m{model_name}\\033[0m\")\n",
    "                    \n",
    "                    # Aggiungi la combinazione al set per evitare duplicazioni\n",
    "                    created_combinations.add((combination_key, model_name))  # Aggiungi la combinazione con il modello\n",
    "                else:\n",
    "                    # Se la combinazione è già stata creata, salta\n",
    "                    print(f\"⚠️ {combination_key} già processato per il modello {model_name}, skip.\")\n",
    "                    continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec1179b-be4f-4bed-a7b2-2fdbfe9179fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcola e stampa il numero totale di combinazioni uniche (e quindi di sweep creati)\n",
    "\n",
    "total_sweeps = len(created_combinations)\n",
    "total_runs = total_sweeps * 200\n",
    "\n",
    "print(f\"Numero totale di sweep creati: {total_sweeps}\")\n",
    "print(f\"Numero totale di runs da eseguire: {total_runs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62744e78-4bbe-447e-9ad7-69ed32828d5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''ESEGUI QUI QUESTA CELLA PER VEDERE COME SI STRUTTURA SWEEP_IDS'''\n",
    "\n",
    "#sweep_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728967c8-3d7e-4181-bae4-25db58a3b68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sweep_ids.keys()\n",
    "#sweep_ids['th_resp_vs_pt_resp'].keys()\n",
    "#sweep_ids['th_resp_vs_pt_resp'].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2504dd0c-f001-4e1c-b180-f59bc41ecb6a",
   "metadata": {},
   "source": [
    "**NOTA BENE**\n",
    "\n",
    "\n",
    "I **numeri degli sweeps** tornano e son corretti! \n",
    "Tuttavia, avendo solo preparato l'inizializzazione degli sweeps dentro 'sweep_ids', \n",
    "Sul sito di weight and biases, io vedo le tre condizioni sperimentali, create ciascuna come un progetto separato, che è corretto, ma ancora le runs di ciascuna le vedo a 0\n",
    "\n",
    "Deduco che questo comportamento, dovrebbe esser normale, dato che ancora non ho avviato l'agente appunto wandb.agent(), con cui gli fornisco lo sweep_id generato adesso in questo loop precedente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c79a08-c751-4ad7-b593-2ed1c09f87a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_dict_preprocessed.keys())\n",
    "print(sweep_ids.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc0980f-70ce-466d-b4dd-9f52d7dd462f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict_preprocessed.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67766b48-dc9b-4fb6-98e2-5e434b788f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict_preprocessed['rest_vs_left_fist'].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9849bf71-2f37-4c85-ba75-335d5ec9b792",
   "metadata": {},
   "source": [
    "**IO**:\n",
    "\n",
    "però non capisco perché aggiornamento del modello e scheduler & early stopping monitorano cose diverse...\n",
    "\n",
    "tu mi hai suggerito di fare così...\n",
    "\n",
    "    \"\n",
    "    # -- Aggiorna miglior modello --\n",
    "            if val_acc > max_val_acc:\n",
    "                max_val_acc = val_acc\n",
    "                best_epoch  = epoch\n",
    "                best_model  = copy.deepcopy(model)\n",
    "\n",
    "            # -- Scheduler & Early Stopping --\n",
    "            scheduler.step(val_loss)\n",
    "            early_stopping(val_loss)\n",
    "            if early_stopping.early_stop:\n",
    "                print(f\"🛑 Early stopping (val_loss) dopo {epoch} epoche.\")\n",
    "                break\n",
    "    \"\n",
    "\n",
    "non dovrebbero vedere o la val loss o val accuracy entrambe? spiegami sta cosa\n",
    "\n",
    "<br>\n",
    "\n",
    "**CHATGPT**:\n",
    "\n",
    "\n",
    "È perfettamente normale — anzi, consigliabile — usare metriche diverse per:\n",
    "\n",
    "Selezionare il “best model” in base all’obiettivo finale (accuracy, F1, AUC…)\n",
    "\n",
    "Gestire l’ottimizzazione del training (scheduler ed early stopping) in base a una funzione di ottimizzazione continua (tipicamente la loss)\n",
    "\n",
    "1. Perché salvo il modello sul miglior val_accuracy\n",
    "Obiettivo finale del tuo task di classificazione è massimizzare l’accuratezza (o qualche altra metrica di performance).\n",
    "\n",
    "Quindi, quando decidi “questo è il modello migliore finora”, lo scegli in base alla metrica che ti interessa davvero in produzione: val_acc.\n",
    "\n",
    "if val_acc > max_val_acc:\n",
    "    max_val_acc = val_acc\n",
    "    best_model  = copy.deepcopy(model)\n",
    "    \n",
    "2. Perché scheduler e early-stopping monitorano la val_loss\n",
    "Scheduler (ReduceLROnPlateau): lavora sulla loss, perché è una curva continua e più liscia.\n",
    "\n",
    "La loss tende a fluttuare meno drasticamente di accuracy (che salta tra 0 e 1), e quindi il plateau su loss è un indicatore più affidabile di “sto smettendo di imparare”.\n",
    "\n",
    "EarlyStopping: idem, se monitori la loss puoi fermarti non appena il modello smette di migliorare nella sua funzione di ottimizzazione primaria, \n",
    "evitando di aspettare 12 epoche solo perché l’accuracy potrebbe oscillare o rimanere piatta un po’ più a lungo.\n",
    "\n",
    "\n",
    "scheduler.step(val_loss)      # dimezza lr se val_loss non cala\n",
    "early_stopping(val_loss)     # ferma se val_loss non cala per 12 epoche\n",
    "\n",
    "\n",
    "3. Riassunto\n",
    "\n",
    "val_loss → serve per ottimizzare il training (quando aggiornare lr, quando fermarsi).\n",
    "val_acc → serve per selezionare quale modello salvare come “migliore”.\n",
    "\n",
    "Questo approccio misto ti dà sia:\n",
    "\n",
    "Un training più stabile e sensibile (via loss),\n",
    "\n",
    "Una scelta di modello finale più allineata all’obiettivo (via accuracy).\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "**IO**:\n",
    "\n",
    "ok quindi qui nello sweep config\n",
    "\n",
    "sweep_config = {\n",
    "    \"method\": \"random\",\n",
    "    \"metric\": {\"name\": \"val_accuracy\", \"goal\": \"maximize\"},\n",
    "    \"parameters\": {\n",
    "        \"lr\": {\"values\": [0.01, 0.001, 0.0005, 0.0001]},\n",
    "        #\"weight_decay\": {\"values\": [0, 0.01, 0.001, 0.0001]},\n",
    "        \"n_epochs\": {\"value\": 100},\n",
    "        \"patience\": {\"value\": 12},\n",
    "        #\"model_name\":{\"values\": ['CNN2D', 'BiLSTM', 'Transformer']},\n",
    "        \"model_name\":{\"values\": ['CNN2D_LSTM_TF', 'BiLSTM', 'Transformer']},\n",
    "        #\"batch_size\": {\"values\": [32, 48, 64, 96]},\n",
    "        \"batch_size\": {\"values\": [32, 48, 64, 72, 84, 96]},\n",
    "        \"standardization\":{\"values\": [True, False]},\n",
    "        \n",
    "    }\n",
    "}\n",
    "\n",
    "commentando le righe con # ho fatto in modo che il training abbia sia l'obiettivo di massimizzare l'accuracy e di usare anche lo scheduler sotto e early stopping su val loss?\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "**CHATGPT**:\n",
    "\n",
    "Sì, esattamente: con quella configurazione dello sweep\n",
    "\n",
    "\n",
    "\"metric\": {\"name\": \"val_accuracy\", \"goal\": \"maximize\"}\n",
    "stai dicendo a W&B di cercare di massimizzare l’accuracy di validazione.\n",
    "E togliendo weight_decay dallo sweep (o commentandolo) e forzandolo a zero nell’Adam, aderisci al setup “puro” del paper.\n",
    "\n",
    "Lo scheduler (ReduceLROnPlateau) e l’early stopping su val_loss non sono parametri di sweep, ma comportamenti che hai inserito dentro training_sweep. In pratica:\n",
    "\n",
    "Sweep esplora solo\n",
    "\n",
    "lr\n",
    "n_epochs (fissato a 100)\n",
    "patience (ora 12, anche se è usato solo per W&B, l’early-stopping vero lo hai forzato a 12 su loss)\n",
    "model_name\n",
    "batch_size\n",
    "standardization\n",
    "\n",
    "Dentro training_sweep\n",
    "\n",
    "Optimizer Adam è costruito con weight_decay=0, betas=(0.9, 0.999), eps=1e-8, e lr=config.lr.\n",
    "Hai creato un ReduceLROnPlateau su val_loss (mode='min', factor=0.5, patience=4).\n",
    "Hai un EarlyStopping su val_loss con patience=12.\n",
    "\n",
    "Metriche loggate a W&B includono sia val_loss sia val_accuracy, quindi il tuo sweep valuta e sceglie la config migliore in base a val_accuracy ma gli aggiustamenti di lr e l’interruzione anticipata sono decisi internamente dal comportamento di scheduler+early stopping sulla curva di loss.\n",
    "\n",
    "Questa separazione ti dà:\n",
    "\n",
    "Una ricerca di iper-parametri incentrata sull’accuracy (quello che desideri massimizzare).\n",
    "Un allenamento stabile e fedele al paper grazie a scheduler e early stopping su loss.\n",
    "\n",
    "Puoi andare avanti così!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2bec6b-090d-44f1-a1c5-842a2327dab2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### **VERSIONE DEL 6 MARZO (RISOLUZIONE DEFINITIVA)**\n",
    "\n",
    "##### **Training Function Edits - EEG Spectrograms - Electrodes x Frequencies ONLY HYPER-PARAMS**\n",
    "\n",
    "#### **Sweep separati per ciascuno dei modelli CNN3D e CNN Sep**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ef23be-119a-4379-a8e6-a58cb6e5bf99",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''CELLA DI ESEMPIO PER VERIFICARE SE QUESTA FUNZIONE FACESSE IL PARSING DELLE STRINGHE DELLE COMBINAZIONI DI FATTORI CORRETTAMENTE'''\n",
    "\n",
    "import re\n",
    "\n",
    "def parse_combination_key(combination_key):\n",
    "    \"\"\"\n",
    "    Estrae condition_experiment e subject_key da combination_key\n",
    "    dove il data_type è fisso a \"spectrograms\".\n",
    "    \n",
    "    Esempio di chiave: \n",
    "    \"pt_resp_vs_shared_resp_spectrograms_familiar_th\"\n",
    "    \"\"\"\n",
    "    match = re.match(\n",
    "        r\"^(rest_vs_left_fist|rest_vs_right_fist|left_fist_vs_right_fist)_spectrograms_(familiar_th|familiar_pt|unfamiliar_th|unfamiliar_pt)$\",\n",
    "        combination_key\n",
    "    )\n",
    "    if match:\n",
    "        condition_experiment = match.group(1)\n",
    "        subject_key = match.group(2)\n",
    "        return condition_experiment, subject_key\n",
    "    else:\n",
    "        raise ValueError(f\"Formato non valido: {combination_key}\")\n",
    "\n",
    "# Test\n",
    "combination_key = \"rest_vs_left_fist_spectrograms_familiar_th\"\n",
    "condition_experiment, subject_key = parse_combination_key(combination_key)\n",
    "\n",
    "print(\"Condizione:\", condition_experiment)\n",
    "print(\"Soggetto:\", subject_key)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bf9173c2-ff97-42ba-9ed2-7948027f8171",
   "metadata": {
    "tags": []
   },
   "source": [
    "'''\n",
    "                                                                ***** FUNZIONE DI TRAINING *****\n",
    "                                                                ***** VERSIONE DEL 5 MARZO *****\n",
    "                                                                \n",
    "                                                    **** SALVATAGGIO SOLO PESI E BIAS DI UN CERTO MODELLO ****      \n",
    "                                                                \n",
    "Il punto critico è garantire che ogni configurazione di iperparametri estratta randomicamente da W&B per OGNI SWEEP sia coerente con:\n",
    "\n",
    "Il dataset giusto (ossia la coppia di condizioni sperimentali corrispondente).\n",
    "Il tipo di dato EEG usato (1_20, 1_45, wavelet ecc.).\n",
    "L'origine dei dati tra le quattro tipologie di soggetti.\n",
    "\n",
    "\n",
    "che io andrei a prelevare ogni volta da 'data_dict_preprocessed'!\n",
    "\n",
    "Quindi, ad ogni iterazione del loop sui dati (i.e., data_dict_preprocessed?)\n",
    "il codice dovrebbe assicurarsi/verificare che, \n",
    "\n",
    "\n",
    "1) la configurazione selezionata da W&B presa da uno SPECIFICO SWEEP,  \n",
    "sia quella che effettivamente corrisponde ad un certo dataset in termini di combinazione di fattori \n",
    "\n",
    "- una specifica condizione sperimentale\n",
    "- una specifico tipo di dato EEG \n",
    "- una specifica combinazione di ruolo/gruppo\n",
    "\n",
    "\n",
    "2) che le run di quella sweep siano inserita nel progetto del dataset di quella specifica condizione sperimentale,\n",
    "\n",
    "\n",
    "(3 PLUS OPZIONALE\n",
    "\n",
    "e che il \"name\" e i \"tag\" (eventualmente, delle runs associate a quello sweep)\n",
    "siano costruiti in maniera coerente con la combinazione di fattori associata allo sweep (e quindi alla condizione sperimentale corrente)\n",
    "\n",
    "\n",
    "\n",
    "****************************** ******************************\n",
    "CONCLUSIONE A CUI SON ARRIVATO LA MATTINA DEL 04/03/2025: \n",
    "****************************** ******************************\n",
    "\n",
    "Dato che ogni sweep si applica per verificare, tra le 15 diversi set di iper-parametri diversi, \n",
    "quale sia la configurazione migliore, per uno specifico set di dati in termini di combinazione di fattori, che sono\n",
    "\n",
    "- relativi ad una certa condizione sperimentale,  \n",
    "- con un certo preprocessing\n",
    "- con un certa provenienza del dato\n",
    "\n",
    "\n",
    "Son arrivato ad un punto in cui credo che sia davvero molto complesso controllare la corrispondenza esatta tra \n",
    "\n",
    "1) di chi esegue lo sweep\n",
    "2) la definizione del nome della sue 15 runs (cioè di quale dato si riferisca etc. in termini di combinazione di fattori) ...\n",
    "\n",
    "Quindi l'unica cosa che ha senso è forse solo creare le runs in modo da inserirle tutte assieme in base al solo nome del progetto,\n",
    "che però è prelevabile dalla prima chiave di 'data_dict_preprocessed'.. \n",
    "\n",
    "in questo modo, pur non avendo il controllo sul nome della run e del suo tag,\n",
    "almeno dovrei esser sicuro che comunque le runs associate all'uso dei dati di ALMENO \n",
    "una certa condizione sperimentale vengano inserite nel relativo progetto su weight and biases...\n",
    "\n",
    "\n",
    "\n",
    "TUTTAVIA, \n",
    "\n",
    "****************************** ******************************\n",
    "ILLUMINAZIONE DEL POMERIGGIO DEL 04/03/2025: \n",
    "****************************** ******************************\n",
    "\n",
    "MI HA PORTATO A PENSARE A PROVARE A CAPIRE ANCORA SE RIESCO A RISOLVERE IL PROBLEMA ...\n",
    "'''\n",
    "\n",
    "\n",
    "#VERSIONE NUOVA!\n",
    "\n",
    "#Fase 2: Creazione della funzione di 'training_sweep' \n",
    "    \n",
    "'''Questa funzione parse_combination_key serve per estrarre \n",
    "le varie stringhe che compongono la combinazioni di fattori (condizione sperimentale, tipo di dato EEG e provenienza del dato EEG) \n",
    "che si riferiscono allo sweep ID corrente.\n",
    "\n",
    "Esempio:\n",
    "\n",
    "Lo tupla sweep (sweep ID, combinazioni di fattori in stringa) è la seguente:\n",
    "\n",
    "Inizio l'agent per sweep_id: ('4u94ovth', 'pt_resp_vs_shared_resp_wavelet_unfamiliar_pt') dove\n",
    "- sweep ID: 4u94ovth\n",
    "- combinazioni di fattori in stringa: pt_resp_vs_shared_resp_wavelet_unfamiliar_pt\n",
    "\n",
    "Di conseguenza, quando avvio l'agent per quella condizione sperimentale nel loop, \n",
    "dentro la funzione di 'training_sweep' io prenderò in input la tupla\n",
    "\n",
    "\n",
    "\"\"\" Esegue il training per uno specifico sweep \"\"\"\n",
    "\n",
    "def training_sweep(data_dict_preprocessed, sweep_config, sweep_ids, sweep_id, sweep_tuple, best_models): \n",
    "\n",
    "sweep_id, combination_key = sweep_tuple\n",
    "exp_cond, data_type, category_subject = parse_combination_key(combination_key)\n",
    "\n",
    "\n",
    "E lui estrarrà la combinazione di fattori che la compongono, in questo caso è \n",
    "\n",
    "1) Condizione Sperimentale = pt_resp_vs_shared_resp\n",
    "2) Tipo di Dato EEG = wavelet\n",
    "3) Provenienza del Tipo di Dato EEG unfamiliar_pt\n",
    "\n",
    "Successivamente, confronta se questa combinazione di stringhe si trova dentro la mia struttura dati e, se la trova\n",
    "\n",
    "1) creerà il progetto con il nome della condizione sperimentale combaciante tra \n",
    " \n",
    " - la combination_key associata allo Sweep ID corrente e\n",
    " - il sottodizionario di data_dict_preprocessed \n",
    " \n",
    "2) le relative run di quello specifico Sweep, verranno nominate con la combinazioni di fattori combaciante su W&B\n",
    "\n",
    "3) Esegue e gestisce il salvataggio della migliore configurazione di iper-parametri del relativo modello preso in esame (CNN1D, BiLSTM e Transformer)\n",
    "   tra le 15 runs di OGNI SWEEP\n",
    "   \n",
    "\n",
    "'''\n",
    "\n",
    "import re\n",
    "\n",
    "def parse_combination_key(combination_key):\n",
    "    \"\"\"\n",
    "    Estrae condition_experiment e subject_key da combination_key\n",
    "    dove il data_type è fisso a \"spectrograms\".\n",
    "    \n",
    "    Esempio di chiave: \n",
    "    \"pt_resp_vs_shared_resp_spectrograms_familiar_th\"\n",
    "    \"\"\"\n",
    "    match = re.match(\n",
    "        r\"^(pt_resp_vs_shared_resp|th_resp_vs_pt_resp|th_resp_vs_shared_resp)_spectrograms_(familiar_th|familiar_pt|unfamiliar_th|unfamiliar_pt)$\",\n",
    "        combination_key\n",
    "    )\n",
    "    if match:\n",
    "        condition_experiment = match.group(1)\n",
    "        subject_key = match.group(2)\n",
    "        return condition_experiment, subject_key\n",
    "    else:\n",
    "        raise ValueError(f\"Formato non valido: {combination_key}\")\n",
    "        \n",
    "        \n",
    "def training_sweep(data_dict_preprocessed, sweep_config, sweep_ids, sweep_id, sweep_tuple, best_models): \n",
    "    \n",
    "    # Per ogni sweep, che viene iterato nel loop, io prendo \n",
    "    #1) la stringa univoca dello Sweep ID\n",
    "    #2) la sua combinazione di fattori stringa (che mi serviranno per prelevare il dato corrispondente da 'data_dict_preprocessed'\n",
    "    \n",
    "    sweep_id, combination_key = sweep_tuple\n",
    "    \n",
    "    # Ora la funzione restituisce solo (exp_condition, subject_key)\n",
    "    exp_cond, category_subject = parse_combination_key(combination_key)\n",
    "    \n",
    "    # Poiché ora i dati sono solo di tipo \"spectrograms\", li impostiamo in modo fisso:\n",
    "    data_type = \"spectrograms\"\n",
    "\n",
    "    if not (exp_cond in data_dict_preprocessed and category_subject in data_dict_preprocessed[exp_cond][data_type]):\n",
    "        raise ValueError(f\"❌ ERRORE - Combinazione \\033[1mNON TROVATA\\033[0m in data_dict_preprocessed: \\033[1m{exp_cond}\\033[0m, \\033[1m{category_subject}\\033[0m\")\n",
    "\n",
    "    run_name = f\"{exp_cond}_{data_type}_{category_subject}\"\n",
    "    tags = [exp_cond, data_type, category_subject]\n",
    "\n",
    "    #Inizializza la run dello specifico Sweep dentro Weights & Biases (W&B) con\n",
    "\n",
    "    #1) un nome del progetto pari alla condizione sperimentale corrente\n",
    "    #2) il nome e tag della run in base alla combinazione di fattori corrispondente\n",
    "    #3) la congiurazione di iper-parametri è pari a quella passata in input a 'training_sweep'\n",
    "\n",
    "    #Vedi questo link su wandb.init() per vedere i suoi parametri --> #https://docs.wandb.ai/ref/python/init/\n",
    "    \n",
    "    # Inizializza la run in W&B nel progetto che termina con \"_spectrograms\"\n",
    "    wandb.init(project=f\"{exp_cond}_spectrograms\", name=run_name, tags=tags)\n",
    "\n",
    "    print(f\"\\nCreo wandb project per: \\033[1m{exp_cond}_spectrograms\\033[0m\")\n",
    "    print(f\"Lo sweep corrente è \\033[1m{sweep_tuple}\\033[0m\")\n",
    "    print(f\"\\nInizio addestramento sul dataset \\033[1m{exp_cond}\\033[0m con dati EEG \\033[1m{data_type}\\033[0m di \\033[1m{category_subject}\\033[0m\")\n",
    "\n",
    "    # Parametri dell'esperimento presi da wandb\n",
    "    config = wandb.config\n",
    "\n",
    "    # Recupera i dati pre-processati per la combinazione corrente una volta verificata l'esatta corrispondenza tra:\n",
    "    #1)il combination_key dello sweep\n",
    "    #2)l'esistenza di specifico dataset con le stesse 'combination_key' dentro data_dict_preprocessed\n",
    "\n",
    "    try:\n",
    "        X_train, X_val, X_test, y_train, y_val, y_test = data_dict_preprocessed[exp_cond][data_type][category_subject]\n",
    "        print(f\"\\nCarico i dati di \\033[1m{exp_cond}\\033[0m, \\033[1m{data_type}\\033[0m, \\033[1m{category_subject}\\033[0m\")\n",
    "        print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "        print(f\"X_val shape: {X_val.shape}, y_val shape: {y_val.shape}\")\n",
    "        print(f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\\n\")\n",
    "    except KeyError:\n",
    "        raise ValueError(f\"❌ ERRORE - Combinazione \\033[1mNON TROVATA\\033[0m in data_dict_preprocessed: \\033[1m{exp_cond}\\033[0m, \\033[1m{data_type}\\033[0m, \\033[1m{category_subject}\\033[0m\")\n",
    "\n",
    "\n",
    "    if config.standardization:\n",
    "        # Standardizzazione\n",
    "        X_train, X_val, X_test = standardize_data(X_train, X_val, X_test)\n",
    "        print(f\"\\nUso DATI \\033[1mSTANDARDIZZATI\\033[0m!\")\n",
    "    else:\n",
    "        print(f\"\\nUso DATI \\033[1mNON STANDARDIZZATI\\033[0m!\")\n",
    "\n",
    "    # Preparazione dei dataloaders (N.B. prendo uno dei modelli considerati dentro config.model_name)\n",
    "    train_loader, val_loader, test_loader, class_weights_tensor = prepare_data_for_model(\n",
    "        X_train, X_val, X_test, y_train, y_val, y_test, model_type=config.model_name, batch_size = config.batch_size\n",
    "    )\n",
    "\n",
    "    #Qui estraggo il relativo modello su cui sto iterando al momento corrente e lo inizializzo\n",
    "\n",
    "    # Inizializza il modello in base al valore scelto in config.model_name\n",
    "    #if config.model_name == \"CNN2D\":\n",
    "    #    model = CNN1D(input_channels=3, num_classes=2)\n",
    "    #    print(f\"\\nInizializzazione Modello \\033[1m{config.model_name}\\033[0m\")\n",
    "    #elif config.model_name == \"BiLSTM\":\n",
    "    #    model = ReadMEndYou(input_size=3, hidden_sizes=[24, 48, 62], output_size=2, bidirectional=True)\n",
    "    #    print(f\"\\nInizializzazione Modello \\033[1m{config.model_name}\\033[0m\")\n",
    "    #elif config.model_name == \"Transformer\":\n",
    "    #    model = ReadMYMind(num_channels=3, seq_length=250, d_model=16, num_heads=4, num_layers=2, num_classes=2)\n",
    "    #    print(f\"\\nInizializzazione Modello \\033[1m{config.model_name}\\033[0m\")\n",
    "        \n",
    "    # Inizializza il modello in base al valore scelto in config.model_name\n",
    "    if config.model_name == \"CNN2D\":\n",
    "        model = CNN2D(input_channels=3, num_classes=2)\n",
    "        print(f\"\\nInizializzazione Modello \\033[1mCNN2D\\033[0m\")\n",
    "        \n",
    "    elif config.model_name == \"BiLSTM\":\n",
    "        # Qui, input_size = canali * frequenze = 3 * 38 = 114\n",
    "        model = ReadMEndYou(input_size= 3 * 38, hidden_sizes=[24, 48, 62], output_size=2, bidirectional=True)\n",
    "        print(f\"\\nInizializzazione Modello \\033[1mBiLSTM\\033[0m\")\n",
    "        \n",
    "    elif config.model_name == \"Transformer\":\n",
    "        # Per il Transformer, passiamo anche i parametri channels e freqs per adattare l'embedding\n",
    "        model = ReadMYMind(d_model=16, num_heads=4, num_layers=2, num_classes=2, channels=3, freqs=38)\n",
    "        print(f\"\\nInizializzazione Modello \\033[1mTransformer\\033[0m\")\n",
    "\n",
    "        \n",
    "    #ORIGINAL VERSION OF TIME SERIES EEG DATA REPRESENTATION  \n",
    "    #def initialize_models():\n",
    "        #model_CNN = CNN1D(input_channels=3, num_classes=2)\n",
    "        #model_LSTM = ReadMEndYou(input_size=3, hidden_sizes=[24, 48, 62], output_size=2, bidirectional=True)\n",
    "        #model_Transformer = ReadMYMind(num_channels=3, seq_length=250, d_model=16, num_heads=4, num_layers=2, num_classes=2)\n",
    "        \n",
    "        #return model_CNN, model_LSTM, model_Transformer\n",
    "\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config.lr, weight_decay=config.weight_decay)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "\n",
    "    # Parametri di training\n",
    "    n_epochs = config.n_epochs\n",
    "    patience = config.patience\n",
    "    early_stopping = EarlyStopping(patience=patience, mode='max')\n",
    "\n",
    "    best_model = None\n",
    "    max_val_acc = 0\n",
    "    best_epoch = 0\n",
    "\n",
    "    pbar = tqdm(range(n_epochs))\n",
    "\n",
    "    for epoch in pbar:\n",
    "        train_loss_tmp = []\n",
    "        correct_train = 0\n",
    "        y_true_train_list, y_pred_train_list = [], []\n",
    "\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            y_pred = model(x)\n",
    "            loss = criterion(y_pred, y.view(-1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss_tmp.append(loss.item())\n",
    "            _, predicted_train = torch.max(y_pred, 1)\n",
    "            correct_train += (predicted_train == y).sum().item()\n",
    "            y_true_train_list.extend(y.cpu().numpy())\n",
    "            y_pred_train_list.extend(predicted_train.cpu().numpy())\n",
    "\n",
    "        accuracy_train = correct_train / len(train_loader.dataset)\n",
    "        loss_train = np.mean(train_loss_tmp)\n",
    "\n",
    "        precision_train = precision_score(y_true_train_list, y_pred_train_list, average='weighted')\n",
    "        recall_train = recall_score(y_true_train_list, y_pred_train_list, average='weighted')\n",
    "        f1_train = f1_score(y_true_train_list, y_pred_train_list, average='weighted')\n",
    "        auc_train = roc_auc_score(y_true_train_list, y_pred_train_list, average='weighted')\n",
    "\n",
    "        loss_val_tmp = []\n",
    "        correct_val = 0\n",
    "        y_true_val_list, y_pred_val_list = [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for x, y in val_loader:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                y_pred = model(x)\n",
    "\n",
    "                loss = criterion(y_pred, y.view(-1))\n",
    "                loss_val_tmp.append(loss.item())\n",
    "                _, predicted_val = torch.max(y_pred, 1)\n",
    "\n",
    "                correct_val += (predicted_val == y).sum().item()\n",
    "                y_true_val_list.extend(y.cpu().numpy())\n",
    "                y_pred_val_list.extend(predicted_val.cpu().numpy())\n",
    "\n",
    "        accuracy_val = correct_val / len(val_loader.dataset)\n",
    "        loss_val = np.mean(loss_val_tmp)\n",
    "\n",
    "        wandb.log({\n",
    "            \"epoch\": epoch,\n",
    "            \"train_loss\": loss_train,\n",
    "            \"train_accuracy\": accuracy_train,\n",
    "            \"train_precision\": precision_train,\n",
    "            \"train_recall\": recall_train,\n",
    "            \"train_f1\": f1_train,\n",
    "            \"train_auc\": auc_train,\n",
    "            \"val_loss\": loss_val,\n",
    "            \"val_accuracy\": accuracy_val\n",
    "        })\n",
    "\n",
    "        if accuracy_val > max_val_acc:\n",
    "            max_val_acc = accuracy_val\n",
    "            best_epoch = epoch\n",
    "            best_model = cp.deepcopy(model)\n",
    "\n",
    "        early_stopping(accuracy_val)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"🛑 Early stopping attivato!\")\n",
    "            break\n",
    "\n",
    "\n",
    "        '''\n",
    "        Qui, si usa config.model_name tra le chiavi di best_models, \n",
    "        così che gestisca automaticamente il salvataggio del best model estratto dalla configurazione randomica di iper-parametri\n",
    "        della specifica run di un determinato sweep, che è relativa allo specifico modello correntemente estratto randomicamente dalla sweep_config!\n",
    "        '''\n",
    "\n",
    "        if best_models[exp_cond][data_type][category_subject][config.model_name][\"max_val_acc\"] == -float('inf'):\n",
    "\n",
    "            # Salvo il primo best_model per quella combinazione\n",
    "            best_models[exp_cond][data_type][category_subject][config.model_name] = {\n",
    "                \"model\": cp.deepcopy(model),\n",
    "                \"max_val_acc\": accuracy_val,\n",
    "                \"best_epoch\": epoch,\n",
    "            }\n",
    "\n",
    "            best_model_name = f\"{config.model_name}_{exp_cond}_{data_type}_{category_subject}\"\n",
    "\n",
    "            model_path = os.path.join(base_dir, exp_cond, data_type, category_subject)\n",
    "\n",
    "            os.makedirs(model_path, exist_ok=True)\n",
    "\n",
    "            model_file = f\"{model_path}/{best_model_name}.pth\"\n",
    "\n",
    "            torch.save(best_model.state_dict(), model_file)\n",
    "            print(f\"Il modello \\n\\033[1m{best_model_name}\\033[0m verrà salvato in questa folder directory: \\n\\033[1m{model_file}\\033[0m\")\n",
    "\n",
    "            #Condizione di aggiornamento:\n",
    "            #Se l'accuracy corrente (accuracy_val) di quel modello di quello sweep supera il valore già salvato in best_models[...], \n",
    "            #allora aggiorniamo il dizionario e sovrascriviamo il file del best model, di quel modello, di quella combinazione di fattori.\n",
    "\n",
    "\n",
    "            # Puoi confrontare e salvare il modello solo se il nuovo è migliore\n",
    "\n",
    "\n",
    "            #Questo assicura che il salvataggio del modello avvenga solo se\n",
    "            #il nuovo modello ha un'accuratezza di validazione (max_val_acc) migliore \n",
    "            #rispetto a quella già memorizzata per la condizione specifica (exp_cond).\n",
    "\n",
    "            #In questo modo, si evita di sovrascrivere il modello salvato con uno peggiore\n",
    "\n",
    "\n",
    "            # Nuovo modello migliore per questa combinazione: aggiorna e sovrascrivi il file\n",
    "\n",
    "\n",
    "        elif accuracy_val > best_models[exp_cond][data_type][category_subject][config.model_name][\"max_val_acc\"]:\n",
    "                best_models[exp_cond][data_type][category_subject][config.model_name] = {\n",
    "                    \"model\": best_model,\n",
    "                    \"max_val_acc\": accuracy_val,\n",
    "                    \"best_epoch\": best_epoch,\n",
    "                }\n",
    "                best_model_name = f\"{config.model_name}_{exp_cond}_{data_type}_{category_subject}\"\n",
    "                model_path = os.path.join(base_dir, exp_cond, data_type, category_subject)\n",
    "                os.makedirs(model_path, exist_ok=True)\n",
    "\n",
    "                print(f\"Il modello di questa folder directory:\\n\\033[1m{model_path}\\033[0m\")\n",
    "                print(f\"\\nHa un MIGLIORAMENTO!\")\n",
    "\n",
    "                model_file = f\"{model_path}/{best_model_name}.pth\"\n",
    "\n",
    "                if os.path.exists(model_file):\n",
    "\n",
    "                    # Se il file esiste, stampiamo un messaggio di aggiornamento\n",
    "                    print(f\"\\n⚠️ ATTENZIONE: \\nIl modello \\033[1m{best_model_name}\\033[0m verrà AGGIORNATO in \\n\\033[1m{model_path}\\033[0m\")\n",
    "\n",
    "                    # Salva il miglior modello solo se è stato aggiornato\n",
    "                    torch.save(best_model.state_dict(), model_file)\n",
    "                    print(f\"\\nIl nome del modello AGGIORNATO è:\\n\\033[1m{best_model_name}\\033[0m\")\n",
    "\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "                #Condizione \"nessun miglioramento\":\n",
    "                #Se il modello corrente non migliora il best già salvato, viene semplicemente stampato un messaggio.\n",
    "\n",
    "                #Questa logica garantisce che per ogni combinazione il file .pth contenga \n",
    "                #sempre i pesi del miglior modello (secondo la validation accuracy) fino a quel momento.\n",
    "                #Adatta eventualmente i nomi delle variabili (es. accuracy_val vs max_val_acc) per essere coerente con il resto del tuo codice.\n",
    "        else:\n",
    "            ''''QUI VA RIDEFINITO LA MODEL_PATH (e anche se vuoi MODE_FILE) ALTRIMENTI IN QUESTO ELSE NON ESISTONO!'''\n",
    "\n",
    "            best_model_name = f\"{config.model_name}_{exp_cond}_{data_type}_{category_subject}\"\n",
    "            model_path = os.path.join(base_dir, exp_cond, data_type, category_subject)\n",
    "            model_file = f\"{model_path}/{best_model_name}.pth\"\n",
    "            print(f\"Nessun miglioramento per il modello \\033[1m{config.model_name}\\033[0m in \\n\\033[1m{model_path}\\033[0m, ossia \\n\\033[1m{model_file}\\033[0m\")\n",
    "\n",
    "    wandb.finish()\n",
    "        \n",
    "    return best_models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55a245a-3946-4f0e-a22c-0a5080301ee4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "                                                                ***** FUNZIONE DI TRAINING *****\n",
    "                                                                ***** VERSIONE DEL 5 MARZO *****\n",
    "                                                                \n",
    "                                                                    **** SALVATAGGIO DI **** \n",
    "                                                        \n",
    "                                                        1) PESI E BIAS DI UN CERTO MODELLO \n",
    "                                                        2) CONFIGURAZIONE IPER-PARAMETRI DI UN CERTO MODELLO\n",
    "                                                                \n",
    "Il punto critico è garantire che ogni configurazione di iperparametri estratta randomicamente da W&B per OGNI SWEEP sia coerente con:\n",
    "\n",
    "Il dataset giusto (ossia la coppia di condizioni sperimentali corrispondente).\n",
    "Il tipo di dato EEG usato (1_20, 1_45, wavelet ecc.).\n",
    "L'origine dei dati tra le quattro tipologie di soggetti.\n",
    "\n",
    "\n",
    "che io andrei a prelevare ogni volta da 'data_dict_preprocessed'!\n",
    "\n",
    "Quindi, ad ogni iterazione del loop sui dati (i.e., data_dict_preprocessed?)\n",
    "il codice dovrebbe assicurarsi/verificare che, \n",
    "\n",
    "\n",
    "1) la configurazione selezionata da W&B presa da uno SPECIFICO SWEEP,  \n",
    "sia quella che effettivamente corrisponde ad un certo dataset in termini di combinazione di fattori \n",
    "\n",
    "- una specifica condizione sperimentale\n",
    "- una specifico tipo di dato EEG \n",
    "- una specifica combinazione di ruolo/gruppo\n",
    "\n",
    "\n",
    "2) che le run di quella sweep siano inserita nel progetto del dataset di quella specifica condizione sperimentale,\n",
    "\n",
    "\n",
    "(3 PLUS OPZIONALE\n",
    "\n",
    "e che il \"name\" e i \"tag\" (eventualmente, delle runs associate a quello sweep)\n",
    "siano costruiti in maniera coerente con la combinazione di fattori associata allo sweep (e quindi alla condizione sperimentale corrente)\n",
    "\n",
    "\n",
    "\n",
    "****************************** ******************************\n",
    "CONCLUSIONE A CUI SON ARRIVATO LA MATTINA DEL 04/03/2025: \n",
    "****************************** ******************************\n",
    "\n",
    "Dato che ogni sweep si applica per verificare, tra le 15 diversi set di iper-parametri diversi, \n",
    "quale sia la configurazione migliore, per uno specifico set di dati in termini di combinazione di fattori, che sono\n",
    "\n",
    "- relativi ad una certa condizione sperimentale,  \n",
    "- con un certo preprocessing\n",
    "- con un certa provenienza del dato\n",
    "\n",
    "\n",
    "Son arrivato ad un punto in cui credo che sia davvero molto complesso controllare la corrispondenza esatta tra \n",
    "\n",
    "1) di chi esegue lo sweep\n",
    "2) la definizione del nome della sue 15 runs (cioè di quale dato si riferisca etc. in termini di combinazione di fattori) ...\n",
    "\n",
    "Quindi l'unica cosa che ha senso è forse solo creare le runs in modo da inserirle tutte assieme in base al solo nome del progetto,\n",
    "che però è prelevabile dalla prima chiave di 'data_dict_preprocessed'.. \n",
    "\n",
    "in questo modo, pur non avendo il controllo sul nome della run e del suo tag,\n",
    "almeno dovrei esser sicuro che comunque le runs associate all'uso dei dati di ALMENO \n",
    "una certa condizione sperimentale vengano inserite nel relativo progetto su weight and biases...\n",
    "\n",
    "\n",
    "\n",
    "TUTTAVIA, \n",
    "\n",
    "****************************** ******************************\n",
    "ILLUMINAZIONE DEL POMERIGGIO DEL 04/03/2025: \n",
    "****************************** ******************************\n",
    "\n",
    "MI HA PORTATO A PENSARE A PROVARE A CAPIRE ANCORA SE RIESCO A RISOLVERE IL PROBLEMA ...\n",
    "'''\n",
    "\n",
    "\n",
    "#VERSIONE NUOVA!\n",
    "\n",
    "#Fase 2: Creazione della funzione di 'training_sweep' \n",
    "    \n",
    "'''Questa funzione parse_combination_key serve per estrarre \n",
    "le varie stringhe che compongono la combinazioni di fattori (condizione sperimentale, tipo di dato EEG e provenienza del dato EEG) \n",
    "che si riferiscono allo sweep ID corrente.\n",
    "\n",
    "Esempio:\n",
    "\n",
    "Lo tupla sweep (sweep ID, combinazioni di fattori in stringa) è la seguente:\n",
    "\n",
    "Inizio l'agent per sweep_id: ('4u94ovth', 'pt_resp_vs_shared_resp_wavelet_unfamiliar_pt') dove\n",
    "- sweep ID: 4u94ovth\n",
    "- combinazioni di fattori in stringa: pt_resp_vs_shared_resp_wavelet_unfamiliar_pt\n",
    "\n",
    "Di conseguenza, quando avvio l'agent per quella condizione sperimentale nel loop, \n",
    "dentro la funzione di 'training_sweep' io prenderò in input la tupla\n",
    "\n",
    "\n",
    "\"\"\" Esegue il training per uno specifico sweep \"\"\"\n",
    "\n",
    "def training_sweep(data_dict_preprocessed, sweep_config, sweep_ids, sweep_id, sweep_tuple, best_models): \n",
    "\n",
    "sweep_id, combination_key = sweep_tuple\n",
    "exp_cond, data_type, category_subject = parse_combination_key(combination_key)\n",
    "\n",
    "\n",
    "E lui estrarrà la combinazione di fattori che la compongono, in questo caso è \n",
    "\n",
    "1) Condizione Sperimentale = pt_resp_vs_shared_resp\n",
    "2) Tipo di Dato EEG = wavelet\n",
    "3) Provenienza del Tipo di Dato EEG unfamiliar_pt\n",
    "\n",
    "Successivamente, confronta se questa combinazione di stringhe si trova dentro la mia struttura dati e, se la trova\n",
    "\n",
    "1) creerà il progetto con il nome della condizione sperimentale combaciante tra \n",
    " \n",
    " - la combination_key associata allo Sweep ID corrente e\n",
    " - il sottodizionario di data_dict_preprocessed \n",
    " \n",
    "2) le relative run di quello specifico Sweep, verranno nominate con la combinazioni di fattori combaciante su W&B\n",
    "\n",
    "3) Esegue e gestisce il salvataggio della migliore configurazione di iper-parametri del relativo modello preso in esame (CNN1D, BiLSTM e Transformer)\n",
    "   tra le 15 runs di OGNI SWEEP\n",
    "   \n",
    "\n",
    "'''\n",
    "\n",
    "import re\n",
    "\n",
    "def parse_combination_key(combination_key):\n",
    "    \"\"\"\n",
    "    Estrae condition_experiment e subject_key da combination_key\n",
    "    dove il data_type è fisso a \"spectrograms\".\n",
    "    \n",
    "    Esempio di chiave: \n",
    "    \"pt_resp_vs_shared_resp_spectrograms_familiar_th\"\n",
    "    \"\"\"\n",
    "    match = re.match(\n",
    "        r\"^(rest_vs_left_fist|rest_vs_right_fist|left_fist_vs_right_fist)_spectrograms_(familiar_th|familiar_pt|unfamiliar_th|unfamiliar_pt)$\",\n",
    "        combination_key\n",
    "    )\n",
    "    if match:\n",
    "        condition_experiment = match.group(1)\n",
    "        subject_key = match.group(2)\n",
    "        return condition_experiment, subject_key\n",
    "    else:\n",
    "        raise ValueError(f\"Formato non valido: {combination_key}\")\n",
    "        \n",
    "        \n",
    "def training_sweep(data_dict_preprocessed, sweep_config, sweep_ids, sweep_id, sweep_tuple, best_models): \n",
    "    \n",
    "    # Per ogni sweep, che viene iterato nel loop, io prendo \n",
    "    #1) la stringa univoca dello Sweep ID\n",
    "    #2) la sua combinazione di fattori stringa (che mi serviranno per prelevare il dato corrispondente da 'data_dict_preprocessed'\n",
    "    \n",
    "    sweep_id, combination_key = sweep_tuple\n",
    "    \n",
    "    # Ora la funzione restituisce solo (exp_condition, subject_key)\n",
    "    exp_cond, category_subject = parse_combination_key(combination_key)\n",
    "    \n",
    "    # Poiché ora i dati sono solo di tipo \"spectrograms\", li impostiamo in modo fisso:\n",
    "    data_type = \"spectrograms\"\n",
    "\n",
    "    if not (exp_cond in data_dict_preprocessed and category_subject in data_dict_preprocessed[exp_cond][data_type]):\n",
    "        raise ValueError(f\"❌ ERRORE - Combinazione \\033[1mNON TROVATA\\033[0m in data_dict_preprocessed: \\033[1m{exp_cond}\\033[0m, \\033[1m{category_subject}\\033[0m\")\n",
    "    \n",
    "\n",
    "    run_name = f\"{exp_cond}_{data_type}_{category_subject}\"\n",
    "    \n",
    "    tags = [exp_cond, data_type, category_subject]\n",
    "\n",
    "    #Inizializza la run dello specifico Sweep dentro Weights & Biases (W&B) con\n",
    "\n",
    "    #1) un nome del progetto pari alla condizione sperimentale corrente\n",
    "    #2) il nome e tag della run in base alla combinazione di fattori corrispondente\n",
    "    #3) la congiurazione di iper-parametri è pari a quella passata in input a 'training_sweep'\n",
    "\n",
    "    #Vedi questo link su wandb.init() per vedere i suoi parametri --> #https://docs.wandb.ai/ref/python/init/\n",
    "    \n",
    "    # Inizializza la run in W&B nel progetto che termina con \"_spectrograms\"\n",
    "    \n",
    "    '''OCCHIO QUI CAMBIATO'''\n",
    "        \n",
    "    wandb.init(project=f\"{exp_cond}_spectrograms_channels_freqs_new_3d_grid_multiband\", name=run_name, tags=tags)\n",
    "\n",
    "    print(f\"\\nCreo wandb project per: \\033[1m{exp_cond}_spectrograms\\033[0m\")\n",
    "    print(f\"Lo sweep corrente è \\033[1m{sweep_tuple}\\033[0m\")\n",
    "    print(f\"\\nInizio addestramento sul dataset \\033[1m{exp_cond}\\033[0m con dati EEG \\033[1m{data_type}\\033[0m di \\033[1m{category_subject}\\033[0m\")\n",
    "\n",
    "    # Parametri dell'esperimento presi da wandb\n",
    "    config = wandb.config\n",
    "\n",
    "    # Recupera i dati pre-processati per la combinazione corrente una volta verificata l'esatta corrispondenza tra:\n",
    "    #1)il combination_key dello sweep\n",
    "    #2)l'esistenza di specifico dataset con le stesse 'combination_key' dentro data_dict_preprocessed\n",
    "\n",
    "    try:\n",
    "        X_train, X_val, X_test, y_train, y_val, y_test = data_dict_preprocessed[exp_cond][data_type][category_subject]\n",
    "        print(f\"\\nCarico i dati di \\033[1m{exp_cond}\\033[0m, \\033[1m{data_type}\\033[0m, \\033[1m{category_subject}\\033[0m\")\n",
    "        print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "        print(f\"X_val shape: {X_val.shape}, y_val shape: {y_val.shape}\")\n",
    "        print(f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\\n\")\n",
    "    except KeyError:\n",
    "        raise ValueError(f\"❌ ERRORE - Combinazione \\033[1mNON TROVATA\\033[0m in data_dict_preprocessed: \\033[1m{exp_cond}\\033[0m, \\033[1m{data_type}\\033[0m, \\033[1m{category_subject}\\033[0m\")\n",
    "\n",
    "\n",
    "    if config.standardization:\n",
    "        # Standardizzazione\n",
    "        X_train, X_val, X_test = standardize_data(X_train, X_val, X_test)\n",
    "        print(f\"\\nUso DATI \\033[1mSTANDARDIZZATI\\033[0m!\")\n",
    "    else:\n",
    "        print(f\"\\nUso DATI \\033[1mNON STANDARDIZZATI\\033[0m!\")\n",
    "\n",
    "    # Preparazione dei dataloaders (N.B. prendo uno dei modelli considerati dentro config.model_name)\n",
    "    train_loader, val_loader, test_loader, class_weights_tensor = prepare_data_for_model(\n",
    "        X_train, X_val, X_test, y_train, y_val, y_test, model_type=config.model_name, batch_size = config.batch_size\n",
    "    )\n",
    "\n",
    "    #Qui estraggo il relativo modello su cui sto iterando al momento corrente e lo inizializzo\n",
    "\n",
    "        \n",
    "    # Inizializza il modello in base al valore scelto in config.model_name\n",
    "    #if config.model_name == \"CNN2D\":\n",
    "    #    model = CNN2D(input_channels=64, num_classes=2)\n",
    "    #    print(f\"\\nInizializzazione Modello \\033[1mCNN2D\\033[0m\")\n",
    "    \n",
    "    '''OCCHIO QUI CAMBIATO'''\n",
    "    #class CNN2D_LSTM_FC(nn.Module):\n",
    "    #def __init__(self, n_freq=45, input_channels=64, num_classes = 2, dropout=0.2):\n",
    "    \n",
    "    if config.model_name == \"CNN3D_LSTM_FC\":\n",
    "        #model = CNN2D_LSTM_FC(n_freq =45, input_channels=64, num_classes=2, dropout=0.2)\n",
    "        \n",
    "        '''OCCHIO QUI CAMBIATO PER GRIGLIA 3D'''\n",
    "    \n",
    "        model = CNN3D_LSTM_FC(\n",
    "            num_classes=2,\n",
    "            dropout=config.dropout,\n",
    "            hidden_size=config.lstm_hidden,\n",
    "            use_lstm=config.use_lstm\n",
    "        )\n",
    "\n",
    "        print(f\"\\nInizializzazione Modello \\033[1mCNN3D_LSTM_FC\\033[0m\")\n",
    "    \n",
    "    \n",
    "    elif config.model_name == \"SeparableCNN2D_LSTM_FC\":\n",
    "        model = SeparableCNN2D_LSTM_FC(\n",
    "            num_classes=2,\n",
    "            dropout=config.dropout,\n",
    "            hidden_size=config.lstm_hidden,\n",
    "            use_lstm=config.use_lstm\n",
    "        )\n",
    "        print(f\"\\nInizializzazione Modello \\033[1mSeparableCNN2D_LSTM_FC\\033[0m\")\n",
    "    \n",
    "    #elif config.model_name == \"TopomapNet\":\n",
    "        #model = TopomapNet(\n",
    "            #input_channels=5,\n",
    "            #num_classes=2,\n",
    "            #base_channels=config.base_channels,\n",
    "            #use_lstm=config.use_lstm,\n",
    "            #lstm_hidden=config.lstm_hidden,\n",
    "            #dropout=config.dropout\n",
    "        #)\n",
    "        #print(f\"\\nInizializzazione Modello \\033[1mTopomapNet\\033[0m\")\n",
    "    else:\n",
    "        raise ValueError(f\"Modello sconosciuto: {config.model_name}\")\n",
    "        \n",
    "    #elif config.model_name == \"BiLSTM\":\n",
    "        # Qui, input_size = canali * frequenze = 3 * 38 = 78\n",
    "        #model = ReadMEndYou(input_size= 64 * 45, hidden_sizes=[24, 48, 62], output_size=2, bidirectional=True)\n",
    "        #print(f\"\\nInizializzazione Modello \\033[1mBiLSTM\\033[0m\")\n",
    "        \n",
    "    #elif config.model_name == \"Transformer\":\n",
    "        # Per il Transformer, passiamo anche i parametri channels e freqs per adattare l'embedding\n",
    "        #model = ReadMYMind(d_model=16, num_heads=4, num_layers=2, num_classes=2, channels=64, freqs=45)\n",
    "        #print(f\"\\nInizializzazione Modello \\033[1mTransformer\\033[0m\")\n",
    "\n",
    "        \n",
    "    #ORIGINAL VERSION OF TIME SERIES EEG DATA REPRESENTATION  \n",
    "    #def initialize_models():\n",
    "        #model_CNN = CNN1D(input_channels=3, num_classes=2)\n",
    "        #model_LSTM = ReadMEndYou(input_size=3, hidden_sizes=[24, 48, 62], output_size=2, bidirectional=True)\n",
    "        #model_Transformer = ReadMYMind(num_channels=3, seq_length=250, d_model=16, num_heads=4, num_layers=2, num_classes=2)\n",
    "        \n",
    "        #return model_CNN, model_LSTM, model_Transformer\n",
    "\n",
    "    '''\n",
    "    Cosa è cambiato rispetto alla tua versione\n",
    "    Optimizer Adam ora prende betas=(0.9,0.999) e eps=1e-8.\n",
    "\n",
    "    ReduceLROnPlateau posizionato subito dopo l’optimizer, chiamato su val_loss ogni epoca.\n",
    "\n",
    "    EarlyStopping con patience=12, mode='min' su val_loss.\n",
    "\n",
    "    Loop sulle epoche fino a config.n_epochs (100), senza limitare a 60.\n",
    "\n",
    "    Tutti i parametri di sweep_config (lr, weight_decay, n_epochs, patience, batch_size, standardization…) rimangono esposti e loggati.\n",
    "\n",
    "    In questo modo riproduci fedelmente il training descritto nel paper, senza stravolgere la tua pipeline di sweep.\n",
    "    '''\n",
    "    \n",
    "    '''OLD VERSION'''\n",
    "    #optimizer = optim.Adam(model.parameters(), lr=config.lr, weight_decay=config.weight_decay)\n",
    "    \n",
    "    '''NEW VERSION'''\n",
    "    optimizer = optim.Adam(\n",
    "        model.parameters(),\n",
    "        lr = config.lr,               # da sweep: es. [0.01,0.001,...]\n",
    "        betas = (config.beta1, config.beta2),          # paper\n",
    "        eps = config.eps,                    # paper\n",
    "        weight_decay=config.weight_decay\n",
    "    )\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss(weight = class_weights_tensor)\n",
    "    \n",
    "    '''NEW VERSION'''\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer,\n",
    "        mode ='min',      # monitoriamo val_loss\n",
    "        factor = 0.1,      # dimezza lr\n",
    "        patience = 8,      # 4 epoche di plateau\n",
    "        verbose = True\n",
    "    )\n",
    "    \n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "\n",
    "    # Parametri di training\n",
    "    n_epochs = config.n_epochs\n",
    "    patience = config.patience\n",
    "    \n",
    "    #early_stopping = EarlyStopping(patience=patience, mode='max')\n",
    "    \n",
    "    '''NEW VERSION'''\n",
    "    early_stopping = EarlyStopping(patience=patience, mode='min')\n",
    "    \n",
    "    best_model = None\n",
    "    max_val_acc = 0\n",
    "    best_epoch = 0\n",
    "\n",
    "    pbar = tqdm(range(n_epochs))\n",
    "\n",
    "    for epoch in pbar:\n",
    "        train_loss_tmp = []\n",
    "        correct_train = 0\n",
    "        y_true_train_list, y_pred_train_list = [], []\n",
    "\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            y_pred = model(x)\n",
    "            loss = criterion(y_pred, y.view(-1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss_tmp.append(loss.item())\n",
    "            _, predicted_train = torch.max(y_pred, 1)\n",
    "            correct_train += (predicted_train == y).sum().item()\n",
    "            y_true_train_list.extend(y.cpu().numpy())\n",
    "            y_pred_train_list.extend(predicted_train.cpu().numpy())\n",
    "\n",
    "        accuracy_train = correct_train / len(train_loader.dataset)\n",
    "        loss_train = np.mean(train_loss_tmp)\n",
    "\n",
    "        precision_train = precision_score(y_true_train_list, y_pred_train_list, average='weighted')\n",
    "        recall_train = recall_score(y_true_train_list, y_pred_train_list, average='weighted')\n",
    "        f1_train = f1_score(y_true_train_list, y_pred_train_list, average='weighted')\n",
    "        auc_train = roc_auc_score(y_true_train_list, y_pred_train_list, average='weighted')\n",
    "\n",
    "        loss_val_tmp = []\n",
    "        correct_val = 0\n",
    "        y_true_val_list, y_pred_val_list = [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for x, y in val_loader:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                y_pred = model(x)\n",
    "\n",
    "                loss = criterion(y_pred, y.view(-1))\n",
    "                loss_val_tmp.append(loss.item())\n",
    "                _, predicted_val = torch.max(y_pred, 1)\n",
    "\n",
    "                correct_val += (predicted_val == y).sum().item()\n",
    "                y_true_val_list.extend(y.cpu().numpy())\n",
    "                y_pred_val_list.extend(predicted_val.cpu().numpy())\n",
    "\n",
    "        accuracy_val = correct_val / len(val_loader.dataset)\n",
    "        loss_val = np.mean(loss_val_tmp)\n",
    "\n",
    "        wandb.log({\n",
    "            \"epoch\": epoch,\n",
    "            \"train_loss\": loss_train,\n",
    "            \"train_accuracy\": accuracy_train,\n",
    "            \"train_precision\": precision_train,\n",
    "            \"train_recall\": recall_train,\n",
    "            \"train_f1\": f1_train,\n",
    "            \"train_auc\": auc_train,\n",
    "            \"val_loss\": loss_val,\n",
    "            \"val_accuracy\": accuracy_val\n",
    "        })\n",
    "\n",
    "        if accuracy_val > max_val_acc:\n",
    "            max_val_acc = accuracy_val\n",
    "            best_epoch = epoch\n",
    "            best_model = cp.deepcopy(model)\n",
    "            \n",
    "        '''OLD VERSION'''\n",
    "        #early_stopping(accuracy_val)\n",
    "        #if early_stopping.early_stop:\n",
    "            #print(\"🛑 Early stopping attivato!\")\n",
    "            #break\n",
    "\n",
    "        '''NEW VERSION'''\n",
    "        scheduler.step(loss_val)\n",
    "        early_stopping(loss_val)\n",
    "        if early_stopping.early_stop:\n",
    "            print(f\"🛑 Early stopping attivato!\")\n",
    "            break\n",
    "\n",
    "        '''\n",
    "        Qui, si usa config.model_name tra le chiavi di best_models, \n",
    "        così che gestisca automaticamente il salvataggio del best model estratto dalla configurazione randomica di iper-parametri\n",
    "        della specifica run di un determinato sweep, che è relativa allo specifico modello correntemente estratto randomicamente dalla sweep_config!\n",
    "        \n",
    "        ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** *****\n",
    "        IMPORTANTISSIMO: COME SALVARSI LA MIGLIORE CONFIGURAZIONE DI IPER-PARAMETRI DI UN CERTO MODELLO, DI UN DATO DI UNA CERTA COMBINAZIONE DI FATTORI\n",
    "        (CONDIZIONE SPERIMENTALE, TIPO DI DATO, PROVENIENZA DEL DATO!)\n",
    "        ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** *****\n",
    "        \n",
    "        CHATGPT:\n",
    "        \n",
    "        Nei run eseguiti con W&B ogni esecuzione registra automaticamente la configurazione degli iper-parametri (tramite wandb.config) \n",
    "        insieme alle metriche e ai log. \n",
    "        Quindi, a meno che tu non abbia modificato il comportamento predefinito, \n",
    "        ogni run con il tuo sweep ha già la configurazione associata registrata nei run logs di W&B.\n",
    "\n",
    "        Tuttavia, per associare in modo “automatico” e diretto la migliore configurazione agli specifici modelli salvati in .pth, \n",
    "        potresti considerare di fare uno o più di questi aggiustamenti:\n",
    "\n",
    "        Salvare la configurazione nel dizionario dei best_models:\n",
    "        Quando aggiorni il dizionario best_models (cioè quando salvi il miglior modello per una determinata combinazione), \n",
    "        puoi salvare anche una copia della configurazione corrente. \n",
    "        \n",
    "        Ad esempio, potresti modificare il blocco in cui aggiorni best_models in questo modo:\n",
    "        \n",
    "        best_models[exp_cond][data_type][category_subject][config.model_name] = {\n",
    "            \"model\": cp.deepcopy(model),\n",
    "            \"max_val_acc\": accuracy_val,\n",
    "            \"best_epoch\": best_epoch,\n",
    "            \"config\": dict(config)  # Salva la configurazione degli iper-parametri\n",
    "        }\n",
    "        \n",
    "        In questo modo, ogni volta che un modello viene considerato il migliore per quella combinazione,\n",
    "        la sua configurazione sarà salvata insieme ai pesi.\n",
    "        Questo ti permetterà, in seguito, di sapere esattamente quali iper-parametri sono stati usati per ottenere quel modello.\n",
    "        \n",
    "        \n",
    "        In sintesi, se hai già usato wandb.config e hai loggato le configurazioni durante le run,\n",
    "        W&B le ha automaticamente salvate nei run logs. \n",
    "        \n",
    "        Se vuoi rendere più esplicita l'associazione tra il modello salvato (.pth) e la sua configurazione, \n",
    "        è utile modificare il tuo codice di TRAINING per salvare ANCHE \n",
    "        \n",
    "        1) il dizionario di configurazione insieme a \n",
    "        2) i pesi nel dizionario best_models oppure nei metadati del file salvato.\n",
    "        \n",
    "        Questo piccolo accorgimento ti consentirà di recuperare facilmente la configurazione ottimale per ogni modello salvato.\n",
    "        \n",
    "        OSSIA\n",
    "        Aggiungendo la chiave \"config\": dict(config) nel dizionario che memorizza il best model,\n",
    "        salvi anche la configurazione degli iper-parametri utilizzata in quella run.\n",
    "        \n",
    "        In questo modo, per ogni modello salvato (.pth) potrai recuperare facilmente sia i pesi che la configurazione ottimale che li ha generati.\n",
    "        \n",
    "        Questo approccio garantisce che ogni modello sia associato in modo esplicito al set di iper-parametri che ha prodotto le migliori performance, \n",
    "        rendendo più semplice il successivo confronto o la replica degli esperimenti.\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        \n",
    "        # ***** ATTENZIONE: CAMBIAMENTI ESEGUITI RISPETTO A PRIMA *****\n",
    "        #1)Al posto di salvarmi solo i migliori pesi (i.e.,  model_file = f\"{model_path}/{best_model_name}.pth\")\n",
    "        #  ora mi salvo anche la MIGLIORE configurazione di iper-parametri trovata rispetto alle 15 RUNS di un certo SWEEP\n",
    "        #  di un certo MODELLO, applicato su un DATASET con una SPECIFICA COMBINAZIONE DI FATTORI\n",
    "        #  condizione sperimentale, tipo di dato e provenienza del dato!\n",
    "        \n",
    "    \n",
    "\n",
    "        if best_models[exp_cond][data_type][category_subject][config.model_name][\"max_val_acc\"] == -float('inf'):\n",
    "\n",
    "            # Salvo il primo best_model per quella combinazione\n",
    "            best_models[exp_cond][data_type][category_subject][config.model_name] = {\n",
    "                \"model\": cp.deepcopy(model),\n",
    "                \"max_val_acc\": accuracy_val,\n",
    "                \"best_epoch\": epoch,\n",
    "                \n",
    "                #***** ATTENZIONE: CAMBIAMENTI ESEGUITI RISPETTO A PRIMA *****\n",
    "                #***** AGGIUNTA DELLA CHIAVE CONFIG CHE PRELEVA AUTOMATICAMENTE LA MIGLIORE CONFIGURAZIONE DI IPER-PARAMETRI DENTRO 'BEST_MODELS'\n",
    "                \n",
    "                # Salva la configurazione degli iper-parametri della migliore run di uno sweep \n",
    "                # in relazione ad un certo modello applicato su un dataset costituito da \n",
    "                # una certa combinazione di fattori: \n",
    "                # condizione sperimentale, tipo di dato EEG usato, provenienza del dato usato\n",
    "                \"config\": dict(config)  \n",
    "            }\n",
    "\n",
    "            best_model_name = f\"{config.model_name}_{exp_cond}_{data_type}_{category_subject}\"\n",
    "\n",
    "            model_path = os.path.join(base_dir, exp_cond, data_type, category_subject)\n",
    "\n",
    "            os.makedirs(model_path, exist_ok=True)\n",
    "            \n",
    "            #***** ATTENZIONE: CAMBIAMENTI ESEGUITI RISPETTO A PRIMA *****\n",
    "            #***** SALVATAGGIO DI UN FILE .PKL, CHE CONTIENE \n",
    "            \n",
    "            # I PESI E BIAS DEL MODELLO DERIVATO DALLA MIGLIORE CONFIGURAZIONE DI IPER-PARAMETRI OTTENUTA DALLA MIGLIORE RUN DI UN CERTO SWEEP\n",
    "            # IN RELAZIONE AD UN CERTO DATASET COSTITUITO DA UNA CERTA COMBINAZIONE DI FATTORI\n",
    "            \n",
    "            '''OLD VERSION (SOLO SALVATAGGIO PESI E BIAS DEL MODELLO!'''\n",
    "            #model_file = f\"{model_path}/{best_model_name}.pth\"\n",
    "            \n",
    "            model_file = f\"{model_path}/{best_model_name}.pkl\"\n",
    "            \n",
    "            '''OLD VERSION (SOLO SALVATAGGIO PESI E BIAS DEL MODELLO!'''\n",
    "            #torch.save(best_model.state_dict(), model_file)\n",
    "            \n",
    "            # Salva un dizionario contenente sia i pesi che la configurazione\n",
    "            torch.save({\n",
    "                \"state_dict\": best_model.state_dict(),\n",
    "                \"config\": dict(config)\n",
    "            }, model_file)\n",
    "\n",
    "            print(f\"Il modello \\n\\033[1m{best_model_name}\\033[0m verrà salvato in questa folder directory: \\n\\033[1m{model_file}\\033[0m\")\n",
    "\n",
    "            #Condizione di aggiornamento:\n",
    "            #Se l'accuracy corrente (accuracy_val) di quel modello di quello sweep supera il valore già salvato in best_models[...], \n",
    "            #allora aggiorniamo il dizionario e sovrascriviamo il file del best model, di quel modello, di quella combinazione di fattori.\n",
    "\n",
    "\n",
    "            # Puoi confrontare e salvare il modello solo se il nuovo è migliore\n",
    "\n",
    "\n",
    "            #Questo assicura che il salvataggio del modello avvenga solo se\n",
    "            #il nuovo modello ha un'accuratezza di validazione (max_val_acc) migliore \n",
    "            #rispetto a quella già memorizzata per la condizione specifica (exp_cond).\n",
    "\n",
    "            #In questo modo, si evita di sovrascrivere il modello salvato con uno peggiore\n",
    "\n",
    "\n",
    "            # Nuovo modello migliore per questa combinazione: aggiorna e sovrascrivi il file\n",
    "\n",
    "\n",
    "        elif accuracy_val > best_models[exp_cond][data_type][category_subject][config.model_name][\"max_val_acc\"]:\n",
    "                best_models[exp_cond][data_type][category_subject][config.model_name] = {\n",
    "                    \"model\": best_model,\n",
    "                    \"max_val_acc\": accuracy_val,\n",
    "                    \"best_epoch\": best_epoch,\n",
    "                    \n",
    "                    # Salva la configurazione degli iper-parametri della migliore run di uno sweep \n",
    "                    # in relazione ad un certo modello applicato su un dataset costituito da \n",
    "                    # una certa combinazione di fattori: \n",
    "                    # condizione sperimentale, tipo di dato EEG usato, provenienza del dato usato\n",
    "                    \"config\": dict(config)  \n",
    "                }\n",
    "                best_model_name = f\"{config.model_name}_{exp_cond}_{data_type}_{category_subject}\"\n",
    "                model_path = os.path.join(base_dir, exp_cond, data_type, category_subject)\n",
    "                os.makedirs(model_path, exist_ok=True)\n",
    "\n",
    "                print(f\"Il modello di questa folder directory:\\n\\033[1m{model_path}\\033[0m\")\n",
    "                print(f\"\\nHa un MIGLIORAMENTO!\")\n",
    "\n",
    "                '''OLD VERSION (SOLO SALVATAGGIO PESI E BIAS DEL MODELLO!'''\n",
    "                #model_file = f\"{model_path}/{best_model_name}.pth\"\n",
    "\n",
    "                model_file = f\"{model_path}/{best_model_name}.pkl\"\n",
    "\n",
    "                if os.path.exists(model_file):\n",
    "\n",
    "                    # Se il file esiste, stampiamo un messaggio di aggiornamento\n",
    "                    print(f\"\\n⚠️ ATTENZIONE: \\nIl modello \\033[1m{best_model_name}\\033[0m verrà AGGIORNATO in \\n\\033[1m{model_path}\\033[0m\")\n",
    "\n",
    "                    # Salva il miglior modello solo se è stato aggiornato\n",
    "                    \n",
    "                    '''OLD VERSION (SOLO SALVATAGGIO PESI E BIAS DEL MODELLO!'''\n",
    "                    #torch.save(best_model.state_dict(), model_file)\n",
    "\n",
    "                    # Salva un dizionario contenente sia i pesi che la configurazione\n",
    "                    torch.save({\n",
    "                        \"state_dict\": best_model.state_dict(),\n",
    "                        \"config\": dict(config)\n",
    "                    }, model_file)\n",
    "                    \n",
    "                    print(f\"\\nIl nome del modello AGGIORNATO è:\\n\\033[1m{best_model_name}\\033[0m\")\n",
    "\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "                #Condizione \"nessun miglioramento\":\n",
    "                #Se il modello corrente non migliora il best già salvato, viene semplicemente stampato un messaggio.\n",
    "\n",
    "                #Questa logica garantisce che per ogni combinazione il file .pth contenga \n",
    "                #sempre i pesi del miglior modello (secondo la validation accuracy) fino a quel momento.\n",
    "                #Adatta eventualmente i nomi delle variabili (es. accuracy_val vs max_val_acc) per essere coerente con il resto del tuo codice.\n",
    "        else:\n",
    "            ''''QUI VA RIDEFINITO LA MODEL_PATH (e anche se vuoi MODE_FILE) ALTRIMENTI IN QUESTO ELSE NON ESISTONO!'''\n",
    "\n",
    "            best_model_name = f\"{config.model_name}_{exp_cond}_{data_type}_{category_subject}\"\n",
    "            model_path = os.path.join(base_dir, exp_cond, data_type, category_subject)\n",
    "            model_file = f\"{model_path}/{best_model_name}.pth\"\n",
    "            print(f\"Nessun miglioramento per il modello \\033[1m{config.model_name}\\033[0m in \\n\\033[1m{model_path}\\033[0m, ossia \\n\\033[1m{model_file}\\033[0m\")\n",
    "\n",
    "    wandb.finish()\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    return best_models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786dde9c-d60d-4f02-ae6e-9539c6fd3904",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### **Weight & Biases Procedure Final Edits - EEG Spectrograms - Electrodes x Frequencies ONLY HYPER-PARAMS**\n",
    "#### **Sweep separati per ciascuno dei modelli CNN3D e CNN Sep**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ce1177-db99-4327-b014-8abfa01fa54d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "                                        QUI IL LOOP LO ESEGUO SU OGNI SINGOLO SWEEP DI OGNI COMBINAZIONE DI FATTORI!!!\n",
    "                                                            \n",
    "                                                                    VERSIONE C \n",
    "                                                                    \n",
    "                                                                    \n",
    "                                                W&B SWEEPS AND TRAING LAUNCH WITH MULTIPLE GPUs MANAGEMENT\n",
    "                                        \n",
    "Questa volta, invece, andiamo ad iterare rispetto a \n",
    "\n",
    "- sweep_tuple, che la tuple che contiene\n",
    "\n",
    "1) relativo codice stringa univoco dello Sweep ID\n",
    "2  la sua combination_key, che ri-associa allo Sweep ID la combinazione di fattori della relativa condizione sperimentale\n",
    "\n",
    "\n",
    "PRIMA FACEVO IN QUESTO MODO\n",
    "\n",
    "for sweep_id in sweep_ids[condition][data_type][category_subject]:\n",
    "    print(f\"\\033[1mInizio l'agent\\033[0m per sweep_id: \\033[1m{sweep_id}\\033[0m\")\n",
    "    \n",
    "ORA INVECE ITERO SULLA TUPLA!\n",
    "\n",
    "\n",
    "for condition in sweep_ids:\n",
    "    for data_type in sweep_ids[condition]:\n",
    "        for category_subject in sweep_ids[condition][data_type]:\n",
    "            for sweep_tuple in sweep_ids[condition][data_type][data_tuples]:\n",
    "        \n",
    "\n",
    "VERSIONE C (SEMPLIFICATA!)\n",
    "\n",
    "\n",
    "****** ****** ****** ****** ****** ****** ****** ****** ****** ****** ****** ****** ****** ****** ****** ****** ****** ****** ****** ****** ******\n",
    "\n",
    "SPIEGAZIONE\n",
    "\n",
    "GPU counter: Ho aggiunto un contatore (gpu_counter) che cicla tra le GPU disponibili. \n",
    "\n",
    "In questo modo, il primo sweep sarà eseguito sulla GPU 0, il secondo sulla GPU 1, e così via. \n",
    "Quando il contatore raggiunge il numero di GPU disponibili, torna a 0 per riusare la prima GPU.\n",
    "\n",
    "Rotazione delle GPU: All'interno del loop, per ogni sweep, viene assegnata una GPU diversa. \n",
    "Se ci sono più di 1 GPU, il contatore incrementa, e la variabile CUDA_VISIBLE_DEVICES cambia automaticamente per assegnare la GPU corretta.\n",
    "\n",
    "Esecuzione parallela: Ogni sweep viene eseguito su una GPU separata. Se ci sono 2 GPU, il primo sweep va su GPU 0, il secondo su GPU 1, il terzo su GPU 0, e così via.\n",
    "\n",
    "Risposta alla tua domanda:\n",
    "In questo modo, ogni sweep_id viene eseguito una sola volta, ma su GPU diverse (se disponibili). Non ci sono duplicati dello stesso sweep su entrambe le GPU.\n",
    "\n",
    "\n",
    "DOMANDE SUL NUOVO CODICE\n",
    "\n",
    "1) Gli sweep sono eseguiti già in parallelo giusto?\n",
    "No, in questo caso gli sweep non sono eseguiti in parallelo in modo esplicito tramite il codice che hai scritto.\n",
    "\n",
    "Anche se hai assegnato ciascun sweep a una GPU diversa, il codice esegue sequenzialmente ogni sweep, solo che li distribuisce su GPU differenti in modo rotazionale.\n",
    "Ogni volta che il ciclo passa ad un nuovo sweep, assegna un ID GPU e poi esegue l'agent su quella GPU. Non vengono eseguiti in parallelo a livello di codice.\n",
    "\n",
    "2) O semplicemente in questo modo faccio in modo di distribuire ogni sweep sull'altra GPU rispetto a quella usata dallo sweep precedente\n",
    "per \"ottimizzare\" il carico computazionale di ogni GPU?\n",
    "\n",
    "Esatto! Quello che stai facendo è distribuire i vari sweep su GPU diverse, assicurandoti che ogni sweep venga eseguito su una GPU separata (se ne hai di disponibili).\n",
    "Questo permette di ottimizzare l'uso delle risorse, evitando che una GPU venga sovraccaricata da più sweep. Se il numero di GPU disponibili è maggiore di 1, \n",
    "allora i sweep sono distribuiti sulle diverse GPU, ma ogni sweep sarà ancora eseguito singolarmente.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Sì, con il codice che hai fornito, stai distribuendo gli sweep tra le diverse GPU, in modo da ottimizzare il carico computazionale e non sovraccaricare una sola GPU.\n",
    "\n",
    "Dettaglio del funzionamento:\n",
    "Distribuzione delle GPU (rotazionale):\n",
    "\n",
    "Quando ci sono più di una GPU, il codice assegna a ciascun sweep una GPU diversa in modo rotazionale.\n",
    "\n",
    "Per ogni ciclo del loop, la variabile gpu_counter determina a quale GPU assegnare il prossimo sweep.\n",
    "\n",
    "Se ci sono 2 GPU, il primo sweep viene eseguito sulla GPU 0, il secondo sulla GPU 1, il terzo di nuovo sulla GPU 0, e così via.\n",
    "\n",
    "Gestione della GPU:\n",
    "\n",
    "Se hai più di una GPU, os.environ[\"CUDA_VISIBLE_DEVICES\"] imposta il dispositivo GPU corrente su cui il codice deve girare (GPU 0 o GPU 1). Questo permette di gestire quale GPU eseguirà l'addestramento per ciascun sweep.\n",
    "\n",
    "Quando num_gpus > 1, il codice alterna l'assegnazione della GPU per ogni sweep, evitando di sovraccaricare una singola GPU con troppe operazioni contemporaneamente.\n",
    "\n",
    "Ottimizzazione del carico computazionale:\n",
    "\n",
    "L'alternanza tra GPU successive per ciascun sweep aiuta a distribuire il carico in modo equilibrato, specialmente se il numero di sweep è alto.\n",
    "\n",
    "In pratica, se hai 2 GPU e 10 sweep da eseguire, ogni GPU eseguirà 5 sweep, evitando di saturare una singola GPU.\n",
    "\n",
    "Parallelizzazione effettiva:\n",
    "Nel tuo codice non c'è parallelismo vero e proprio tra le GPU (come quello che otterresti con DataParallel o DistributedDataParallel), ma piuttosto distribuisci gli sweep su GPU diverse. Ogni sweep è eseguito sequenzialmente su una GPU diversa, ma non stai parallelizzando il training dello stesso sweep su più GPU.\n",
    "\n",
    "Se volessi fare in modo che un singolo sweep fosse parallelizzato su più GPU (in modo che il lavoro venga diviso tra le GPU per uno stesso sweep), dovresti usare DataParallel o DistributedDataParallel, come descritto in precedenza. Ma in questo caso, ogni sweep è isolato e viene eseguito su una sola GPU, quindi non c'è un vero parallelismo dentro ogni singolo sweep.\n",
    "\n",
    "Domande che potrebbero sorgere:\n",
    "Gli sweep vengono eseguiti in parallelo?\n",
    "\n",
    "No, i sweep sono eseguiti uno alla volta, ma su GPU diverse. Quindi, mentre il primo sweep usa la GPU 0, il secondo usa la GPU 1 e così via. Ogni sweep viene gestito separatamente, ma sfrutti più GPU per parallelizzare l'esecuzione di più sweep contemporaneamente.\n",
    "\n",
    "La distribuzione delle GPU tra gli sweep è ottimizzata?\n",
    "\n",
    "Sì, stai bilanciando il carico computazionale tra le GPU, assegnando a ogni GPU uno sweep alternato. Se hai molte GPU, puoi ottimizzare ulteriormente distribuendo i sweep su più dispositivi.\n",
    "\n",
    "Se volessi parallelizzare più agenti W&B su diverse GPU, il codice che stai utilizzando sarebbe corretto, ma per ottimizzare ulteriormente i tempi di esecuzione, potresti prendere in considerazione anche l'utilizzo di tecniche come DataParallel o DistributedDataParallel per far sì che più GPU lavorino contemporaneamente sullo stesso sweep. Ma la logica che hai già implementato va bene per distribuire più sweep tra le GPU.\n",
    "\n",
    "Se hai bisogno di ulteriori dettagli su come implementare il parallelismo vero e proprio (inclusi DataParallel o DistributedDataParallel), fammi sapere!\n",
    "\n",
    "\n",
    "\n",
    "****** ****** ****** ****** ****** ****** ****** ****** ****** ****** ****** ****** ****** ****** ****** ****** ****** ****** ****** ****** ******\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "Per modificare il loop in modo che accetti i sweeps per ogni modello e gestisca correttamente\n",
    "l'esecuzione del training per ciascun modello con il relativo sweep, dobbiamo fare alcune modifiche.\n",
    "\n",
    "\n",
    "Modifiche principali:\n",
    "\n",
    "1) Funzione make_train_wrapper:\n",
    "La funzione dovrà essere adattata per passare correttamente la configurazione di sweep per ogni modello, \n",
    "invece di passare un'unica configurazione generica (sweep_config).\n",
    "\n",
    "2) Identificazione corretta del modello: \n",
    "Nel loop, per ogni combinazione (condition, data_type, category_subject)\n",
    "e per ogni modello (ad esempio, CNN3D_LSTM_FC e SeparableCNN2D_LSTM_FC), \n",
    "\n",
    "dobbiamo passare al wandb.agent il relativo sweep ID per il modello e la sua configurazione.\n",
    "\n",
    "3) Modifica della funzione make_train_wrapper per gestire ogni modello separatamente: \n",
    "Ogni modello avrà il proprio sweep e la propria configurazione.\n",
    "\n",
    "\n",
    "Spiegazione delle modifiche:\n",
    "\n",
    "1) Funzione make_train_wrapper:\n",
    "\n",
    "Adesso prende anche model_name per passare il relativo sweep_config dal dizionario sweep_config_dict.\n",
    "Passa il sweep_config corretto per ogni modello, a seconda del model_name passato nel ciclo.\n",
    "\n",
    "2) Dizionario sweep_config_dict:\n",
    "\n",
    "Ho creato un dizionario sweep_config_dict che associa ciascun modello (\"CNN3D_LSTM_FC\" e \"SeparableCNN2D_LSTM_FC\")\n",
    "alla sua configurazione di sweep (sweep_config_cnn3d e sweep_config_cnn_sep).\n",
    "Questo permette di usare la corretta configurazione per ogni modello.\n",
    "\n",
    "3) Modifica nel ciclo:\n",
    "\n",
    "Il ciclo ora scorre su model_name (i.e., i modelli CNN3D_LSTM_FC e SeparableCNN2D_LSTM_FC) \n",
    "per ogni combinazione di condition, data_type, category_subject.\n",
    "\n",
    "Per ogni modello, il relativo sweep viene creato ed eseguito.\n",
    "\n",
    "\n",
    "Risultato:\n",
    "Ora, per ogni combinazione di condition, data_type, e category_subject, \n",
    "il codice creerà e gestirà separatamente gli sweeps per ciascun modello,\n",
    "e li eseguirà utilizzando la funzione training_sweep con la relativa configurazione specifica per ogni modello.\n",
    "\n",
    "Questa modifica ti consente di avere il corretto flusso di lavoro per eseguire\n",
    "il training separato per ogni modello con la sua configurazione.\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "import time  # Importa il modulo time\n",
    "\n",
    "\n",
    "# Definiamo una funzione wrapper che \"cattura\" lo sweep_id e le altre variabili\n",
    "\n",
    "'''ATTENZIONE AGGIUNTO model_name tra i parametri di --> make_train_wrapper'''\n",
    "\n",
    "def make_train_wrapper(sweep_id, sweep_tuple, condition, data_type, category_subject, model_name):\n",
    "    def train_wrapper():\n",
    "\n",
    "        # Qui chiamiamo la funzione di training con i parametri appropriati\n",
    "        #print(f\"\\nSetto il training per lo Sweep ID \\033[1m{condition}_{data_type}_{category_subject}\\033[0m con sweep_id {sweep_id}\")\n",
    "        #print(f\"\\nSetting Up Training per lo Sweep ID \\033[1m{sweep_id}\\033[0m --> \\033[1m{combination_key}\\033[0m\")\n",
    "        \n",
    "        print(f\"\\nSetting Up Training per lo Sweep ID \\033[1m{sweep_id}\\033[0m --> \\033[1m{combination_key}\\033[0m, modello \\033[1m{model_name}\\033[0m\")\n",
    "        training_sweep(\n",
    "            data_dict_preprocessed, \n",
    "            sweep_config_dict[model_name], # Prendi la configurazione per il modello specifico\n",
    "            sweep_ids,\n",
    "            sweep_id,\n",
    "            sweep_tuple,\n",
    "            best_models  # Best models viene aggiornato all'interno della funzione\n",
    "        )\n",
    "    return train_wrapper\n",
    "                        \n",
    "\n",
    "# Dizionari di configurazione per ogni modello\n",
    "sweep_config_dict = {\n",
    "    \"CNN3D_LSTM_FC\": sweep_config_cnn3d,\n",
    "    \"SeparableCNN2D_LSTM_FC\": sweep_config_cnn_sep\n",
    "}\n",
    "\n",
    "# Verifica quante GPU sono disponibili\n",
    "num_gpus = torch.cuda.device_count()\n",
    "\n",
    "\n",
    "# Crea un contatore per assegnare un GPU diversa a ciascun sweep\n",
    "gpu_counter = 0\n",
    "\n",
    "# Registra il tempo di inizio\n",
    "start_time = time.time()\n",
    "\n",
    "for condition in sweep_ids:\n",
    "    for data_type in sweep_ids[condition]:\n",
    "        for category_subject in sweep_ids[condition][data_type]:\n",
    "            \n",
    "            for model_name in sweep_ids[condition][data_type][category_subject]:  # Aggiunto loop per il modello\n",
    "                \n",
    "                #for sweep_tuple in sweep_ids[condition][data_type][category_subject]:\n",
    "                \n",
    "                 for sweep_tuple in sweep_ids[condition][data_type][category_subject][model_name]:  # Itera sugli sweep per ciascun modello\n",
    "\n",
    "                    # Esegui l'unpacking della tupla per ottenere solo il primo elemento della tupla (sweep_id, combination_key)\n",
    "                    sweep_id, combination_key = sweep_tuple\n",
    "                    \n",
    "                    \n",
    "                    combination_key = f\"{condition}_{data_type}_{category_subject}\"\n",
    "                    \n",
    "                    # Un modo efficace per \"catturare\" il contesto (come sweep_id e le altre variabili) \n",
    "                    # per ogni iterazione è definire una funzione wrapper locale all'interno del ciclo\n",
    "                    # In questo modo, ogni volta che chiami l'agente, il wrapper avrà già i parametri specifici per quella combinazione\n",
    "\n",
    "\n",
    "                    # Se ci sono più di 1 GPU, assegna a ciascuna GPU uno sweep diverso\n",
    "                    if num_gpus > 1:\n",
    "\n",
    "                        '''ATTENZIONE AGGIUNTO model_name tra i parametri di --> make_train_wrapper''' \n",
    "                        \n",
    "                        # Assegna la GPU in modo rotazionale\n",
    "                        os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(gpu_counter)\n",
    "                        \n",
    "                        agent_function = make_train_wrapper(sweep_id, sweep_tuple, condition, data_type, category_subject, model_name)\n",
    "                    \n",
    "                        wandb.agent(sweep_id, function=make_train_wrapper(sweep_id, sweep_tuple, condition, data_type, category_subject, model_name), project=f\"{condition}_spectrograms_channels_freqs_new_3d_grid_multiband\", count=200)\n",
    "                        \n",
    "                        # Passa alla prossima GPU per il prossimo sweep\n",
    "                        gpu_counter = (gpu_counter + 1) % num_gpus\n",
    "\n",
    "                    else:\n",
    "                        \n",
    "                        # Se c'è una sola GPU, esegui il sweep sulla GPU 0\n",
    "                        os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "                        \n",
    "                        agent_function = make_train_wrapper(sweep_id, sweep_tuple, condition, data_type, category_subject, model_name)\n",
    "                        \n",
    "                        wandb.agent(sweep_id, function=make_train_wrapper(sweep_id, sweep_tuple, condition, data_type, category_subject, model_name), project=f\"{condition}_spectrograms_channels_freqs_new_3d_grid_multiband\", count=200)\n",
    "\n",
    "\n",
    "                    # Crea la funzione wrapper per l'agent\n",
    "                    '''COMMENTATO'''\n",
    "                    #agent_function = make_train_wrapper(sweep_id, sweep_tuple, condition, data_type, category_subject)\n",
    "\n",
    "\n",
    "                    # NOTA: non assegno il valore di wandb.agent a best_models, lascio che training_sweep aggiorni best_models internamente!\n",
    "                    '''DEVI INSERIRE PER L'AGENTE COME PARAMETRO IL NOME DELLA CONDIZIONE SPERIMENTALE DEL PROGETTO SU  W&B\n",
    "                       ALTRIMENTI CERCA LO SWEEP NEL PROGETTO SBAGLIATO '''\n",
    "\n",
    "                    print(f\"Inizio l'\\033[1magent\\033[0m per \\033[1msweep_id\\033[0m \\tN°: \\033[1m{sweep_tuple}\\033[0m\")\n",
    "\n",
    "                    '''COMMENTATO'''\n",
    "                    #wandb.agent(sweep_id, function=agent_function, project = f\"{condition}_spectrograms_channels_freqs_new_2d_grid_multiband_topomap\", count=15)\n",
    "\n",
    "                    print(f\"\\nLo sweep id corrente \\033[1m{sweep_id}\\033[0m ha la combinazione di fattori stringhe: \\033[1m{condition}; {data_type}; {category_subject}\\033[0m\\n\")\n",
    "\n",
    "                    torch.cuda.empty_cache()\n",
    "\n",
    "# Registra il tempo di fine\n",
    "end_time = time.time()\n",
    "\n",
    "# Calcola il tempo totale\n",
    "total_time = end_time - start_time\n",
    "hours = int(total_time // 3600)\n",
    "minutes = int((total_time % 3600) // 60)\n",
    "seconds = int(total_time % 60)\n",
    "\n",
    "# Stampa il tempo totale in formato leggibile\n",
    "print(f\"\\nTempo totale impiegato: \\033[1m{hours} ore, {minutes} minuti e {seconds} secondi\\033[0m.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55e4593-5874-4eb4-934d-3b99df0e8962",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Finito Training su W&B !')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3b800c-16b4-4a74-8b22-add0b3b25671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stampa il numero totale di sweeps\n",
    "print(f\"Numero totale di sweeps che verranno eseguiti: {total_sweeps}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f257c944-93de-4b26-bffe-2c7507b0fc28",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Impostazione **Recupero DL Optimized Models** con **Rappresentazione Frequenza-Elettrodi dei miei dati EEG** a seconda del Dataset del Task scelto\n",
    "\n",
    "\n",
    "Notebook **\"EEG Data Stats Descriptives & GradCam Checks\"**\n",
    "\n",
    "- Task 1: Motor Execution (Open and close right or left fist) - Unilateral - Runs 3, 7, 11 \n",
    "- Task 2: Motor Imagery (Imagine opening and closing right and left fists) - Unilateral - Runs 4, 8, 12 \n",
    "- Task 3: Motor Execution (Open and close both fists and feet) - Bilateral - Runs 5, 9, 13 \n",
    "- Task 4: Motor Imagery (Imagine opening and closing both fists and feet) - Bilateral - Runs 6, 10, 14 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9970a57-9132-435f-9fd7-d225a881a822",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Caricare l'intero dizionario annidato con pickle\n",
    "path = '/home/stefano/EEGMMIDB_Analyses/'\n",
    "\n",
    "# Caricare l'intero dizionario annidato con pickle\n",
    "#with open(f'{path_channels}ordered_electrodes.pkl', 'rb') as f:\n",
    "\n",
    "with open(f'{path}electrode_grid_map.pkl', 'rb') as f:\n",
    "    EEG_channels_names = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ca49fc-de19-49fa-b438-4fe57b376ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(EEG_channels_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a1cc20-44f6-4f9d-980f-9609ba10d50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# supponendo che EEG_channels_names sia la tua lista originale\n",
    "#EEG_channels_names = [ch.rstrip('.') for ch in EEG_channels_names]\n",
    "#print(EEG_channels_names, end = '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb0dbb8-16ce-4ae8-be60-55f8811a9ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(EEG_channels_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56dfdf7-f620-43e1-9cf6-5d9757e5fbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(EEG_channels_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b072afb-50e1-4785-83c2-cbdb669ca79a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "EEG_channels_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323752f6-70b7-42d6-9876-843e8a070223",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### **Weight & Biases Login & REMOTE CHECKS - EEG Spectrograms - Electrodes x Frequencies**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ac7f94-dff8-4489-9edb-515fde6a3cd1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### **Weight & Biases Login PRECEDURA CORRETTA ✅ (CANCELLAZIONE RUNS e NON SWEEPS!) - EEG Spectrograms - Electrodes x Frequencies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fa2b77-1573-4df2-8737-da7d537b856b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Puoi usare l’API Python di W&B per elencare da remoto tutti i progetti di una certa entity (tuo utente o organizzazione).\n",
    "\n",
    "Ad esempio:\n",
    "\n",
    "'''\n",
    "\n",
    "import wandb\n",
    "\n",
    "# 1) autenticati (se non l’hai già fatto con wandb.login())\n",
    "# wandb.login()\n",
    "\n",
    "# 2) crea un’istanza dell’API\n",
    "api = wandb.Api()\n",
    "\n",
    "# 3) scegli la tua entity (nome utente o org). \n",
    "#    Se omesso, prende la tua entity di default.\n",
    "\n",
    "entity = 'stefano-bargione-universit-di-roma-tor-vergata'\n",
    "\n",
    "# 4) prendi la lista dei progetti\n",
    "projects = api.projects(entity=entity)\n",
    "\n",
    "# 5) stampa i nomi\n",
    "for proj in projects:\n",
    "    print(proj.name)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "798e8068-1271-4211-8e8d-7872cace357e",
   "metadata": {
    "tags": []
   },
   "source": [
    "###TUTTE ASSIEME\n",
    "\n",
    "\n",
    "import wandb\n",
    "\n",
    "# Nomi dei progetti\n",
    "project_names = [\n",
    "    'left_fist_vs_right_fist_spectrograms_channels_freqs_params_hyperparams',\n",
    "    'rest_vs_right_fist_spectrograms_channels_freqs_params_hyperparams',\n",
    "    'rest_vs_left_fist_spectrograms_channels_freqs_params_hyperparams'\n",
    "]\n",
    "\n",
    "user_name = 'stefano-bargione-universit-di-roma-tor-vergata'\n",
    "\n",
    "# Connessione all'API di W&B\n",
    "api = wandb.Api()\n",
    "\n",
    "# Itera su tutti i progetti\n",
    "for project_name in project_names:\n",
    "    print(f\"\\nSelezione delle run per il progetto: \\033[1m{project_name}\\033[0m\")\n",
    "    \n",
    "    # Recupera tutte le run del progetto\n",
    "    runs = api.runs(f\"{user_name}/{project_name}\")\n",
    "    \n",
    "    # Salva gli ID delle run da eliminare\n",
    "    run_ids_to_delete = []\n",
    "    \n",
    "    for run in runs:\n",
    "        #print(f\"Estrazione run ID: {run.id} - Run Name: {run.name}\")\n",
    "        run_ids_to_delete.append(run.id)  # Aggiungi l'ID della run alla lista\n",
    "    \n",
    "    print(f\"\\nTotale runs da eliminare: \\033[1m{len(run_ids_to_delete)}\\033[0m\")\n",
    "    \n",
    "    # Elimina le run\n",
    "    for run_id in run_ids_to_delete:\n",
    "        run = api.run(f\"{user_name}/{project_name}/{run_id}\")\n",
    "        run.delete()  # Elimina la run\n",
    "        #print(f\"Eliminata la run con ID: {run_id}\")\n",
    "    print(f\"Eliminazione runs completata\")\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad78ac73-740b-4d30-a314-f7ad225e8b63",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### **Weight & Biases Procedure FINAL SEQUENCE OF STEPS - EEG Spectrograms - Electrodes x Frequencies ONLY HYPER-PARAMS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e23988-9245-4a61-ba21-eab035629b30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Library Importing \n",
    "    \n",
    "import os\n",
    "import math\n",
    "import copy as cp \n",
    "\n",
    "import tqdm\n",
    "from tqdm import tqdm\n",
    "\n",
    "import random \n",
    "\n",
    "#import mne \n",
    "import scipy\n",
    "\n",
    "import numpy as np  # NumPy per operazioni numeriche\n",
    "import matplotlib.pyplot as plt  # Matplotlib per la visualizzazione dei dati\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import random\n",
    "\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e551093c-c964-440b-b63c-76cdf0058085",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '/home/stefano/Interrogait/all_datas/Spectrograms_channels_frequencies_motor_tasks/'\n",
    "\n",
    "# Controlla se la cartella esiste, altrimenti la crea\n",
    "if not os.path.exists(base_path):\n",
    "    os.makedirs(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c87dac-077d-40a9-b26d-54cc32d357a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Caricare l'intero dizionario annidato con pickle\n",
    "with open(f'{base_path}new_all_th_concat_spectrograms_coupled_exp_task_1_2d_grid_multiband.pkl', 'rb') as f:\n",
    "    new_all_th_concat_spectrograms_coupled_exp_task_1 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826f842e-6961-4c84-a336-4fe74b2e0c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_all_th_concat_spectrograms_coupled_exp_task_1.keys() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4f96a5-ae09-4586-b254-3dc93978f141",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_all_th_concat_spectrograms_coupled_exp_task_1['rest_vs_left_fist'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87ba32c-7f6f-4c27-af91-343a1d300a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new_all_th_concat_spectrograms_coupled_exp_task_1['rest_vs_left_fist']['data'].shape)\n",
    "print()\n",
    "print(new_all_th_concat_spectrograms_coupled_exp_task_1['rest_vs_right_fist']['data'].shape)\n",
    "print()\n",
    "print(new_all_th_concat_spectrograms_coupled_exp_task_1['left_fist_vs_right_fist']['data'].shape)\n",
    "print()\n",
    "print(np.unique(new_all_th_concat_spectrograms_coupled_exp_task_1['rest_vs_left_fist']['labels'], return_counts = True))\n",
    "print()\n",
    "print(np.unique(new_all_th_concat_spectrograms_coupled_exp_task_1['rest_vs_right_fist']['labels'], return_counts = True))\n",
    "print()\n",
    "print(np.unique(new_all_th_concat_spectrograms_coupled_exp_task_1['left_fist_vs_right_fist']['labels'], return_counts = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0dad8e-06f6-4fc4-94ed-21bb6e8ff798",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### **Utils Functions - EEG Spectrograms - Electrodes x Frequencies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7effe9-4fd7-4f75-8d33-331539e76002",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "QUI DENTRO HO CONFIGURATO \n",
    "LE FUNZIONI DI CONTROLLO DELLE STRINGHE \n",
    "PER IL SALVATAGGIO DELLE PERFORMANCE DEL MODELLO\n",
    "NELLE RELATIVE SUBFOLDERS\n",
    "\n",
    "(I.E., get_subfolder_from_key, get_subfolder_from_key_hyper)\n",
    "\n",
    "IN MODO CHE SI LEGHINO ALLA CHIAVE 'STANDARDIZATION' DELL'OGGETTO SWEEP_CONFIG\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def load_data(data_type, category, subject_type, condition = \"th_resp_vs_pt_resp\"):\n",
    "    \"\"\"\n",
    "    Carica i dati EEG dalla directory appropriata, già salvati con la finestra temporale (0°-640° punto)\n",
    "\n",
    "    Parameters:\n",
    "    - data_type: str, \"spectrograms\",\n",
    "    - category: str, \"task_1\"\n",
    "    - subject_type: str, \"th\" (terapisti)\n",
    "    - condition: str, condizione sperimentale da selezionare\n",
    "    \n",
    "\n",
    "    Returns:\n",
    "    - X: Dati EEG sotto-selezionati (50°-300° punto e canali selezionati se applicabile)\n",
    "    - y: Etichette corrispondenti\n",
    "    \"\"\"\n",
    "\n",
    "    # Definizione dei percorsi base\n",
    "    base_paths = {\n",
    "        \"spectrograms\": {\n",
    "            \"familiar\": \"/home/stefano/Interrogait/all_datas/Spectrograms_channels_frequencies_motor_tasks/\"\n",
    "            #\"unfamiliar\": \"/home/stefano/Interrogait/all_datas/Unfamiliar_Spectrograms/\"\n",
    "        },\n",
    "    }\n",
    "\n",
    "    # Seleziona il path corretto\n",
    "    base_path = base_paths[data_type][category]\n",
    "\n",
    "    # Determina il nome del file corretto\n",
    "    if data_type in [\"spectrograms\"]:\n",
    "        filename = f\"new_all_{subject_type}_concat_spectrograms_coupled_exp_task_1_2d_grid_multiband.pkl\"\n",
    "    else:\n",
    "        raise ValueError(\"data_type non valido!\")\n",
    "        \n",
    "    # Caricamento del file\n",
    "    filepath = base_path + filename\n",
    "    \n",
    "    with open(filepath, \"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "    \n",
    "    '''\n",
    "    Per i dati spectrogram, la funzione seleziona la condizione desiderata (i.e., condition = \"th_resp_vs_pt_resp\") \n",
    "    e preleva i dati e le etichette associati a quella condizione.\n",
    "    '''\n",
    "    \n",
    "    # Selezione della finestra temporale e delle etichette\n",
    "    X = data[condition][\"data\"]\n",
    "    y = data[condition][\"labels\"]\n",
    "\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "\n",
    "def select_channels(data, channels=[12, 30, 48]):\n",
    "    \"\"\"\n",
    "    Seleziona i canali EEG specificati SOLO per i dati 1-20 e 1-45.\n",
    "\n",
    "    Parameters:\n",
    "    - data: array NumPy, dati EEG con shape (n_trials, n_channels, n_timepoints)\n",
    "    - channels: list, indici dei canali da selezionare\n",
    "\n",
    "    Returns:\n",
    "    - data filtrato sui canali specificati\n",
    "    \"\"\"\n",
    "    return data[:, channels, :]\n",
    "\n",
    "\n",
    "# Funzione per train-test split\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "\n",
    "def split_data(X, y, test_size=0.2, val_size=0.2):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=val_size, random_state=42)\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test\n",
    "\n",
    "'''ATTENZIONE CAMBIATA'''\n",
    "# Funzione per standardizzare i dati\n",
    "def standardize_data(X_train, X_val, X_test, eps = 1e-8):\n",
    "    \n",
    "    mean = X_train.mean(axis=0, keepdims=True)\n",
    "    std = X_train.std(axis=0, keepdims=True)\n",
    "    \n",
    "    X_train = (X_train - mean) / (std + eps)\n",
    "    X_val = (X_val - mean) / (std + eps)\n",
    "    X_test = (X_test - mean) / (std + eps)\n",
    "    \n",
    "    return X_train, X_val, X_test\n",
    "\n",
    "\n",
    "# Import modelli (definisci le classi CNN1D, ReadMEndYou, ReadMYMind)\n",
    "#from models import CNN1D, ReadMEndYou, ReadMYMind  # Assicurati di avere i modelli definiti in 'models.py'\n",
    "\n",
    "# Funzione per inizializzare i modelli\n",
    "def initialize_models():\n",
    "    #model = CNN1D(input_channels=3, num_classes=2)\n",
    "    model_CNN = CNN2D(input_channels = 61, num_classes=2)\n",
    "    #model_LSTM = ReadMEndYou(input_size=3, hidden_sizes=[24, 48, 62], output_size=2, bidirectional=True)\n",
    "    model_LSTM = ReadMEndYou(input_size=61 * 26, hidden_sizes=[24, 48, 62], output_size=2, bidirectional=True)\n",
    "    #model_Transformer = ReadMYMind(num_channels=3, seq_length=250, d_model=16, num_heads=4, num_layers=2, num_classes=2)\n",
    "    model_Transformer = ReadMYMind(d_model=16, num_heads=4, num_layers=2, num_classes=2, channels=61, freqs=26)\n",
    "    \n",
    "    return model_CNN, model_LSTM, model_Transformer\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "\n",
    "'''\n",
    "Questa funzione prende in input i dati di training, validation e test, \n",
    "il tipo di modello scelto e la dimensione del batch. Si occupa di:\n",
    "\n",
    "Calcolare i pesi delle classi.\n",
    "Convertire i dati in tensori PyTorch, con le opportune trasformazioni per CNN, LSTM o Transformer.\n",
    "Creare i dataset e i dataloader per il training.\n",
    "'''\n",
    "\n",
    "\n",
    "def prepare_data_for_model(X_train, X_val, X_test, y_train, y_val, y_test, model_type, batch_size=48):\n",
    "    \n",
    "    # Calcolo dei pesi delle classi\n",
    "    class_weights = compute_class_weight(class_weight='balanced', \n",
    "                                         classes=np.unique(y_train), \n",
    "                                         y=y_train)\n",
    "    \n",
    "    class_weights_tensor = torch.tensor(class_weights, dtype=torch.float32)\n",
    "    class_weights_tensor = class_weights_tensor.to(dtype=torch.float32, device=device)\n",
    "    \n",
    "    # Conversione delle etichette in interi\n",
    "    y_train = y_train.astype(int)\n",
    "    y_val = y_val.astype(int)\n",
    "    y_test = y_test.astype(int)\n",
    "    \n",
    "    # Conversione dei dati in tensori PyTorch con permutazione se necessario\n",
    "    \n",
    "    '''ATTENZIONE CAMBIATO QUI!'''\n",
    "    #if model_type == \"CNN2D\":\n",
    "    \n",
    "    if model_type == \"CNN2D_LSTM_FC\":\n",
    "        X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "        X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "        X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "    \n",
    "    elif model_type == \"TopomapNet\":\n",
    "        X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "        X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "        X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "    \n",
    "    elif model_type == \"CNN3D_LSTM_FC\":\n",
    "        X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "        X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "        X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "    \n",
    "    elif model_type == \"SeparableCNN2D_LSTM_FC\":\n",
    "        X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "        X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "        X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "\n",
    "    #BiLSTM (ReadMEndYou):\n",
    "    #Ora il modello si aspetta l’input con shape (batch, canali, frequenze, tempo) \n",
    "    #e, al suo interno, \n",
    "    #esegue la permutazione per avere il tempo come dimensione sequenziale. \n",
    "    #Non serve quindi applicare una permutazione anche qui.\n",
    "    \n",
    "    elif model_type == \"BiLSTM\":\n",
    "            \n",
    "        X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "        X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "        X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "    \n",
    "    #Transformer (ReadMYMind):\n",
    "    #Analogamente, il modello gestisce internamente la riorganizzazione dell’input, quindi lasciamo i dati nella loro forma originale.\n",
    "    elif model_type == \"Transformer\":\n",
    "        X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "        X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "        X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(\"Modello non riconosciuto. Scegli tra 'CNN', 'LSTM' o 'Transformer'.\")\n",
    "    \n",
    "    # Conversione delle etichette in tensori\n",
    "    y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "    y_val_tensor = torch.tensor(y_val, dtype=torch.long)\n",
    "    y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "    \n",
    "    # Creazione dei dataset\n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "    test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "    \n",
    "    # Creazione dei dataloader\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    return train_loader, val_loader, test_loader, class_weights_tensor\n",
    "\n",
    "\n",
    "'''\n",
    "OLD VERSIONS BEFORE GRADCAM COMPUTATION ON CNN2D\n",
    "\n",
    "# Funzione per determinare a quale subfolder appartiene la chiave\n",
    "def get_subfolder_from_key(key, model_standardization):\n",
    "    \n",
    "    #DEFINIZIONE DELLA PATH DOVE VIENE SALVATO IL FILE\n",
    "    if '_familiar_th' in key:\n",
    "        return 'th_fam'\n",
    "    elif '_unfamiliar_th' in key:\n",
    "        return 'th_unfam'\n",
    "    elif '_familiar_pt' in key:\n",
    "        return 'pt_fam'\n",
    "    elif '_unfamiliar_pt' in key:\n",
    "        return 'pt_unfam'\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "     \n",
    "# Funzione per salvare i risultati\n",
    "def save_performance_results(model_name, my_train_results, my_test_results, key, exp_cond, model_standardization, base_folder):\n",
    "    \"\"\"\n",
    "    Funzione che salva i risultati del modello in base alla combinazione di 'key' e 'model_name'.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Identificazione del subfolder in base alla chiave\n",
    "    subfolder = get_subfolder_from_key(key, model_standardization)\n",
    "    \n",
    "    # Debug: controllo sulla subfolder\n",
    "    print(f\"\\nDEBUG - Chiave: \\033[1m{key}\\033[0m, Subfolder ottenuto: \\033[1m{subfolder}\\033[0m\")\n",
    "    \n",
    "    if subfolder is None:\n",
    "        print(f\"Errore: La chiave \\033[1m{key}\\033[0m non corrisponde a nessun subfolder valido.\\n\")\n",
    "        return\n",
    "    \n",
    "    # Determinazione del tipo di dato direttamente dalla chiave\n",
    "    if \"spectrograms\" in key:\n",
    "        data_type_str = \"spectrograms\"\n",
    "    else:\n",
    "        print(f\"Errore: Tipo di dato non riconosciuto nella chiave '{key}'.\")\n",
    "        return\n",
    "\n",
    "    # Creazione del nome del file con l'inclusione della combinazione key + model_name\n",
    "    if model_standardization:\n",
    "        file_name = f\"{model_name}_performances_{exp_cond}_{data_type_str}_{subfolder}_std.pkl\"\n",
    "        folder_path = os.path.join(base_folder, exp_cond, data_type_str, subfolder)\n",
    "        \n",
    "    else:\n",
    "        file_name = f\"{model_name}_performances_{exp_cond}_{data_type_str}_{subfolder}.pkl\"\n",
    "        folder_path = os.path.join(base_folder, exp_cond, data_type_str, subfolder)\n",
    "    \n",
    "    # Verifica se la cartella di destinazione esiste, altrimenti creala\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "    \n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "    # Creazione del dizionario con i risultati\n",
    "    results_dict = {\n",
    "        \n",
    "        'my_train_results': my_train_results,\n",
    "        'my_test_results': my_test_results\n",
    "    }\n",
    "\n",
    "    # Salvataggio del dizionario con i risultati\n",
    "    try:\n",
    "        with open(file_path, 'wb') as f:\n",
    "            pickle.dump(results_dict, f)\n",
    "        print(f\"\\nRisultati salvati con successo 👍 in: \\n\\033[1m{file_path}\\033[0m\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌Errore durante il salvataggio dei risultati: {e}\")\n",
    "'''\n",
    "\n",
    "\n",
    "#NEW VERSIONS FOR SPECTROGRAMS WITH GRADCAM COMPUTATION ON CNN2D!\n",
    "\n",
    "# Funzione per determinare a quale subfolder appartiene la chiave\n",
    "def get_subfolder_from_key(key, model_standardization):\n",
    "    \n",
    "    #DEFINIZIONE DELLA PATH DOVE VIENE SALVATO IL FILE\n",
    "    if '_familiar_th' in key:\n",
    "        return 'th_fam'\n",
    "    elif '_unfamiliar_th' in key:\n",
    "        return 'th_unfam'\n",
    "    elif '_familiar_pt' in key:\n",
    "        return 'pt_fam'\n",
    "    elif '_unfamiliar_pt' in key:\n",
    "        return 'pt_unfam'\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "import io\n",
    "import pickle\n",
    "import os\n",
    "     \n",
    "# Funzione per salvare i risultati\n",
    "def save_performance_results(model_name, \n",
    "                             my_train_results,\n",
    "                             my_test_results, \n",
    "                             key,\n",
    "                             exp_cond,\n",
    "                             model_standardization,\n",
    "                             base_folder,\n",
    "                             gradcam_image = None):\n",
    "    \"\"\"\n",
    "    Funzione che salva i risultati del modello in base alla combinazione di 'key' e 'model_name'.\n",
    "    Se gradcam_image è fornita, la salva anche in formato PNG con un nome che inizia con 'GradCAM_results'.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Identificazione del subfolder in base alla chiave\n",
    "    subfolder = get_subfolder_from_key(key, model_standardization)\n",
    "    \n",
    "    # Debug: controllo sulla subfolder\n",
    "    print(f\"\\nDEBUG - Chiave: \\033[1m{key}\\033[0m, Subfolder ottenuto: \\033[1m{subfolder}\\033[0m\")\n",
    "    \n",
    "    if subfolder is None:\n",
    "        print(f\"Errore: La chiave \\033[1m{key}\\033[0m non corrisponde a nessun subfolder valido.\\n\")\n",
    "        return\n",
    "    \n",
    "    # Determinazione del tipo di dato direttamente dalla chiave\n",
    "    if \"spectrograms\" in key:\n",
    "        data_type_str = \"spectrograms\"\n",
    "    else:\n",
    "        print(f\"Errore: Tipo di dato non riconosciuto nella chiave '{key}'.\")\n",
    "        return\n",
    "\n",
    "    # Creazione del nome del file pickle con l'inclusione della combinazione key + model_name\n",
    "    if model_standardization:\n",
    "        \n",
    "        '''AGGIUNGO _multiband ALLA FINE PER DISTINGUERE DA QUELLI TOTAL POWER'''\n",
    "        \n",
    "        file_name = f\"{model_name}_performances_{exp_cond}_{data_type_str}_{subfolder}_std_3d_multiband.pkl\"\n",
    "        folder_path = os.path.join(base_folder, exp_cond, data_type_str, subfolder)\n",
    "    else:\n",
    "        file_name = f\"{model_name}_performances_{exp_cond}_{data_type_str}_{subfolder}_3d_multiband.pkl\"\n",
    "        folder_path = os.path.join(base_folder, exp_cond, data_type_str, subfolder)\n",
    "    \n",
    "    # Verifica se la cartella di destinazione esiste, altrimenti creala\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "    \n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "    # Creazione del dizionario con i risultati\n",
    "    results_dict = {\n",
    "        'my_train_results': my_train_results,\n",
    "        'my_test_results': my_test_results\n",
    "    }\n",
    "\n",
    "    # Salvataggio del dizionario con i risultati\n",
    "    try:\n",
    "        with open(file_path, 'wb') as f:\n",
    "            pickle.dump(results_dict, f)\n",
    "        print(f\"\\n🔬Risultati salvati con successo 👍 in: \\n\\033[1m{file_path}\\033[0m\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌Errore durante il salvataggio dei risultati: {e}\")\n",
    "    \n",
    "    # Se è stata fornita l'immagine GradCAM, salvala come file PNG\n",
    "    if gradcam_image is not None:\n",
    "        if model_standardization:\n",
    "            \n",
    "            '''AGGIUNGO _multiband ALLA FINE PER DISTINGUERE DA QUELLI TOTAL POWER'''\n",
    "            \n",
    "            gradcam_file_name = f\"GradCAM_results_{model_name}_{exp_cond}_{data_type_str}_{subfolder}_std_3d_multiband.png\"\n",
    "        else:\n",
    "            gradcam_file_name = f\"GradCAM_results_{model_name}_{exp_cond}_{data_type_str}_{subfolder}_3d_multiband.png\"\n",
    "        \n",
    "        gradcam_file_path = os.path.join(folder_path, gradcam_file_name)\n",
    "        \n",
    "        #try:\n",
    "        #    with open(gradcam_file_path, \"wb\") as f_img:\n",
    "        #        f_img.write(gradcam_image)\n",
    "        #    print(f\"\\n📸Immagine GradCAM salvata con successo 👍 in: \\n\\033[1m{gradcam_file_path}\\033[0m\\n\")\n",
    "        \n",
    "        try:\n",
    "            \n",
    "            '''\n",
    "            Se gradcam_image è un oggetto BytesIO, allora rappresenta un flusso di dati binari in memoria.\n",
    "            Quando si leggono dati da un BytesIO, il cursore interno avanza come in un file normale. \n",
    "            Se il cursore non è all'inizio, Image.open() potrebbe non leggere correttamente l'immagine.\n",
    "            👉 seek(0) riporta il cursore all'inizio del buffer prima di leggerlo con Image.open()\n",
    "            \n",
    "            Per maggior info leggi cella successiva!\n",
    "            '''\n",
    "            \n",
    "            # 🔄 Se gradcam_image è un buffer, convertirlo in immagine PIL\n",
    "            if isinstance(gradcam_image, io.BytesIO):\n",
    "                gradcam_image.seek(0)  # 🔄 Reset puntatore del buffer\n",
    "                gradcam_image = Image.open(gradcam_image)\n",
    "            \n",
    "            '''\n",
    "            Il messaggio di errore indica che il tuo oggetto gradcam_image è di tipo bytes e non ha il metodo save(), \n",
    "            che è tipico di un oggetto PIL. \n",
    "            \n",
    "            Per risolvere questo, devi convertire i byte in un'immagine PIL. \n",
    "            Per farlo, controlla se gradcam_image sia un oggetto di tipo bytes e,\n",
    "            in tal caso, usa io.BytesIO per creare un buffer da passare a Image.open(). \n",
    "            \n",
    "            Inserisci questa conversione all'interno del blocco che salva l'immagine, così da assicurarti che,\n",
    "            indipendentemente dal tipo, gradcam_image diventi un oggetto PIL e possa chiamare il metodo save().\n",
    "            '''\n",
    "            \n",
    "            if isinstance(gradcam_image, bytes):\n",
    "                gradcam_image = io.BytesIO(gradcam_image)\n",
    "                gradcam_image.seek(0)\n",
    "                gradcam_image = Image.open(gradcam_image)\n",
    "            \n",
    "            \n",
    "            print(f\"\\n📸Immagine \\033[1mGradCAM salvata\\033[0m con successo 👍 in: \\n\\033[1m{gradcam_file_path}\\033[0m\\n\")\n",
    "            # 🔄 Salvare l'immagine nel percorso specificato\n",
    "            gradcam_image.save(gradcam_file_path, format = \"PNG\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌Errore durante il salvataggio dell'immagine GradCAM: {e}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "94119a5c-3bd3-4b17-a854-6a9560cc5bce",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "Quando si parla di buffer o file, immagina che ci sia un piccolo cursore invisibile che tiene traccia di dove ci troviamo nella lettura/scrittura.\n",
    "\n",
    "📌 Cos'è il cursore di un file o buffer?\n",
    "Il cursore interno è un puntatore che indica la posizione attuale nel file (o buffer).\n",
    "\n",
    "Quando scrivi dati, il cursore avanza alla fine di ciò che hai scritto.\n",
    "Quando leggi, il cursore avanza man mano che scorri i dati.\n",
    "Se tenti di leggere senza riportare il cursore all'inizio, potresti ottenere dati incompleti o un errore.\n",
    "📌 Esempio con un file\n",
    "Immagina un file di testo chiamato esempio.txt con questo contenuto:\n",
    "\n",
    "Copia\n",
    "Modifica\n",
    "Ciao, come stai?\n",
    "Ora vediamo cosa succede quando lo leggiamo:\n",
    "\n",
    "python\n",
    "Copia\n",
    "Modifica\n",
    "# Apriamo il file in modalità lettura\n",
    "with open(\"esempio.txt\", \"r\") as f:\n",
    "    print(f.read())  # ✅ Leggiamo tutto -> \"Ciao, come stai?\"\n",
    "    \n",
    "    print(f.read())  # ❌ Ora il cursore è alla fine -> \"\" (stringa vuota!)\n",
    "Il secondo read() non restituisce nulla perché il cursore è già alla fine del file.\n",
    "Per rileggere il file dobbiamo spostare il cursore all'inizio con seek(0):\n",
    "\n",
    "python\n",
    "Copia\n",
    "Modifica\n",
    "with open(\"esempio.txt\", \"r\") as f:\n",
    "    print(f.read())  # ✅ Legge tutto -> \"Ciao, come stai?\"\n",
    "    \n",
    "    f.seek(0)  # 🔄 Riporta il cursore all'inizio\n",
    "    \n",
    "    print(f.read())  # ✅ Ora rilegge tutto -> \"Ciao, come stai?\"\n",
    "📌 Esempio con BytesIO (buffer in memoria)\n",
    "Un BytesIO funziona come un file, ma è in RAM. Vediamo cosa succede senza seek(0):\n",
    "\n",
    "python\n",
    "Copia\n",
    "Modifica\n",
    "import io\n",
    "\n",
    "# Creiamo un buffer\n",
    "buffer = io.BytesIO()\n",
    "buffer.write(b\"Ciao, come stai?\")  # ✍️ Scriviamo qualcosa\n",
    "\n",
    "print(buffer.read())  # ❌ \"\" perché il cursore è alla fine!\n",
    "\n",
    "buffer.seek(0)  # 🔄 Riportiamo il cursore all'inizio\n",
    "print(buffer.read())  # ✅ \"Ciao, come stai?\"\n",
    "📌 Applicazione al tuo codice GradCAM\n",
    "Nel tuo caso, la sequenza è questa:\n",
    "\n",
    "1️⃣ Crei un BytesIO()\n",
    "2️⃣ Salvi l'immagine nel buffer → il cursore ora è alla fine\n",
    "3️⃣ Per poterla leggere con Image.open(), devi riportarlo all'inizio con seek(0)\n",
    "\n",
    "python\n",
    "Copia\n",
    "Modifica\n",
    "buf = io.BytesIO()\n",
    "plt.savefig(buf, format='png')  # ✍️ Salvataggio avanza il cursore\n",
    "buf.seek(0)  # 🔄 Riporta il cursore all'inizio per poterlo leggere\n",
    "fig_image = buf.getvalue()  # Ora possiamo leggere i byte correttamente!\n",
    "buf.close()\n",
    "E quando passi il buffer a save_performance_results, devi ripetere il seek(0) prima di aprirlo con Image.open().\n",
    "\n",
    "💡 Conclusione:\n",
    "Il cursore è come un segnalibro in un file o buffer. Se non lo riporti all'inizio, leggere i dati successivamente potrebbe fallire! 🚀"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bc872d-548c-4a9d-91f1-cc05ca6c767e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### **NUOVE UTILS DATI POST W&B (PER RICHIAMARE MODELLI OTTIMIZZATI)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6651956-a81c-49ee-b811-dc731103d3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Parsing della chiave e costruzione del path:\n",
    "Usando la funzione parse_combination_key si estraggono \n",
    "\n",
    "exp_cond, data_type e category_subject dalla chiave del dataset. \n",
    "\n",
    "Questi vengono usati per costruire il percorso in cui cercare i file .pkl.\n",
    "'''\n",
    "import re \n",
    "\n",
    "# Funzione per parsare la chiave\n",
    "def parse_combination_key(combination_key):\n",
    "    \"\"\"\n",
    "    Estrae (exp_cond, data_type, category_subject) da combination_key.\n",
    "    Il formato atteso è:\n",
    "    \"th_resp_vs_pt_resp|pt_resp_vs_shared_resp|th_resp_vs_shared_resp\" _ \n",
    "    \"1_20|1_45|wavelet\" _ \n",
    "    \"familiar_th|familiar_pt|unfamiliar_th|unfamiliar_pt\"\n",
    "    \"\"\"\n",
    "    match = re.match(\n",
    "        #r\"^(th_resp_vs_pt_resp|pt_resp_vs_shared_resp|th_resp_vs_shared_resp)_(spectrograms)_(familiar_th|familiar_pt|unfamiliar_th|unfamiliar_pt)$\", \n",
    "        #r\"^(rest_vs_left_fist|rest_vs_right_fist|left_fist_vs_right_fist)_spectrograms_(familiar_th|familiar_pt|unfamiliar_th|unfamiliar_pt)$\",\n",
    "        r\"^(rest_vs_left_fist|rest_vs_right_fist|left_fist_vs_right_fist)_(spectrograms)_(familiar_th|familiar_pt|unfamiliar_th|unfamiliar_pt)$\",\n",
    "        combination_key\n",
    "    )\n",
    "    if match:\n",
    "        return match.groups()  # (exp_cond, data_type, category_subject)\n",
    "    else:\n",
    "        raise ValueError(f\"Formato non valido: {combination_key}\")\n",
    "        \n",
    "\n",
    "'''CELLA DI ESEMPIO PER VERIFICARE SE QUESTA FUNZIONE FACESSE IL PARSING DELLE STRINGHE DELLE COMBINAZIONI DI FATTORI CORRETTAMENTE'''\n",
    "\n",
    "# Test\n",
    "combination_key = \"rest_vs_left_fist_spectrograms_familiar_th\"\n",
    "condition_experiment, data_type, subject_key = parse_combination_key(combination_key)\n",
    "\n",
    "print(\"Condizione:\", condition_experiment)\n",
    "print(\"Data Type:\", data_type)\n",
    "print(\"Soggetto:\", subject_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404f147a-dd60-451e-bf63-e58c1b7cb4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Verifica del file .pkl:\n",
    "La funzione load_config_if_available cerca, per ogni modello, il file con nome del tipo\n",
    "\"{model_name}_{exp_cond}_{data_type}_{category_subject}.pkl\"\n",
    "all’interno della struttura di cartelle basata su base_path. \n",
    "\n",
    "Se il file esiste, allora viene passata poi a load_model_config_and_weights, \n",
    "che carica il dizionario di partenza \n",
    "e da questo estrae i 2 sotto-dizionari 'config' e 'state_dict'.\n",
    "'''\n",
    "\n",
    "def load_config_if_available(dataset_key, model_name, base_path):\n",
    "    \"\"\"\n",
    "    Data una chiave (es. \"th_resp_vs_pt_resp_wavelet_familiar_th\") e il nome del modello,\n",
    "    cerca il file .pkl corrispondente e ritorna (config, state_dict).\n",
    "    Se non esiste, restituisce (None, None).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        exp_cond, data_type, category_subject = parse_combination_key(dataset_key)\n",
    "        config, state_dict = load_model_config_and_weights(exp_cond, data_type, category_subject, model_name, base_path)\n",
    "        print(f\"✅ File .pkl trovato per \\033[1m{model_name}\\033[0m su \\033[1m{dataset_key}\\033[0m\")\n",
    "        \n",
    "        return config, state_dict\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Nessun file .pkl per {model_name} su {dataset_key} - uso parametri di default. ({e})\")\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee72d02d-b6a4-451e-af0c-e4b74816cec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Caricamento del file .pkl:\n",
    "La funzione load_model_config_and_weights cerca, per ogni modello, il file con nome del tipo\n",
    "\"{model_name}_{exp_cond}_{data_type}_{category_subject}.pkl\"\n",
    "all’interno della struttura di cartelle basata su base_path. Se il file esiste, vengono restituiti config e state_dict.\n",
    "'''\n",
    "\n",
    "# Funzione per caricare il file .pkl con la configurazione e i pesi ottimali\n",
    "def load_model_config_and_weights(exp_cond, data_type, category_subject, model_name, base_path):\n",
    "    \"\"\"\n",
    "    Costruisce il path usando:\n",
    "        base_path / exp_cond / data_type / category_subject\n",
    "    e il nome del file:\n",
    "        {model_name}_{exp_cond}_{data_type}_{category_subject}.pkl\n",
    "    Se il file esiste, lo carica e restituisce (config, state_dict).\n",
    "    \"\"\"\n",
    "    \n",
    "    file_name = f\"{model_name}_{exp_cond}_{data_type}_{category_subject}.pkl\"\n",
    "    file_path = os.path.join(base_path, exp_cond, data_type, category_subject, file_name)\n",
    "    \n",
    "    if os.path.exists(file_path):\n",
    "        print(f\"🕵️‍♂️🔍Caricamento file .pkl: \\033[1m{file_path}\\033[0m\")\n",
    "        \n",
    "        # Il file .pkl è stato salvato con torch.save() e contiene un dizionario con chiavi al suo interno che sono: \"config\" e \"state_dict\"\n",
    "        with open(file_path, \"rb\") as f:\n",
    "            data = torch.load(f)\n",
    "        return data[\"config\"], data[\"state_dict\"]\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"File {file_path} non trovato.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195b2249-dbcb-4b86-9916-8fb0a8c1fe25",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### **TESTING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78035f42-3985-4605-8fa5-5cd01e074c1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "TESTING FUNCTION: CORRETTA ANCHE PER IL GRAD-CAM\n",
    "\n",
    "SUCCESSIVAMENTE, DENTRO AL FOR LOOP DEL TRAINING E TESTING, \n",
    "SI RICHIAMA LA FUNZIONE DIRETTAMENTE DI \n",
    "\n",
    "1) compute_gradcam_figure, LA QUALE AL SUO INTERNO PRESENTA GIÀ \n",
    "TUTTO QUELLO CHE SERVE PER CALCOLARE IL GRADCAM, DI MODO CHE VADA A \n",
    "\n",
    "Selezionare esempi rappresentativi per ciascuna classe.\n",
    "Calcolare le mappe GradCAM e gli overlay.\n",
    "Creare una figura con le heatmap e le sovrapposizioni, completa di titoli esplicativi.\n",
    "Restituire un'immagine (buffer) pronta per essere salvata\n",
    "\n",
    "SUCCESSIVAMENTE, QUINDI, IL PROCEDIMENTO DIVENTA COME SEGUE:\n",
    "\n",
    "1) Si esegue il TESTING, per ottenere le metriche e salvare i risultati (senza GradCAM)\n",
    "\n",
    "2) Nel loop principale di TRAINING & TESTING, se il modello è CNN2D, allora \n",
    "\n",
    " - richiama la funzione 'compute_gradcam_figure', la quale va a\n",
    "    - calcolare le mappe di attivazione e successivamente creo le immagini che gli ho chiesto\n",
    "    - passa l'immagine ottenuta da GradCAM alla funzione 'save_performance_results', la quale va a \n",
    "        - salvare i risultati di test ottenuti dalla funzione di 'testing'\n",
    "        - salvare l'immagine risultatante del GradCAM e la sovrapposizione del GradCAM sullo spettrogramma originale della classe risultante\n",
    "        \n",
    "        \n",
    "Questo approccio garantisce chiarezza e separa la parte di performance (testing) dalla parte di explainability (GradCAM).\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import io\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "\n",
    "def testing(results, test_loader, criterion):\n",
    "    \n",
    "    # Recupera il miglior modello ottenuto durante la validazione\n",
    "    model = results['best_model']\n",
    "    model.to(device)\n",
    "    \n",
    "    model.eval()  # Imposta il modello in modalità valutazione\n",
    "\n",
    "    y_true_list = []  # Lista per salvare le etichette reali\n",
    "    y_pred_list = []  # Lista per salvare le previsioni del modello\n",
    "    \n",
    "    '''AGGIUNTA NUOVA PER CALCOLO AUC-ROC'''\n",
    "    y_score_list = []   # <— Lista per salvare gli score per le probabilità della classe positiva (per auc-roc!)\n",
    "    \n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    test_performances = {\n",
    "        \"test_loss\": [],\n",
    "        \"test_accuracy\": [],\n",
    "        \"test_precision\": [],\n",
    "        \"test_recall\": [],\n",
    "        \"test_f1_score\": [],\n",
    "        \"test_auc\": []\n",
    "    }\n",
    "    \n",
    "\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        pbar = tqdm(test_loader, desc=\"Testing\")\n",
    "        \n",
    "        for inputs, labels in pbar:\n",
    "            \n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # Ottenere le predizioni del modello\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            '''AGGIUNTA NUOVA PER CALCOLO AUC-ROC'''\n",
    "            # aggiungi queste due righe\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            y_score_list.extend(probs[:,1].cpu().numpy())\n",
    "\n",
    "            # Calcolare la loss\n",
    "            test_loss = criterion(outputs, labels)\n",
    "            total_loss += test_loss.item()\n",
    "\n",
    "            # Memorizzare predizioni ed etichette vere\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            y_pred_list.extend(predicted.cpu().numpy())\n",
    "            y_true_list.extend(labels.cpu().numpy())\n",
    "\n",
    "            # Aggiornare il numero di predizioni corrette\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            pbar.set_description(f\"Loss: {test_loss.item():.4f}\")\n",
    "\n",
    "    # Calcolare l'accuratezza complessiva\n",
    "    accuracy = correct / len(test_loader.dataset)\n",
    "    \n",
    "    \n",
    "    # Calcolare precision, recall, F1-score, AUC durante il testing\n",
    "    precision_test = precision_score(y_true_list, y_pred_list, average='weighted')\n",
    "    recall_test = recall_score(y_true_list, y_pred_list, average='weighted')\n",
    "    f1_test = f1_score(y_true_list, y_pred_list, average='weighted')\n",
    "    \n",
    "    '''OLD VERSION'''\n",
    "    #auc_test = roc_auc_score(y_true_list, y_pred_list, average='weighted')  # Assicurati che il problema sia binario o multi-class\n",
    "    \n",
    "    '''AGGIUNTA NUOVA PER CALCOLO AUC-ROC\n",
    "    \n",
    "    In questo modo l’roc_auc_score calcola l’area sotto tutta la curva ROC (tutte le soglie), invece di valutare un solo punto corrispondente alla soglia 0.5\n",
    "    '''\n",
    "    \n",
    "    #https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html\n",
    "    auc_test = roc_auc_score(y_true_list, y_score_list)\n",
    "\n",
    "\n",
    "    # Aggiungere questi valori nel dizionario delle performance (arrotondando a 4 decimali)\n",
    "    test_performances[\"test_loss\"].append(round(total_loss / len(test_loader), 4))  # Media della loss\n",
    "    test_performances[\"test_accuracy\"].append(round(accuracy, 4))\n",
    "    test_performances[\"test_precision\"].append(round(precision_test, 4))\n",
    "    test_performances[\"test_recall\"].append(round(recall_test, 4))\n",
    "    test_performances[\"test_f1_score\"].append(round(f1_test, 4))\n",
    "    test_performances[\"test_auc\"].append(round(auc_test, 4))\n",
    "    \n",
    "    # Creare la confusion matrix\n",
    "    conf_matrix = confusion_matrix(y_true_list, y_pred_list)\n",
    "    \n",
    "    # Stampare classification report\n",
    "    class_report = classification_report(y_true_list, y_pred_list)\n",
    "\n",
    "    print(f\"\\nTest Accuracy: {accuracy:.4f}\")\n",
    "    print(\"\\nClassification Report:\\n\", class_report)\n",
    "\n",
    "    # Visualizzare la confusion matrix\n",
    "    #plt.figure(figsize=(8, 6))\n",
    "    #sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "    #plt.title(\"Confusion Matrix\")\n",
    "    #plt.xlabel(\"Predicted\")\n",
    "    #plt.ylabel(\"True\")\n",
    "    #plt.show()\n",
    "    \n",
    "    # Salviamo l'immagine della confusion matrix in un buffer\n",
    "    #buf = io.BytesIO()\n",
    "    #plt.savefig(buf, format='png')\n",
    "    #buf.seek(0)\n",
    "    #conf_matrix_image_data = buf.getvalue()\n",
    "    #buf.close()\n",
    "    \n",
    "    \n",
    "    # Salviamo l'immagine della confusion matrix in un buffer\n",
    "    buf = io.BytesIO()\n",
    "    plt.figure(figsize=(8, 6))  # Nuova figura per evitare sovrapposizioni\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.savefig(buf, format='png')  # Salva l'immagine nel buffer\n",
    "    buf.seek(0)  # Torna all'inizio del buffer\n",
    "    conf_matrix_image_data = buf.getvalue()  # Ottieni l'immagine in formato binario\n",
    "    buf.close()  # Chiudi il buffer\n",
    "\n",
    "    # Mostra la confusion matrix (opzionale)\n",
    "    #plt.show()\n",
    "    \n",
    "    # Salvataggio della configurazione del modello e iper-parametri\n",
    "    '''COMMENTATO'''\n",
    "    #model_config = {\n",
    "        #\"model_architecture\": str(model),\n",
    "        #\"batch_size_test\": test_loader.batch_size,\n",
    "    #}\n",
    "    \n",
    "    '''COMMENTATO'''\n",
    "    # Dizionario degli iper-parametri\n",
    "    #hyperparams = {\n",
    "        #\"optimizer\": str(optimizer),\n",
    "        #\"loss_function\": str(criterion),\n",
    "        #\"learning_rate\": optimizer.param_groups[0]['lr'],\n",
    "    #}\n",
    "\n",
    "    \n",
    "    '''COMMENTATO'''\n",
    "    # Restituisci i risultati come dizionario\n",
    "    #test_results = {\n",
    "        #\"test_performances\": test_performances,  # Aggiungi il dizionario delle performance\n",
    "        #\"confusion_matrix\": conf_matrix,\n",
    "        #\"classification_report\": class_report,\n",
    "        #\"model_configuration\": model_config,\n",
    "        #\"hyperparameters\": hyperparams,  # Aggiunti i due nuovi dizionari\n",
    "        #\"confusion_matrix_image\": conf_matrix_image_data,  # Aggiunta l'immagine della confusion matrix\n",
    "    #}\n",
    "    \n",
    "    \n",
    "    # Restituisci i risultati come dizionario\n",
    "    test_results = {\n",
    "        \"test_performances\": test_performances,  # Aggiungi il dizionario delle performance\n",
    "        \"confusion_matrix\": conf_matrix,\n",
    "        \"classification_report\": class_report,\n",
    "        \"confusion_matrix_image\": conf_matrix_image_data,  # Aggiunta l'immagine della confusion matrix\n",
    "    }\n",
    "    \n",
    "        \n",
    "    return test_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fee1422-59f3-444c-b559-68e70c2e9b91",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### **CREAZIONE CLASSE GRADCAM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b111606-03de-42a1-aa0c-6b850b84155d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##### **CREAZIONE CLASSE GRADCAM**\n",
    "\n",
    "'''\n",
    "Creazione della classe GradCAM\n",
    "\n",
    "-----1. Costruttore (init)-----\n",
    "\n",
    "Cosa fa:\n",
    "\n",
    "Salva il modello e il layer target (ad esempio, l'ultimo strato convoluzionale) su cui calcolare le mappe di attivazione.\n",
    "\n",
    "A) Inizializza due variabili, \n",
    "\n",
    "1) self.activations e 2) self.gradients, che verranno usate per memorizzare rispettivamente \n",
    "1) le attivazioni (feature maps) e 2) i gradienti di quel layer\n",
    "\n",
    "B) Registra due hook sul target_layer:\n",
    "\n",
    "1) Forward Hook: Quando il modello effettua la forward pass, viene eseguito save_activation per salvare le attivazioni\n",
    "2) Backward Hook: Durante la backward pass, save_gradient viene chiamato per salvare i gradienti\n",
    "\n",
    "\n",
    "-----2. Hook per Salvare Attivazioni e Gradienti-----\n",
    "\n",
    "B) Save Activation\n",
    "\n",
    "def save_activation(self, module, input, output):\n",
    "    self.activations = output.detach()\n",
    "\n",
    "Cosa fa:\n",
    "\n",
    "Quando viene eseguita la forward pass sul target_layer, questo hook cattura l'output (le attivazioni) del layer.\n",
    "Usa detach() per ottenere una copia dei dati senza il tracking dei gradienti, \n",
    "in modo da non interferire con la retropropagazione.\n",
    "\n",
    "C) Save Gradient\n",
    "\n",
    "def save_gradient(self, module, grad_input, grad_output):\n",
    "    self.gradients = grad_output[0].detach()\n",
    "\n",
    "\n",
    "Cosa fa:\n",
    "\n",
    "Durante la backward pass, questo hook cattura i gradienti che fluiscono attraverso il target_layer.\n",
    "grad_output è una tupla; solitamente il primo elemento contiene i gradienti utili. \n",
    "\n",
    "Anche qui si usa detach() per isolare i dati dai grafi di calcolo.\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class GradCAM:\n",
    "    def __init__(self, model, target_layer):\n",
    "        self.model = model\n",
    "        self.target_layer = target_layer\n",
    "        self.activations = None\n",
    "        self.gradients = None\n",
    "        \n",
    "        # Registra hook per catturare attivazioni e gradienti\n",
    "        self.target_layer.register_forward_hook(self.save_activation)\n",
    "        self.target_layer.register_backward_hook(self.save_gradient)\n",
    "\n",
    "    def save_activation(self, module, input, output):\n",
    "        self.activations = output.detach()\n",
    "\n",
    "    def save_gradient(self, module, grad_input, grad_output):\n",
    "        self.gradients = grad_output[0].detach()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b7fd24-c494-4c8a-815f-152907f61cbd",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### **FINAL IMPLEMENTATION OF GRADCAM COMPUTATION: FREQUENCIES X ELECTRODES PER EEG STATS**\n",
    "\n",
    "##### **CONV3D & CONV SEPARABLE**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09c165c-46de-4344-9aba-d7e063b719ea",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### **CONV3D & CONV SEPARABLE: Codice per il Calcolo del GradCAM**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b47f2e-edd4-4047-8cf7-bca92bc4c4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "                                                                        NEW VERSION 17/11/2025\n",
    "                                                                        \n",
    "                                                                \n",
    "                                                                        \n",
    "                                                                  \n",
    "                                                                    VERSION FREQUENCY x CHANNELS\n",
    "                                                                            \n",
    "                                                                     ****** PER GRID 2D! ******\n",
    "                                                                      ****** MULTI BAND******\n",
    "                                                                      \n",
    "                                                                      PER CONVOLUZIONE 3D (PURA)\n",
    "                                                                              +\n",
    "                                                                      PER CONVOLUZIONI SEPARABILI\n",
    "                                                                      \n",
    "                                                              \n",
    "                                                                CON VALORI MEAN GRADCAM e MEAN RAW POWER\n",
    "                                                                            SU STESSA SCALA\n",
    "                                                                PER OGNI CLASSE E BANDA DI FREQUENZA!\n",
    "                                                                \n",
    "                                                                        ^^^^^SENZA COMMENTI^^^^^\n",
    "                                                                        ^^^^^            ^^^^^\n",
    "                                                                        \n",
    "                                                                    SENZA ADOZIONE DELLA MASCHERA \n",
    "                                                                PER INDICARE LE POSIZIONI DELLA GRIGLIA REALI    \n",
    "                                                            \n",
    "                                                            1) STIMOLA A VERIFICARE CHE LA RETE DISTINGUA TRA \n",
    "                                                        \n",
    "                                                        COORDINATE ELETTRODICHE REALI VS FITTIZIE (SPAZI VUOTI GRIGLIA)\n",
    "                                                            \n",
    "                                                            2) CONFERMA IN MODO DATA-DRIVEN LA RILEVANZA NEUROFISIOLOGICA\n",
    "                                                            DEL FENOMENO IPOTIZZATO\n",
    "                                                            \n",
    "\n",
    "OLTRETUTTO\n",
    "\n",
    "1) senza mask vedevi hotspot che escono fuori dalla “sagoma” degli elettrodi;\n",
    "\n",
    "2) con la mask, l’informazione si appiattisce / cambia abbastanza \n",
    "→ questo ti dice che il modello 2D sta effettivamente usando anche le celle fittizie / bordi / padding come feature.\n",
    "Mascherando a posteriori, tu forzi la visualizzazione dentro la sagoma, \n",
    "ma non stai più mostrando fedelmente dove il modello guarda.\n",
    "\n",
    "\n",
    "Quindi la tua intuizione:\n",
    "\n",
    "“non imporre una maschera aiuta a capire se davvero il modello discrimina tra posizioni reali e non reali”\n",
    "\n",
    "è giusta al 100%. La mask è solo un filtro di visualizzazione, non cambia il modello: se la applichi \n",
    "puoi rendere la mappa “più neuro-plausibile”, ma rischi di nascondere il fatto che\n",
    "la Separable CNN2D sta facendo cose un po’ spurie nella parte fittizia della griglia.\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "'''\n",
    "SINTESI DELLA FUNZIONE check_negative_residuals\n",
    "\n",
    "\n",
    "| Blocco                          | Scopo                                                                                                                                                                                                                                                                                                                                                                                                                                         | Perché serve                                                                                                                                                                                                                                                                                                                                                                                   |\n",
    "| ------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
    "| **1. eps / “dynamic tol”**      | Calcola una soglia *dinamica* sotto la quale i valori negativi sono quasi certamente puro rumore numerico.<br><br>`python<br>eps32 = np.finfo(np.float32).eps  # ≈ 1.19e‑7<br>dynamic_tol = -eps32 * max(arr.max(), 1.0)`                                                                                                                                                                                                                     | *machine‑epsilon* (ε) è l’errore di arrotondamento massimo relativo per `float32` vicino a 1.<br>Moltiplicandolo per il massimo **positivo** trovato nella mappa definiamo una “fascia di tolleranza” proporzionale alla scala reale del dato. Tutto ciò che cade **sotto** `dynamic_tol` è troppo piccolo perché sia fisico — è, con ottima probabilità, soltanto rumore di rappresentazione. |\n",
    "| **2. Negativi “significativi”** | Conta e, se ce ne sono, stampa quante celle sono < `dynamic_tol`, quanto è il minimo osservato e la tolleranza stessa.                                                                                                                                                                                                                                                                                                                        | Ti permette di capire a colpo d’occhio se il preprocessing ha generato valori negativi (che non dovrebbero esistere in potenza) che **superano** il rumore ammesso.                                                                                                                                                                                                                            |\n",
    "| **3. Log‑hint**                 | Se *non* ci sono negativi significativi, calcola il **dynamic range** della mappa (max/min **> 0**) e decide se suggerire la scala log.<br><br>`python<br>positive = arr[arr > 0]<br>if positive.size == 0:<br>    ratio = np.inf          # tutto zero<br>else:<br>    min_pos = positive.min()<br>    max_pos = positive.max()<br>    ratio   = max_pos / max(min_pos, 1e‑12)<br>note = \"LOG consigliato\" if ratio > 1e3 else \"lineare ok\"` | – Ignoriamo gli zeri: la scala log non li supporta.<br>– Aggiungiamo un “cuscinetto” di `1e‑12` per evitare div/0.<br>– Se il range è > 10³ (tre ordini di grandezza ≃ “la potenza massima è **> 1000 ×** la minima”), la lettura lineare diventa poco informativa → meglio log10.                                                                                                             |\n",
    "\n",
    "\n",
    "\n",
    "In sintesi\n",
    "\n",
    "Prima parte → caccia ai negativi “numeric‑noise” tramite ε.\n",
    "\n",
    "Seconda parte → valuta solo i valori positivi e suggerisce log‑scale quando il dynamic‑range supera ~3 decadi (≈ 10³).\n",
    "\n",
    "\n",
    "Quando il codice passa in log‑scale?\n",
    "Raccogli tutte le mappe (di entrambe le classi e di tutte le bande)\n",
    "\n",
    "\n",
    "all_mean_pow = np.concatenate([...])\n",
    "\n",
    "Filtra i positivi e trova vmin_pow (con un 10 % di margine per non “appiattire” il minimo nella color‑bar)\n",
    "\n",
    "positive_vals = all_mean_pow[all_mean_pow > 0]\n",
    "vmin_pow = positive_vals.min() * 0.9 if positive_vals.size else 1e‑12\n",
    "vmax_pow = all_mean_pow.max()\n",
    "\n",
    "Decidi\n",
    "\n",
    "use_log = vmax_pow / max(vmin_pow, 1e‑12) > 1e3\n",
    "Se la potenza massima è > 1000 × la minima positiva, usare LogNorm.\n",
    "\n",
    "Come si spiega “tre ordini di grandezza”?\n",
    "\n",
    "“Il massimo è mille volte il minimo”.\n",
    "“Dynamic‑range di 3 decadi”.\n",
    "Oppure “max/min > 10³”.\n",
    "\n",
    "\n",
    "\n",
    "Riassunto finale\n",
    "ε: misura il rumore di quantizzazione, ti dice quando un (piccolo) negativo è solo un effetto di arrotondamento.\n",
    "\n",
    "Dynamic‑range: se la banda ha valori reali che variano più di 10³ ×, la scala log10 rende le differenze leggibili senza “schiacciare” i dettagli bassi.\n",
    "\n",
    "La funzione: un’unica utility per\n",
    "\n",
    "diagnosticare residui numerici,\n",
    "\n",
    "suggerire in automatico la rappresentazione (lineare / log) più sensata per i tuoi plot di potenza.\n",
    "\n",
    "Così il flusso diventa:\n",
    "\n",
    "\n",
    "check_negative_residuals(...)   # → log “SCALA LOG consigliata”\n",
    "↓\n",
    "use_log = True                  # ratio > 1e3\n",
    "↓\n",
    "plot con LogNorm + LogLocator   # color‑bar pulita, dettagli visibili\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Perché vedi ratio = inf\n",
    "* Nelle bande Beta e Gamma la tua mappa media è tutta a zero (o comunque tutti i valori ≤ ε).\n",
    "* Con soli zeri il vettore positive = arr[arr > 0] è vuoto, quindi lo tratto come “dynamic‑range infinito” per evitare la divisione per 0.\n",
    "* In realtà non hai un’«escursione infinita»; semplicemente non hai segnale in quelle bande → la scala log non aggiungerebbe nulla.\n",
    "\n",
    "Se vuoi evitare quel suggerimento “falso‑positivo”, basta cambiare la logica così (l’ho già indicato ma lo riscrivo compatto):\n",
    "\n",
    "positive = arr[arr > 0]\n",
    "if positive.size < 2:          # 0 o 1 valore positivo → niente dinamica utile\n",
    "    ratio = 0                  # forza il consiglio a “lineare”\n",
    "else:\n",
    "    ratio = positive.max() / max(positive.min(), 1e-12)\n",
    "    \n",
    "    \n",
    "Linear vs log: quale usare davvero?\n",
    "Banda\tDynamic‑range (≈ max/min)\tScala consigliabile\n",
    "Delta ‑ Theta\t3‑11 ×\tLineare: già leggibile.\n",
    "Alpha\t12 ×\tAncora lineare (o log, ma non cambia molto).\n",
    "Beta – Gamma\t0 (tutti zeri)\tLog inutile: non c’è potenza da mostrare.\n",
    "\n",
    "Di conseguenza:\n",
    "\n",
    "Mantieni la scala lineare globale come nel tuo blocco finale.\n",
    "\n",
    "Se in altri dataset vedrai rapporti > 1 000 con almeno 2 valori positivi, allora attiva la parte LogNorm.\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "def check_negative_residuals(band_names, tensor_dict, tag, log_hint=True):\n",
    "    \n",
    "    \"\"\"\n",
    "    • band_names   : lista di stringhe  (lunghezza = n_bands)\n",
    "    • tensor_dict  : {cls: [np.ndarray(H,W), … n_bands]} --> dict  {cls: [np.ndarray(H,W), … 5 bande]}\n",
    "    • tag          : prefisso stampato nel log --> string visualizzato nel log\n",
    "    • log_hint     : se True mostra il rapporto max/min ⇒ aiuta a decidere\n",
    "                     se usare la scala log nei plot.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    #https://numpy.org/doc/2.1/reference/generated/numpy.finfo.html\n",
    "    eps32 = np.finfo(np.float32).eps        # 1.19e‑7\n",
    "    for cls in [0, 1]:\n",
    "        for b, b_name in enumerate(band_names):\n",
    "            arr   = tensor_dict[cls][b]\n",
    "            \n",
    "            # Soglia dinamica = −eps * valore_massimo_della_mappa\n",
    "            \n",
    "            #dynamic_tol = -eps32 * arr.max()      # tolleranza dinamica\n",
    "            \n",
    "            dynamic_tol = -eps32 * max(arr.max(), 1.0)   # evita max==0\n",
    "            \n",
    "            neg_mask  = arr < dynamic_tol # “negativi significativi”\n",
    "            \n",
    "            min_v, max_v = float(arr.min()), float(arr.max())\n",
    "            \n",
    "            if np.any(neg_mask):\n",
    "                print(f\"Valori sotto la soglia per classe e banda:\\n\")\n",
    "                \n",
    "                #forma\tcosa fa\tquando differisce\n",
    "                #np.count_nonzero(neg_mask)\tconverte il bool‑array in int (True→1, False→0) e somma gli 1\tè sempre un intero Python\n",
    "                \n",
    "                #neg_mask.sum()\tchiama il metodo .sum() dell’ndarray; \n",
    "                #per tipo bool fa esattamente la stessa somma di sopra\trestituisce uno numpy.int_ (stesso valore, differente tipo)\n",
    "                \n",
    "                n_neg   = np.count_nonzero(neg_mask)\n",
    "                \n",
    "                min_val = arr.min()\n",
    "                \n",
    "                print(f\"[{tag} {b_name}] class={cls}  band={b_name:<6}  \"\n",
    "                      f\"neg={n_neg}  min={min_val:.3e}  tol={dynamic_tol:.3e}\")\n",
    "            else:\n",
    "                print(f\"Nessun valore sotto la soglia per classe {cls} e banda {b_name}\\n\")\n",
    "                print(f\"Definisco il range minimo e massimo per classe {cls} e banda{b_name} :\\n\")\n",
    "                \n",
    "                # ‑‑ opzionale: suggerimento scala log\n",
    "                if log_hint:                    \n",
    "                    #if max_v == 0 or min_v == 0:\n",
    "                    positive = arr[arr > 0]           # considera solo i valori > 0\n",
    "                    \n",
    "                    #Se il primo valore della potenza è proprio 0:\n",
    "                    #per evitare problemi di NaN lo impongo ad infinito\n",
    "                    if positive.size == 0:\n",
    "                        ratio = float('inf')          # tutto zero → range “infinito”\n",
    "                    \n",
    "                    #Se il primo valore della potenza è proprio 0:\n",
    "                    #per evitare problemi di NaN lo impongo ad infinito\n",
    "                    else:\n",
    "                        min_pos = positive.min()\n",
    "                        max_pos = positive.max()\n",
    "                        ratio   = max_pos / max(min_pos, 1e-12)\n",
    "                    note = f\"\\033[1mSCALA LOG per plots consigliata\\033[0m\" if ratio > 1e3 else f\"\\033[1mSCALA LINEARE per plots consigliata ok\\033[0m\"\n",
    "                    print(f\"        dynamic‑range ≈ {ratio:8.1f}  → {note}\")\n",
    "            print()\n",
    "                \n",
    "                \n",
    "                \n",
    "import torch.nn as nn\n",
    "\n",
    "def model_has_cudnn_rnn(model):\n",
    "    \"\"\"Ritorna True se il modello usa LSTM/GRU/RNN supportati da CuDNN.\"\"\"\n",
    "    return any(isinstance(m, (nn.LSTM, nn.GRU, nn.RNN)) for m in model.modules())\n",
    "\n",
    "\n",
    "from matplotlib.ticker import FixedLocator\n",
    "\n",
    "from matplotlib.colors import LogNorm\n",
    "from matplotlib.ticker import (LogLocator, LogFormatterMathtext,\n",
    "                               ScalarFormatter)\n",
    "\n",
    "\n",
    "'''RICORDATI: aggiunto parametro TEST_LOADER_RAW per i plots della POTENZA SPETTRALE MEDIA PER BANDA (i.e., test_loader_raw)'''\n",
    "def compute_gradcam_figure(model, test_loader, test_loader_raw, exp_cond, data_type, category_subject, device, channel_names=None, debug = False):\n",
    "    \n",
    "    \n",
    "    '''SOLO PER I MODELLI OTTIMIZZATI CON ANCHE LA LSTM'''\n",
    "    \n",
    "    #Solo i modelli con LSTM entrano in questo giro; gli altri non cambiano di stato.\n",
    "    #Con questa sequenza:\n",
    "    #non ottieni più l’errore “cudnn RNN backward…”;\n",
    "    #la rete “si comporta” come in eval (Dropout off, BN congelato) mentre calcoli le CAM;\n",
    "    #l’ambiente di chiamata (il tuo loop di testing) riceve il modello esattamente nello stato in cui l’aveva passato alla funzione compute_gradcam_figure\n",
    "    \n",
    "\n",
    "    ### Perché serve model.train() anche se la CAM è presa prima della LSTM\n",
    "    \n",
    "    #Il backward, per arrivare dal loss (o dal logit scelto) fino al tuo layer conv3, deve comunque attraversare l’LSTM che sta più avanti nella rete.\n",
    "    #Le implementazioni CuDNN degli RNN (LSTM/GRU) alzano un’eccezione se provi a chiamare tensor.backward() mentre il modulo è in modalità eval().\n",
    "    #RuntimeError: cudnn RNN backward can only be called in training mode\n",
    "    #Quindi, anche se la CAM è calcolata su conv3, devi mettere l’intero modello in train() per il tempo del backward.\n",
    "    #condition_names = exp_cond.split(\"_vs_\") if \"_vs_\" in exp_cond else [\"Class 0\", \"Class 1\"]\n",
    "    \n",
    "    \n",
    "    ### Che cos’è model.training\n",
    "    \n",
    "    #model.training è un semplice flag booleano (impostato da nn.Module.train() / nn.Module.eval()), ereditato da tutti i sotto‑moduli.\n",
    "    #Con was_training = model.training ricordi in che stato era il modello (quasi sempre False, cioè eval, nel tuo flusso)\n",
    "    #per poterlo ripristinare dopo.\n",
    "    \n",
    "    #Facendo così\n",
    "    \n",
    "    #for m in model.modules():\n",
    "    #if isinstance(m, (nn.BatchNorm1d, nn.BatchNorm2d, nn.BatchNorm3d,\n",
    "                      #nn.Dropout, nn.Dropout2d, nn.Dropout3d)):\n",
    "        #if m.training:         # cioè erano in train\n",
    "            #m.eval()\n",
    "            #frozen_layers.append(m)\n",
    "    \n",
    "    #Li sposti in eval uno per uno, senza toccare il resto della rete che deve restare in train() per far funzionare CuDNN‑RNN.\n",
    "    \n",
    "    \n",
    "    ### Perché, a fine blocco, servono due ripristini\n",
    "    \n",
    "    #1) Riattivo i BatchNorm / Dropout che avevo forzato in eval:\n",
    "    \n",
    "    #for m in frozen_layers:\n",
    "        #m.train()              # torna come prima\n",
    "    \n",
    "    #2) Riporto l’intero modello nello stato in cui si trovava prima del Grad‑CAM:\n",
    "    \n",
    "    #model.train(was_training)  # se era eval() torna eval, altrimenti resta train\n",
    "    \n",
    "    #Se non facessi il punto 1, lasceresti quei moduli permanentemente in eval anche quando, più tardi, \n",
    "    #rientri in training (per esempio in un fine‑tuning).\n",
    "    #Se non facessi il punto 2, lasceresti tutto il modello in train → dropout attivo, BN che accumula statistiche, ecc.\n",
    "\n",
    "    \n",
    "    \n",
    "    # ------------------------------------------------------------ ------------------------------------------------------------\n",
    "    # ❶ — se serve, abilito temporaneamente la modalità train per il modello ottimizzato che aveva ANCHE la LSTM... \n",
    "    # ------------------------------------------------------------ ------------------------------------------------------------\n",
    "    \n",
    "    needs_train_mode = model_has_cudnn_rnn(model)\n",
    "    \n",
    "    if needs_train_mode:\n",
    "        was_training = model.training      # salvo lo stato\n",
    "        model.train()                      # abilito backward su CuDNN‑RNN\n",
    "        \n",
    "        # ➊ salvo lo stato di OGNI BN/Dropout\n",
    "        \n",
    "        saved = [(m, m.training) for m in model.modules()\n",
    "             if isinstance(m, (nn.BatchNorm1d, nn.BatchNorm2d, nn.BatchNorm3d,\n",
    "                               nn.Dropout, nn.Dropout2d, nn.Dropout3d))]\n",
    "        \n",
    "        model.train()                              # abilita backward su CuDNN‑RNN\n",
    "        \n",
    "        # ➋ congelo in ogni layer della rete gli strati di BatchNorm e Dropout\n",
    "        for m, _ in saved:\n",
    "            m.eval()\n",
    "    \n",
    "    # ------------------------------------------------------------\n",
    "    # ❷ — QUI sotto metti tutto il tuo codice Grad‑CAM\n",
    "    #      (forward, backward, costruzione delle mappe, plot, …)\n",
    "    # ------------------------------------------------------------\n",
    "\n",
    "    # … il tuo lunghissimo corpo della funzione rimane invariato …\n",
    "    # → al momento di fare backward NON avrà più l’eccezione\n",
    "    #   “cudnn RNN backward can only be called in training mode”\n",
    "\n",
    "    \n",
    "    '''SE VUOI USARE STESSO LAYER PER GRADCAM IN ENTRAMBE ARCHITETTURE'''\n",
    "    target_layer = model.conv2b #model.conv3\n",
    "    \n",
    "    \n",
    "    '''SE VUOI USARE DIVERSI LAYER PER GRADCAM NELLE 2 ARCHITETTURE'''\n",
    "    #if isinstance(model, CNN3D_LSTM_FC):\n",
    "        #target_layer = model.conv2b\n",
    "        \n",
    "    #elif isinstance(model, SeparableCNN2D_LSTM_FC):\n",
    "        #target_layer = model.pw_conv1  # feature map 9x9, allineata 1:1 alla griglia\n",
    "    \n",
    "    gradcam = GradCAM(model, target_layer)\n",
    "    \n",
    "    # Determina il target layer in base al tipo di modello\n",
    "    #if isinstance(model, SeparableCNN2D_LSTM_FC):\n",
    "        #target_layer = model.dw_conv1  # Per il modello separabile 2D\n",
    "    #else:\n",
    "        #target_layer = model.conv3  # Per il modello CNN3D\n",
    "        \n",
    "\n",
    "    condition_names = exp_cond.split(\"_vs_\") if \"_vs_\" in exp_cond else [\"Class 0\", \"Class 1\"]\n",
    "    \n",
    "    \n",
    "    # ✅ Raccogli TUTTI i campioni per ciascuna classe\n",
    "    # Itera sul test_loader fino a trovare almeno un esempio per ciascuna classe (0 e 1)\n",
    "    \n",
    "    \n",
    "    #PER IL CASO CONV 3D\n",
    "    \n",
    "    # Ogni mio sample è 3D, perché infatti è fatto per convoluzione 3d pura o convoluzioni separabili, \n",
    "    # Quindi ha shape  (B, C, D, H, W), dove:  \n",
    "    \n",
    "    #B = batch (in questo caso, per ogni singolo esempio quindi sarà 1 -> singolo esempio alla volta)\n",
    "    #C = feature maps/canali (numero di feature maps estratte dalla convoluzione, o meglio anche noti come  canali convoluzionali)\n",
    "    #D = depth (la dimensione di profondità del mio tensore --> 5 ossia, la potenza spettrale ad ogni banda di frequenza - i.e.,  delta, theta, alfa, beta e gamma)\n",
    "    #H = height (altezza, prima dimensione SPAZIALE del mio tensore i.e., altezza griglia, canali EEG) \n",
    "    #W = width (larghezza, seconda dimensione SPAZIALE del mio tensore i.e., larghezza griglia, canali EEG)\n",
    "    \n",
    "    \n",
    "    '''SHAPE DEI DATI ORIGINALE SAREBBE (B, 9, 9, 5)'''\n",
    "    samples = {0: [], 1: []}\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        for i, label in enumerate(labels):\n",
    "            label_int = int(label.item())\n",
    "            if label_int in samples:  # Assumendo solo classi 0 e 1\n",
    "                \n",
    "                '''OSSIA QUI DIVENTA (1, 9, 9, 5)'''\n",
    "                samples[label_int].append(inputs[i].unsqueeze(0))\n",
    "                \n",
    "    \n",
    "    '''TEST_LOADER RAW (B, 9, 9, 5)'''\n",
    "    samples_raw = {0: [], 1: []}\n",
    "    for inputs, labels in test_loader_raw:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        for i, label in enumerate(labels):\n",
    "            label_int = int(label.item())\n",
    "            if label_int in samples_raw:  # Assumendo solo classi 0 e 1\n",
    "                \n",
    "                '''OSSIA QUI DIVENTA (1, 9, 9, 5)'''\n",
    "                samples_raw[label_int].append(inputs[i].unsqueeze(0))\n",
    "                \n",
    "    # ============================================================\n",
    "    # Calcolo delle Grad-CAM per ogni singola banda di frequenza\n",
    "    # ============================================================\n",
    "    \n",
    "    n_bands = 5  # numero di canali/bande di frequenza\n",
    "    band_names = ['Delta (δ)', 'Theta (Θ)', 'Alpha (α)', 'Beta (β) ', 'Gamma (γ)']  \n",
    "    \n",
    "    \n",
    "    '''STRUTTURE DATI PER CONV3D'''\n",
    "    #✅ Struttura per il GradCAM 3D, ossia qui raccolgo il GradCAM 3D di ogni esempio\n",
    "    # quindi la mappa di attivazione che identifica l'attivazioni più rilevanti per la classificazione di una esemplare di una certa classe\n",
    "    # sia spazialmente (height and width, ossia le dimensioni spaziali del mio tensore)\n",
    "    # sia frequenzialmente (depth), ossia le attivazioni più rilevanti in base alla banda di frequenza\n",
    "    \n",
    "    global_cams_3d = {0: [], 1: []} # shape (D, 9, 9)\n",
    "    \n",
    "    #Poi qui abbiamo: \n",
    "\n",
    "    # ✅ Struttura: classe → banda → immagini raw di input filtrate per singola banda (senza passare dal modello)\n",
    "    #tutte le mappe di potenza per la classe cls nella banda b-esima\n",
    "    \n",
    "    #La struttura per salvare invece lo potenza spettrale media per ogni relativa banda \n",
    "    raw_power_per_band_3d = {0: [[] for _ in range(n_bands)], 1: [[] for _ in range(n_bands)]}\n",
    "    \n",
    "    #La struttura che salverà la \"fetta\" del gradcam3D, ossia dove plotto solo la fetta della banda a partire dal global_cam_3d\n",
    "    #Ossia per ogni esempio di una specifica classe, prenderò la mappa di attivazione spazialmente più rilevante, in base alla specifica banda di frequenza indagata\n",
    "\n",
    "    #✅ Struttura: classe → banda → lista CAM\n",
    "    #cams_per_band_3d[cls][banda]: la slice D-esima (ossia la slice frequenziale) della mappa GradCAM per ogni campione di classe cls.\n",
    "    \n",
    "    cams_per_band_3d = {0: [[] for _ in range(n_bands)], 1: [[] for _ in range(n_bands)]}\n",
    "    \n",
    "    '''STRUTTURE DATI PER CONV SEPARABLE'''\n",
    "\n",
    "    \n",
    "    global_cams_2d = {0: [], 1: []} \n",
    "    \n",
    "    raw_power_per_band_2d = {0: [[] for _ in range(n_bands)], 1: [[] for _ in range(n_bands)]}\n",
    "    \n",
    "    cams_per_band_2d = {0: [[] for _ in range(n_bands)], 1: [[] for _ in range(n_bands)]}\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    Da qui in giù, vado a eseguire i passaggi essenziali per:\n",
    "    \n",
    "    1) Calcolare il GradCAM 3D per ogni esempio,\n",
    "    2) Isolare le fette (slice) per banda,\n",
    "    3) Raccogliere le immagini di potenza raw per ogni banda,\n",
    "    4) Calcolare le medie per classe e banda.\n",
    "    \n",
    "    '''\n",
    "\n",
    "\n",
    "    for cls in [0, 1]:\n",
    "        \n",
    "        for sample_input, sample_input_raw in zip(samples[cls], samples_raw[cls]):\n",
    "            \n",
    "            # 1) Preparo il sample per il calcolo\n",
    "            sample_input = sample_input.clone().detach().requires_grad_(True)\n",
    "            \n",
    "            '''\n",
    "            \n",
    "            Devo far squeeze perché essendo prelevati dal test loader, li avevo già resi con un 1 davanti ossia qui sopra\n",
    "\n",
    "            samples[label_int].append(inputs[i].unsqueeze(0))\n",
    "            \n",
    "            perché io, è vero che prendo i dati dal test_loader che son in formato batch (batch, D, H, W)\n",
    "            ma siccome poi prelevo ogni singolo esempio per metterli dentro a \"samples\", allora quella dimensione di batch si leva nel dizionario \"samples\".\n",
    "            \n",
    "            Per cui, quando voglio prendermi il singolo esempio per salvarmelo dentro a \"raw_vol\" (ossia la potenza spettrale del volume proprio di ogni esempio),\n",
    "            allora devo ri-assegnare ad ogni esempio la dimensione del batch (ossia 1, ossia il singolo esempio)\n",
    "            quando li salvo dentro samples. \n",
    "            \n",
    "            Ed infatti, quindi quell' \".unsqueeze(0)\" --> samples[label_int].append(inputs[i].unsqueeze(0)) serve proprio a questo...\n",
    "\n",
    "            Quando poi, devo prendere il singolo esempio da salvare, nei termini di potenza spettrale di ogni esempio (come volume 3D), \n",
    "            allora devo rifare .squeeze(), per togliere nuovamente la dimensione del batch (ossia 1, ossia il singolo esempio)\n",
    "            perché la rappresentazione del singolo esempio è, appunto, composta da, le sole dimensioni che costituiscono proprio il singolo esempio,\n",
    "            ossia 9x9x5 -->  ossia la griglia 3D !\n",
    "\n",
    "            E quindi, per ogni esempio, mi salvo la griglia 3d, ossia\n",
    "            \"raw_vol = sample_input.detach().cpu().numpy().squeeze()   # → (9, 9, 5)\"\n",
    "            \n",
    "            E poi, la divido però per banda \n",
    "            \n",
    "            \"for b in range(n_bands):\n",
    "                raw_power_per_band_3d[cls][b].append(raw_vol[:, :, b])\n",
    "            \"\n",
    "            '''\n",
    "            \n",
    "            # 2) Subito qui prendo la potenza raw del volume 9×9×5, senza passare dal modello!\n",
    "            #raw_vol[:, :, b] è una mappa 2D (9, 9) della potenza spettrale per la banda b per ogni singolo esempio\n",
    "            \n",
    "            raw_vol = sample_input_raw.detach().cpu().numpy().squeeze()     # → (9, 9, 5)\n",
    "            \n",
    "            '''CASTING IN FLOAT64'''\n",
    "            #raw_vol = sample_input.detach().cpu().numpy().squeeze().astype(np.float64)         # 🔹 cast a float64   # → (9, 9, 5)\n",
    "            \n",
    "            for b in range(n_bands):\n",
    "                \n",
    "                \n",
    "                # Determina in base al tipo di modello i dati e le shape da salvare:\n",
    "                \n",
    "                #if isinstance(model, CNN3D_LSTM_FC):\n",
    "                #if isinstance(model, SeparableCNN2D_LSTM_FC):\n",
    "                \n",
    "                    #target_layer = model.dw_conv1  # Per il modello separabile 2D\n",
    "                #else:\n",
    "                    #target_layer = model.conv3  # Per il modello CNN3D\n",
    "                    \n",
    "                if isinstance(model, CNN3D_LSTM_FC):\n",
    "                    \n",
    "                    #raw_power_per_band_3d invece raccoglie TUTTE le mappe 2D (9, 9) di ogni singolo esempio che conterrà la potenza spettrale alla stessa banda b \n",
    "                    #Lista di mappe di potenza 2D (una per trial) per la relativa banda\n",
    "\n",
    "                    raw_power_per_band_3d[cls][b].append(raw_vol[:, :, b])\n",
    "                    \n",
    "                elif isinstance(model, SeparableCNN2D_LSTM_FC):\n",
    "                    raw_power_per_band_2d[cls][b].append(raw_vol[:,:,b])\n",
    "\n",
    "            \n",
    "            # 2) Esegui il forward pass\n",
    "            output = model(sample_input)\n",
    "            target_class = output.argmax(dim=1).item()\n",
    "            \n",
    "            # 3) Esegui il backward pass\n",
    "            model.zero_grad()\n",
    "            target = output[0, target_class]\n",
    "            target.backward()\n",
    "            \n",
    "            # 4) Preleva attivazioni e gradienti\n",
    "            activ = gradcam.activations   # shape può essere 5D (B,C,D,H,W) per CNN3D o 4D (B, C, H, W) per CNN Separable\n",
    "            grads = gradcam.gradients # shape può essere 5D (B,C,D,H,W) per CNN3D o 4D (B, C, H, W) per CNN Separable\n",
    "            \n",
    "            #Nel caso 3D dovrebbe essere\n",
    "\n",
    "            #Media dei gradienti solo su H,W → (B,C,D,1,1)\n",
    "            #w3d = torch.mean(grads, dim=(3, 4))\n",
    "\n",
    "            # b) Sommo sui canali → (B,D,H,W)\n",
    "            #cam3d = F.relu(torch.sum(w3d * activ, dim=1))\n",
    "            \n",
    "            #e così la shape finale sarebbe 3D con (B,C,D)\n",
    "            \n",
    "            #✔️ w3d è correttamente calcolato per ogni (B, C, D, 1, 1)\n",
    "            #✔️ La somma su dim=1 aggrega le feature maps con pesi per ogni banda\n",
    "            #✔️ ReLU rimuove componenti negative\n",
    "            \n",
    "            '''\n",
    "            Nel caso della CNN3D calcoli una mappa Grad-CAM 3D \"globale\" direttamente dal layer convoluzionale 3D, ottenendo attivazioni di shape \n",
    "            (B,C,D,H,W) e quindi una CAM volumetrica per ogni trial\n",
    "            \n",
    "            CNN3D → calcoli una CAM 3D da attivazioni (B,C,D,H,W), una volta sola per ogni esempio.\n",
    "\n",
    "            '''\n",
    "            \n",
    "            if activ.ndim == 5:  # Caso per modello CNN3D pura \n",
    "                \n",
    "                # 3D Volumetric Grad-CAM\n",
    "                \n",
    "                # a) Media dei gradienti solo su H,W → (B,C,D,1,1)\n",
    "                w3d = torch.mean(grads, dim=(3, 4), keepdim=True)\n",
    "\n",
    "                # b) Sommo sui canali (feature maps) → (B,D,H,W)\n",
    "                cam3d = F.relu(torch.sum(w3d * activ, dim=1))\n",
    "                \n",
    "                # c) Upsample H×W, mantenendo D intatto\n",
    "                B, D, H, W = cam3d.shape\n",
    "                cam_flat = cam3d.view(B*D, 1, H, W)\n",
    "                cam_up   = F.interpolate(cam_flat,\n",
    "                                         size=(9, 9),\n",
    "                                         mode='bilinear',\n",
    "                                         align_corners=False)\n",
    "                \n",
    "                cam_vol  = cam_up.view(B, D, 9, 9).cpu().numpy()\n",
    "                \n",
    "                # d) Prendi ogni batch-item\n",
    "                \n",
    "                '''\n",
    "                Quindi qui ottengo che:\n",
    "            \n",
    "                1) appendo a global_cams_3d che cosa qui? il gradcam 3D ossia la mappa di attivazione di volume,\n",
    "                ossia OGNI esempio (volumetrico) per ogni classe (ossia 9x9x5 ancora, di OGNI esempio)\n",
    "                \n",
    "                Quindi semplicemente anziché rendere il dato come 'batch, D, H, W'.. siccome prendiamo ogni esempio UNO ALLA VOLTA\n",
    "                è inutile mantenere la dimensione batch (che sarebbe sempre 1, perché parliamo di ogni esempio, uno alla volta)\n",
    "                \n",
    "                ossia anziché fare \n",
    "                \n",
    "                global_cams_3d[cls].append(cam_vol)\n",
    "                \n",
    "                faccio\n",
    "                \n",
    "                global_cams_3d[cls].append(cam_vol[0])\n",
    "                \n",
    "                \n",
    "                E quindi, mi salvo per OGNI esempio direttamente la mappa cam 3d, per ogni banda, direttamente\n",
    "                ossia ogni esempio sarà costituito da 3 dimensioni (D, H, W) anziché dire \n",
    "                \n",
    "                \"Ogni dato (ossia ogni esempio) è composto da (batch, D, H, W) \n",
    "                se tanto il batch = 1 (perché il batch è il singolo esempio ogni volta)\n",
    "                \n",
    "                e quindi significherebbe aggiungere una dimensione (quella del batch) che in realtà è inutile, \n",
    "                perché si riferisce all'esempio stesso di già!\n",
    "                \n",
    "                Quindi:\n",
    "                👉 cam_vol[0] estrae la CAM 3D senza la dimensione \"batch\", che è inutile in quel contesto\n",
    "                👉 Serve per poter fare medie e slicing banda per banda correttamente dopo lo stack\n",
    "                👉 Questo rende compatibile il risultato finale con imshow (che accetta solo 2D o 3D RGB)\n",
    "       \n",
    "                2) appendo anche l'esempio volumetrico a cams_per_band_3d, MA GIA' suddiviso per banda! (per cui diventa 2d là dentro! 9x9)\n",
    "\n",
    "                '''\n",
    "                \n",
    "                global_cams_3d[cls].append(cam_vol[0])\n",
    "                \n",
    "                for b in range(n_bands):\n",
    "                    cams_per_band_3d[cls][b].append(cam_vol[0,b])\n",
    "            \n",
    "                '''\n",
    "                Nel caso della SeparableCNN2D, invece, il layer convoluzionale è 2D e riceve in input \n",
    "                (B,5,9,9), cioè con le bande di frequenza come canali (non come profondità). \n",
    "\n",
    "                Questo significa che non puoi ottenere direttamente una CAM 3D nello stesso modo, \n",
    "                ma si può ottenere una CAM 2D per ogni banda, \n",
    "                \"mascherando\" l’input attivando una banda alla volta\n",
    "\n",
    "                SeparableCNN2D → non hai accesso diretto a una \"profondità\" come in GradCAM 3D, quindi:\n",
    "\n",
    "                Simuli la profondità attivando una banda alla volta.\n",
    "\n",
    "                Ottieni una CAM 2D per ogni slice (banda), iterando sulle bande.\n",
    "\n",
    "                Questo approccio ti consente di costruire comunque strutture 3D:\n",
    "                cams_per_band_2d[cls][b] con b = 0...4 contiene \n",
    "                le CAM 2D relative alla banda b, ricostruendo idealmente la distribuzione tridimensionale\n",
    "                '''\n",
    "            \n",
    "            elif activ.ndim == 4: #Caso per il modello Conv Separabili \n",
    "                \n",
    "                # 1) Preparo il sample per il calcolo\n",
    "                sample_input = sample_input.clone().detach().requires_grad_(True) # sample_input: (1, 9, 9, 5)\n",
    "                \n",
    "                \n",
    "                '''\n",
    "                il mio sample input ora è sempre 4D, ma a differenza di prima, io sto trattando in questo caso \n",
    "                le bande come CANALI, e non come DEPTH (della convoluzione 3d pura!)\n",
    "                \n",
    "                Come prima, devo togliere la dimensione del batch ...\n",
    "                '''\n",
    "                \n",
    "                \n",
    "                # 2) Subito qui prendo la potenza raw del volume 9×9×5, senza passare dal modello!\n",
    "                #raw_vol[:, :, b] è una mappa 2D (9, 9) della potenza spettrale per la banda b per ogni singolo esempio\n",
    "                \n",
    "                raw_vol = sample_input_raw.detach().cpu().numpy().squeeze()     # → (9, 9, 5)\n",
    "                \n",
    "                '''CASTING IN FLOAT64'''\n",
    "                #raw_vol = sample_input.detach().cpu().numpy().squeeze().astype(np.float64)         # 🔹 cast a float64   # → (9, 9, 5)\n",
    "                \n",
    "                \n",
    "                '''\n",
    "                cams_per_band_2d e raw_power_per_band_2d son dentro al loop di MASKING, \n",
    "                perché entrambe si riferiscono alla banda e quindi devo essere inserite dentro al loop di masking...\n",
    "                \n",
    "                --> raw_power_per_band_2d[cls][b] e cams_per_band_2d[cls][b] sono dentro il loop (for b in ...) \n",
    "\n",
    "\n",
    "                \n",
    "                mentre global_cams_2d è FUORI da quel loop, perché raccoglie tutti gli esempi delle gradcam, \n",
    "                considerando però le mappe di attivazione di ogni banda singolarmente \n",
    "                e le aggrega per avere una visualizzazione dell'impatto complessivo di ogni singola banda sulla decisione del modello,\n",
    "                facendo vedere dove son maggiormente concentrate le attivazioni a livello spaziale TRA le bande ( = considerando TUTTE le bande assieme!)\n",
    "                \n",
    "                --> global_cams_2d[cls] sta dopo quel for b, raccogliendo una sola mappa 2D “complessiva” per trial\n",
    "                \n",
    "                In questo modo:\n",
    "\n",
    "                raw_power_per_band_2d e cams_per_band_2d catturano tutti i trial per banda.\n",
    "\n",
    "                global_cams_2d cattura un’unica mappa per trial, che poi aggregherò in global_mean_cams_2d per ottenere la heatmap 2D “globale”\n",
    "                che comprende tutte le bande insieme\n",
    "\n",
    "                '''\n",
    "                \n",
    "                \n",
    "                per_band_cams = []  # 👈 CAM di questo trial, una per banda\n",
    "                \n",
    "                \n",
    "                for b in range(n_bands):\n",
    "                    \n",
    "                    #raw_power_per_band_2d invece raccoglie TUTTE le mappe 2D (9, 9) di ogni singolo esempio che conterrà la potenza spettrale alla stessa banda b \n",
    "                    #Lista di mappe di potenza 2D (una per trial) per la relativa banda\n",
    "                    raw_power_per_band_2d[cls][b].append(raw_vol[:, :, b])\n",
    "                    \n",
    "                    # ✅ Creo un input mascherato con **solo** la banda b attiva\n",
    "                    masked = np.zeros_like(raw_vol)  # (9, 9, 5)\n",
    "                    \n",
    "                    masked[:, :, b] = raw_vol[:, :, b]  # attiva solo la banda b\n",
    "                    \n",
    "                    #Qui lo prepari in formato 4D, come vorrebbe il modello Conv Separable\n",
    "                    masked_tensor = torch.tensor(masked).unsqueeze(0).to(device)  # (1, 9, 9, 5)\n",
    "                    \n",
    "                    # Preparo il sample\n",
    "                    masked_tensor.requires_grad_(True)\n",
    "                    \n",
    "                    # Forward + backward\n",
    "                    output = model(masked_tensor)\n",
    "                    target_class = output.argmax(dim=1).item()\n",
    "                    model.zero_grad()\n",
    "                    \n",
    "                    target = output[0, target_class]\n",
    "                    target.backward()\n",
    "\n",
    "                    activ = gradcam.activations   # (B, C, H, W)\n",
    "                    grads = gradcam.gradients     # (B, C, H, W)\n",
    "                    \n",
    "                    # Calcolo CAM 2D (come standard GradCAM)\n",
    "                    w2d = torch.mean(grads, dim=(2, 3), keepdim=True)  # (B, C, 1, 1)\n",
    "                    cam = F.relu(torch.sum(w2d * activ, dim=1))        # (B, H, W) --> # (1, H, W)\n",
    "                    \n",
    "                    # ---- stesso nome in entrambi i casi ----\n",
    "                    \n",
    "                    B, H, W = cam.shape\n",
    "                    \n",
    "                    '''\n",
    "                    NEL CASO LAYER SIA DIVERSO DA pw_conv1, ALLORA FACCIO UPSAMPLING\n",
    "                    Cosa cambia in pratica:\n",
    "\n",
    "                    Se il target_layer è pw_conv1 (feature map 32×9×9):\n",
    "\n",
    "                    H, W = 9, 9 → salta l’interpolate, quindi nessuna distorsione spaziale.\n",
    "\n",
    "                    Se un domani cambi target_layer a un layer dopo un pool (es. conv2b con mappe 4×4):\n",
    "\n",
    "                    H, W != 9 → scatta l’upsampling e tutto continua a funzionare come prima.\n",
    "\n",
    "                    Il ramo 3D (activ.ndim == 5) non lo tocchi, lì l’upsampling è ancora necessario (4×4 → 9×9).\n",
    "\n",
    "                    Con questa modifica il caso SeparableCNN2D è “pulito” e allineato alla griglia elettrodica 1:1\n",
    "                    '''\n",
    "                    \n",
    "                    if (H, W) != (9, 9):\n",
    "                    \n",
    "                        #Riporto la shape con .unsqueeze(1) a 4D per fare interpolation e alla fine di nuovo in 3d\n",
    "                        cam = F.interpolate(cam.unsqueeze(1), size=(9, 9), mode='bilinear', align_corners=False).squeeze(1)\n",
    "                    \n",
    "                    \n",
    "                    # caso pw_conv1: la mappa è già 9x9 → nessun upsampling\n",
    "                    \n",
    "                    #Riporto la shape con .squeeze(1) a 3D per salvare i dati\n",
    "                    #cam_2d = cam_up.squeeze(1).cpu().numpy()  # (B, 9, 9)\n",
    "                    \n",
    "                    cam_2d = cam.detach().cpu().numpy()      # (B,9,9)\n",
    "\n",
    "                    # ✅ Aggiungo la mappa CAM alla banda corrispondente\n",
    "                    cams_per_band_2d[cls][b].append(cam_2d[0])  # prende il CAM per il sample corrente (9x9)\n",
    "                    \n",
    "                    # Conteggio della CAM corrente, per questo trial\n",
    "                    per_band_cams.append(cam_2d[0])                   \n",
    "                    \n",
    "                #Qui “ricompatti” i 5 CAM 2D in un volume e poi medii, per ottenere una mappa 2D complessiva che tenga insieme l’informazione su tutte le bande.\n",
    "                #Durante il loop, dopo il masking e il calcolo di cam_2d, fai:\n",
    "                # cam_2d ha shape (1,9,9) → [0] è la matrice 9×9\n",
    "                \n",
    "                # 👇 qui, fuori dal for b\n",
    "                \n",
    "                all_cams_2d_per_band = np.mean(np.stack(per_band_cams), axis=0)  # (9,9)\n",
    "                \n",
    "                global_cams_2d[cls].append(all_cams_2d_per_band)\n",
    "            else:\n",
    "                raise RuntimeError(f\"activ.ndim inatteso: {activ.ndim}\")\n",
    "                \n",
    "                \n",
    "    '''\n",
    "    CASO MODELLO CON 3D PURO, dovrei fare: \n",
    "\n",
    "    1) per global_cams_3d vado ad ottenere una media, ossia una global_mean_cams_3d, che riassume il contributo GLOBALE della gradcam 3D aggregata\n",
    "    all'interno dell'intero volume 3D (che poi al massimo si può scorporare vedendo per ogni banda successivamante)\n",
    "\n",
    "    '''\n",
    "    \n",
    "    if isinstance(model, CNN3D_LSTM_FC):\n",
    "        \n",
    "        #1) global_cams_3d → media “globale” del volume 3D Grad‑CAM\n",
    "        # media sul numero di esempi per ogni classe → ottieni un array (D, H, W)\n",
    "        global_mean_cams_3d = {\n",
    "            cls: np.mean(np.stack(global_cams_3d[cls]), axis=0)  # da [ (1,D,H,W), … ] a (D,H,W)\n",
    "            for cls in [0,1]\n",
    "        }\n",
    "        \n",
    "        # ➜ CAM 2D globale per classe (media su TUTTE le bande dal VOLUME 3D)\n",
    "        global_2d_from3d = {\n",
    "            cls: np.mean(global_mean_cams_3d[cls], axis=0)  # (9,9)\n",
    "            for cls in [0, 1]\n",
    "        }\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "        '''\n",
    "        2) poi, dentro a raw_power_per_band_3d (siccome è già suddivsa ogni potenza spettrale in 2D di ogni esempio, per ogni classe e per ogni banda !)\n",
    "        ottenere una media sulla potenza spettrale dei gradcam di ogni trial della relativa classe, sulla relativa banda... (i.e., mean_raw_power_per_band_3d)\n",
    "        '''\n",
    "\n",
    "        #2) raw_power_per_band_3d → media della potenza raw per banda\n",
    "        #Hai già raccolto, per ogni cls e per ogni banda b, tutte le mappe 2D raw_power_per_band_3d[cls][b] (una per trial).\n",
    "        #La media diventa:\n",
    "\n",
    "        mean_raw_power_per_band_3d = {\n",
    "            cls: [ np.mean(np.stack(raw_power_per_band_3d[cls][b]), axis=0)\n",
    "                   for b in range(n_bands) ]\n",
    "            for cls in [0,1]\n",
    "        }\n",
    "\n",
    "        # risultato: mean_raw_power_per_band_3d[cls][b] è (H,W)\n",
    "\n",
    "        '''\n",
    "        3) dentro a cams_per_band_3d, (siccome è già suddivsa ogni gradcam in 2D di ogni esempio, per ogni classe e per ogni banda !) \n",
    "        ottenere una media sulle gradcam di ogni trial della relativa classe, sulla relativa banda... (i.e., mean_cam_3d_per_band) \n",
    "\n",
    "        '''\n",
    "\n",
    "        #3) cams_per_band_3d → media della Grad‑CAM per banda\n",
    "        #Analogamente hai raccolto tutte le slice 2D di Grad‑CAM in cams_per_band_3d[cls][b].\n",
    "        #La media diventa:\n",
    "\n",
    "        mean_cams_per_band_3d = {\n",
    "            cls: [ np.mean(np.stack(cams_per_band_3d[cls][b]), axis=0)\n",
    "                   for b in range(n_bands) ]\n",
    "            for cls in [0,1]\n",
    "        }\n",
    "        # mean_cam_3d_per_band[cls][b] ha shape (H,W)\n",
    "\n",
    "\n",
    "        '''\n",
    "        Con queste tre strutture (global_mean_cams_3d, mean_raw_power_per_band_3d, mean_cam_3d_per_band) puoi\n",
    "\n",
    "        riga 1–2: istogrammi di mean_cam_3d_per_band[cls][b]\n",
    "\n",
    "        riga 3–4: heatmap di mean_cam_3d_per_band[cls][b]\n",
    "\n",
    "        riga 5–6: heatmap di mean_raw_power_per_band_3d[cls][b]\n",
    "\n",
    "        riga 7–8: slice di global_mean_cams_3d[cls] per ogni b\n",
    "\n",
    "        '''\n",
    "    \n",
    "    elif isinstance(model, SeparableCNN2D_LSTM_FC):\n",
    "    \n",
    "        '''\n",
    "        CASO MODELLO CONV SEPARABLE, dovrei fare: \n",
    "\n",
    "        1) per global_cams_2d vado ad ottenere una media, ossia una global_mean_cams_2d, che riassume il contributo GLOBALE della gradcam 2D aggregata\n",
    "        all'interno di TUTTE LE BANDE ASSIME (che mi dovrebbe dare quindi per OGNI CLASSE un plot unico, \n",
    "        e non come il global_mean_cams_3d, dove dovrei vedere in quel caso, invece, la stessa mappa di “rilevanza complessiva”, MA distribuita lungo la profondità,\n",
    "        ossia tra le bande e quindi potrei vedere se effettivamente io abbia una banda che è specificatamente più attiva di altre COMPLESSIVAMENTE...\n",
    "\n",
    "        Per la SeparableCNN2D ricostruisci un Grad‑CAM “3D” artificiale facendo 5 Grad‑CAM 2D una per ogni banda\n",
    "        '''\n",
    "\n",
    "        #global_cams_2d\n",
    "        #Qui “ricompatti” i 5 CAM 2D in un volume e poi medii, per ottenere una mappa 2D complessiva che tenga insieme l’informazione su tutte le bande.\n",
    "        #Durante il loop, dopo il masking e il calcolo di cam_2d, fai:\n",
    "\n",
    "        # cam_2d ha shape (1,9,9) → [0] è la matrice 9×9\n",
    "        #global_cams_2d[cls].append(cam_2d[0])\n",
    "\n",
    "        global_mean_cams_2d = {\n",
    "            cls: np.mean(np.stack(global_cams_2d[cls]), axis=0)\n",
    "            for cls in [0,1]\n",
    "        }\n",
    "        # global_mean_cams_2d[cls] shape = (9,9)\n",
    "\n",
    "        '''\n",
    "        2) poi, dentro a raw_power_per_band_2d (siccome è già suddivsa ogni potenza spettrale in 2D di ogni esempio, per ogni classe e per ogni banda !)\n",
    "        ottenere una media sulla potenza spettrale dei gradcam di ogni trial della relativa classe, sulla relativa banda... (i.e., mean_raw_power_per_band_2d)\n",
    "        '''\n",
    "\n",
    "        #raw_power_per_band_2d\n",
    "        #Hai già in raw_power_per_band_2d[cls][b] tutte le mappe 2D di potenza (9×9) per trial, per ciascuna banda b.\n",
    "        #La media finale:\n",
    "\n",
    "\n",
    "        mean_raw_power_per_band_2d = {\n",
    "            cls: [ np.mean(np.stack(raw_power_per_band_2d[cls][b]), axis=0)\n",
    "                  for b in range(n_bands) ]\n",
    "            for cls in [0,1]\n",
    "        }\n",
    "\n",
    "        # mean_raw_power_per_band_2d[cls][b] shape = (9,9)\n",
    "\n",
    "\n",
    "        '''\n",
    "        3) dentro a cams_per_band_2d, (siccome è già suddivsa ogni gradcam in 2D di ogni esempio, per ogni classe e per ogni banda !) \n",
    "        ottenere una media sulle gradcam di ogni trial della relativa classe, sulla relativa banda... (i.e., mean_cam_2d_per_band) \n",
    "\n",
    "        '''\n",
    "\n",
    "        #cams_per_band_2d\n",
    "        #Durante il masking loop appendi in cams_per_band_2d[cls][b] il CAM 2D (9×9) di ogni trial.\n",
    "        #La media finale:\n",
    "\n",
    "        mean_cams_per_band_2d = {\n",
    "            cls: [ np.mean(np.stack(cams_per_band_2d[cls][b]), axis=0)\n",
    "                   for b in range(n_bands) ]\n",
    "            for cls in [0,1]\n",
    "        }\n",
    "        # mean_cam_2d_per_band[cls][b] shape = (9,9)\n",
    "\n",
    "        '''\n",
    "        Con queste tre strutture —\n",
    "\n",
    "        mean_raw_power_per_band_2d (5 mappe 9×9),\n",
    "\n",
    "        mean_cam_2d_per_band (5 mappe 9×9),\n",
    "\n",
    "        global_mean_cams_2d (1 mappa 9×9) —\n",
    "\n",
    "        puoi costruire esattamente le stesse righe di plot che avevi per il caso 3D, solo che al posto di “slice” del volume userai le CAM 2D mascherate.\n",
    "\n",
    "\n",
    "        '''\n",
    "    \n",
    "    # Preleva la struttura corretta in base al modello\n",
    "    \n",
    "    if isinstance(model, SeparableCNN2D_LSTM_FC):\n",
    "        mean_cams_per_band = mean_cams_per_band_2d\n",
    "        mean_raw_power_per_band = mean_raw_power_per_band_2d\n",
    "        global_mean_cams = global_mean_cams_2d\n",
    "    \n",
    "    else:  # Caso per modello CNN3D\n",
    "        mean_cams_per_band = mean_cams_per_band_3d\n",
    "        mean_raw_power_per_band = mean_raw_power_per_band_3d\n",
    "        \n",
    "        #global_mean_cams = global_mean_cams_3d\n",
    "        \n",
    "        \n",
    "        \n",
    "        '''NUOVA MODIFICA''' \n",
    "        global_mean_cams = global_2d_from3d\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # prima di salvare la figura, solo se richiesto vedi i valori delle potenze medie per banda e condizione sperimentale...\n",
    "    \n",
    "    #\"tag_names=[f\"{model.__class__.__name__} power\"]\")\n",
    "    \n",
    "    if debug:\n",
    "        if isinstance(model, CNN3D_LSTM_FC):\n",
    "            model_tag = f\"{model.__class__.__name__} power\"\n",
    "            check_negative_residuals(band_names,\n",
    "                                     mean_raw_power_per_band_3d,\n",
    "                                     model_tag)\n",
    "        else:\n",
    "            model_tag = f\"{model.__class__.__name__} power\"\n",
    "            check_negative_residuals(band_names,\n",
    "                                     mean_raw_power_per_band_2d,\n",
    "                                     model_tag)\n",
    "            \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Crea la figura dinamicamente in base al modello\n",
    "    if isinstance(model, SeparableCNN2D_LSTM_FC):\n",
    "        fig, axs = plt.subplots(8, 5, figsize=(24, 30))  # 2 righe per 5 colonne per modello 2D\n",
    "    else:\n",
    "        fig, axs = plt.subplots(8, 5, figsize=(24, 30))  # 5 righe per 2 colonne per modello 3D\n",
    "\n",
    "    \n",
    "    \n",
    "            \n",
    "    title = (\n",
    "        f\"Grad-CAM Mapping over EEG Trials – Experimental Conditions: {exp_cond}\\n\\n\"\n",
    "        \"Row 1-2: Histogram of Mean Grad-CAM raw values for each class and frequency band\\n\"\n",
    "        \"Row 3-4: Normalized Mean Grad-CAM heatmaps for Class 0 (top) and Class 1 (bottom)\\n\"\n",
    "        \"Row 5-6: Log Mean Raw power maps for Class 0 (top) and Class 1 (bottom)\\n\"\n",
    "        \"Row 7-8: Global CAM per Class\"\n",
    "        )\n",
    "    \n",
    "    plt.suptitle(title, fontsize=15)\n",
    "\n",
    "    # Spaziatura verticale per evitare sovrapposizione\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    \n",
    "    plt.subplots_adjust(hspace = 0.7, wspace = 0.4)  # Fine tuning della spaziatura tra subplot\n",
    "    \n",
    "    #PER PLOT RIGA 1-2 \n",
    "    \n",
    "    from matplotlib.ticker import ScalarFormatter, MaxNLocator\n",
    "\n",
    "    # Crea un formatter per notazione scientifica\n",
    "    sci_formatter = ScalarFormatter(useMathText=True)\n",
    "    \n",
    "    #Questa chiamata serve a forzare il range entro cui usare la notazione scientifica\n",
    "    #Se non metti questo limite, il comportamento può variare leggermente a seconda della scala dei dati —\n",
    "    #a volte sarà decimale (0.0001), altre volte esponenziale (1e-4), e potrebbe non essere uniforme tra subplot.\n",
    "    \n",
    "    sci_formatter.set_powerlimits((-3, 3))  # usa 1e-xxx se valori sono piccoli\n",
    "\n",
    "    for b, b_name in enumerate(band_names):\n",
    "    \n",
    "        for j, cls in enumerate([0, 1]):\n",
    "            \n",
    "            # Calcola l'istogramma dei valori della heatmap media\n",
    "            # rispetto alle 2 classi in base alla banda di frequenza isolata\n",
    "            \n",
    "            ax = axs[0, b] if cls == 0 else axs[1, b]\n",
    "            \n",
    "            ax.hist(mean_cams_per_band[cls][b].flatten(), bins='auto', color='blue', edgecolor='black')\n",
    "            ax.set_title(f\"{b_name} - Class {condition_names[cls]}\", fontsize=10)\n",
    "            ax.set_xlabel(\"Grad-CAM Value\")\n",
    "            ax.set_ylabel(\"Count\")\n",
    "            \n",
    "            # ✅ Format tick con notazione scientifica\n",
    "            ax.xaxis.set_major_formatter(sci_formatter)\n",
    "            ax.xaxis.set_major_locator(MaxNLocator(4))      # max ~4 tick\n",
    "            \n",
    "            #ax.tick_params(axis='x', labelrotation=45, labelsize=6)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #PER PLOT RIGA 3-4 \n",
    "    \n",
    "    '''\n",
    "    Concateno tutte le mean-CAM (cls 0+1, tutte le bande) in un unico array\n",
    "    in modo da confrontare le Gradcam tra classi e bande tra di loro! \n",
    "    '''\n",
    "    \n",
    "    all_mean_cams = np.concatenate([\n",
    "        mean_cams_per_band[0][b].flatten()\n",
    "        for b in range(n_bands)\n",
    "    ] + [\n",
    "        mean_cams_per_band[1][b].flatten()\n",
    "        for b in range(n_bands)\n",
    "    ])\n",
    "    vmin_cam = all_mean_cams.min()\n",
    "    vmax_cam = all_mean_cams.max()\n",
    "    \n",
    "    \n",
    "    for b, band in enumerate(band_names):                                 \n",
    "        \n",
    "        for j, cls in enumerate([0, 1]):\n",
    "            \n",
    "            ax = axs[2, b] if cls == 0 else axs[3, b]\n",
    "            \n",
    "            cam = mean_cams_per_band[cls][b] \n",
    "            \n",
    "            # Controlla se la forma è corretta per l'input di imshow\n",
    "            assert cam.ndim == 2, f\"Expected 2D array, got {cam.ndim}D array\"\n",
    "            \n",
    "            im = ax.imshow(\n",
    "                cam,\n",
    "                cmap = 'RdYlBu_r',\n",
    "                vmin = vmin_cam, \n",
    "                vmax = vmax_cam,\n",
    "                aspect = 'equal',\n",
    "                origin = 'upper'\n",
    "            )\n",
    "            \n",
    "            ticks = np.linspace(vmin_cam, vmax_cam, 6)\n",
    "\n",
    "            cbar = fig.colorbar(\n",
    "                im, ax=ax, orientation='horizontal', pad=0.12, ticks=ticks, format='%.1e')\n",
    "            \n",
    "            cbar.set_ticks(ticks)\n",
    "            cbar.ax.xaxis.set_major_locator(FixedLocator(ticks))\n",
    "            cbar.set_ticklabels([f\"{t:.2f}\" for t in ticks])\n",
    "\n",
    "            ax.set_title(\n",
    "                f\"{band} - Class {condition_names[cls]}\",\n",
    "                fontsize=10\n",
    "            )\n",
    "\n",
    "            if channel_names is not None:\n",
    "                ax.set_xticks([])\n",
    "                ax.set_yticks([])\n",
    "                for name, (y, x) in channel_names.items():\n",
    "                    ax.text(\n",
    "                        x, y, name,\n",
    "                        ha='center', va='center',\n",
    "                        fontsize=6, color='black', weight='bold'\n",
    "                    )\n",
    "            else:\n",
    "                ax.axis(\"off\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    #PER PLOT RIGA 5-6 \n",
    "    \n",
    "    '''\n",
    "    Concateno tutte lo spettogrammam medio logaritmico\n",
    "    da confrontare tra le classi per ogni banda tra di loro! \n",
    "    '''\n",
    "\n",
    "    \n",
    "    # Log-trasform delle mappe di potenza per banda\n",
    "    log_mean_power_per_band = {\n",
    "        cls: [np.log1p(mean_raw_power_per_band[cls][b])\n",
    "              for b in range(n_bands)]\n",
    "        for cls in [0, 1]\n",
    "    }\n",
    "    \n",
    "    #Concateno tutte le mean-power (cls 0+1, tutte le bande) in un unico array\n",
    "    \n",
    "    \n",
    "    # concateno tutte le log mean-power (cls 0+1, tutte le bande) in un unico array\n",
    "    all_mean_pow = np.concatenate([\n",
    "        log_mean_power_per_band[0][b].flatten()\n",
    "        for b in range(n_bands)\n",
    "    ] + [\n",
    "        log_mean_power_per_band[1][b].flatten()\n",
    "        for b in range(n_bands)\n",
    "    ])\n",
    "    vmin_pow = all_mean_pow.min()\n",
    "    vmax_pow = all_mean_pow.max()\n",
    "    \n",
    "    ticks = np.linspace(vmin_pow, vmax_pow, 6)\n",
    "    \n",
    "    from matplotlib.ticker import ScalarFormatter\n",
    "\n",
    "    sci = ScalarFormatter(useMathText=True)\n",
    "    sci.set_powerlimits((-2, 2))          # forza 1eX fuori dall’intervallo 1e‑2 … 1e2\n",
    "\n",
    "    for b, band in enumerate(band_names):\n",
    "        \n",
    "        for cls in [0, 1]:\n",
    "            ax = axs[4, b] if cls == 0 else axs[5, b]\n",
    "\n",
    "            log_power = log_mean_power_per_band[cls][b]\n",
    "\n",
    "            im = ax.imshow(\n",
    "                log_power,\n",
    "                cmap='jet',\n",
    "                vmin=vmin_pow,\n",
    "                vmax=vmax_pow,\n",
    "                aspect='equal',\n",
    "                origin='upper'\n",
    "            )\n",
    "            \n",
    "            cbar = fig.colorbar(im, ax=ax, orientation='horizontal', pad=0.12, ticks = ticks, format= sci)#format='%.1e')\n",
    "\n",
    "            cbar.ax.xaxis.set_major_formatter(sci) # <-- solo formatter\n",
    "            cbar.ax.tick_params(labelsize=6)\n",
    "\n",
    "            ax.set_title(f\"{band} Log Mean Power - Class {condition_names[cls]}\", fontsize=10)\n",
    "            \n",
    "            if channel_names is not None:\n",
    "                ax.set_xticks([])\n",
    "                ax.set_yticks([])\n",
    "                for name, (y, x) in channel_names.items():\n",
    "                    ax.text(x, y, name, ha='center', va='center', fontsize=6, color='black', weight='bold')\n",
    "            else:\n",
    "                ax.axis(\"off\")\n",
    "                \n",
    "                \n",
    "    '''\n",
    "    OLD PLOTS SPETTROGRAMMA RAW \n",
    "    \n",
    "    \n",
    "    #****** ****** ****** ****** ****** ****** ****** ****** ****** ****** ****** ****** ****** ****** ****** ******\n",
    "     \n",
    "    #PER PLOT RIGA 5-6 (SCALA LINEARE)\n",
    "    \n",
    "    from matplotlib.ticker import ScalarFormatter\n",
    "\n",
    "    sci = ScalarFormatter(useMathText=True)\n",
    "    sci.set_powerlimits((-2, 2))          # forza 1eX fuori dall’intervallo 1e‑2 … 1e2\n",
    "\n",
    "    \n",
    "    #Concateno tutte le mean-power (cls 0+1, tutte le bande) in un unico array\n",
    "    \n",
    "    \n",
    "    # concateno tutte le mean-power (cls 0+1, tutte le bande) in un unico array\n",
    "    all_mean_pow = np.concatenate([\n",
    "        mean_raw_power_per_band[0][b].flatten()\n",
    "        for b in range(n_bands)\n",
    "    ] + [\n",
    "        mean_raw_power_per_band[1][b].flatten()\n",
    "        for b in range(n_bands)\n",
    "    ])\n",
    "    vmin_pow = all_mean_pow.min()\n",
    "    vmax_pow = all_mean_pow.max()\n",
    "    \n",
    "    \n",
    "    ticks = np.linspace(vmin_pow, vmax_pow, 6)\n",
    "    \n",
    "    # Riga 3: Mappa della potenza media rispetto a distribuzione congiunta (su ciascuna banda e classe)\n",
    "    for b, band in enumerate(band_names):\n",
    "        \n",
    "        for cls in [0, 1]:\n",
    "            ax = axs[4, b] if cls == 0 else axs[5, b]\n",
    "            \n",
    "            power = mean_raw_power_per_band[cls][b] \n",
    "            \n",
    "            im = ax.imshow(\n",
    "                power, \n",
    "                cmap='jet',\n",
    "                vmin= vmin_pow,\n",
    "                vmax= vmax_pow,\n",
    "                aspect='equal',\n",
    "                origin='upper'\n",
    "            )\n",
    "            \n",
    "            #ticks = np.linspace(vmin_pow, vmax_pow, 6)\n",
    "            \n",
    "            cbar = fig.colorbar(im, ax=ax, orientation='horizontal', pad=0.12, ticks = ticks, format= sci)#format='%.1e')\n",
    "            \n",
    "            #cbar.ax.xaxis.set_major_locator(FixedLocator(ticks))\n",
    "            #cbar.set_ticklabels([f\"{t:.2f}\" for t in ticks])\n",
    "            \n",
    "            cbar.ax.xaxis.set_major_formatter(sci)   # <-- solo formatter\n",
    "            cbar.ax.tick_params(labelsize=6)\n",
    "            \n",
    "            ax.set_title(f\"{band} Power - Class {condition_names[cls]}\", fontsize=10)\n",
    "            \n",
    "            if channel_names is not None:\n",
    "                ax.set_xticks([])\n",
    "                ax.set_yticks([])\n",
    "                for name, (y, x) in channel_names.items():\n",
    "                    ax.text(x, y, name, ha='center', va='center', fontsize=6, color='black', weight='bold')\n",
    "            else:\n",
    "                ax.axis(\"off\")\n",
    "                \n",
    "                \n",
    "    \n",
    "    #****** ****** ****** ****** ****** ****** ****** ****** ****** ****** ****** ****** ****** ****** ****** ******\n",
    "    \n",
    "    #PER PLOT RIGA 5-6 (SCALA LOGARITMICA)\n",
    "        \n",
    "    \n",
    "    # ----- 1. calcola vmin_pow / vmax_pow -----\n",
    "    \n",
    "    #Concateno tutte le mean-power (cls 0+1, tutte le bande) in un unico array\n",
    "    \n",
    "    \n",
    "    # concateno tutte le mean-power (cls 0+1, tutte le bande) in un unico array\n",
    "    all_mean_pow = np.concatenate([\n",
    "        mean_raw_power_per_band[0][b].flatten()\n",
    "        for b in range(n_bands)\n",
    "    ] + [\n",
    "        mean_raw_power_per_band[1][b].flatten()\n",
    "        for b in range(n_bands)\n",
    "    ])\n",
    "    vmin_pow = all_mean_pow.min()\n",
    "    vmax_pow = all_mean_pow.max()\n",
    "    \n",
    "    #Filtra solo i valori strettamente > 0 (la scala log non accetta zeri o negativi).\n",
    "    #Perché? Se l’intero array fosse ≤ 0 (caso patologico) avremmo positive.size == 0.\n",
    "    positive = all_mean_pow[all_mean_pow > 0]\n",
    "    \n",
    "    \n",
    "    \n",
    "    #In pratica: stiamo abbassando il bordo inferiore del colormap di un 10 % rispetto al minimo positivo reale, \n",
    "    #così quei pixel non finiscono “incollati” al limite della color‑bar. Se preferisci usare un altro margine (5 %, 1 %) basta cambiare 0.9 in 0.95, 0.99, ecc.\n",
    "    #Se invece vuoi proprio che vada esattamente sul minimo, puoi togliere *0.9 (ma occhio ai warning di Matplotlib)\n",
    "    \n",
    "    #Il resto del blocco:\n",
    "\n",
    "    #Calcola vmax_pow dal massimo globale.\n",
    "    #Decide automaticamente use_log se il dynamic‑range supera 10³.\n",
    "    #Imposta una sola logica di plotting: quando use_log è True usa LogNorm, LogLocator e LogFormatterMathtext; altrimenti scala lineare + ScalarFormatter.\n",
    "\n",
    "    #I titoli aggiungono “(log10)” solo quando serve.\n",
    "    #Nota: quando use_log è True, passiamo vmin/vmax tramite LogNorm; quando è False, li passiamo direttamente a imshow con i parametri vmin=…, vmax=….\n",
    "    #Così la stessa funzione disegna correttamente entrambe le situazioni senza dover duplicare codice.\n",
    "    \n",
    "    \n",
    "    #1. Se esistono valori positivi, prende il più piccolo e lo moltiplica per 0.9 (−10 %).\n",
    "    # Obiettivo: Creare un piccolo margine: il vero minimo non cade esattamente sul bordo inferiore della scala log, evitando clip / warning.\n",
    "    \n",
    "    #2. Se non esistono, imposta un fallback sicur0\n",
    "    # Obiettivo: Garantire che vmin_pow > 0 in ogni caso (requisito di LogNorm).\n",
    "    \n",
    "    #vmin_pow = positive.min()*0.9 if positive.size else 1e-12\n",
    "    #vmin_pow = positive.min() if positive.size else 1e-12\n",
    "    \n",
    "    vmin_pow = positive.min()\n",
    "    \n",
    "    vmax_pow = all_mean_pow.max()\n",
    "\n",
    "    use_log  = vmax_pow / max(vmin_pow, 1e-12) > 1e3   # o il flag suggest_log\n",
    "\n",
    "    if use_log:\n",
    "        norm      = LogNorm(vmin=vmin_pow, vmax=vmax_pow)\n",
    "        locator   = LogLocator(base=10.0)\n",
    "        formatter = LogFormatterMathtext(base=10.0)\n",
    "    else:\n",
    "        norm      = None\n",
    "        locator   = None\n",
    "        formatter = ScalarFormatter(useMathText=True)\n",
    "        formatter.set_powerlimits((-2, 2))         # 1e‑2 – 1e2 lineare\n",
    "\n",
    "    # ----- 2. plot -----\n",
    "    for b, band in enumerate(band_names):\n",
    "        for cls in (0, 1):\n",
    "            ax   = axs[4, b] if cls == 0 else axs[5, b]\n",
    "            pow_ = mean_raw_power_per_band[cls][b]\n",
    "\n",
    "            im = ax.imshow(pow_, cmap='jet', norm=norm,\n",
    "                           vmin=None if use_log else vmin_pow,\n",
    "                           vmax=None if use_log else vmax_pow,\n",
    "                           aspect='equal', origin='upper')\n",
    "\n",
    "            cbar = fig.colorbar(im, ax=ax, orientation='horizontal', pad=0.12)\n",
    "            \n",
    "            if locator is not None:\n",
    "                cbar.locator   = locator\n",
    "            cbar.formatter = formatter\n",
    "            cbar.update_ticks()\n",
    "            cbar.ax.tick_params(labelsize=8)\n",
    "\n",
    "            scale = \"(log10)\" if use_log else \"\"\n",
    "            ax.set_title(f\"{band} Power {scale} – Class {condition_names[cls]}\",\n",
    "                         fontsize=10)\n",
    "            \n",
    "            if channel_names is not None:\n",
    "                ax.set_xticks([])\n",
    "                ax.set_yticks([])\n",
    "                for name, (y, x) in channel_names.items():\n",
    "                    ax.text(x, y, name, ha='center', va='center', fontsize=6, color='black', weight='bold')\n",
    "            else:\n",
    "                ax.axis(\"off\")\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    \n",
    "    \n",
    "    #PER PLOT RIGA 7-8\n",
    "    \n",
    "    '''\n",
    "    Vorrei solo verificare allora l'ultima riga 7-8 per la differenza tra i due modelli, perchè: \n",
    "    \n",
    "    \n",
    "    1) Nel caso del modello 3d puro, ho ancora una fetta rappresentata, ossia\n",
    "\n",
    "    per global_cams_3d vado ad ottenere una media, ossia una global_mean_cams_3d, che riassume il contributo GLOBALE della gradcam 3D aggregata\n",
    "    all'interno dell'intero volume 3D (che poi al massimo si può scorporare vedendo per ogni banda successivamante) \n",
    "\n",
    "    ed è quello che vorrei fare per il modello Conv3D puro...\n",
    "\n",
    "    2) per il modello Conv Separabili invece, \n",
    "\n",
    "    per global_cams_2d vado ad ottenere una media, ossia una global_mean_cams_2d, che riassume il contributo GLOBALE della gradcam 2D aggregata\n",
    "    all'interno di TUTTE LE BANDE ASSIEME (che mi dovrebbe dare quindi per OGNI CLASSE un plot unico, \n",
    "    \n",
    "    e non come il global_mean_cams_3d, dove dovrei vedere in quel caso, invece, la stessa mappa di “rilevanza complessiva”, MA distribuita lungo la profondità,\n",
    "    ossia tra le bande e quindi potrei vedere se effettivamente io abbia una banda che è specificatamente più attiva di altre COMPLESSIVAMENTE ...\n",
    "\n",
    "    devo verificare che per queste righe 7-8, a seconda del modello, il codice sia corretto, in base a come so che \n",
    "\n",
    "    global_mean_cams_3d e global_mean_cams_2d sono in realtà adesso ossia \n",
    "    \n",
    "    global_mean_cams_3d[cls]\t(5, 9, 9)\tvolume medio 3D\n",
    "    global_mean_cams_2d[cls]\t(9, 9)\theatmap 2D “globale” su tutte le bande\n",
    "\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    Costruiamo la distribuzione congiunta della media del singolo input multi-canale per ogni classe\n",
    "    '''\n",
    "    \n",
    "    all_global_mean_cams = np.concatenate([global_mean_cams[0].flatten(), global_mean_cams[1].flatten()])\n",
    "    \n",
    "    global_vmin_cam = all_global_mean_cams.min()\n",
    "    global_vmax_cam = all_global_mean_cams.max()\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    In sintesi:\n",
    "\n",
    "    CNN3D: global_mean_cams_3d[cls] è già shape (5,9,9), quindi fai subito mat2d = global_mean_cams_3d[cls][b]\n",
    "    SeparableCNN2D: global_mean_cams_2d[cls] è shape (9,9), e la metti in axs[6, cls]\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    \n",
    "    #'''Global CAM 2D: una mappa per classe, entrambe su riga 6'''\n",
    "    \n",
    "    if isinstance(model, SeparableCNN2D_LSTM_FC):\n",
    "        \n",
    "        #mean_cams_per_band = mean_cams_per_band_2d\n",
    "        #mean_raw_power_per_band = mean_raw_power_per_band_2d\n",
    "        global_mean_cams = global_mean_cams_2d\n",
    "        \n",
    "        # Global 2D: una sola heatmap per classe\n",
    "        for cls in [0, 1]:\n",
    "            ax = axs[6, cls]\n",
    "            mat2d = global_mean_cams[cls]  # (9,9)\n",
    "            im = ax.imshow(mat2d,\n",
    "                           cmap='RdYlBu_r',\n",
    "                           vmin=global_vmin_cam,\n",
    "                           vmax=global_vmax_cam,\n",
    "                           aspect='equal',\n",
    "                           origin='upper')\n",
    "            ticks = np.linspace(global_vmin_cam, global_vmax_cam, 6)\n",
    "            cbar = fig.colorbar(im, ax=ax,\n",
    "                                orientation='horizontal',\n",
    "                                pad=0.12,\n",
    "                                ticks=ticks,\n",
    "                                format='%.1e')\n",
    "            cbar.ax.xaxis.set_major_locator(FixedLocator(ticks))\n",
    "            cbar.set_ticklabels([f\"{t:.2f}\" for t in ticks])\n",
    "            ax.set_title(f\"Global CAM 2D (across bands) – Class {condition_names[cls]}\", fontsize=10)\n",
    "\n",
    "            if channel_names is not None:\n",
    "                ax.set_xticks([]);  ax.set_yticks([])\n",
    "                for name, (y, x) in channel_names.items():\n",
    "                    ax.text(x, y, name,\n",
    "                            ha='center', va='center',\n",
    "                            fontsize=6, color='black', weight='bold')\n",
    "            else:\n",
    "                ax.axis(\"off\")\n",
    "\n",
    "        # spegni i subplot vuoti\n",
    "        for col in range(2, n_bands):\n",
    "            axs[6, col].axis(\"off\")\n",
    "        for col in range(n_bands):\n",
    "            axs[7, col].axis(\"off\")\n",
    "\n",
    "    else:\n",
    "        \n",
    "        '''\n",
    "        # Global 3D: una heatmap per banda e per classe\n",
    "        #mean_cams_per_band = mean_cams_per_band_3d\n",
    "        #mean_raw_power_per_band = mean_raw_power_per_band_3d\n",
    "        \n",
    "        global_mean_cams = global_mean_cams_3d\n",
    "        \n",
    "        for b, band in enumerate(band_names):\n",
    "            \n",
    "            #for cls in [0, 1]:\n",
    "            for j, cls in enumerate([0, 1]):\n",
    "                \n",
    "                #ax = axs[6 + cls, b]  # cls==0→riga6, cls==1→riga7\n",
    "                \n",
    "                ax = axs[6, b] if cls == 0 else axs[7, b]\n",
    "                \n",
    "                vol3d = global_mean_cams[cls]     # (5,9,9) --> perché? \n",
    "                                                  # Perché sopra è stato fatto 'global_cams_3d[cls].append(cam_vol[0])'\n",
    "                                                  # Quindi ogni dato non era più fatto da (B, D, W, H) dove B = 1 (ossia l'esempio stesso)\n",
    "                                                  # Per cui dopo in global_mean_cams_3d quando ho fatto la media, ho ottenuto una rappresentazione MEDIA\n",
    "                                                  # del gradcam 3D, PER OGNI BANDA. Quindi, quando prelevo la SINGOLA BANDA, basta che faccio lo 'slicing' ossia\n",
    "                                                  # mat2d = vol3d[b]  --> da (5,9,9) diventa --> (9,9)\n",
    "                \n",
    "                mat2d = vol3d[b]                  # slice b → (9,9)\n",
    "                \n",
    "                im = ax.imshow(mat2d,\n",
    "                               cmap='RdYlBu_r',\n",
    "                               vmin=global_vmin_cam,\n",
    "                               vmax=global_vmax_cam,\n",
    "                               aspect='equal',\n",
    "                               origin='upper')\n",
    "                ticks = np.linspace(global_vmin_cam, global_vmax_cam, 6)\n",
    "                cbar = fig.colorbar(im, ax=ax,\n",
    "                                    orientation='horizontal',\n",
    "                                    pad=0.12,\n",
    "                                    ticks=ticks,\n",
    "                                    format='%.1e')\n",
    "                cbar.ax.xaxis.set_major_locator(FixedLocator(ticks))\n",
    "                cbar.set_ticklabels([f\"{t:.2f}\" for t in ticks])\n",
    "                ax.set_title(f\"{band} Global CAM 3D – Class {condition_names[cls]}\", fontsize=10)\n",
    "\n",
    "                if channel_names is not None:\n",
    "                    ax.set_xticks([]);  ax.set_yticks([])\n",
    "                    for name, (y, x) in channel_names.items():\n",
    "                        ax.text(x, y, name,\n",
    "                                ha='center', va='center',\n",
    "                                fontsize=6, color='black', weight='bold')\n",
    "                else:\n",
    "                    ax.axis(\"off\")\n",
    "        '''\n",
    "        \n",
    "        \n",
    "        '''\n",
    "        # Global 3D: una heatmap per classe TRA le bande\n",
    "        '''\n",
    "        \n",
    "        # ➜ CNN3D: una sola mappa 2D globale per classe (media sulle bande)\n",
    "        #   global_2d_from3d[cls] ha shape (9,9)\n",
    "        \n",
    "        global_mean_cams = global_2d_from3d\n",
    "        \n",
    "        for cls in [0, 1]:\n",
    "            ax = axs[6, cls]   # uso riga 7, colonne 0 e 1\n",
    "            mat2d = global_2d_from3d[cls]  # (9,9)\n",
    "\n",
    "            im = ax.imshow(\n",
    "                mat2d,\n",
    "                cmap='RdYlBu_r',\n",
    "                vmin=global_vmin_cam,\n",
    "                vmax=global_vmax_cam,\n",
    "                aspect='equal',\n",
    "                origin='upper'\n",
    "            )\n",
    "            ticks = np.linspace(global_vmin_cam, global_vmax_cam, 6)\n",
    "            cbar = fig.colorbar(\n",
    "                im, ax=ax,\n",
    "                orientation='horizontal',\n",
    "                pad=0.12,\n",
    "                ticks=ticks,\n",
    "                format='%.1e'\n",
    "            )\n",
    "            cbar.ax.xaxis.set_major_locator(FixedLocator(ticks))\n",
    "            cbar.set_ticklabels([f\"{t:.2f}\" for t in ticks])\n",
    "            ax.set_title(f\"Global CAM 3D (across bands) – Class {condition_names[cls]}\", fontsize=10)\n",
    "\n",
    "            if channel_names is not None:\n",
    "                ax.set_xticks([]); ax.set_yticks([])\n",
    "                for name, (y, x) in channel_names.items():\n",
    "                    ax.text(x, y, name,\n",
    "                            ha='center', va='center',\n",
    "                            fontsize=6, color='black', weight='bold')\n",
    "            else:\n",
    "                ax.axis(\"off\")\n",
    "\n",
    "        # spegni gli altri subplot della riga 7–8\n",
    "        for col in range(2, n_bands):\n",
    "            axs[6, col].axis(\"off\")\n",
    "        for col in range(n_bands):\n",
    "            axs[7, col].axis(\"off\")\n",
    "    \n",
    "    \n",
    "    # ------------------------------------------------------------ ------------------------------------------------------------\n",
    "    # ❸ — Ripristino allo stato precedente il modello ottimizzato trovato migliore, che aveva incluso anche layer LSTM\n",
    "    # ------------------------------------------------------------ ------------------------------------------------------------\n",
    "    \n",
    "    if needs_train_mode:\n",
    "        # ➌ ripristino layer singoli (i.e., riporto BN/Dropout dove stavano in eval mode)\n",
    "        for m, old_flag in saved:\n",
    "            m.train(old_flag)\n",
    "        # ➍ ripristino lo stato globale del modello (di nuovo ad .eval())\n",
    "        # i.e.,  come era stato passato in input alla funzione compute_gradcam_figure a partire 'load_best_run_results'!\n",
    "        \n",
    "        #Così simuli l’eval (Dropout off, BN congelato) pur essendo in train() per soddisfare CuDNN‑RNN.\n",
    "        model.train(was_training)\n",
    "        \n",
    "    \n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "                                \n",
    "    \n",
    "    #Passaggio 8: Salvataggio della figura\n",
    "    #Qui la figura viene salvata in un buffer di memoria, pronto per essere salvato o inviato altrove\n",
    "    \n",
    "    # -------------------------------\n",
    "    # Passaggio 8: Salvataggio della figura in un buffer\n",
    "    # -------------\n",
    "\n",
    "    # Salva la figura in un buffer (che potrai poi passare a save_performance_results)\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='png')\n",
    "    buf.seek(0)\n",
    "    fig_image = buf.getvalue()\n",
    "    buf.close()\n",
    "    plt.close(fig)\n",
    "    \n",
    "    return fig_image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaef1d84-355e-4ecd-8994-9734df7ba735",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### **MODELLI CNN3D e Conv Separable**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156d2952-8db1-4b09-a475-85ed4e5b74d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "VERSIONE CONVOLUZIONE 3D PURA e CONVOLUZIONI SEPARABILI 19 LUGLIO 2025\n",
    "\n",
    "\n",
    "Due versioni dell’architettura:\n",
    "\n",
    "CNN3D_LSTM_FC: usa nn.Conv3d per eseguire una vera convoluzione 3D sui cinque depth (bande di frequenza), \n",
    "mantenendo il resto del flusso identico.\n",
    "\n",
    "SeparableCNN2D_LSTM_FC: applica in sequenza una convoluzione depthwise (gruppi = canali) e una pointwise (1×1) \n",
    "per fondere i cinque canali in modo efficiente.\n",
    "\n",
    "Entrambe le classi si integrano con il tuo blocco LSTM e il classificatore come nella versione originale.\n",
    "\n",
    "\n",
    "\n",
    "Per ottenere un Grad‑CAM “3D” su ciascuna delle 5 bande (cioè un volume 9×9×5) \n",
    "invece di schiacciare tutto in una mappa 9×9, bisogna:\n",
    "\n",
    "Non appiattire la dimensione di profondità (“depth” = bande) con cam.mean(dim=1).\n",
    "\n",
    "Calcolare i pesi medi dei gradienti solo su altezza e larghezza, non su depth, in modo da preservare D=5.\n",
    "\n",
    "Upsample (solo) le due dimensioni spaziali H×W, lasciando inalterata la profondità D.\n",
    "\n",
    "(Opzionale) \n",
    "\n",
    "Se il tuo primo Conv3d usa un kernel di profondità pari all’intera profondità d’ingresso, \n",
    "quella informazione viene compressa in D=1!\n",
    "\n",
    "Se vuoi davvero avere D=5 in uscita, devi cambiare conv1 in:\n",
    "\n",
    "\n",
    "# ❌ kernel_size=(5,3,3), padding=(0,1,1) → D_out = 1\n",
    "self.conv1 = nn.Conv3d(1, 32, kernel_size=(3,3,3), padding=(1,1,1))\n",
    "così la profondità si conserva da 5→5.\n",
    "\n",
    "\n",
    "\n",
    "1) Perché in conv1 useremo padding=(1,1,1) e negli altri layer padding=(0,1,1)\n",
    "Obiettivo: mantenere la profondità (numero di bande, D = 5) costante lungo tutta la rete.\n",
    "\n",
    "In conv1, abbiamo scelto kernel_size=(3,3,3) perché vogliamo che il filtro “scorra” su tutti e tre gli assi (D,H,W).\n",
    "\n",
    "Con kernel_depth=3, per avere\n",
    "\n",
    "𝐷out = (𝐷in + 2⋅𝑃 depth − 𝐾 depth)/ 𝑆 + 1 = 5\n",
    "\n",
    "Da qui (1,1,1) per (depth, height, width).\n",
    "\n",
    "Negli altri layer 3D (conv2a, conv2b, conv3) il kernel depth = 1 (kernel_size=(1,3,3)), \n",
    "quindi la profondità non cambia se mettiamo padding_depth=0 con padding (0,1,1) nel layer conv2 e conv3\n",
    "\n",
    "In altre parole, su quell’asse non serve alcun padding:\n",
    "\n",
    "se P dept = 0 allora diventa infatti\n",
    "\n",
    "𝐷out = (𝐷in + 2⋅0 − 𝐾 depth)/ 𝑆 + 1 = 5\n",
    "\n",
    "2⋅0\n",
    "\n",
    "\n",
    "Non è che la tua rete “CNN3D_LSTM_FC” sia sbagliata in senso assoluto, \n",
    "ma — proprio a causa di quel primo Conv3d con kernel_size=(5,3,3) e padding=(0,1,1) — \n",
    "\n",
    "stai automaticamente comprimendo tutte e 5 le bande nella singola fetta di profondità:\n",
    "\n",
    "\n",
    "self.conv1 = nn.Conv3d(\n",
    "    in_channels=1, out_channels=32,\n",
    "    kernel_size=(5, 3, 3),  # → D_out = (5 − 5 + 2·0)/1 + 1 = 1\n",
    "    padding=(0, 1, 1)\n",
    ")\n",
    "Quindi il tuo tensore (B, 1, 5, 9, 9) diventa (B, 32, 1, 9, 9): la dimensione depth (5) si riduce a 1 subito.\n",
    "\n",
    "Se invece vuoi davvero preservare le 5 “fette” come vera terza dimensione spaziale, hai due possibili correzioni:\n",
    "\n",
    "Usare un kernel 3×3×3 (o 1×3×3) in conv1, in modo da non “abbracciare” tutta la profondità d’ingresso:\n",
    "\n",
    "\n",
    "- self.conv1 = nn.Conv3d(1, 32, kernel_size=(5, 3, 3), padding=(0, 1, 1))\n",
    "+ # preserva D: depth out = depth in = 5\n",
    "+ self.conv1 = nn.Conv3d(1, 32, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
    "\n",
    "Oppure, se vuoi mantenere le bande completamente indipendenti in questo layer,\n",
    "\n",
    "\n",
    "self.conv1 = nn.Conv3d(1, 32, kernel_size=(1, 3, 3), padding=(0, 1, 1))\n",
    "che trasforma (B,1,5,9,9) → (B,32,5,9,9).\n",
    "\n",
    "Lasciare com’è, sapendo però che la rete “fonderà” le 5 bande in un’unica mappa di profondità: \n",
    "non è un bug, è una scelta architetturale.\n",
    "\n",
    "La SeparableCNN2D_LSTM_FC\n",
    "Quella architettura non comprime mai le bande all’interno di un’unica fetta, perché:\n",
    "\n",
    "Le bande diventano canali di un Conv2d depth‑wise:\n",
    "\n",
    "\n",
    "x = x.permute(0, 3, 1, 2)  # (B,5,9,9)\n",
    "self.dw_conv1 = nn.Conv2d(5, 5, kernel_size=3, padding=1, groups=5)\n",
    "Ogni “fetta” (banda) resta separata fino al pointwise e agli strati successivi.\n",
    "\n",
    "Quindi se il tuo obiettivo è avere un’uscita per banda (e poi poter plottare un Grad‑CAM 2D per ciascuna),\n",
    "la SeparableCNN2D è già configurata correttamente.\n",
    "\n",
    "Se invece vuoi un Grad‑CAM “volumetrico” 3D (5×9×9) direttamente dal modello 3D puro,\n",
    "la vera modifica necessaria è solo sul primo Conv3d, come mostrato sopra.\n",
    "\n",
    "Fammi sapere quale dei due setup stai usando e ti aiuto a integrare il Grad‑CAM 3D di conseguenza!\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "Ecco l’implementazione completa di CNN3D_LSTM_FC (“approccio sequenza di profondità”) in cui:\n",
    "\n",
    "mantieni il tuo primo blocco 3D con kernel (3,3,3) e padding (1,1,1), quindi D rimane 5 fino alla fine;\n",
    "\n",
    "riduci le spatial singleton dims (H=1,W=1) e trasformi la depth D=5 in una sequenza di lunghezza 5;\n",
    "\n",
    "imposti l’input_size=128 nell’LSTM (feature per time‑step = 128);\n",
    "\n",
    "\n",
    "Con questa versione:\n",
    "\n",
    "la sequenza per l’LSTM ha lunghezza D=5;\n",
    "\n",
    "ogni passo ha 128 feature, esattamente input_size=128;\n",
    "\n",
    "non servono trucchi di reshape su scala globale.\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN3D_LSTM_FC(nn.Module):\n",
    "    \"\"\"\n",
    "    Version with pure 3D convolutions treating the 5 frequency bands\n",
    "    as a sequence (depth) for the LSTM.\n",
    "    Input: Tensor of shape (B, 9, 9, 5) --> reshaped to (B, 1, 5, 9, 9)\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=2, dropout=0.5, hidden_size=64, use_lstm=True):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.hidden_size = hidden_size\n",
    "        self.use_lstm = use_lstm\n",
    "\n",
    "        # --- Block 1 (3D) ---\n",
    "        self.conv1   = nn.Conv3d(1,  32, kernel_size=(3,3,3), padding=(1,1,1))\n",
    "        self.bn1     = nn.BatchNorm3d(32)\n",
    "        self.pool3d  = nn.MaxPool3d((1,2,2))  # non tocca D\n",
    "\n",
    "        # --- Block 2 (3D Residual) ---\n",
    "        self.res_conv3d = nn.Conv3d(32, 64, kernel_size=1, bias=False)\n",
    "        self.res_bn3d   = nn.BatchNorm3d(64)\n",
    "        self.conv2a     = nn.Conv3d(32, 64, kernel_size=(1,3,3), padding=(0,1,1))\n",
    "        self.bn2a       = nn.BatchNorm3d(64)\n",
    "        self.conv2b     = nn.Conv3d(64, 64, kernel_size=(1,3,3), padding=(0,1,1))\n",
    "        self.bn2b       = nn.BatchNorm3d(64)\n",
    "\n",
    "        # --- Block 3 (3D) ---\n",
    "        self.conv3 = nn.Conv3d(64, 128, kernel_size=(1,3,3), padding=(0,1,1))\n",
    "        self.bn3   = nn.BatchNorm3d(128)\n",
    "\n",
    "        # LSTM o FC finale\n",
    "        if self.use_lstm:\n",
    "            # input_size = feature_dim per time‑step = 128\n",
    "            self.lstm       = nn.LSTM(input_size=128,\n",
    "                                      hidden_size=self.hidden_size,\n",
    "                                      num_layers=1,\n",
    "                                      batch_first=True)\n",
    "            self.classifier = nn.LazyLinear(num_classes)\n",
    "        else:\n",
    "            self.classifier = nn.LazyLinear(num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, 9, 9, 5)\n",
    "        if x.ndim == 4:\n",
    "            # -> (B,1,D=5,H=9,W=9)\n",
    "            x = x.permute(0, 3, 1, 2).unsqueeze(1)\n",
    "\n",
    "        # --- Block 1 ---\n",
    "        x = F.relu(self.bn1(self.conv1(x)))  # (B,32,5,9,9)\n",
    "        x = self.pool3d(x)                   # (B,32,5,4,4)\n",
    "\n",
    "        # --- Block 2 (Residual) ---\n",
    "        res = self.res_bn3d(self.res_conv3d(x))  # (B,64,5,4,4)\n",
    "        x   = F.relu(self.conv2a(x))             # (B,64,5,4,4)\n",
    "        x   = self.bn2b(self.conv2b(x))          # (B,64,5,4,4)\n",
    "        x   = F.relu(x + res)                    # (B,64,5,4,4)\n",
    "        x   = self.pool3d(x)                     # (B,64,5,2,2)\n",
    "\n",
    "        # --- Block 3 ---\n",
    "        x = F.relu(self.bn3(self.conv3(x)))      # (B,128,5,2,2)\n",
    "        x = self.pool3d(x)                       # (B,128,5,1,1)\n",
    "\n",
    "        # Stampa delle dimensioni prima di passare al classifier\n",
    "        #print(f\"Dimensioni prima del classifier: {x.shape}\")\n",
    "\n",
    "        if self.use_lstm:\n",
    "            # x: (B,128,5,1,1)\n",
    "            # -> squeeze spatial dims → (B,128,5)\n",
    "            x = x.squeeze(-1).squeeze(-1)\n",
    "            # -> permute per batch_first → (B, seq_len=5, feat=128)\n",
    "            x = x.permute(0, 2, 1)\n",
    "            x = self.dropout(x)\n",
    "            out, _ = self.lstm(x)               # out: (B,5,hidden_size)\n",
    "            last    = out[:, -1, :]             # prendo l’ultimo time-step\n",
    "            logits  = self.classifier(last)     # (B, num_classes)\n",
    "        else:\n",
    "            # x: (B,128,5,1,1) → flatten → (B,128)\n",
    "            x = x.view(x.size(0), -1)\n",
    "            logits = self.classifier(self.dropout(x))\n",
    "\n",
    "        return logits\n",
    "\n",
    "    \n",
    "\n",
    "class SeparableCNN2D_LSTM_FC(nn.Module):\n",
    "    \"\"\"\n",
    "    Version with depthwise + pointwise separable convolutions\n",
    "    across the 5 channels.\n",
    "    Input: Tensor of shape (B, 9, 9, 5) -> (B,5,9,9)\n",
    "    \n",
    "    \n",
    "    groups=5 → impone che ogni canale venga convoluto indipendentemente dagli altri → depthwise ✅\n",
    "\n",
    "    kernel_size=1 → combina i 5 canali in un nuovo spazio di 32 feature maps → pointwise ✅\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=2, dropout=0.5, hidden_size=64, use_lstm=True):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.hidden_size = hidden_size\n",
    "        self.use_lstm = use_lstm\n",
    "\n",
    "        # --- Block 1 separabile ---\n",
    "        self.dw_conv1 = nn.Conv2d(5, 5, kernel_size=3, padding=1, groups=5)\n",
    "        self.pw_conv1 = nn.Conv2d(5, 32, kernel_size=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # --- Block 2 (residuo) ---\n",
    "        self.res_conv = nn.Conv2d(32, 64, kernel_size=1, bias=False)\n",
    "        self.res_bn = nn.BatchNorm2d(64)\n",
    "        self.bn2a = nn.BatchNorm2d(32)\n",
    "        self.conv2a = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn2b = nn.BatchNorm2d(64)\n",
    "        self.conv2b = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "\n",
    "        # --- Block 3 ---\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size=128 * 5, hidden_size=self.hidden_size, num_layers=1, batch_first=True)\n",
    "\n",
    "        if self.use_lstm:\n",
    "            self.lstm = nn.LSTM(\n",
    "                input_size=128 * 1,\n",
    "                hidden_size=self.hidden_size,\n",
    "                num_layers=1,\n",
    "                batch_first=True\n",
    "            )\n",
    "            self.classifier = nn.Linear(self.hidden_size, num_classes)\n",
    "        else:\n",
    "            self.classifier = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 3, 1, 2)  # -> (B,5,9,9)\n",
    "\n",
    "        x = F.relu(self.dw_conv1(x))\n",
    "        x = F.relu(self.bn1(self.pw_conv1(x)))\n",
    "        x = self.pool(x)\n",
    "\n",
    "        res = self.res_bn(self.res_conv(x))\n",
    "        x = F.relu(self.conv2a(self.bn2a(x)))\n",
    "        x = self.bn2b(self.conv2b(x))\n",
    "        x = F.relu(x + res)\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.pool(x)  # (B,128,1,1)\n",
    "\n",
    "        if self.use_lstm:\n",
    "            x = x.permute(0, 2, 1, 3).reshape(x.size(0), 1, -1)  # (B,1,128)\n",
    "            out, _ = self.lstm(self.dropout(x))\n",
    "            last = out[:, -1, :]\n",
    "            logits = self.classifier(last)\n",
    "        else:\n",
    "            x = x.view(x.size(0), -1)\n",
    "            logits = self.classifier(self.dropout(x))\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62df629-6f58-46ae-aa43-4b56fa6afa0f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### **NUOVO LOOP PER DATI NON HYPER SU CNN2D, BiLSTM e Transformer**\n",
    "\n",
    "##### **CON RICHIAMO DEI VALORI DA WAND LOG**\n",
    "\n",
    "Qui vado a creare una funzione che al posto di \"training\" (che ri-eseguiva il training, sbagliando), \n",
    "\n",
    "1) mi prenda fornisca in output i risultati delle metriche estratte dal wand.log ...\n",
    "PERO' QUESTA VOLTA della run con la migliore accuratezza di validazione ottenuta per quel modello e progetto corrispondente..\n",
    "\n",
    "2) prova a suggerirmi se in qualche modo ci sia dentro questa ultima funzione da creare, di ricostruirmi il modo di ricomputare\n",
    "l'auc roc per il training allora (senza dover far ripartire l'ottimizzazione degli iper-parametri...)\n",
    "\n",
    "3) a quel punto in output a questa funzione da creare, vorrei ottenere una stessa struttura che ottenevo in output della funzione di training ... \n",
    "la differenza, sostanzialmente è che, mentre prima si ri-eseguiva il training sul modello già ottimizzato, sbagliando, \n",
    "qui invece dovrebbe solo estrarsi le metriche ottenute proprio quel modello migliore che è quello con la val accuracy migliore \n",
    "(ossia il mio modello migliore già salvato in best model), \n",
    "\n",
    "ossia dalla run di quel progetto e modello corrispondente con la run che possiede appunto la val accuracy migliore (ossia il mio modello migliore già salvato in best model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d9cdc5-51da-47e1-a7f8-941b909abc86",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### **Implementazione: Carico Dati** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57141266-742c-40a1-8d7f-eb74e7bf8436",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''VERSIONE NUOVA UFFICIALE\n",
    "\n",
    "\n",
    "Ecco come puoi correggere solo il calcolo dell’AUC–ROC sul training set a posteriori, \n",
    "lasciando invariato tutto il resto di load_best_run_results. \n",
    "\n",
    "\n",
    "L’idea è:\n",
    "\n",
    "1) Estrarre la history normale da W&B (che contiene il vecchio train_auc)\n",
    "2) Individuare best_epoch\n",
    "3) Caricare il modello migliore da disco\n",
    "4) Rifare un passaggio solo sullo train_loader per ottenere le vere probabilità e ricalcolare la ROC–AUC\n",
    "5) Sovrascrivere il vecchio valore auc_train_history[best_epoch] e aggiornare best_metrics[\"train_auc\"]\n",
    "\n",
    "\n",
    "\n",
    "Cosa è cambiato\n",
    "\n",
    "1) Ti ho inserito un passaggio 6) in cui ricalcoli l’AUC–ROC vero del train set, usando torch.softmax(…,dim=1)[:,1].\n",
    "2) Sostituisci il vecchio auc_train_history[best_epoch] col valore corretto.\n",
    "3) Ricomponi best_metrics[\"train_auc\"] con true_auc_train.\n",
    "\n",
    "Da qui in poi, puoi chiamare subito dopo la tua testing(...) per ottenere anche tutte le metriche sul test set e salvare la tabella finale in cui:\n",
    "\n",
    "“Train” = best_metrics[\"train_*\"] (ora con AUC corretta)\n",
    "\n",
    "“Test” = test_results[\"test_performances\"]\n",
    "\n",
    "Ecco fatto: nessun re‑training, solo un passaggio aggiuntivo per correggere il calcolo dell’AUC–ROC sul train set.\n",
    "\n",
    "\n",
    "\n",
    "Quindi il punto 6\n",
    "\n",
    "# --- 6) Ricalcolo vero train AUC–ROC sul train_loader ---\n",
    "\n",
    "serve per ri-calcolarsi correttamente l'auc roc al train set nell'epoca in cui sul val set ho ottenuto la migliore validation accuracy, \n",
    "che corrisponde quindi al modello salvato dentro il best_model che io ri-prelevo quando poi lo do in pasto al test set?\n",
    "\n",
    "\n",
    "Esattamente: quel passaggio 6):\n",
    "\n",
    "Riprende il modello caricato dal file .pkl (che è proprio il best_model scelto sull’epoca di miglior val_accuracy),\n",
    "\n",
    "Lo mette in eval() e senza gradienti scorre tutto il train_loader,\n",
    "\n",
    "Calcola le probabilità (softmax(:,1)) e da quelle ricava la vera ROC–AUC per il train set,\n",
    "\n",
    "Infine sovrascrive auc_train_history[best_epoch] e aggiorna best_metrics[\"train_auc\"] con questo valore corretto.\n",
    "\n",
    "In questo modo la tua colonna “Train” nella tabella conterrà davvero l’AUC–ROC calcolata sulle probabilità del modello nella stessa epoca \n",
    "in cui hai ottenuto la migliore validazione, cioè esattamente quei pesi che poi passerai al test set.\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "from wandb import Api\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, roc_auc_score, confusion_matrix, classification_report\n",
    ")\n",
    "import io\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "import re\n",
    "\n",
    "\n",
    "    \n",
    "'''\n",
    "1) questa serve per plottare le metriche di loss e accuracy in ogni modello e condizione sperimentale\n",
    "per salvarla dentro al dizionario 'training_plot' come buffer di memoria\n",
    "'''\n",
    "\n",
    "\n",
    "def plot_training_results(loss_train_history, loss_val_history, accuracy_train_history, accuracy_val_history):\n",
    "    \n",
    "    '''\n",
    "    # Creazione di una figura con 2 subplot\n",
    "    '''\n",
    "    fig, ax = plt.subplots(2, 1, figsize=(10, 8))  # 2 righe, 1 colonna, dimensione figura\n",
    "\n",
    "    #Plot della loss\n",
    "    ax[0].plot(loss_train_history, label='Train Loss', color='blue')\n",
    "    ax[0].plot(loss_val_history, label='Validation Loss', color='orange')\n",
    "    #ax[0].set_title(f'Loss during Training: {exp_cond_1} vs {exp_cond_2}', fontsize=16)  # Titolo più grande\n",
    "    ax[0].set_title(f'Loss during Training: ', fontsize=12)  # Titolo più grande\n",
    "    ax[0].set_xlabel('Epochs', fontsize=12)  # Dimensione font asse x\n",
    "    ax[0].set_ylabel('Loss', fontsize=12)    # Dimensione font asse y\n",
    "    ax[0].legend(fontsize=12)  # Dimensione font legenda\n",
    "    ax[0].grid(True)\n",
    "\n",
    "    # Plot dell'accuracy\n",
    "    ax[1].plot(accuracy_train_history, label='Train Accuracy', color='blue')\n",
    "    ax[1].plot(accuracy_val_history, label='Validation Accuracy', color='orange')\n",
    "    #ax[1].set_title(f'Accuracy during Training: {exp_cond_1} vs {exp_cond_2}', fontsize=16)  # Titolo più grande\n",
    "    ax[1].set_title(f'Accuracy during Training: ', fontsize=12)  # Titolo più grande\n",
    "    ax[1].set_xlabel('Epochs', fontsize=12)  # Dimensione font asse x\n",
    "    ax[1].set_ylabel('Accuracy', fontsize=12)  # Dimensione font asse y\n",
    "    ax[1].legend(fontsize=12)  # Dimensione font legenda\n",
    "    ax[1].grid(True)\n",
    "    \n",
    "    # Regolare la spaziatura tra i subplot\n",
    "    plt.tight_layout()  # Alternativa: fig.subplots_adjust(hspace=0.3)\n",
    "    \n",
    "    #plt.close(fig)\n",
    "    \n",
    "    '''\n",
    "    # Salvare il plot in un buffer di memoria\n",
    "    '''\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='png')  # Salviamo il plot in formato PNG\n",
    "    buf.seek(0)  # Torniamo all'inizio del buffer\n",
    "\n",
    "    # Convertire il buffer in un'immagine PIL (opzionale, per visualizzarla)\n",
    "    img = Image.open(buf)\n",
    "\n",
    "    # Aggiungere i dati dell'immagine nel dizionario\n",
    "    plot_image_data = buf.getvalue()  # Otteniamo i dati binari dell'immagine\n",
    "    buf.close()\n",
    "    \n",
    "    # Ritorniamo i dati dell'immagine da salvare nel dizionario\n",
    "    return plot_image_data\n",
    "\n",
    "\n",
    "'''\n",
    "2) questa serve per estrarmi le stringhe per ricostruire il nome del progetto su W&B per \n",
    "poi estrarmi le metriche ottenute sul training e validation \n",
    "da salvare sempre dentro al dizionario 'training_plot' \n",
    "'''\n",
    "\n",
    "# Funzione per parsare la chiave\n",
    "def parse_combination_key(combination_key):\n",
    "    \"\"\"\n",
    "    Estrae (exp_cond, data_type, category_subject) da combination_key.\n",
    "    Il formato atteso è:\n",
    "    \"th_resp_vs_pt_resp|pt_resp_vs_shared_resp|th_resp_vs_shared_resp\" _ \n",
    "    \"1_20|1_45|wavelet\" _ \n",
    "    \"familiar_th|familiar_pt|unfamiliar_th|unfamiliar_pt\"\n",
    "    \"\"\"\n",
    "    match = re.match(\n",
    "        r\"^(rest_vs_left_fist|rest_vs_right_fist|left_fist_vs_right_fist)_(spectrograms)_(familiar_th|familiar_pt|unfamiliar_th|unfamiliar_pt)$\",\n",
    "        combination_key\n",
    "    )\n",
    "    if match:\n",
    "        return match.groups()  # (exp_cond, data_type, category_subject)\n",
    "    else:\n",
    "        raise ValueError(f\"Formato non valido: {combination_key}\")\n",
    "        \n",
    "\n",
    "'''CELLA DI ESEMPIO PER VERIFICARE SE QUESTA FUNZIONE FACESSE IL PARSING DELLE STRINGHE DELLE COMBINAZIONI DI FATTORI CORRETTAMENTE'''\n",
    "\n",
    "# Test\n",
    "#combination_key = \"rest_vs_left_fist_spectrograms_familiar_th\"\n",
    "#condition_experiment, data_type, subject_key = parse_combination_key(combination_key)\n",
    "\n",
    "#print(\"Condizione:\", condition_experiment)\n",
    "#print(\"Data Type:\", data_type)\n",
    "#print(\"Soggetto:\", subject_key)\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "Ecco come puoi correggere solo il calcolo dell’AUC–ROC sul training set a posteriori, lasciando invariato tutto il resto di load_best_run_results. \n",
    "\n",
    "\n",
    "L’idea è:\n",
    "\n",
    "1) Estrarre la history normale da W&B (che contiene il vecchio train_auc)\n",
    "2) Individuare best_epoch\n",
    "3) Caricare il modello migliore da disco\n",
    "4) Rifare un passaggio solo sullo train_loader per ottenere le vere probabilità e ricalcolare la ROC–AUC\n",
    "5) Sovrascrivere il vecchio valore auc_train_history[best_epoch] e aggiornare best_metrics[\"train_auc\"]\n",
    "\n",
    "\n",
    "\n",
    "Cosa è cambiato\n",
    "\n",
    "1) Ti ho inserito un passaggio 6) in cui ricalcoli l’AUC–ROC vero del train set, usando torch.softmax(…,dim=1)[:,1].\n",
    "2) Sostituisci il vecchio auc_train_history[best_epoch] col valore corretto.\n",
    "3) Ricomponi best_metrics[\"train_auc\"] con true_auc_train.\n",
    "\n",
    "Da qui in poi, puoi chiamare subito dopo la tua testing(...) per ottenere anche tutte le metriche sul test set e salvare la tabella finale in cui:\n",
    "\n",
    "“Train” = best_metrics[\"train_*\"] (ora con AUC corretta)\n",
    "\n",
    "“Test” = test_results[\"test_performances\"]\n",
    "\n",
    "Ecco fatto: nessun re‑training, solo un passaggio aggiuntivo per correggere il calcolo dell’AUC–ROC sul train set.\n",
    "\n",
    "\n",
    "\n",
    "Quindi il punto 6\n",
    "\n",
    "# --- 6) Ricalcolo vero train AUC–ROC sul train_loader ---\n",
    "\n",
    "serve per ri-calcolarsi correttamente l'auc roc al train set nell'epoca in cui sul val set ho ottenuto la migliore validation accuracy, \n",
    "che corrisponde quindi al modello salvato dentro il best_model che io ri-prelevo quando poi lo do in pasto al test set?\n",
    "\n",
    "\n",
    "Esattamente: quel passaggio 6):\n",
    "\n",
    "Riprende il modello caricato dal file .pkl (che è proprio il best_model scelto sull’epoca di miglior val_accuracy),\n",
    "\n",
    "Lo mette in eval() e senza gradienti scorre tutto il train_loader,\n",
    "\n",
    "Calcola le probabilità (softmax(:,1)) e da quelle ricava la vera ROC–AUC per il train set,\n",
    "\n",
    "Infine sovrascrive auc_train_history[best_epoch] e aggiorna best_metrics[\"train_auc\"] con questo valore corretto.\n",
    "\n",
    "In questo modo la tua colonna “Train” nella tabella conterrà davvero l’AUC–ROC calcolata sulle probabilità del modello nella stessa epoca \n",
    "in cui hai ottenuto la migliore validazione, cioè esattamente quei pesi che poi passerai al test set.\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "'''\n",
    "3) Dopodiché, comincia la funzione di load_best_run_results che, \n",
    "per ogni progetto e sweep del relativo modello,\n",
    "\n",
    "si va ad estrarre le metriche del train (corregge il calcolo del train_auc)\n",
    "e si calcola anche per il validation phase la confusion matrix e classification report\n",
    "\n",
    "\n",
    "4) dopodichè dovrebbe richiamare la funzione di \n",
    "\"plot_training_results\" in modo che poi si salvi i plot di training e validation (sia loss che accuracy)\n",
    "in modo che si salvi tutto in una immagine come buffer che viene spuntato fuori da quella funzione \n",
    "\n",
    "e poi inserito come valore dentro al dizionario training_results che sarà l'output di \"load_best_run_results\" \n",
    "\n",
    "\n",
    "quindi qui sotto mi manca richiamare la funzione \"plot_training_results\" con una variabile tipo training_plot = plot_training_results che avrà come argomenti\n",
    "\n",
    "queste liste qua salvate come colonne del df creato dentro a 'load_best_run_results!'\n",
    "\n",
    "\n",
    "loss_train_history     = df[\"train_loss\"].tolist()\n",
    "loss_val_history       = df[\"val_loss\"].tolist()\n",
    "accuracy_train_history = df[\"train_accuracy\"].tolist()\n",
    "accuracy_val_history   = df[\"val_accuracy\"].tolist()\n",
    "\n",
    "\n",
    "5) dopodiché mi serve caricare tutte queste info dentro al dizionario train_results, che sarà l'output di load_best_run_results... \n",
    "e su questo ho dei dubbi su quali chiavi del dizionario tenere separate oppure se \"unirne\" qualcuna, aggregando tutte le info del sweep_config assieme, \n",
    "sia che siano veri iper-parametri (learning rate etc) o parametri architetturali della rete (anche se avevano valori fissi) il più delle volte se vedi\n",
    "\n",
    "\n",
    "\n",
    "# 2.1 – Sweep config per ciascun modello\n",
    "sweep_config_cnn3d = {\n",
    "    \"method\": \"random\",\n",
    "    \"metric\": {\"name\": \"val_accuracy\", \"goal\": \"maximize\"},\n",
    "    \"parameters\": {\n",
    "        \"lr\": {\"values\": [1e-5, 5e-5, 1e-4, 5e-4, 1e-3, 5e-3, 1e-2]},\n",
    "        \"weight_decay\": {\"values\": [0, 1e-4, 1e-3, 1e-2, 1e-1]},\n",
    "        \"n_epochs\": {\"value\": 100},\n",
    "        \"patience\": {\"value\": 12},\n",
    "        \"model_name\": {\"values\": [\"CNN3D_LSTM_FC\"]},\n",
    "        \"batch_size\": {\"values\": [32, 48, 64, 96]},\n",
    "        \"standardization\": {\"values\": [True, False]},\n",
    "        \"beta1\": {\"values\": [0.9, 0.95]},\n",
    "        \"beta2\": {\"values\": [0.99, 0.995]},\n",
    "        \"eps\": {\"values\": [1e-8, 1e-7]},\n",
    "        \"use_lstm\": {\"values\": [True, False]},\n",
    "        \"lstm_hidden\": {\"values\": [32]},\n",
    "        \"dropout\": {\"values\": [0.5]},\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "sweep_config_cnn_sep = {\n",
    "    \"method\": \"random\",\n",
    "    \"metric\": {\"name\": \"val_accuracy\", \"goal\": \"maximize\"},\n",
    "    \"parameters\": {\n",
    "        \"lr\": {\"values\": [1e-5, 5e-5, 1e-4, 5e-4, 1e-3, 5e-3, 1e-2]},\n",
    "        \"weight_decay\": {\"values\": [0, 1e-4, 1e-3, 1e-2, 1e-1]},\n",
    "        \"n_epochs\": {\"value\": 100},\n",
    "        \"patience\": {\"value\": 12},\n",
    "        \"model_name\": {\"values\": [\"SeparableCNN2D_LSTM_FC\"]},\n",
    "        \"batch_size\": {\"values\": [32, 48, 64, 96]},\n",
    "        \"standardization\": {\"values\": [True, False]},\n",
    "        \"beta1\": {\"values\": [0.9, 0.95]},\n",
    "        \"beta2\": {\"values\": [0.99, 0.995]},\n",
    "        \"eps\": {\"values\": [1e-8, 1e-7]},\n",
    "        \"use_lstm\": {\"values\": [True, False]},\n",
    "        \"lstm_hidden\": {\"values\": [32]},\n",
    "        \"dropout\": {\"values\": [0.5]},\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "def load_best_run_results(\n",
    "    key, # es. \"rest_vs_left_fist_spectrograms_familiar_th\"\n",
    "    model, # # <-- istanza PyTorch già caricata con i pesi best es. \"CNN3D_LSTM_FC\"\n",
    "    \n",
    "    sweep_config,      # <— qui richiamo lo sweep config del modello corrispondente\n",
    "    \n",
    "    data_loaders, # dict con DataLoader per \"train\" e \"val\"\n",
    "    entity= \"my_wb_entity\"): # entity = \"stefano‑bargione‑universit‑di‑roma‑tor‑vergata\"\n",
    "    \n",
    "    \n",
    "    # --- 1) Parse key e ricava project name ---\n",
    "    exp_cond, data_type, category_subject = parse_combination_key(key)\n",
    "    \n",
    "    project = f\"{exp_cond}_{data_type}_channels_freqs_new_3d_grid_multiband\"\n",
    "    \n",
    "    model_name = type(model).__name__\n",
    "    \n",
    "\n",
    "    '''SE ESTRAGGO SWEEP ID A POSTERIORI DAL PROGETTO\n",
    "\n",
    "    1) Prendo tutte le run del progetto e modello corrispondente\n",
    "    2) Filtro solo quelle con config[\"model_name\"] == model_name.\n",
    "    3) Controllo che ce ne sia almeno una (altrimenti errore).\n",
    "    4) Costruisce un set di tutti gli r.sweep e verifica che sia esattamente uno (altrimenti errore).\n",
    "    5) Estrae quello unico (.pop()) e lo stampa insieme al numero di run.\n",
    "    6) Infine, seleziona la singola best_run sulla base di val_accuracy.\n",
    "\n",
    "    '''\n",
    "    \n",
    "    # 2) Recupero tutte le run del progetto\n",
    "    api  = Api()\n",
    "    runs = api.runs(f\"{entity}/{project}\")\n",
    "\n",
    "    # 3) filtro solo quelle del modello giusto\n",
    "    runs_filtered = [r for r in runs if r.config.get(\"model_name\", \"\") == model_name]\n",
    "    n_runs = len(runs_filtered)\n",
    "\n",
    "    if n_runs == 0:\n",
    "        raise RuntimeError(f\"Nessuna run trovata per progetto `{project}` e modello `{model_name}`\")\n",
    "\n",
    "    # 4) controllo che le run filtrate appartengano tutte allo stesso sweep\n",
    "    unique_sweeps = {r.sweep for r in runs_filtered}\n",
    "    if len(unique_sweeps) != 1:\n",
    "        raise RuntimeError(\n",
    "            f\"Trovati più sweep per progetto `{project}` e modello `{model_name}`: {unique_sweeps}\"\n",
    "        )\n",
    "\n",
    "    # 5) estraggo lo sweep_id\n",
    "    sweep_id_unico = unique_sweeps.pop()\n",
    "    #print(f\"✓ Trovate \\033[1m{n_runs}\\033[0m runs in progetto `{project}` e modello `{model_name}`, sweep: `{sweep_id_unico}`\")\n",
    "    print(f\"✓ Trovate \\033[1m{n_runs}\\033[0m runs\\n\")\n",
    "    print(f\"✓ Progetto \\033[1m`{project}`\\033[0m\\n\")\n",
    "    print(f\"✓ Modello \\033[1m`{model_name}`\\033[0m\\n\")\n",
    "    print(f\"✓ Sweep \\033[1m`{sweep_id_unico}`\\033[0m\\n\\n\")\n",
    "\n",
    "    # 6) scelgo la run con val_accuracy massima\n",
    "    best_run = max(runs_filtered, key=lambda r: r.summary.get(\"val_accuracy\", 0.0))\n",
    "\n",
    "    # --- 7) Estraggo tutta la history (compresi i train_auc sbagliati) ---\n",
    "    df = best_run.history(\n",
    "        keys=[\n",
    "          \"train_loss\",\"train_accuracy\",\"train_precision\",\n",
    "          \"train_recall\",\"train_f1\",\"train_auc\",\n",
    "          \"val_loss\",\"val_accuracy\"\n",
    "        ],\n",
    "        pandas=True\n",
    "    )\n",
    "    # converto in liste\n",
    "    loss_train_history     = df[\"train_loss\"].tolist()\n",
    "    loss_val_history       = df[\"val_loss\"].tolist()\n",
    "    accuracy_train_history = df[\"train_accuracy\"].tolist()\n",
    "    accuracy_val_history   = df[\"val_accuracy\"].tolist()\n",
    "    precision_train_history= df[\"train_precision\"].tolist()\n",
    "    recall_train_history   = df[\"train_recall\"].tolist()\n",
    "    f1_train_history       = df[\"train_f1\"].tolist()\n",
    "    auc_train_history      = df[\"train_auc\"].tolist()\n",
    "\n",
    "    # best_epoch (su val_accuracy)\n",
    "    best_epoch = int(df[\"val_accuracy\"].idxmax())\n",
    "\n",
    "    # --- 8) Prendo il modello ottimizzato .pkl corrispondente passato in input ---\n",
    "    device     = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    model.to(device).eval()\n",
    "\n",
    "    # --- 9) Ricalcolo vero train AUC–ROC sul train_loader ---\n",
    "    y_t_train, y_s_train = [], []\n",
    "    with torch.no_grad():\n",
    "        for x,y in data_loaders[\"train\"]:\n",
    "            x = x.to(device)\n",
    "            logits = model(x)\n",
    "            probs  = torch.softmax(logits, dim=1)[:,1].cpu().numpy()\n",
    "            y_s_train.extend(probs)\n",
    "            y_t_train.extend(y.numpy())\n",
    "            \n",
    "    true_auc_train = roc_auc_score(np.array(y_t_train), np.array(y_s_train))\n",
    "\n",
    "    # Sovrascrivo il vecchio valore sbagliato\n",
    "    auc_train_history[best_epoch] = true_auc_train\n",
    "\n",
    "    # Ricostruisco best_metrics\n",
    "    best_metrics = {\n",
    "      \"train_loss\":       [round(loss_train_history[best_epoch],4)],\n",
    "      \"train_accuracy\":   [round(accuracy_train_history[best_epoch],4)],\n",
    "      \"train_precision\":  [round(precision_train_history[best_epoch],4)],\n",
    "      \"train_recall\":     [round(recall_train_history[best_epoch],4)],\n",
    "      \"train_f1_score\":   [round(f1_train_history[best_epoch],4)],\n",
    "      \"train_auc\":        [round(true_auc_train,4)]\n",
    "    }\n",
    "\n",
    "    # --- 10) Ricreo confusion matrix e classification report su val set ---\n",
    "    y_t_val, y_p_val = [], []\n",
    "    with torch.no_grad():\n",
    "        for x,y in data_loaders[\"val\"]:\n",
    "            x = x.to(device)\n",
    "            logits = model(x)\n",
    "            probs  = torch.softmax(logits, dim=1)[:,1].cpu().numpy()\n",
    "            preds  = (probs >= 0.5).astype(int)\n",
    "            y_p_val.extend(preds)\n",
    "            y_t_val.extend(y.numpy())\n",
    "            \n",
    "    confusion_matrix_val = confusion_matrix(y_t_val, y_p_val)\n",
    "    classification_report_val = classification_report(y_t_val, y_p_val, output_dict=False)\n",
    "\n",
    "    # --- 10) Plot delle curve loss/accuracy tra train e test ---\n",
    "    training_plot = plot_training_results(\n",
    "        loss_train_history,\n",
    "        loss_val_history,\n",
    "        accuracy_train_history,\n",
    "        accuracy_val_history\n",
    "    )\n",
    "\n",
    "    # --- 11) Composizione del dict finale identico a `training()` ---\n",
    "    \n",
    "    # Restituire tutti i risultati in un dizionario\n",
    "    train_results = {\n",
    "        \"training_performances\": best_metrics,  # Aggiungi il dizionario delle performance\n",
    "        \n",
    "        \"loss_train_history\": loss_train_history,\n",
    "        \"loss_val_history\": loss_val_history,\n",
    "        \n",
    "        \"accuracy_train_history\": accuracy_train_history,\n",
    "        \"accuracy_val_history\": accuracy_val_history,\n",
    "        \n",
    "        \"best_model\": model,\n",
    "        \n",
    "        \"confusion_matrix_val\": confusion_matrix_val,\n",
    "        \"classification_report\": classification_report_val,\n",
    "    \n",
    "        \"hyperparams\" : {k: best_run.config[k] for k in best_run.config.keys() if k in sweep_config[\"parameters\"]},\n",
    "            \n",
    "        \"training_plot\": training_plot  # Salviamo il buffer con il plot\n",
    "    }\n",
    "    \n",
    "    '''\n",
    "    Ho questo errore \"Errore “cudnn RNN backward can only be called in training mode”\" solo con i dati di \n",
    "    left_fist_vs_right_fist, per il modello SeparableCNN2D_LSTM_FC, \n",
    "    mentre con i dati delle altre condizioni sperimentali, ossia:\n",
    "    \n",
    "    rest_vs_left_fist o rest_vs_right_fist, sempre per il modello SeparableCNN2D_LSTM_FC,non succede ... come mai solo con l'ultimo succede? \n",
    "    \n",
    "    cioè dove dovrei aver lasciato il modello caricato in eval.() ?\n",
    "    \n",
    "    probabilmente qui nella funzione load_best_train_results!?\n",
    "    \n",
    "    quindi qui poi alla fine dovrei rimettere il modello in un'altra modalità alla fine della funzione? \n",
    "    perché in sostanza, dovrebbe succedere che in sostanza... non succede nulla per lo stesso modello per  gli altri dati, \n",
    "    perché ogni volta che ne prendo uno lo porto in eval e vabbè.. ma poi il problema succede solo per l'ultimo caso solo, \n",
    "    perché forse l'ultimo proprio, ossia solo SeparableCNN2D_LSTM_FC usa proprio il layer LSTM e quindi da errore là,\n",
    "    perché dentro a load_best_train_results è rimasto in .eval() ed ha il layer LSTM e quindi dà errore?\n",
    "    \n",
    "    \n",
    "    \n",
    "    Perché l’errore appare “solo” con l’ultima combinazione\n",
    "\n",
    "    1. load_best_run_results() termina con:\n",
    "\n",
    "    model.to(device).eval()   # ← il modello rimane in eval()\n",
    "    \n",
    "    2. In compute_gradcam_figure() tu usi il best model che hai messo in train_results[\"best_model\"] (quello appena impostato in eval()), poi esegui:\n",
    "\n",
    "   \n",
    "    output = model(sample_input)\n",
    "    ...\n",
    "    target.backward()         # <-- gradiente attraverso l’LSTM\n",
    "    3. Il kernel CuDNN per gli RNN (LSTM/GRU) rifiuta il backward quando il modulo è in modalità inference (eval()), e solleva:\n",
    "\n",
    "    \n",
    "    RuntimeError: cudnn RNN backward can only be called in training mode\n",
    "    \n",
    "    4. Per le combinazioni precedenti con lo stesso modello “SeparableCNN2D_LSTM_FC” non è esploso perché, con ogni probabilità, \n",
    "    use_lstm=False nelle relative run migliori (quindi l’LSTM non c’è e CuDNN non interviene).\n",
    "    \n",
    "    Nell’ultima combinazione invece la best‑run ha use_lstm=True, quindi compare l’LSTM e l’errore salta fuori.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "\n",
    "    \n",
    "    return train_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb229302-076f-473c-9123-88dfa0b96ded",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#LOOP PER CARICARE I DATI NON HYPER\n",
    "data_dict = {}\n",
    "\n",
    "# Condizioni sperimentali\n",
    "#experimental_conditions = [\"th_resp_vs_pt_resp\", \"th_resp_vs_shared_resp\", \"pt_resp_vs_shared_resp\"]\n",
    "\n",
    "experimental_conditions = [\"rest_vs_left_fist\", \"rest_vs_right_fist\", \"left_fist_vs_right_fist\"]\n",
    "\n",
    "for condition in experimental_conditions:\n",
    "\n",
    "    for data_type in [\"spectrograms\"]:\n",
    "        \n",
    "        #for category in [\"familiar\", \"unfamiliar\"]:\n",
    "        for category in [\"familiar\"]:\n",
    "            \n",
    "            #for subject_type in [\"th\", \"pt\"]:\n",
    "            for subject_type in [\"th\"]:\n",
    "            \n",
    "                # Caricamento e suddivisione dei dati\n",
    "                if data_type == \"wavelet\":\n",
    "                    X, y = load_data(data_type, category, subject_type, wavelet_level=\"delta\", condition = condition)\n",
    "                else:\n",
    "                    X, y = load_data(data_type, category, subject_type, condition = condition)\n",
    "\n",
    "                #key = f\"{condition}/{data_type}_{category}_{subject_type}\"\n",
    "                key = f\"{condition}_{data_type}_{category}_{subject_type}\"\n",
    "                data_dict[key] = (X, y)\n",
    "\n",
    "                # Stampa di conferma\n",
    "                print(f\"Dataset caricato: \\033[1m{key}\\033[0m - Forma X: {X.shape}, Lunghezza y: {len(y)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5ba82b-08cb-43b2-b1e2-c8ed23e652fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74744242-c264-4c16-ba13-bb4b847d0b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_dict['rest_vs_left_fist_spectrograms_familiar_th'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b5587a-eb77-4ea1-8c17-3cadd1f45e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "perfetto ora, siccome ho creato data_dict nel modo di cui sopra, \n",
    "ora dentro ogni chiave, \n",
    "ci sono già tutte le chiavi associate correttamente, per estrarmi i dati e labels corrispondenti di quella combinazione di fattori lì.\n",
    "\n",
    "infatti dentro ogni chiave c'è una tupla, con 2 elementi, il primo è l'array dei dati, il secondo è l'array delle labels\n",
    "'''\n",
    "\n",
    "#data_dict['rest_vs_left_fist']['spectrograms'][0].shape\n",
    "\n",
    "data_dict['rest_vs_left_fist_spectrograms_familiar_th'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b5eace-91ae-4195-a51b-00b8ff79a2c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''NEW VERSION'''\n",
    "\n",
    "# Percorso base per il salvataggio\n",
    "#base_folder = \"/home/stefano/Interrogait/spectrograms_best_models_post_WB_GradCAM_Checks_motor_task_1_new\"\n",
    "\n",
    "base_folder = \"/home/stefano/Interrogait/spectrograms_best_models_channels_frequencies_params_post_WB_GradCAM_Checks_motor_task_1_new_3d_grid_multiband\"\n",
    "\n",
    "os.makedirs(base_folder, exist_ok=True)\n",
    "\n",
    "# Condizioni sperimentali\n",
    "#experimental_conditions = [\"th_resp_vs_pt_resp\", \"th_resp_vs_shared_resp\", \"pt_resp_vs_shared_resp\"]\n",
    "\n",
    "experimental_conditions = [\"rest_vs_left_fist\", \"rest_vs_right_fist\", \"left_fist_vs_right_fist\"]\n",
    "\n",
    "# Tipologie di dati\n",
    "data_types = [\"spectrograms\"]\n",
    "\n",
    "# Subfolders per tipologia di soggetto\n",
    "#subfolders = [\"th_fam\", \"th_unfam\", \"pt_fam\", \"pt_unfam\"]\n",
    "subfolders = [\"th_fam\"]\n",
    "\n",
    "# Creazione della struttura delle cartelle\n",
    "for condition in experimental_conditions:\n",
    "    for data_type in data_types:\n",
    "        for subfolder in subfolders:\n",
    "            \n",
    "            path = os.path.join(base_folder, condition, data_type, subfolder)\n",
    "            \n",
    "            if not os.path.exists(path):\n",
    "                os.makedirs(path, exist_ok=True)\n",
    "            \n",
    "            print(f\"Cartella creata: \\033[1m{path}\\033[0m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bccb5d-9934-4b4d-9653-8129ed31c95f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 2.1 – Sweep config per ciascun modello\n",
    "sweep_config_cnn3d = {\n",
    "    \"method\": \"random\",\n",
    "    \"metric\": {\"name\": \"val_accuracy\", \"goal\": \"maximize\"},\n",
    "    \"parameters\": {\n",
    "        \"lr\": {\"values\": [1e-5, 5e-5, 1e-4, 5e-4, 1e-3, 5e-3, 1e-2]},\n",
    "        \"weight_decay\": {\"values\": [0, 1e-4, 1e-3, 1e-2, 1e-1]},\n",
    "        \"n_epochs\": {\"value\": 100},\n",
    "        \"patience\": {\"value\": 12},\n",
    "        \"model_name\": {\"values\": [\"CNN3D_LSTM_FC\"]},\n",
    "        \"batch_size\": {\"values\": [32, 48, 64, 96]},\n",
    "        \"standardization\": {\"values\": [True, False]},\n",
    "        \"beta1\": {\"values\": [0.9, 0.95]},\n",
    "        \"beta2\": {\"values\": [0.99, 0.995]},\n",
    "        \"eps\": {\"values\": [1e-8, 1e-7]},\n",
    "        \"use_lstm\": {\"values\": [True, False]},\n",
    "        \"lstm_hidden\": {\"values\": [32]},\n",
    "        \"dropout\": {\"values\": [0.5]},\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "sweep_config_cnn_sep = {\n",
    "    \"method\": \"random\",\n",
    "    \"metric\": {\"name\": \"val_accuracy\", \"goal\": \"maximize\"},\n",
    "    \"parameters\": {\n",
    "        \"lr\": {\"values\": [1e-5, 5e-5, 1e-4, 5e-4, 1e-3, 5e-3, 1e-2]},\n",
    "        \"weight_decay\": {\"values\": [0, 1e-4, 1e-3, 1e-2, 1e-1]},\n",
    "        \"n_epochs\": {\"value\": 100},\n",
    "        \"patience\": {\"value\": 12},\n",
    "        \"model_name\": {\"values\": [\"SeparableCNN2D_LSTM_FC\"]},\n",
    "        \"batch_size\": {\"values\": [32, 48, 64, 96]},\n",
    "        \"standardization\": {\"values\": [True, False]},\n",
    "        \"beta1\": {\"values\": [0.9, 0.95]},\n",
    "        \"beta2\": {\"values\": [0.99, 0.995]},\n",
    "        \"eps\": {\"values\": [1e-8, 1e-7]},\n",
    "        \"use_lstm\": {\"values\": [True, False]},\n",
    "        \"lstm_hidden\": {\"values\": [32]},\n",
    "        \"dropout\": {\"values\": [0.5]},\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61d2d0a-2e76-4438-98ec-d8494d549aae",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### **Implementazione: Richiamo Reti Ottimizzate dopo W&B** "
   ]
  },
  {
   "cell_type": "raw",
   "id": "a8d26e94-705b-4fef-bd96-bf61d2020dc3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "'''\n",
    "                                                        ALTRE NOTE PER RAGIONAMENTO SU IMPLEMENTAZIONE\n",
    "\n",
    "Allora da quello che esce fuori, viene che ci sono dei valori che vanno sotto la soglia di risoluzione in determinate bande \n",
    "\n",
    "[CNN3D_LSTM_FC power Delta (δ)] class=0  band=Delta (δ)  neg=59  min=-7.707e-02  tol=-1.192e-07\n",
    "[CNN3D_LSTM_FC power Theta (Θ)] class=0  band=Theta (Θ)  neg=58  min=-5.573e-02  tol=-1.192e-07\n",
    "[CNN3D_LSTM_FC power Alpha (α)] class=0  band=Alpha (α)  neg=7  min=-1.780e-02  tol=-1.192e-07\n",
    "[CNN3D_LSTM_FC power Delta (δ)] class=1  band=Delta (δ)  neg=57  min=-1.032e-01  tol=-1.192e-07\n",
    "[CNN3D_LSTM_FC power Theta (Θ)] class=1  band=Theta (Θ)  neg=54  min=-8.738e-02  tol=-1.192e-07\n",
    "[CNN3D_LSTM_FC power Alpha (α)] class=1  band=Alpha (α)  neg=59  min=-1.171e-01  tol=-1.192e-07\n",
    "\n",
    "\n",
    "ora, che cosa si può fare per questi valori? nel senso, riesci a farmi vedere graficamente \n",
    "quanto sotto effettivamente questi valori sono sotto la soglia?\n",
    "\n",
    "perché se capisco bene, per ogni banda e classe, lui trova un set di valori sotto la soglia e \n",
    "mi trova il minimo all'interno di questo pool di valori sotto toglia e la tolleranza accettata (che dovrebbe esser sempre la stessa, se capiscono bene).. giusto?\n",
    "\n",
    "\n",
    "\n",
    "1  | Che cos’è eps (machine‑epsilon)\n",
    "\n",
    "Il granello più piccolo che un certo tipo floating‑point riesce a distinguere da 1 · 0.\n",
    "\n",
    "\n",
    "| tipo      | `np.finfo(dtype).eps` | scala min di variazione | note rapide                 |\n",
    "| --------- | --------------------: | ----------------------- | --------------------------- |\n",
    "| `float32` |        `1.192 × 10⁻⁷` | \\~7 decimal digits      | usato di default da PyTorch |\n",
    "| `float64` |       `2.220 × 10⁻¹⁶` | \\~16 decimal digits     | doppia precisione           |\n",
    "\n",
    "\n",
    "\n",
    "Quando moltiplichi eps per un valore‐riferimento (es. il massimo assoluto della mappa) ottieni \n",
    "la precisione relativa che ti puoi aspettare in quel range.\n",
    "Un residuo “negativo numerico” è tipicamente nell’ordine di −eps*|valore|.\n",
    "\n",
    "\n",
    "\n",
    "2  | Perché uso max(arr.max(), 1.0) nella soglia dinamica\n",
    "\n",
    "dynamic_tol = -eps32 * max(arr.max(), 1.0)\n",
    "\n",
    "\n",
    "Se la tua mappa ha picchi molto piccoli (p.es. 10⁻⁵), la soglia diventerebbe −1.2 × 10⁻¹²: \n",
    "praticamente tutte le fluttuazioni di rumore sembrerebbero “significative”.\n",
    "\n",
    "Con il max(…, 1.0) mi assicuro che la tolleranza non scenda mai sotto −1.2 × 10⁻⁷ (una unità di eps32 pura),\n",
    "così intercetto solo gli errori di segno veri e propri – non il semplice rumore.\n",
    "\n",
    "Se invece lavori sempre con potenze dello stesso ordine di grandezza (10⁻² – 10¹) la versione corta che usavi (-eps32*arr.max()) va benissimo.\n",
    "\n",
    "\n",
    "3  | Grafico: “quante volte sotto la soglia?”\n",
    "Nell’area qui sotto vedi un esempio (con dati finti) di ciò che potresti produrre: sull’asse x c’è\n",
    "|residuo| / |dynamic_tol| → “quante unità di eps sotto la soglia va ciascun punto”.\n",
    "\n",
    "\n",
    "\n",
    "grafico : vedi la distribuzione campionaria dei residui negativi in unità di eps – quelli che stanno appena a 1× tol sono rumore puro, \n",
    "quelli che cadono a 4–10× sono un po’ più anomali, ma di solito restano comunque trascurabili rispetto alla dinamica reale.\n",
    "\n",
    "Per farlo con i tuoi veri dati devi semplicemente:\n",
    "\n",
    "\n",
    "# dopo aver avuto mean_raw_power_per_band_xx\n",
    "neg_values = []\n",
    "for cls in (0,1):\n",
    "    for b in range(5):\n",
    "        arr = mean_raw_power_per_band[cls][b]\n",
    "        tol = -eps32 * max(arr.max(), 1.0)\n",
    "        neg_values.extend( (-arr[arr < tol] / tol) )   # valori in unità di eps\n",
    "\n",
    "plt.hist(neg_values, bins=30)\n",
    "plt.xlabel(\"|residuo| / |tol|  (unità di eps)\")\n",
    "...\n",
    "\n",
    "(Se vuoi vederli separati per classe/banda puoi fare un subplot 2 × 5 con lo stesso identico codice, filtrando per cls e b.)\n",
    "\n",
    "\n",
    "4  | Che cosa fare con i residui\n",
    "\n",
    "\n",
    "Dopo che li hai “misurati” puoi:\n",
    "\n",
    "Clippare: arr = np.clip(arr, 0.0, None) – sicuro, semplice, nessun impatto sull’analisi.\n",
    "\n",
    "Alzare la precisione: .astype(np.float64). Utile soprattutto prima di sommare o suddividere mappe molte volte.\n",
    "\n",
    "Ignorarli se restano < 0.1 % dell’escursione reale: nei plot non li vedrai più una volta applicato vmin=0.\n",
    "\n",
    "\n",
    "\n",
    "TL;DR\n",
    "I residui negativi che vedi derivano dall’errore di arrotondamento di float32.\n",
    "\n",
    "Usare eps ti dà una soglia “giusta” per capire se sono solo rumore.\n",
    "\n",
    "Con l’istogramma in unità di eps puoi verificarlo visivamente: la stragrande maggioranza cadrà attorno a 1–3 × eps.\n",
    "\n",
    "Clip a 0 oppure ricalcola le mappe in float64 se, per la tua applicazione, anche ‑1 × 10⁻² è considerato “pericoloso”.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "IO:\n",
    "\n",
    "Ancora non ho capito bene:\n",
    "\n",
    "1) eps (machine‑epsilon) è il valore più piccolo per discriminare un valore da un altro (in questo caso, rispetto all'1 se capisco bene), se adotto un floating-point con un certo livello di risoluzione numerica per approssimare il valore dei miei dati (?) \n",
    " \n",
    "2) Qualunque numero con modulo minore‑uguale a eps è così piccolo che può CAMBIARE SEGNO o AZZERARSI per effetto degli arrotondamenti.\n",
    "\n",
    "Per questo lo usiamo come unità di misura del “rumore” numerico.\n",
    "\n",
    "Di fatto eps è la “granularità” con cui il tipo float32 può rappresentare i numeri vicino a 1.\n",
    "\n",
    "Qualsiasi valore con modulo ≲ 1.19 · 10⁻⁷ rischia di essere PERSO o CAMBIATO DI SEGNO durante operazioni aritmetiche.\n",
    "\n",
    "Ecco perché lo usiamo come SOGLIA per distinguere:\n",
    "\n",
    "a) Residui di arrotondamento – ampiezza ≪ eps → li possiamo ignorare o forzare a zero.\n",
    "b) Valori fisicamente significativi – ampiezza ≫ eps → vanno tenuti o sistemati\n",
    "\n",
    "Di conseguenza, questo eps se lo moltiplichiamo per un valore di riferimento (es. il massimo assoluto dei tuoi dati, quindi quella sopra viene definita 'ampiezza'?) possiamo definire la precisione relativa per quel range di dati che gli fornisco (che nel mio caso è lo stesso o dipende in questo caso dal range dei valori di potenza della banda di frequenza specifica allora?)\n",
    "\n",
    "ora, quindi, con il metodo che abbiamo implementato \n",
    "\n",
    "dynamic_tol = -eps32 * max(arr.max(), 1.0)\n",
    "\n",
    "\"imponiamo\" tra virgolette in un certo senso che la \"soglia di tolleranza\" per definire quel valore come un residuo “negativo numerico” è proprio data da eps stesso, ossia la differenza minima assoluta affinché un valore sia distinguibile da 1.\n",
    "\n",
    "Se quindi un valore si trova al di sotto di questa soglia, allora viene considerato sicuramente come residuo 'negativo numerico'?\n",
    "\n",
    "ora, se ho capito correttamente, allora, dovrei capire delle altre cose:\n",
    "\n",
    "1) il numero di volte che viene trovato un numero come residuo 'negativo numerico' è pari al numero di trial rispetto a quella classe e banda?\n",
    "\n",
    "2) potrebbe aver senso aggiungere alla funzione 'check_negative_residuals'\n",
    "\n",
    "\n",
    "def check_negative_residuals(band_names, tensor_dict, tag):\n",
    "    \"\"\"\n",
    "    tensor_dict  :  dict  {cls: [np.ndarray(H,W), … 5 bande]}\n",
    "    tag          :  string visualizzato nel log\n",
    "    \"\"\"\n",
    "    \n",
    "    #https://numpy.org/doc/2.1/reference/generated/numpy.finfo.html\n",
    "    eps32 = np.finfo(np.float32).eps        # 1.19e‑7\n",
    "    for cls in [0, 1]:\n",
    "        for b, b_name in enumerate(band_names):\n",
    "            arr   = tensor_dict[cls][b]\n",
    "            \n",
    "            # Soglia dinamica = −eps * valore_massimo_della_mappa\n",
    "            \n",
    "            #dynamic_tol = -eps32 * arr.max()      # tolleranza dinamica\n",
    "            \n",
    "            dynamic_tol = -eps32 * max(arr.max(), 1.0)   # evita max==0\n",
    "            \n",
    "            neg_mask  = arr < dynamic_tol # “negativi significativi”\n",
    "            \n",
    "            print(f\"Valori sotto la soglia per classe e banda:\\n\")\n",
    "            if np.any(neg_mask):\n",
    "           \n",
    "                \n",
    "                n_neg   = np.count_nonzero(neg_mask)\n",
    "                \n",
    "                min_val = arr.min()\n",
    "                \n",
    "                print(f\"[{tag} {b_name}] class={cls}  band={b_name:<6}  \"\n",
    "                      f\"neg={n_neg}  min={min_val:.3e}  tol={dynamic_tol:.3e}\")\n",
    "            print()\n",
    "\n",
    "come suggerivi tu, di creare una figura con un subplot 2 × 5 filtrando per cls e b, per vedere la distribuzione campionaria dei residui negativi in unità di eps per \n",
    "\n",
    "ogni condizione sperimentale (quindi classe) e banda ?\n",
    "\n",
    "3) se 1) è veramente così, dovrei capire sostanzialmente che cosa farci.\n",
    "\n",
    "tu suggerivi di \n",
    "\n",
    "\"\n",
    "Dopo che li hai “misurati” puoi:\n",
    "\n",
    "Clippare: arr = np.clip(arr, 0.0, None) – sicuro, semplice, nessun impatto sull’analisi.\n",
    "\n",
    "Alzare la precisione: .astype(np.float64). Utile soprattutto prima di sommare o suddividere mappe molte volte.\n",
    "\n",
    "Ignorarli se restano < 0.1 % dell’escursione reale: nei plot non li vedrai più una volta applicato vmin=0.\n",
    "\"\n",
    "\n",
    "tra queste soluzioni propenderei per clipparli (o insomma imporre il loro valore a 0), ma prima vedendo in base a, rispetto a quella condizione sperimentale (ossia classe) e banda di frequenza, corrispondano ad una porzione statisticamente significativa dei dati. \n",
    "\n",
    "ossia, ho il timore che se 1) è vero, allora vuol dire che son tanti dati (trials) che per alcune condizioni e bande, c'è questo problema.\n",
    "\n",
    "per cui, prima di far qualsiasi cosa, vorrei capire bene rispetto alla distribuzione campionaria considerata, a quanti dati effettivamente corrispondano...\n",
    "\n",
    "ossia, ho il sospetto che, togliendo questi valori, cambiano completamente poi le mappe mostrate...\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "CHATGPT\n",
    "\n",
    "\n",
    "Di seguito rispondo punto‑per‑punto ai tuoi dubbi e ti propongo un mini‑workflow per ispezionare e, se serve, correggere quei residui negativi.\n",
    "\n",
    "\n",
    "\n",
    "0  | Ricordiamo in due righe cos’è eps\n",
    "eps = np.finfo(dtype).eps è l’errore relativo massimo che quel tipo può commettere quando rappresenta 1.0.\n",
    "* float32 → ≈ 1.19 · 10⁻⁷ (7 cifre decimali “sicure”)\n",
    "* float64 → ≈ 2.22 · 10⁻¹⁶ (16 cifre decimali)\n",
    "\n",
    "Un valore di modulo ≲ eps · |riferimento| è così piccolo che può cambiare segno o “sparire” nei calcoli successivi.\n",
    "\n",
    "1  | Il senso di dynamic_tol = -eps32 * max(arr.max(), 1.0)\n",
    "arr.max() porta la soglia alla scala reale dei tuoi dati (se i picchi sono grandi, la tolleranza cresce; se sono piccolissimi, non scende sotto un eps “puro”).\n",
    "\n",
    "Il max(…, 1.0) evita casi estremi (array quasi nulli → soglia ridicola).\n",
    "\n",
    "Qual è il criterio? ‑ Un punto è considerato “residuo negativo numerico” se\n",
    "arr < dynamic_tol, cioè se il suo modulo è almeno un’unità di eps sotto zero.\n",
    "\n",
    "\n",
    "\n",
    "2  | Domande rapide\n",
    "\n",
    "\n",
    "|   #   | tua domanda                                         | risposta                                                                                                                                                                                                    |\n",
    "| :---: | --------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
    "| **1** | *“n\\_neg è il numero di trial?”*                    | No. <br>Stai lavorando su **mappe medie** (H × W): `n_neg` è il numero di celle (‐ pixel) di quella mappa che risultano sotto la soglia, **non** il n° di trial.                                            |\n",
    "| **2** | *Ha senso aggiungere un print che mostri i valori?* | Sì, ma evita `print()` dentro ogni iterazione se poi vuoi plottare: raccogli prima i dati in liste e stampa/plotta una volta sola.                                                                          |\n",
    "| **3** | *Che fare con tanti residui?*                       | a) Se il rapporto `n_neg / arr.size` è piccolo (< 0.1 %) → `np.clip`. <br>b) Se è grande, rifai il **computo in `float64`** prima della media: `arr64 = np.stack(lista, axis=0).astype(np.float64).mean(0)` |\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "IO:\n",
    "\n",
    "\n",
    "quindi \n",
    "\n",
    "1) eps dovrebbe allora essere l'errore massimo di arrotondamento RELATIVO ai float32, che si commette in questo TIPO di rappresentazione dei valori numerici dei dati per discriminare la distanza tra il valore 1 ed il suo valore immediatamente adiacente?\n",
    "\n",
    "2) questa distanza verrebbe usata come coefficiente (in un certo senso un peso) per capire se, nel mio set di dati, io abbia dei valori numerici che, nella loro approssimazione, son stati rappresentati almeno un certo numero di unità inferiori pari all' eps stesso.\n",
    "\n",
    "per stabilire propriamente questo, si usa questa formula       \n",
    "\n",
    "\"dynamic_tol = -eps32 * max(arr.max(), 1.0)\"\n",
    "\n",
    "per imporre che la soglia corrisponda proprio ad eps (?)\n",
    "\n",
    " \n",
    "\n",
    "3) se dici che \n",
    "\n",
    "\"n_neg è il numero di celle (‐ pixel) di quella mappa che risultano sotto la soglia, non il n° di trial\" \n",
    "\n",
    "allora se inferisco correttamente, vuol dire che ci sono diversi pixel della mia mappa media, per ogji classe e banda, che son \"mal rappresentati\" nelle mie mappe medie della potenza spettrale per la relativa banda e condizione sperimentale?\n",
    "\n",
    "perché vengono rappresenti molto sotto rispetto alla loro reale rappresentazione nella distribuzione campionaria di quei valori, che dovrebbe imporre quegli stessi valori al minimo ammissibile per quella distribuzione dei miei dati (che, rappresentando le potenze medie per banda di frequenza, non possono che esser positive e quindi per forza maggior od uguali a 0...?)\n",
    "\n",
    "rispondi anche esattamente alla mie domande per favore \n",
    "\n",
    "\n",
    "\n",
    "CHAT:\n",
    "\n",
    "\n",
    "\n",
    "1  | Che cos’è, in concreto, eps\n",
    "Per il tipo float32\n",
    "\n",
    "\n",
    "np.finfo(np.float32).eps   # 1.1920929e‑07\n",
    "è l’errore di arrotondamento relativo intorno a 1.0:\n",
    "\n",
    "in base 2 vale 2⁻²³ (23 bit di mantissa);\n",
    "\n",
    "tradotto in decimale ≈ 1.19 · 10⁻⁷.\n",
    "\n",
    "Vuol dire che tra 1.0 e il successivo numero rappresentabile c’è uno “scalino” di circa 1.19e‑07.\n",
    "Se sommassi 1 + (eps / 2) il risultato sarebbe ancora 1, perché non c’è abbastanza “spazio” per distinguere i due valori.\n",
    "\n",
    "2  | Perché moltiplichiamo eps per max(arr.max(), 1.0)\n",
    "eps vale per i numeri vicini a 1.0.\n",
    "\n",
    "Se i tuoi dati hanno ampiezza 0.001 o 100, la “granulosità” sale o scende in proporzione.\n",
    "\n",
    "La soglia\n",
    "\n",
    "\n",
    "dynamic_tol = -eps32 * max(arr.max(), 1.0)\n",
    "fa due cose:\n",
    "\n",
    "Scala eps con la massima ampiezza reale della mappa (arr.max()); così la tolleranza è “x unità di eps” rispetto alla scala dei dati.\n",
    "\n",
    "Usa max(…, 1.0) per evitare che arr.max() sia 0 o troppo piccolo (altrimenti la soglia collasserebbe a 0).\n",
    "\n",
    "Quindi dynamic_tol non è uguale a eps, è eps × scala_dati (con scala≥1).\n",
    "\n",
    "3  | Interpretare n_neg\n",
    "Sulla mappa media (dimensioni H×W) ogni cella è la media delle potenze in quella posizione, su tutti i trial.\n",
    "\n",
    "n_neg conta quante di quelle celle risultano < dynamic_tol (cioè “negativi significativi”).\n",
    "\n",
    "Non dice quanti trial: una singola cella vale 1 anche se deriva da 100 trial.\n",
    "\n",
    "Se la fisica ti impone che la potenza ≥ 0, ogni cella negativa indica soltanto rumore di arrotondamento; non un errore di stima della potenza, ma della sua rappresentazione binaria dopo tante somme/divisioni in float32.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Cosa fare all’atto pratico\n",
    "\n",
    "| Caso                                                                         | Indicatore                            | Azione consigliata                                                     |\n",
    "| ---------------------------------------------------------------------------- | ------------------------------------- | ---------------------------------------------------------------------- |\n",
    "| Pochi residui < 0.1 % delle celle <br>e ampiezza ≲ 1–2 × `eps·scala`         | `< 0.1 %` di `arr.size`               | `arr = np.clip(arr, 0.0, None)` — basta.                               |\n",
    "| \\~Qualche % di celle <br>o residui più profondi (10–100 × eps·scala)         | monitor `n_neg/arr.size` e istogramma | Rifai la **media in `float64`** prima di clippare.                     |\n",
    "| Residui tanti e grandi<br>(segno “sbagliato” comparso già nei singoli trial) | succede raramente                     | Re‑calcola le mappe origine in `float64` o controlla il preprocessing. |\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Riassunto espresso in 3 righe\n",
    "\n",
    "eps è la dimensione del più piccolo “scalino” che float32 distingue vicino a 1.\n",
    "\n",
    "Moltiplichiamo eps per l’ampiezza reale dei dati → soglia relativa (dynamic_tol).\n",
    "\n",
    "Le celle < dynamic_tol sono residui numerici: si possono ignorare, clippare a 0 o, se molti, ricalcolare in float64.\n",
    "\n",
    "Così eviti che quei falsi negativi distorcano i tuoi plot o le statistiche successive.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "^^^^^^^ ^^^^^^^ ^^^^^^^ ^^^^^^^ ^^^^^^^ ^^^^^^^ ^^^^^^^ ^^^^^^^ ^^^^^^^ ^^^^^^^ ^^^^^^^ ^^^^^^^ ^^^^^^^ ^^^^^^^ ^^^^^^^ ^^^^^^^ ^^^^^^^ ^^^^^^^\n",
    "\n",
    "\n",
    "RIPETO LE STESSE DOMANDE MA CHIEDO A CHAT DI RISPONDERE\n",
    "\n",
    "\n",
    "ok MA rispondi esattamente alle mie domande\n",
    "\n",
    "1) eps dovrebbe allora essere l'errore massimo di arrotondamento RELATIVO ai float32, che si commette in questo TIPO di rappresentazione dei valori numerici dei dati per discriminare la distanza tra il valore 1 ed il suo valore immediatamente adiacente?\n",
    "\n",
    "2) questa distanza verrebbe usata come coefficiente (in un certo senso un peso) per capire se, nel mio set di dati, io abbia dei valori numerici che, nella loro approssimazione, son stati rappresentati almeno un certo numero di unità inferiori pari all' eps stesso.\n",
    "\n",
    "per stabilire propriamente questo, si usa questa formula       \n",
    "\n",
    "\"dynamic_tol = -eps32 * max(arr.max(), 1.0)\"\n",
    "\n",
    "per imporre che la soglia corrisponda proprio ad eps (?)\n",
    "\n",
    " \n",
    "\n",
    "3) se dici che \n",
    "\n",
    "\"n_neg è il numero di celle (‐ pixel) di quella mappa che risultano sotto la soglia, non il n° di trial\" \n",
    "\n",
    "allora se inferisco correttamente, vuol dire che ci sono diversi pixel della mia mappa media, per ogji classe e banda, che son \"mal rappresentati\" nelle mie mappe medie della potenza spettrale per la relativa banda e condizione sperimentale?\n",
    "\n",
    "perché vengono rappresenti molto sotto rispetto alla loro reale rappresentazione nella distribuzione campionaria di quei valori, che dovrebbe imporre quegli stessi valori al minimo ammissibile per quella distribuzione dei miei dati (che, rappresentando le potenze medie per banda di frequenza, non possono che esser positive e quindi per forza maggior od uguali a 0...?)\n",
    "\n",
    "rispondi anche esattamente alla mie domande per favore \n",
    "\n",
    "^^^^^^^ ^^^^^^^ ^^^^^^^ ^^^^^^^ ^^^^^^^ ^^^^^^^ ^^^^^^^ ^^^^^^^ ^^^^^^^ ^^^^^^^ ^^^^^^^ ^^^^^^^ ^^^^^^^ ^^^^^^^ ^^^^^^^ ^^^^^^^ ^^^^^^^ ^^^^^^^\n",
    "\n",
    "\n",
    "CHAT:\n",
    "\n",
    "\n",
    "1) Che cos’è eps per float32?\n",
    "Sì.\n",
    "np.finfo(np.float32).eps è l’errore di arrotondamento relativo massimo vicino a 1 per il formato float32.\n",
    "Indica di quanto deve cambiare 1.0 perché il numero rappresentabile successivo sia diverso da 1.0.\n",
    "Per float32 vale 2⁻²³ ≈ 1.19 · 10⁻⁷.\n",
    "\n",
    "\n",
    "2) Perché la soglia è\n",
    "dynamic_tol = -eps32 * max(arr.max(), 1.0) e non semplicemente -eps32?\n",
    " \n",
    " \n",
    "eps32 vale solo per numeri intorno a 1.\n",
    "\n",
    "Se la tua mappa ha valori più grandi (o molto più piccoli) la “granulosità” effettiva scala con l’ampiezza dei dati.\n",
    "\n",
    "\n",
    "Perciò:\n",
    "\n",
    "\n",
    "|tolleranza| = eps32 × scala_massima_dati\n",
    "\n",
    "\n",
    "\n",
    "dove scala_massima_dati = max(arr.max(), 1.0) (≥ 1 per evitare 0).\n",
    "\n",
    "Quindi la soglia non “corrisponde” a eps, è eps moltiplicato per la scala dei tuoi valori; in pratica:\n",
    "\n",
    "«Tutto ciò che è più negativo di “una unità di eps relativa al massimo valore presente” lo considero residuo numerico».\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "3) Interpretazione di n_neg\n",
    "La tua mappa media (H×W) contiene la media sui trial in ogni cella.\n",
    "\n",
    "n_neg conta quante di quelle celle (pixel) risultano < dynamic_tol.\n",
    "Non c’entra il numero di trial.\n",
    "\n",
    "Se alcune celle sono negative:\n",
    "\n",
    "Non significa che la potenza dei trial fosse negativa.\n",
    "Significa che, dopo tante somme/divisioni in float32, l’errore di arrotondamento ha fatto “sforare” di qualche × eps sotto lo zero.\n",
    "\n",
    "Sono valori fisicamente validi ma numericamente imprecisi.\n",
    "In un contesto dove la potenza deve essere ≥ 0 li tratti come residui di calcolo e, di norma, li clip a zero oppure rifai la media in float64 se sono molti.\n",
    "\n",
    "In breve\n",
    "\n",
    "a) eps32 = scalino minimo distinguibile vicino a 1 con float32.\n",
    "\n",
    "b) Moltiplichiamo eps32 per l’ampiezza dei dati per ottenere una soglia relativa adatta alla tua mappa.\n",
    "\n",
    "c) n_neg è il conteggio dei pixel sotto quella soglia; non dei trial. Se il fenomeno è raro si clippa a 0 senza influire sull’analisi fisica.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "IO\n",
    "\n",
    "\n",
    "\n",
    "quindi \n",
    "\n",
    "\n",
    "1) per ogni valore massimo della scala dei miei dati,  in termini di classe e valore di potenza alla relativa banda, impongo un valore di tollerenza diversa...?\n",
    "\n",
    "2) \"n_neg è il numero di celle (‐ pixel) di quella mappa che risultano sotto la soglia, non il n° di trial\" \n",
    "\n",
    "allora se inferisco correttamente, vuol dire che ci sono diversi pixel della mia mappa media, per ogji classe e banda, che son \"mal rappresentati\" nelle mie mappe medie della potenza spettrale per la relativa banda e condizione sperimentale?\n",
    "\n",
    "perché vengono rappresenti molto sotto rispetto alla loro reale rappresentazione nella distribuzione campionaria di quei valori di QUELLA MAPPA, che dovrebbe imporre quegli stessi valori al minimo ammissibile per quella distribuzione dei miei dati (che, rappresentando le potenze medie per banda di frequenza, non possono che esser positive e quindi per forza maggior od uguali a 0...?)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "CHAT\n",
    "\n",
    "\n",
    "\n",
    "1) La soglia dynamic_tol cambia davvero da mappa a mappa?\n",
    "Sì. dynamic_tol = ‑eps32 × max(arr.max(), 1.0) viene ricalcolata per ogni mappa media (classe × banda):\n",
    "\n",
    "\n",
    "classe 0, banda Delta  →  arr.max() = 2.4  →  tol = −2.4·eps32 ≈ −2.9e‑7\n",
    "classe 1, banda Gamma  →  arr.max() = 0.15 →  tol = −1.0·eps32 ≈ −1.2e‑7\n",
    "\n",
    "Se la banda ha valori più grandi, la soglia è un po’ più ampia; se sono più piccoli rimane comunque ≥ −eps32.\n",
    "In questo modo la soglia è proporzionata all’escursione reale della mappa e non segna come “errore” un numero che, \n",
    "in quel contesto, è realisticamente troppo piccolo per essere rilevante.\n",
    "\n",
    "\n",
    "2) Cosa significa che quei pixel sono “mal rappresentati”?\n",
    "\n",
    "n_neg conteggia i pixel della mappa media la cui intensità cade sotto dynamic_tol.\n",
    "\n",
    "Non misura quanti trial originali fossero affetti, ma quante celle del risultato medio escono leggermente sotto 0.\n",
    "\n",
    "Perché succede?\n",
    "\n",
    "Durante la media di molti trial in float32 si sommano errori di arrotondamento di segno opposto.\n",
    "\n",
    "Se il valore vero della cella è molto vicino a 0, basta un errore cumulato di poche × eps32 perché diventi −10⁻⁷ o −10⁻⁴.\n",
    "\n",
    "Il “difetto” non indica che la potenza reale fosse negativa: è soltanto rumore numerico.\n",
    "\n",
    "Quanto sono “fuori scala”?\n",
    "\n",
    "Confrontali con la potenza massima della stessa mappa. Se il massimo vale 0.08 e il minimo spurio è −0.001, l’errore è ~1 % del range: visivamente irrilevante ma fastidioso perché imshow forza il vmin.\n",
    "\n",
    "Come gestirli?\n",
    "\n",
    "Clip: arr = np.clip(arr, 0.0, None). Semplice e sicuro: le mappe restano correct‑by‑definition (potenza ≥ 0).\n",
    "\n",
    "Ricalcola in float64 (solo le medie finali) se vuoi eliminarli alla radice; costa più memoria ma riduce n_neg quasi a 0.\n",
    "\n",
    "Tieni così se n_neg / (H·W) ≪ 1 %: con la scala a colori (vmin = 0) quei residui non influenzano il plot.\n",
    "\n",
    "\n",
    "In pratica:\n",
    "\n",
    "\n",
    "if n_neg > 0:\n",
    "    print(f\"{n_neg} pixel sotto soglia; errore massimo {abs(min_val):.2e}\")\n",
    "    # correzione rapida\n",
    "    arr[arr < 0] = 0.0\n",
    "Dopo il clip le tue heat‑map mostreranno la distribuzione fisica della potenza senza interferenze visuali, e l’informazione statistica rimane intatta.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "IO\n",
    "\n",
    "\n",
    "ok rispondi a questa domanda per favore:\n",
    "\n",
    "\"n_neg è il numero di celle (‐ pixel) di quella mappa che risultano sotto la soglia\" \n",
    "\n",
    "allora se inferisco correttamente, vuol dire che ci sono diversi pixel della mia mappa media, \n",
    "per ogni classe e banda, che son \"mal rappresentati\" nelle mie mappe medie della potenza spettrale per la relativa banda e condizione sperimentale?\n",
    "\n",
    "perché vengono rappresenti molto sotto rispetto alla loro reale rappresentazione nella distribuzione campionaria di quei valori di QUELLA MAPPA,\n",
    "che dovrebbe imporre che invece quegli stessi valori che vado come sotto 0 'negativi' dovrebbero essere considerati \n",
    "come pari al minimo ammissibile per quella distribuzione dei miei dati (che, rappresentando le potenze medie per banda di frequenza,\n",
    "non possono che esser positive e quindi per forza maggior od uguali a 0...?)\n",
    "\n",
    "\n",
    "CHAT\n",
    "\n",
    "\n",
    "Sì, il tuo ragionamento è sostanzialmente corretto, ma con due precisazioni importanti.\n",
    "\n",
    "\n",
    "### Cosa indica davvero n_neg\n",
    "\n",
    "n_neg conta i pixel della mappa media (una 9 × 9) che risultano inferiori alla soglia dynamic_tol.\n",
    "\n",
    "Quei pixel sono “negativi” solo per effetto del rumore numerico accumulato durante la media in float32; il valore fisico reale è ≈ 0, non sotto zero.\n",
    "\n",
    "In altre parole sono mal rappresentati, non mis‑misurati.\n",
    "\n",
    "\n",
    "\n",
    "### Perché succede\n",
    "\n",
    "Ogni trial ha potenze ≥ 0.\n",
    "\n",
    "Sommi centinaia di trial in float32 → arrotondamenti ± ε.\n",
    "\n",
    "Se il valore vero, dopo la media, è ad es. +3·10⁻⁵, basta un errore di −4 · 10⁻⁵ (quattro machine‑epsilon relative alla scala) per farlo diventare leggermente negativo.\n",
    "\n",
    "Quindi il segno «‑» non riflette la distribuzione campionaria ma solamente l’accumulo di errori di rounding.\n",
    "\n",
    "\n",
    "\n",
    "### Cosa fare\n",
    "\n",
    "Clippare quei valori a 0 è la scelta più semplice e corretta:\n",
    "\n",
    "\n",
    "arr[arr < 0] = 0.0\n",
    "\n",
    "\n",
    "\n",
    "Non altera la statistica di potenza (parliamo di differenze nell’ordine di 10⁻⁴ ÷ 10⁻⁶ rispetto a un range che vale 10⁻² ÷ 10⁻¹).\n",
    "\n",
    "Elimina artefatti visivi nei colori di imshow().\n",
    "\n",
    "Se preferisci una soluzione più “pulita” puoi calcolare la media in float64, ma raramente fa differenza significativa per queste mappe.\n",
    "\n",
    "\n",
    "\n",
    "### Riassunto operativo\n",
    "\n",
    "\n",
    "| cosa vedi                                                | cosa significa                                                                      | cosa fare                              |\n",
    "| -------------------------------------------------------- | ----------------------------------------------------------------------------------- | -------------------------------------- |\n",
    "| `n_neg = 0`                                              | nessun residuo                                                                      | nessuna azione                         |\n",
    "| qualche decina di pixel, `min ≳ -1e‑3`                   | rumore di rounding                                                                  | `clip a 0` (o lasci così con `vmin=0`) |\n",
    "| centinaia di pixel con valori comparabili al range utile | *non* dovrebbe capitare: sarebbe un errore a monte nei dati o nella normalizzazione | ricontrollare pipeline                 |\n",
    "\n",
    "\n",
    "\n",
    "Finché i valori sotto soglia restano molto più piccoli dell’escursione reale della mappa, puoi considerarli “sporcizia numerica” e trattarli \n",
    "come zero fisico.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f74ff8-0a2e-43a3-b84c-dc6800d3de68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''                                              *************** CON NUOVE MODIFICHE DEL PAPER ***************\n",
    "                                                                    \n",
    "                                                                    NEW VERSION CON\n",
    "                                                            \n",
    "                                                                   load_best_run_results\n",
    "\n",
    "\n",
    "Cosa cambia rispetto a prima\n",
    "\n",
    "1) load_config_if_available:\n",
    "\n",
    "    estrae la config (batch_size, lr, β₁, β₂, ε, ecc.)\n",
    "    carica i best_weights salvati in .pkl da W&B\n",
    "\n",
    "2) processed_datasets / processed_models\n",
    "\n",
    "    evitano duplicate runs\n",
    "\n",
    "3) Optimizer & Scheduler & EarlyStopping\n",
    "\n",
    "    sono configurati con i valori estratti da config\n",
    "    scheduler con patience=4 (dimezza lr dopo 4 epoche senza miglioramento di val_loss)\n",
    "    early‐stopping con patience=12 sul val_loss\n",
    "\n",
    "4) Training/testing\n",
    "\n",
    "    la tua funzione training(...) dovrebbe accettare ora anche scheduler e early_stopping\n",
    "\n",
    "5) GradCAM\n",
    "\n",
    "    calcolato e salvato solo per il tuo CNN2D+LSTM\n",
    "\n",
    "Con queste modifiche, il tuo loop:\n",
    "\n",
    "    rispetta fedelmente il setup del paper\n",
    "    mantiene la pipeline di W&B per la logica di sweep e salvataggio dei migliori modelli\n",
    "    aggiunge minimi cambiamenti, lasciando intatte le tue funzioni training(), testing() e save_performance_results()\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "# Imposta il seme per la riproducibilità\n",
    "\n",
    "#Imposta il seme per i generatori casuali di PyTorch (per operazioni sui tensori e inizializzazione dei pesi dei modelli).\n",
    "#Importante se vuoi garantire che l'addestramento del modello produca gli stessi risultati in diverse esecuzioni.\n",
    "torch.manual_seed(32)\n",
    "\n",
    "#Imposta il seme per NumPy, utile se NumPy viene usato per operazioni casuali (ad es. shuffling dei dati, inizializzazione di matrici, ecc.).\n",
    "#Importante se usi NumPy per il preprocessing dei dati e vuoi riproducibilità.\n",
    "\n",
    "np.random.seed(32)\n",
    "\n",
    "#mposta il seme per il modulo random di Python (utile se si usano funzioni di randomizzazione di Python puro).\n",
    "#Importante solo se usi random per operazioni come mescolamento di liste.\n",
    "random.seed(32)\n",
    "\n",
    "#Imposta il seme per i generatori casuali su GPU, se disponibile.\n",
    "#Utile se stai eseguendo il codice su una GPU per garantire riproducibilità anche in quel contesto.\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(32)\n",
    "\n",
    "       \n",
    "'''\n",
    "\n",
    "In questo caso, \n",
    "\n",
    "il set processed_datasets traccia i dataset già elaborati, \n",
    "e il set processed_models tiene traccia delle combinazioni già effettuate (modello + dataset). \n",
    "\n",
    "In questo modo, puoi escludere un dataset dal training se è già stato utilizzato in precedenza, \n",
    "anche se usato con un modello differente.\n",
    "'''\n",
    "\n",
    "# Dizionario per tracciare la standardizzazione usata per ogni combinazione d\n",
    "# Dizionario per salvare informazioni sul modello (es. se i dati sono standardizzati)\n",
    "models_info = {}\n",
    "\n",
    "\n",
    "# Set per tenere traccia dei dataset già elaborati\n",
    "processed_datasets = set()\n",
    "\n",
    "# Set per tenere traccia delle combinazioni già elaborate\n",
    "processed_models = set()\n",
    "\n",
    "\n",
    "# Path delle performance dei modelli ottimizzati con weight and biases\n",
    "# Path per trovare le best performances di ogni modello per ogni combinazione dei dati\n",
    "base_folder = \"/home/stefano/Interrogait/WB_spectrograms_best_results_channels_frequencies_params_motor_task_1_new_3d_grid_multiband\"\n",
    "                                        #WB_spectrograms_best_results_motor_task_1\n",
    "\n",
    "# Path di salvataggio delle performance dei modelli dopo estrazione best models da base_folder\n",
    "#save_path_folder = \"/home/stefano/Interrogait/spectrograms_best_models_post_WB\"\n",
    "\n",
    "\n",
    "save_path_folder = \"/home/stefano/Interrogait/spectrograms_best_models_channels_frequencies_params_post_WB_GradCAM_Checks_motor_task_1_new_3d_grid_multiband\"\n",
    "                    \n",
    "                                              #spectrograms_best_models_post_WB_GradCAM_Checks_motor_task_1_new\n",
    "                                    #spectrograms_best_models_channels_frequencies_params_post_WB_GradCAM_Checks_motor_task_1_new\n",
    "\n",
    "\n",
    "# --- LOOP PRINCIPALE (con minime modifiche) ---\n",
    "for key, (X_data, y_data) in data_dict.items():\n",
    "    \n",
    "    print(f\"\\n\\nEstrazione Dati per il dataset: \\033[1m{key}\\033[0m, \\tShape X: \\033[1m{X_data.shape}\\033[0m, Shape y: \\033[1m{y_data.shape}\\033[0m\")\n",
    "    \n",
    "    if key in processed_datasets:\n",
    "        print(f\"ATTENZIONE: Il dataset {key} è già stato elaborato! Salto iterazione...\")\n",
    "        continue\n",
    "        \n",
    "    processed_datasets.add(key)\n",
    "    \n",
    "    X_train, X_val, X_test, y_train, y_val, y_test = split_data(X_data, y_data)\n",
    "    print(f\"Dataset Splitting: Train: \\033[1m{X_train.shape}\\033[0m, Val: \\033[1m{X_val.shape}\\033[0m, Test: \\033[1m{X_test.shape}\\033[0m\")\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    CREO COPIA TEST_LOADER_RAW PER I PLOT DEL POWER RAW PER BANDA E CLASSE\n",
    "    '''\n",
    "    # 1) salva una copia RAW dei soli dati di test PRIMA di standardizzare\n",
    "    X_test_raw = X_test.copy()\n",
    "    y_test_raw = y_test.copy()\n",
    "    \n",
    "    # 2) tensori\n",
    "    X_raw_tensor = torch.tensor(X_test_raw, dtype=torch.float32)\n",
    "    y_raw_tensor = torch.tensor(y_test_raw, dtype=torch.long)\n",
    "    \n",
    "    \n",
    "    #for model_name in [\"CNN2D\", \"BiLSTM\", \"Transformer\"]:\n",
    "    \n",
    "    '''ATTENZIONE MODIFICA QUI'''\n",
    "    \n",
    "    #for model_name in [\"CNN2D_LSTM_TF\", \"BiLSTM\", \"Transformer\"]:\n",
    "    for model_name in [\"CNN3D_LSTM_FC\", \"SeparableCNN2D_LSTM_FC\"]:\n",
    "\n",
    "        model_key = f\"{model_name}_{key}\"\n",
    "        if model_key in processed_models:\n",
    "            print(f\"ATTENZIONE: Il modello {model_name} per il dataset {key} è già stato addestrato! Salto iterazione...\")\n",
    "            continue\n",
    "        processed_models.add(model_key)\n",
    "        \n",
    "        print(f\"\\nPreparazione dati per il dataset \\033[1m{key}\\033[0m e il modello \\033[1m{model_name}\\033[0m...\")\n",
    "        \n",
    "        # Prova a caricare la configurazione e i pesi ottimali dal file .pkl\n",
    "        \n",
    "        '''\n",
    "        load_config_if_available --> prende in input 'key' che è la chiave composita (i.e, th_resp_vs_pt_resp_1_20_familiar_th)\n",
    "        parse_combination_key --> prende in input 'key' che suddivide la chiave composita in stringhe separate\n",
    "        \n",
    "        exp_cond, data_type, category_subject che sfrutto per crearmi la directory path che mi servirà per caricarmi \n",
    "        pesi del modello e i suoi iper-parametri\n",
    "        \n",
    "        Diciamo che in questo caso, sfrutto 'parse_combination_key per qualcosa che serve a 'load_config_if_available' in modo IMPLICITO..\n",
    "        '''\n",
    "        \n",
    "        config, best_weights = load_config_if_available(key, model_name, base_folder)\n",
    "        \n",
    "        if config is None:\n",
    "            raise ValueError(f\"\\033[1mNessun file .pkl trovato per {model_name} su {key}\\033[0m. Non posso procedere senza la configurazione ottimale.\")\n",
    "        \n",
    "        '''\n",
    "        Successivamente, queste variabili vengono invece create in maniera ESPLICITA per fasi successive del loop\n",
    "        MA in questo caso, parsifica la chiave una VOLTA SOLA e memorizza i valori!\n",
    "        '''\n",
    "        \n",
    "        # Parsifica la chiave una volta sola e memorizza i valori\n",
    "        exp_cond, data_type, category_subject = parse_combination_key(key)\n",
    "        \n",
    "        '''\n",
    "        Dpodiché, \n",
    "        \n",
    "        1) si carica i vari valori degli iper-parametri,\n",
    "        2) si esegue la standardizzazione se servisse,\n",
    "        3) prepara il modello per la divisione in train_loader etc.,\n",
    "        4) si carica la configurazione dei pesi del modello, \n",
    "        5) assegna i vari valori degli iper-parametri del modello corrente per la combinazione di dati correntemente iterata \n",
    "        \n",
    "        6) esegue il training e il test e poi\n",
    "        \n",
    "        7) si salva il tutto nella path corrispondente...\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        '''\n",
    "        PER DARE UNIFORMITÀ AL CODICE, CAMBIO IL NOME DELLE VARIABILI, CHE CONTENGONO I VALORI OTTIMIZZATI \n",
    "        DA FORNIRE IN INPUT ALLE VARIE FUNZIONI CHE SONO RICHIAMATE NEL LOOP'''\n",
    "        \n",
    "        \n",
    "        #\"lr\": {\"values\": [1e-5, 5e-5, 1e-4, 5e-4, 1e-3, 5e-3, 1e-2]},\n",
    "        #\"weight_decay\": {\"values\": [0, 1e-4, 1e-3, 1e-2, 1e-1]},\n",
    "        #\"n_epochs\": {\"value\": 100},\n",
    "        #\"patience\": {\"value\": 12},\n",
    "        \n",
    "        #\"model_name\": {\"values\": [\"SeparableCNN2D_LSTM_FC\"]},\n",
    "        #\"batch_size\": {\"values\": [32, 48, 64, 96]},\n",
    "        #\"standardization\": {\"values\": [True, False]},\n",
    "        #\"beta1\": {\"values\": [0.9, 0.95]},\n",
    "        #\"beta2\": {\"values\": [0.99, 0.995]},\n",
    "        #\"eps\": {\"values\": [1e-8, 1e-7]},\n",
    "        \n",
    "        #\"use_lstm\": {\"values\": [True, False]},\n",
    "        #\"lstm_hidden\": {\"values\": [32]},\n",
    "        #\"dropout\": {\"values\": [0.5]},\n",
    "        \n",
    "        \n",
    "        model_lr = config[\"lr\"]\n",
    "        model_weight_decay = config[\"weight_decay\"]\n",
    "        model_n_epochs = config[\"n_epochs\"]\n",
    "        model_patience = config[\"patience\"]\n",
    "        \n",
    "        \n",
    "        model_batch_size = config[\"batch_size\"]\n",
    "        model_standardization = config[\"standardization\"]\n",
    "    \n",
    "        \n",
    "        '''NUOVE MODIFICHE'''\n",
    "        model_beta1 =  config[\"beta1\"]\n",
    "        model_beta2 =  config[\"beta2\"]\n",
    "        model_eps = config[\"eps\"]\n",
    "        \n",
    "\n",
    "        '''Per CNN3D_LSTM_FC e SeparableCNN2D_LSTM_FC'''\n",
    "        model_use_lstm      = config[\"use_lstm\"]\n",
    "        model_lstm_hidden   = config[\"lstm_hidden\"]\n",
    "        model_dropout       = config[\"dropout\"]\n",
    "    \n",
    "            \n",
    "        #print(f\"Parametri per \\033[1m{model_name}\\033[0m: batch_size= \\033[1m{model_batch_size}\\033[0m, n_epochs= \\033[1m{model_n_epochs}\\033[0m, patience= \\033[1m{model_patience}\\033[0m, lr= \\033[1m{model_lr}\\033[0m, weight_decay= \\033[1m{model_weight_decay}\\033[0m, standardization= \\033[1m{model_standardization}\\033[0m\")\n",
    "        print(f\"Parametri per \\033[1m{model_name}\\033[0m: batch_size= \\033[1m{model_batch_size}\\033[0m, n_epochs= \\033[1m{model_n_epochs}\\033[0m, patience= \\033[1m{model_patience}\\033[0m, lr= \\033[1m{model_lr}\\033[0m, model_beta1= \\033[1m{model_beta1}\\033[0m,  model_beta2= \\033[1m{model_beta2}\\033[0m,  model_eps= \\033[1m{model_eps}\\033[0m, standardization= \\033[1m{model_standardization}\\033[0m\")\n",
    "        \n",
    "        # Salva nel dizionario se per quella combinazione è stata applicata la standardizzazione ai dati\n",
    "        models_info[model_key] = {\"standardization\": model_standardization}\n",
    "        \n",
    "        \n",
    "        \n",
    "        # 3) dataset & loader per test set (per plots power raw) –‑  IMPORTANTISSIMO: shuffle=False\n",
    "        raw_dataset = TensorDataset(X_raw_tensor, y_raw_tensor)\n",
    "        test_loader_raw = DataLoader(raw_dataset,\n",
    "                             batch_size=model_batch_size,\n",
    "                             shuffle=False)\n",
    "        \n",
    "        '''PER MANTENERE LA STESSA LOGICA DEL CODICE (ANCHE SE POTREI INSERIRLA DENTRO PREPARE_DATA_FOR_MODEL MODIFICANDO LA FUNZIONE (SI VEDA IN CELLA SOPRA COME)\n",
    "        IMPONGONO LA STANDARDIZZAZIONE PRIMA DI QUESTA FUNZIONE\n",
    "        '''\n",
    "\n",
    "        if model_standardization:\n",
    "            X_train, X_val, X_test = standardize_data(X_train, X_val, X_test)\n",
    "            print(f\"\\033[1mSÌ Standardizzazione Dati!\\033[0m\")\n",
    "        else:\n",
    "            print(f\"\\033[1mNO Standardizzazione Dati!\\033[0m\")\n",
    "        \n",
    "        # Sposta il modello sulla GPU (se disponibile)\n",
    "        device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "        \n",
    "        # Preparazione dei dataloaders\n",
    "        train_loader, val_loader, test_loader, class_weights_tensor = prepare_data_for_model(\n",
    "            X_train, X_val, X_test, y_train, y_val, y_test, model_type = model_name, batch_size = model_batch_size)\n",
    "        \n",
    "\n",
    "        # Inizializzazione del modello\n",
    "        #if model_name == \"CNN2D\":\n",
    "        #    model = CNN2D(input_channels=64, num_classes=2)\n",
    "        \n",
    "        #if model_name == \"CNN2D_LSTM_FC\":\n",
    "            \n",
    "            #model = CNN2D_LSTM_FC(n_freq = 45, input_channels=64, num_classes=2, dropout = 0.2)\n",
    "            #model = CNN2D_LSTM_FC(input_channels = 5, num_classes=2, dropout=0.2)\n",
    "            \n",
    "        #elif model_name == \"BiLSTM\":\n",
    "        #    model = ReadMEndYou(input_size= 64 * 81, hidden_sizes=[24, 48, 62], output_size=2, bidirectional=True)\n",
    "        #elif model_name == \"Transformer\":\n",
    "        #    model = ReadMYMind(d_model=16, num_heads=4, num_layers=2, num_classes=2, channels=64, freqs=81)\n",
    "        \n",
    "        #elif model_name == \"TopomapNet\":\n",
    "            #model = TopomapNet(\n",
    "                #input_channels=5,\n",
    "                #num_classes=2,\n",
    "                #base_channels=model_base_channels,\n",
    "                #use_lstm=model_use_lstm,\n",
    "                #lstm_hidden=model_lstm_hidden,\n",
    "                #dropout=model_dropout\n",
    "            #)\n",
    "        \n",
    "        '''OCCHIO QUI CAMBIATO PER GRIGLIA 3D'''\n",
    "        if model_name == \"CNN3D_LSTM_FC\":\n",
    "            \n",
    "            sweep_config = sweep_config_cnn3d\n",
    "            \n",
    "            model = CNN3D_LSTM_FC(\n",
    "                num_classes=2,\n",
    "                dropout=model_dropout,\n",
    "                hidden_size=model_lstm_hidden,\n",
    "                use_lstm=model_use_lstm)\n",
    "\n",
    "            print(f\"\\nInizializzazione Modello \\033[1mCNN3D_LSTM_FC\\033[0m\")\n",
    "        \n",
    "        elif model_name == \"SeparableCNN2D_LSTM_FC\":\n",
    "            \n",
    "            sweep_config = sweep_config_cnn_sep\n",
    "            \n",
    "            model = SeparableCNN2D_LSTM_FC(\n",
    "                num_classes=2,\n",
    "                dropout=model_dropout,\n",
    "                hidden_size=model_lstm_hidden,\n",
    "                use_lstm=model_use_lstm\n",
    "            )\n",
    "            print(f\"\\nInizializzazione Modello \\033[1mSeparableCNN2D_LSTM_FC\\033[0m\")\n",
    "            \n",
    "        else:\n",
    "            raise ValueError(f\"Modello {model_name} non riconosciuto.\")\n",
    "        \n",
    "        \n",
    "        # Se abbiamo caricato i pesi ottimali, li carichiamo nel modello\n",
    "        if best_weights is not None:\n",
    "            try:\n",
    "                model.load_state_dict(best_weights)\n",
    "                print(f\"📊 Modello \\033[1m{model_name}\\033[0m inizializzato con \\033[01i pesi ottimizzati\\033[0m tramite hyper-parameter tuning su \\033[1mWeight & Biases\\033[0m\")\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️Errore nel caricamento dei pesi per {model_name} su {key}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        '''OLD VERSION'''\n",
    "        # Definizione del criterio di perdita\n",
    "        #criterion = nn.CrossEntropyLoss(weight = class_weights_tensor)\n",
    "        \n",
    "        '''NUOVE MODIFICHE'''\n",
    "        criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
    "        \n",
    "        '''OLD VERSION'''\n",
    "        # Definizione dell'ottimizzatore con i parametri aggiornati\n",
    "        #optimizer = torch.optim.Adam(model.parameters(), lr = model_lr, weight_decay = model_weight_decay)\n",
    "        \n",
    "        '''NUOVE MODIFICHE'''\n",
    "        \n",
    "         # 10) ottimizzatore + scheduler + early stopping\n",
    "        optimizer = torch.optim.Adam(\n",
    "            model.parameters(),\n",
    "            lr    = model_lr,\n",
    "            betas = (model_beta1, model_beta2),\n",
    "            eps   = model_eps, \n",
    "            weight_decay = model_weight_decay\n",
    "        )\n",
    "            \n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer,\n",
    "            mode     = \"min\",   # monitoriamo val_loss\n",
    "            factor   = 0.1,\n",
    "            patience = 8,\n",
    "            verbose  = True\n",
    "        )\n",
    "        \n",
    "        \n",
    "        #early_stopping = EarlyStopping(patience=model_patience, mode=\"min\")\n",
    "        \n",
    "        '''OLD VERSION'''\n",
    "        #print(f\"🏋️‍♂️Avvio del training per \\033[1m{model_name}\\033[0m sul dataset \\033[1m{key}\\033[0m...\")\n",
    "        #my_train_results = training(model, train_loader, val_loader, optimizer, criterion, n_epochs = model_n_epochs, patience = model_patience)\n",
    "        \n",
    "        '''NEW VERSION'''\n",
    "        # --- dopo model.load_state_dict(best_weights) e criterion = nn.CrossEntropyLoss() ---\n",
    "\n",
    "        # 1) prepara i data_loaders per train/val\n",
    "        data_loaders = {\n",
    "            \"train\": train_loader,\n",
    "            \"val\":   val_loader\n",
    "        }\n",
    "        \n",
    "        print(f\"🏋️‍♂️Salvo le metriche del training per \\033[1m{model_name}\\033[0m sul dataset \\033[1m{key}\\033[0m a seguito della ottimizzazione su W&B ...\")\n",
    "        # 2) richiama la funzione che pesca da W&B la best‐run e corregge la train AUC\n",
    "        \n",
    "        #ATTENZIONE al potenziale problema di stringa, non di API: \n",
    "\n",
    "        #i due esempi che hai postato in realtà usano diversi caratteri “‑” (uno è il classico ASCII U+002D, l’altro è un non‑breaking hyphen U+2011 o simili), quindi quando chiami\n",
    "        \n",
    "        #entity = \"stefano‑bargione‑universit‑di‑roma‑tor‑vergata\"\n",
    "        #stai passando un nome che W&B non riconosce (e quindi api.projects(entity=…) torna vuoto), mentre con\n",
    "\n",
    "        #entity = \"stefano-bargione-universit-di-roma-tor-vergata\"\n",
    "        #funziona perché lì usi i semplici - ASCII.\n",
    "\n",
    "        my_train_results = load_best_run_results(\n",
    "            key=key,\n",
    "            model = model,\n",
    "            sweep_config = sweep_config,\n",
    "            data_loaders = data_loaders,\n",
    "            entity = \"stefano-bargione-universit-di-roma-tor-vergata\"\n",
    "        )\n",
    "        \n",
    "        \n",
    "        \n",
    "        '''\n",
    "        L’entity che passi a Api().runs(f\"{entity}/{project}\") è semplicemente il tuo account (o l’organizzazione) su W&B,\n",
    "        cioè la parte che compare subito prima del nome del progetto nell’URL.\n",
    "\n",
    "        Per esempio, se quando apri il tuo progetto su W&B vedi un indirizzo del tipo\n",
    "        \n",
    "        -> https://wandb.ai/steclab/some_project_name, allora entity = \"steclab\".\n",
    "        \n",
    "        Se invece lavori sotto un’organizzazione \n",
    "        \n",
    "        -> “cool‑team”, e l’URL è https://wandb.ai/cool-team/some_project_name, allora userai entity = \"cool-team\".\n",
    "\n",
    "        Puoi verificarlo:\n",
    "\n",
    "        Accedi a wandb.ai e vai sul progetto.\n",
    "        Leggi la prima parte dell’URL (tra wandb.ai/ e il /project_name).\n",
    "        Copiala esattamente come stringa in entity.\n",
    "\n",
    "        Così il tuo Api().runs(f\"{entity}/{project}\") andrà a pescare proprio le run che hai lanciato tu.\n",
    "\n",
    "        my_train_results = load_best_run_results(\n",
    "            key= key,\n",
    "            model = model,\n",
    "            sweep_config = sweep_config,\n",
    "            data_loaders = data_loaders,\n",
    "            entity= \"mio-entity\"\n",
    "        )\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        print(f\"Avvio del testing per \\033[1m{model_name}\\033[0m sul dataset \\033[1m{key}\\033[0m...\")\n",
    "        # 3) usa il best_model caricato dentro `train_results` e chiama il testing\n",
    "        my_test_results = testing(my_train_results, test_loader, criterion)\n",
    "        \n",
    "        '''\n",
    "        GRADCAM COMPUTATION PER IL MODELLO CNN3D e ConvSep\n",
    "        \n",
    "        La funzione compute_gradcam_figure estrae i campioni (per ogni classe) e crea una figura con le due righe richieste.\n",
    "        \n",
    "        Il parametro gradcam_image (un buffer binario o un'immagine) viene passato alla funzione di salvataggio, \n",
    "        'save_performance_results', in modo da essere salvato nella path corretta. \n",
    "        \n",
    "        La funzione 'save_performance_results' è stata modificata \n",
    "        per gestire ANCHE questo nuovo input dell'immagine \n",
    "        \n",
    "        (ossia, per salvare il file con un nome che inizia con 'GradCAM_results_'\n",
    "        seguito da tutte le altre stringhe corrispondenti alla combinazione di fattori che costituiscono il dataset corrente:\n",
    "        \n",
    "        - coppia di condizioni sperimentali da cui provengono i dati (i.e., th_resp_vs_pt_resp )\n",
    "        - tipologia di dato EEG prelevato (i.e., spectrograms) \n",
    "        - provenienza del dato stesso (i.e., familiar_th)\n",
    "        )\n",
    "        \n",
    "        Spiegazione:\n",
    "        \n",
    "        La funzione compute_gradcam_figure eseguire il calcolo di GradCAM (vedi dettagli nella sua funzione)\n",
    "        e alla fine ritornerà in output una variabile \n",
    "        \n",
    "        'fig_image' che sarà poi assegnata alla variabile 'gradcam_image',\n",
    "        che è un oggetto buffer, che contiene i dati binari dell'immagine in formato PNG\n",
    "        (poiché abbiamo usato plt.savefig con format='png'). \n",
    "        \n",
    "        Quindi, quando passi gradcam_image (cioè fig_image) alla funzione 'save_performance_results',\n",
    "        viene scritto direttamente su disco come file PNG.\n",
    "        \n",
    "        Non c'è bisogno di ri-aprire o convertire ulteriormente, a meno che tu non voglia manipolare l'immagine in seguito.\n",
    "        Quindi, la soluzione è corretta così com'è:\n",
    "        il buffer viene salvato come file PNG nella directory specificata, \n",
    "        e successivamente potrai aprirlo con una libreria come cv2 o PIL se necessario.        \n",
    "        \n",
    "        Quindi, gradcam_image (i.e., fig_image) viene quindi passato correttamente dentro al loop di training e test, \n",
    "        tramite 'save_performance_results', come input, \n",
    "        che salverà quindi poi l'immagine nella path corrispondente \n",
    "\n",
    "        '''\n",
    "        \n",
    "        # Se il modello è CNN2D, calcola anche GradCAM per la visualizzazione\n",
    "        gradcam_image = None\n",
    "        \n",
    "        #if model_name == \"CNN2D\":\n",
    "        \n",
    "        '''ATTENZIONE MODIFICA QUI'''\n",
    "        \n",
    "        #if model_name == \"CNN2D_LSTM_FC\":\n",
    "        \n",
    "        if model_name in (\"CNN3D_LSTM_FC\", \"SeparableCNN2D_LSTM_FC\"):\n",
    "            \n",
    "            gradcam_image = compute_gradcam_figure(model, test_loader, test_loader_raw, exp_cond, data_type, category_subject, device, EEG_channels_names, debug = False)\n",
    "            if gradcam_image is not None:\n",
    "                print(f\"Creazione di \\033[1mGradCAM Image\\033[0m per il modello \\033[1m{model_name}\\033[0m.\")\n",
    "                \n",
    "        print(f\"Salvataggio dei risultati per \\033[1m{model_name}\\033[0m sul dataset \\033[1m{key}\\033[0m...\")\n",
    "        save_performance_results(model_name,\n",
    "                                 my_train_results,\n",
    "                                 my_test_results,\n",
    "                                 key,\n",
    "                                 exp_cond,\n",
    "                                 model_standardization,\n",
    "                                 base_folder = save_path_folder,\n",
    "                                 gradcam_image = gradcam_image)\n",
    "        \n",
    "        \n",
    "        '''\n",
    "        N.B\n",
    "        \n",
    "        gradcam_image = None avverrà solo all'inizio cioè per il primo modello, che verrà testato con una certa combinazione di dati.. \n",
    "        ma servirebbe tracciare in qualche modo \n",
    "\n",
    "        1) o che la gradcam_image di ogni combinazione venga ri-azzerata alla fine loop\n",
    "        2) o che venga monitorato che gradcam_image di una combinazione di dati già analizzata venga esclusa poi\n",
    "        (o messa in un set) in modo che rivenga per errore sovrascritta più volte.. \n",
    "        \n",
    "        Forse la strada più veloce potrebbe essere la soluzione 1)\n",
    "        \n",
    "        La soluzione più veloce e semplice è re-impostare la variabile gradcam_image a None alla fine dell'iterazione per ogni combinazione di dati\n",
    "        (cioè, all'interno del ciclo esterno che itera su key). \n",
    "         \n",
    "        In questo modo, per ogni nuovo dataset la variabile viene \"azzera\" e viene calcolata l'immagine GradCAM solo per quella combinazione, \n",
    "        evitando di sovrascrivere accidentalmente i risultati già calcolati per combinazioni precedenti.\n",
    "         \n",
    "        Un'altra possibilità sarebbe tenere traccia delle chiavi (o combinazioni) per cui hai già calcolato la GradCAM,\n",
    "        ad esempio usando un set, e saltare il calcolo se la combinazione è già presente. \n",
    "        \n",
    "        Tuttavia, se ogni combinazione deve avere la sua immagine, \n",
    "        la soluzione più semplice è quella di reimpostare gradcam_image = None alla fine dell'iterazione.\n",
    "        \n",
    "        Quindi, per esempio, alla fine del ciclo per ogni dataset (key) potresti fare:\n",
    "        (VEDI SOTTO)\n",
    "        \n",
    "        In questo modo, ti assicuri che per ogni nuova combinazione la variabile sia pulita e pronta per essere ricalcolata, \n",
    "        senza rischio di sovrascrivere o confondere i risultati\n",
    "        '''\n",
    "        \n",
    "        # Reimposta gradcam_image a None per la prossima combinazione di dati\n",
    "        gradcam_image = None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f618c99-6faa-42c9-bad4-1d7ed1ba2051",
   "metadata": {},
   "outputs": [],
   "source": [
    "#axs[0, j].hist(mean_cams_per_band[cls][b].flatten(), bins='auto', color='blue', edgecolor='black')\n",
    "            #axs[0, j].set_title(f\"\\nClass {condition_names[cls]} - Band {b_name}\", fontsize=9)\n",
    "            #axs[0, j].set_xlabel(\"Grad-CAM value\")\n",
    "            #axs[0, j].set_ylabel(\"Count\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353f06a5-bc89-4a86-935c-94d72d331ce5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"finito\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64152395-630f-4f2b-b3d2-aa444371158f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(models_info.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2059098f-40a9-42a9-a9e8-472e60fdc356",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/stefano/Interrogait/spectrograms_best_models_channels_freqs_params_post_WB_GradCAM_Checks_motor_task_1_new_3d_grid_multiband.pkl', 'wb') as f:\n",
    "    pickle.dump(models_info, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed09c211-f059-4af5-87bd-a32b33672adf",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### **CREAZIONE DELLE TABLES CON INTEGRAZIONE DELLE PERFORMANCE TRAINING & TEST DEI MODELLI DENTRO DATAFRAME**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7b6b93-ea69-4aca-872b-86175d5a4fd6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### **Integrazioni in Tabella delle Performance Training e Test del Modello dentro DataFrame - NEW APPROACH**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f1788e-cae8-4ad6-b505-35c4fd35d2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "path = '/home/stefano/Interrogait/'\n",
    "\n",
    "#with open(f\"{path}spectrograms_best_models_post_WB_GradCAM_Checks_motor_task_1_new.pkl\", \"rb\") as f: \n",
    "with open(f\"{path}spectrograms_best_models_channels_freqs_params_post_WB_GradCAM_Checks_motor_task_1_new_3d_grid_multiband.pkl\", \"rb\") as f:\n",
    "    models_info = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab79d68b-dc7f-4936-9bf1-8561f8e62242",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "In questo codice:\n",
    "\n",
    "model_info.get('standardization', False) cerca la chiave 'standardization' all'interno di ogni sottodizionario. \n",
    "Se non esiste, restituirà False come valore di default.\n",
    "Se standardization è True, stampa la chiave associata.\n",
    "'''\n",
    "\n",
    "# Ciclo attraverso le chiavi di 'models_info'\n",
    "for key, model_info in models_info.items():\n",
    "    # Controllo se 'standardization' è True\n",
    "    if model_info.get('standardization', False):  # Default a False nel caso in cui non esista la chiave\n",
    "        print(key)  # Stampa la chiave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ea62b9-ccdc-4712-8268-6c2a849565bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68786331-e52f-4258-8dff-1801ffc6c221",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for key, model_info in all_models.items():\n",
    "#    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc09642b-db72-4a27-860a-4f58ad65b3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Siccome la stringa associata alla category subject è diversa tra i due.. \n",
    "\n",
    "familiar_th  familiar_pt unfamiliar_pt unfamiliar_pt  da un lato (models_info)\n",
    "th_fam, pt_fam, th_unfam, pt_unfam  dall'altro (all_models)\n",
    "\n",
    "la corrispondenza non avverrà mai... per cui, si deve fare il mapping corrispondente tra \n",
    "le stringhe di uno e dell'altro, in modo che models_info cambi come parte della stringa della sua chiave da queste \n",
    "\n",
    "familiar_th  familiar_pt unfamiliar_pt unfamiliar_pt\n",
    "a queste\n",
    "th_fam, pt_fam, th_unfam, pt_unfam \n",
    "\n",
    "'''\n",
    "\n",
    "mapping_subject = {\n",
    "    \"familiar_th\": \"th_fam\",\n",
    "    \"familiar_pt\": \"pt_fam\",\n",
    "    \"unfamiliar_th\": \"th_unfam\",\n",
    "    \"unfamiliar_pt\": \"pt_unfam\"\n",
    "}\n",
    "\n",
    "# Creiamo un nuovo dizionario con le chiavi corrette\n",
    "updated_models_info = {}\n",
    "\n",
    "for key, value in models_info.items():\n",
    "    for old_suffix, new_suffix in mapping_subject.items():\n",
    "        if key.endswith(old_suffix):\n",
    "            new_key = key.replace(old_suffix, new_suffix)\n",
    "            updated_models_info[new_key] = value\n",
    "            break  # Evita sostituzioni multiple se una è già stata fatta\n",
    "    else:\n",
    "        # Se nessuna sostituzione è stata fatta, mantieni la chiave originale\n",
    "        updated_models_info[key] = value\n",
    "\n",
    "# Sostituisci il vecchio dizionario con quello aggiornato\n",
    "models_info = updated_models_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ec502d-f533-4a3f-a077-0a7a33107f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_info.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddf5bc3-b497-4361-b0d8-4a224002d66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Ciclo attraverso le chiavi di 'models_info' AGGIORNATO!'''\n",
    "\n",
    "for key, model_info in models_info.items():\n",
    "    # Controllo se 'standardization' è True\n",
    "    if model_info.get('standardization', False):  # Default a False nel caso in cui non esista la chiave\n",
    "        print(key)  # Stampa la chiavi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59ce997-6156-4508-ad91-095f85332fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Parsing della chiave e costruzione del path:\n",
    "Usando la funzione parse_combination_key si estraggono \n",
    "\n",
    "exp_cond, data_type e category_subject dalla chiave del dataset. \n",
    "\n",
    "Questi vengono usati per costruire il percorso in cui cercare i file .pkl.\n",
    "'''\n",
    "\n",
    "# Funzione per parsare la chiave\n",
    "def parse_combination_models_keys(combination_key):\n",
    "    \"\"\"\n",
    "    Estrae (exp_cond, data_type, category_subject) da combination_key.\n",
    "    \n",
    "    Il formato atteso PRIMA è:\n",
    "    \n",
    "    \"th_resp_vs_pt_resp|pt_resp_vs_shared_resp|th_resp_vs_shared_resp\" _ spectrograms\" _ \"familiar_th|familiar_pt|unfamiliar_th|unfamiliar_pt\"\n",
    "    \n",
    "    Il formato atteso ORA è:\n",
    "    \n",
    "     \"th_resp_vs_pt_resp|pt_resp_vs_shared_resp|th_resp_vs_shared_resp\" _ spectrograms\" _ \"th_fam|th_unfam|pt_fam|pt_unfam\"\n",
    "     \n",
    "    \"\"\"\n",
    "    #r\"^(th_resp_vs_pt_resp|pt_resp_vs_shared_resp|th_resp_vs_shared_resp)_(spectrograms)_(th_fam|th_unfam|pt_fam|pt_unfam)$\", \n",
    "    \n",
    "    match = re.match(\n",
    "        r\"^(rest_vs_left_fist|rest_vs_right_fist|left_fist_vs_right_fist)_(spectrograms)_(th_fam|th_unfam|pt_fam|pt_unfam)$\",\n",
    "        combination_key\n",
    "    )\n",
    "    if match:\n",
    "        return match.groups()  # (exp_cond, data_type, category_subject)\n",
    "    else:\n",
    "        raise ValueError(f\"Formato non valido: {combination_key}\")\n",
    "        \n",
    "    return exp_cond, data_type, category_subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba993e3-4f79-4b48-8ebc-ddcc5dc72060",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "NEW APPROACH \n",
    "\n",
    "Adesso replichiamo l'approccio usato prima, ma stavolta integrado tutte le combinazioni di dati. \n",
    "Andiamo a\n",
    "\n",
    "1) iterare sulla struttura delle directory a partire da base_folder, \n",
    "2) caricare i modelli .pkl per ogni combinazione di fattori che compongono i dati\n",
    "3) creare un DataFrame che raccolga le metriche di tutti i modelli relativi alla stessa combinazione di dati. \n",
    "\n",
    "Infine, salviamo questa tabella come immagine all'interno della cartella corrispondente\n",
    "'''\n",
    "\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import table\n",
    "\n",
    "\n",
    "\n",
    "# Base folder\n",
    "#base_folder = \"/home/stefano/Interrogait/spectrograms_best_models_post_WB\"\n",
    "\n",
    "base_folder = \"/home/stefano/Interrogait/spectrograms_best_models_channels_frequencies_params_post_WB_GradCAM_Checks_motor_task_1_new_3d_grid_multiband\"\n",
    "                                        #spectrograms_best_models_channels_frequencies_params_post_WB_GradCAM_Checks_motor_task_1_new\n",
    "                                            \n",
    "# Condizioni sperimentali\n",
    "#experimental_conditions = [\"th_resp_vs_pt_resp\", \"th_resp_vs_shared_resp\", \"pt_resp_vs_shared_resp\"]\n",
    "\n",
    "experimental_conditions = [\"rest_vs_left_fist\", \"rest_vs_right_fist\", \"left_fist_vs_right_fist\"]\n",
    "\n",
    "\n",
    "# Tipologie di dati\n",
    "data_types = [\"spectrograms\"]\n",
    "\n",
    "# Subfolders per tipologia di soggetto\n",
    "#subfolders = [\"th_fam\", \"th_unfam\", \"pt_fam\", \"pt_unfam\"]\n",
    "\n",
    "subfolders = [\"th_fam\"]\n",
    "\n",
    "# Dizionario per salvare tutti i modelli\n",
    "all_models = {}\n",
    "\n",
    "# Caricamento dei modelli\n",
    "for condition in experimental_conditions:\n",
    "    for data_type in data_types:\n",
    "        for subfolder in subfolders:\n",
    "            \n",
    "            path = os.path.join(base_folder, condition, data_type, subfolder)\n",
    "            \n",
    "            if not os.path.exists(path):\n",
    "                print(f\"Directory non trovata: {path}\")\n",
    "                continue\n",
    "            \n",
    "            # Creiamo la chiave per questa combinazione\n",
    "            key = f\"{condition}_{data_type}_{subfolder}\"\n",
    "            all_models[key] = {}\n",
    "\n",
    "            # Otteniamo la lista di file nella directory\n",
    "            files = os.listdir(path)\n",
    "            \n",
    "            # Filtriamo e carichiamo i file .pkl\n",
    "            for file in files:\n",
    "                if file.endswith(\".pkl\"):  # Controlliamo se è un file modello\n",
    "                    file_path = os.path.join(path, file)\n",
    "                    try:\n",
    "                        with open(file_path, \"rb\") as f:\n",
    "                            all_models[key][file] = pickle.load(f)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Errore nel caricamento di {file}: {e}\")\n",
    "\n",
    "# Creazione delle tabelle di performance\n",
    "for key, models_dict in all_models.items():\n",
    "    \n",
    "    # Otteniamo le informazioni dalla chiave\n",
    "    condition, data_type, subfolder = parse_combination_models_keys(key)\n",
    "    \n",
    "    print(f\"\\nProcessing: \\033[1m{condition}\\033[0m - \\033[1m{data_type}\\033[0m - \\033[1m{subfolder}\\033[0m\\n\")\n",
    "    \n",
    "    # Creazione della tabella\n",
    "    df_data = {\"Metriche\": [\"Accuracy\", \"Loss\", \"Precision\", \"Recall\", \"F1-Score\", \"AUC-ROC\"]}\n",
    "\n",
    "    # Iteriamo sui modelli caricati\n",
    "    for model_name, model_data in models_dict.items():\n",
    "        \n",
    "        # Estrai il nome del modello dal file (ad esempio, \"CNN1D\" da \"CNN1D_performances_...pkl\")\n",
    "        #name_model = model_name.split(\"_\")[0]\n",
    "        \n",
    "        # Estrai il nome del modello, gestendo il caso speciale di CNN2D_LSTM\n",
    "        #if model_name.startswith(\"CNN2D_LSTM\"):\n",
    "            #name_model = \"_\".join(model_name.split(\"_\")[:2])  # Prende CNN2D_LSTM\n",
    "            \n",
    "        # estraiamo sempre la porzione fino a “_LSTM\n",
    "        #if model_name.startswith((\"CNN2D_LSTM\", \"CNN3D_LSTM\", \"SeparableCNN2D_LSTM\")):\n",
    "        if model_name.startswith((\"CNN3D_LSTM\", \"SeparableCNN2D_LSTM\")):\n",
    "            \n",
    "            # es. “CNN3D_LSTM_FC”  →  split → [“CNN3D”, “LSTM”, “FC”] → prendi i primi 2 elementi\n",
    "            parts = model_name.split(\"_\")\n",
    "            name_model = \"_\".join(parts[:2])      # “CNN3D_LSTM” o “SeparableCNN2D_LSTM”\n",
    "        else:\n",
    "            name_model = model_name.split(\"_\")[0]  # Prende solo CNN1D, CNN2D\n",
    "        \n",
    "        print(f\"    Processing model: \\033[1m{name_model}\\033[0m\")\n",
    "        \n",
    "        # Costruisci la chiave utilizzata nel dizionario models_info\n",
    "        \n",
    "        '''\n",
    "        Nota: occorrerà che il formato della chiave sia consistente tra i due loop.\n",
    "        \n",
    "        Ad esempio, se nel primo loop era f\"{key}_{model_name}\", qui potresti dover fare:\n",
    "        model_key = f\"{key}_{name_model}\"\n",
    "        \n",
    "        Oppure, se nel primo loop era f\"{model_name}_{key}\", qui potresti dover fare:\n",
    "        model_key = f\"{name_model}_{key}\"\n",
    "        \n",
    "        '''\n",
    "        model_key = f\"{name_model}_{key}\"\n",
    "        \n",
    "        # Controlla se i dati sono stati standardizzati per questo modello\n",
    "        standardization_flag = models_info.get(model_key, {}).get(\"standardization\", False)\n",
    "        \n",
    "        if standardization_flag:\n",
    "            suffix = \"\" \n",
    "        else:\n",
    "            suffix = \"\" \n",
    "        \n",
    "        try:\n",
    "            # Recupera i risultati di training e testing\n",
    "            train_scores = model_data.get('my_train_results', {}).get('training_performances', {})\n",
    "            test_scores = model_data.get('my_test_results', {}).get('test_performances', {})\n",
    "            \n",
    "            # Converti i valori in float\n",
    "            train_scores = {key: float(value[0]) for key, value in train_scores.items()}\n",
    "            test_scores = {key: float(value[0]) for key, value in test_scores.items()}\n",
    "            \n",
    "            \n",
    "            # Aggiunge le metriche di training, modificando il nome della colonna se è vera la condizione\n",
    "            col_train = f\"{name_model} (Training){suffix}\"  # Usa suffix qui per il nome\n",
    "            \n",
    "            df_data[f\"{col_train}\"] = [\n",
    "                train_scores[\"train_accuracy\"],\n",
    "                train_scores[\"train_loss\"],\n",
    "                train_scores[\"train_precision\"],\n",
    "                train_scores[\"train_recall\"],\n",
    "                train_scores[\"train_f1_score\"],\n",
    "                train_scores[\"train_auc\"],\n",
    "            ]\n",
    "\n",
    "            # Aggiunge le metriche di training, modificando il nome della colonna se è vera la condizione\n",
    "            col_test = f\"{name_model} (Test){suffix}\"  # Usa suffix qui per il nome\n",
    "            \n",
    "            df_data[f\"{col_test}\"] = [\n",
    "                test_scores[\"test_accuracy\"],\n",
    "                test_scores[\"test_loss\"],\n",
    "                test_scores[\"test_precision\"],\n",
    "                test_scores[\"test_recall\"],\n",
    "                test_scores[\"test_f1_score\"],\n",
    "                test_scores[\"test_auc\"],\n",
    "            ]\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"    Errore nell'elaborazione di {model_name}: {e}\")\n",
    "\n",
    "    # Creazione del DataFrame\n",
    "    df_performances = pd.DataFrame(df_data)\n",
    "\n",
    "    # Crea un'immagine della tabella\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    ax.axis('off')\n",
    "    \n",
    "    # Aggiunta del titolo\n",
    "    #title = f\"DL Models performances for Exp Conditions: {condition}, EEG data: {data_type}, Subject: {subfolder}\"\n",
    "    title = f\"DL Models performances for Exp Conditions: {condition}, EEG data: {data_type}\"\n",
    "    ax.set_title(title, fontsize=12, fontweight=\"bold\", pad=20)\n",
    "\n",
    "    tabla = table(ax, df_performances, loc='center', colWidths=[0.2] * len(df_performances.columns))\n",
    "    tabla.auto_set_font_size(True)\n",
    "    tabla.set_fontsize(10)\n",
    "    tabla.scale(2, 2)\n",
    "\n",
    "    # Evidenzia i nomi delle colonne\n",
    "    for key, cell in tabla.get_celld().items():\n",
    "        if key[0] == 0:\n",
    "            cell.set_text_props(weight='bold')\n",
    "\n",
    "    # Salva l'immagine della tabella\n",
    "    path = os.path.join(base_folder, condition, data_type, subfolder)\n",
    "    file_name = f\"models_performances_{condition}_{data_type}_{subfolder}.png\"\n",
    "    img_file_path = os.path.join(path, file_name)\n",
    "    fig.savefig(img_file_path, bbox_inches='tight', dpi=300)\n",
    "    plt.close(fig)\n",
    "\n",
    "    print(f\"\\nTabella dei dati di \\033[1m{condition}_{data_type}_{subfolder}\\033[0m salvati in: \\n\\033[1m{img_file_path}\\033[0m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9678f8d-2ba9-40f9-bdc2-21befc1b98bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mne_env",
   "language": "python",
   "name": "mne_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  },
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
